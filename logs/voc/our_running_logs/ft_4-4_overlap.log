nohup: ignoring input
25
kvoc_4-4_FT On GPUs 0\Writing in results/seed_2023-ov/2023-03-07_voc_4-4_FT.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[6, 0, 7, 2]
Current Client Index:  6
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Current Client Index:  2
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[8, 5, 3, 7]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[5, 2, 0, 3]
Current Client Index:  5
Current Client Index:  2
Current Client Index:  0
Current Client Index:  3
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[3, 6, 1, 7]
Current Client Index:  3
Current Client Index:  6
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.09879439324140549, Reg Loss=0.0 (without scaling)

Total samples: 341.000000
Overall Acc: 0.957759
Mean Acc: 0.761733
FreqW Acc: 0.923270
Mean IoU: 0.703965
Class IoU:
	class 0: 0.9539515191877496
	class 1: 0.7615770129403676
	class 2: 0.2054173196242969
	class 3: 0.8920301311931925
	class 4: 0.7068509839220561
Class Acc:
	class 0: 0.9848764620456163
	class 1: 0.7738026584549321
	class 2: 0.27733822617675347
	class 3: 0.9519182023560161
	class 4: 0.8207287142557349

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[0, 12, 6, 10]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: None
Epoch 1, lr = 0.001000
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Epoch 1, Batch 10/52, Loss=1.3540820837020875
Loss made of: CE 1.3721317052841187, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.8822885870933532
Loss made of: CE 0.7267225980758667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.6490374743938446
Loss made of: CE 0.6042317152023315, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.44029379487037656
Loss made of: CE 0.3094981908798218, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.42056539058685305
Loss made of: CE 0.2735617756843567, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7329537868499756, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.7329537868499756, Class Loss=0.7329537868499756, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/52, Loss=0.3464257061481476
Loss made of: CE 0.3286474645137787, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.28303014785051345
Loss made of: CE 0.26128315925598145, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.30311905443668363
Loss made of: CE 0.35860681533813477, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.305172324180603
Loss made of: CE 0.3175269365310669, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.2692997843027115
Loss made of: CE 0.31832167506217957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.297012060880661, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.297012060880661, Class Loss=0.297012060880661, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/52, Loss=0.22197460234165192
Loss made of: CE 0.19477146863937378, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.263274559378624
Loss made of: CE 0.23158416152000427, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.23725322037935256
Loss made of: CE 0.3463805615901947, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.2583219915628433
Loss made of: CE 0.18997728824615479, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.23369917571544646
Loss made of: CE 0.16474692523479462, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2422102689743042, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.2422102689743042, Class Loss=0.2422102689743042, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/52, Loss=0.23032453656196594
Loss made of: CE 0.32587212324142456, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.20479706376791001
Loss made of: CE 0.1492307335138321, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.2360106885433197
Loss made of: CE 0.17297916114330292, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.19929055050015448
Loss made of: CE 0.12287139147520065, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.1805759683251381
Loss made of: CE 0.19533821940422058, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2095445990562439, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.2095445990562439, Class Loss=0.2095445990562439, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/52, Loss=0.19621302634477616
Loss made of: CE 0.2510520815849304, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.16771432906389236
Loss made of: CE 0.11635100841522217, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.1843160405755043
Loss made of: CE 0.1566351354122162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.16880745738744735
Loss made of: CE 0.18039724230766296, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.17693643122911454
Loss made of: CE 0.16112074255943298, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18212924897670746, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.18212924897670746, Class Loss=0.18212924897670746, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/52, Loss=0.15882133021950723
Loss made of: CE 0.1396695077419281, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.1738919734954834
Loss made of: CE 0.1618659347295761, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.21557846069335937
Loss made of: CE 0.22495803236961365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.1498115785419941
Loss made of: CE 0.15097375214099884, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.1806614652276039
Loss made of: CE 0.18603786826133728, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1748027503490448, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.1748027503490448, Class Loss=0.1748027503490448, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/40, Loss=1.1776183128356934
Loss made of: CE 1.0647609233856201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/40, Loss=0.8427342176437378
Loss made of: CE 0.5775872468948364, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/40, Loss=0.43774729669094087
Loss made of: CE 0.45430636405944824, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/40, Loss=0.4189172685146332
Loss made of: CE 0.3660336434841156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7192542552947998, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.7192542552947998, Class Loss=0.7192542552947998, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/40, Loss=0.30049304813146593
Loss made of: CE 0.1666230708360672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/40, Loss=0.2734623610973358
Loss made of: CE 0.23307737708091736, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/40, Loss=0.2829514592885971
Loss made of: CE 0.2776820659637451, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/40, Loss=0.2385263204574585
Loss made of: CE 0.26122158765792847, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27385830879211426, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.27385830879211426, Class Loss=0.27385830879211426, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/40, Loss=0.22222942113876343
Loss made of: CE 0.162998765707016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/40, Loss=0.2213399142026901
Loss made of: CE 0.2729592025279999, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/40, Loss=0.19943443238735198
Loss made of: CE 0.1757238358259201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/40, Loss=0.20763919055461882
Loss made of: CE 0.18359892070293427, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2126607447862625, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.2126607447862625, Class Loss=0.2126607447862625, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/40, Loss=0.20790325254201888
Loss made of: CE 0.24659663438796997, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/40, Loss=0.20689058303833008
Loss made of: CE 0.13570599257946014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/40, Loss=0.15666441917419432
Loss made of: CE 0.15380921959877014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/40, Loss=0.19231706708669663
Loss made of: CE 0.23773054778575897, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.19094382226467133, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.19094382226467133, Class Loss=0.19094382226467133, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/40, Loss=0.16788946390151976
Loss made of: CE 0.1483037769794464, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/40, Loss=0.1550538122653961
Loss made of: CE 0.2024325579404831, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/40, Loss=0.1555637985467911
Loss made of: CE 0.11640115827322006, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/40, Loss=0.162539567053318
Loss made of: CE 0.1280626654624939, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16026166081428528, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.16026166081428528, Class Loss=0.16026166081428528, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/40, Loss=0.15149647668004035
Loss made of: CE 0.1154601201415062, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/40, Loss=0.14048410654067994
Loss made of: CE 0.170604407787323, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/40, Loss=0.16247067898511885
Loss made of: CE 0.18900446593761444, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/40, Loss=0.14231802225112916
Loss made of: CE 0.10920092463493347, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14919231832027435, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.14919231832027435, Class Loss=0.14919231832027435, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/34, Loss=1.8042972564697266
Loss made of: CE 1.9773950576782227, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.9905225038528442
Loss made of: CE 0.5633154511451721, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.6126377075910568
Loss made of: CE 0.47111091017723083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.0454965829849243, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=1.0454965829849243, Class Loss=1.0454965829849243, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/34, Loss=0.3278408408164978
Loss made of: CE 0.2871571481227875, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.271999204158783
Loss made of: CE 0.32342880964279175, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.2575039863586426
Loss made of: CE 0.23343192040920258, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2792804539203644, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.2792804539203644, Class Loss=0.2792804539203644, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/34, Loss=0.2397301122546196
Loss made of: CE 0.2682323753833771, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.226326185464859
Loss made of: CE 0.21985022723674774, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.23058117628097535
Loss made of: CE 0.2314639538526535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22805076837539673, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.22805076837539673, Class Loss=0.22805076837539673, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/34, Loss=0.20176467001438142
Loss made of: CE 0.1575937271118164, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.2183617725968361
Loss made of: CE 0.19626852869987488, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.22910218834877014
Loss made of: CE 0.3680288791656494, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21089306473731995, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.21089306473731995, Class Loss=0.21089306473731995, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/34, Loss=0.19309583380818368
Loss made of: CE 0.11453189700841904, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.18740495666861534
Loss made of: CE 0.2113640308380127, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.17482561320066453
Loss made of: CE 0.15110258758068085, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18852666020393372, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.18852666020393372, Class Loss=0.18852666020393372, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/34, Loss=0.19439317435026168
Loss made of: CE 0.22608596086502075, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.1669948197901249
Loss made of: CE 0.23783761262893677, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.17784916162490844
Loss made of: CE 0.13699185848236084, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1809079349040985, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.1809079349040985, Class Loss=0.1809079349040985, Reg Loss=0.0
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=1.1263322591781617
Loss made of: CE 1.049452304840088, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=0.8720516562461853
Loss made of: CE 0.8002709746360779, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.5787966281175614
Loss made of: CE 0.46408507227897644, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8243829011917114, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.8243829011917114, Class Loss=0.8243829011917114, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/33, Loss=0.4627213358879089
Loss made of: CE 0.44087088108062744, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.4025730073451996
Loss made of: CE 0.6919463872909546, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.3218998610973358
Loss made of: CE 0.26407262682914734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.38797056674957275, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.38797056674957275, Class Loss=0.38797056674957275, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/33, Loss=0.2829925909638405
Loss made of: CE 0.28255996108055115, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.2638970732688904
Loss made of: CE 0.20679494738578796, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.2743967443704605
Loss made of: CE 0.19375281035900116, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27134910225868225, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.27134910225868225, Class Loss=0.27134910225868225, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/33, Loss=0.25093960464000703
Loss made of: CE 0.17845647037029266, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.19824316203594208
Loss made of: CE 0.18095481395721436, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.21539173573255538
Loss made of: CE 0.1697365641593933, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22175154089927673, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.22175154089927673, Class Loss=0.22175154089927673, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/33, Loss=0.21314284950494766
Loss made of: CE 0.32783931493759155, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.2073027566075325
Loss made of: CE 0.23641625046730042, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.20595595836639405
Loss made of: CE 0.20096707344055176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20622307062149048, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.20622307062149048, Class Loss=0.20622307062149048, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/33, Loss=0.21981033086776733
Loss made of: CE 0.3102641701698303, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.1719255767762661
Loss made of: CE 0.19193953275680542, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.17985993027687072
Loss made of: CE 0.15380915999412537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19170929491519928, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.19170929491519928, Class Loss=0.19170929491519928, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.41476818919181824, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.870435
Mean Acc: 0.347120
FreqW Acc: 0.763434
Mean IoU: 0.299520
Class IoU:
	class 0: 0.8800409
	class 1: 0.028906515
	class 2: 0.00028597334
	class 3: 0.0
	class 4: 0.17175628
	class 5: 0.0
	class 6: 0.62529206
	class 7: 0.36128813
	class 8: 0.628114
Class Acc:
	class 0: 0.99641174
	class 1: 0.028989384
	class 2: 0.00028597334
	class 3: 0.0
	class 4: 0.17213881
	class 5: 0.0
	class 6: 0.70735806
	class 7: 0.36888617
	class 8: 0.85000646

federated global round: 6, step: 1
select part of clients to conduct local training
[11, 5, 8, 12]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/43, Loss=0.5787117868661881
Loss made of: CE 0.3102475106716156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/43, Loss=0.4407335966825485
Loss made of: CE 0.450936883687973, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/43, Loss=0.3571259528398514
Loss made of: CE 0.2535754144191742, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/43, Loss=0.3048476308584213
Loss made of: CE 0.38385066390037537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4113248884677887, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.4113248884677887, Class Loss=0.4113248884677887, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/43, Loss=0.2659654259681702
Loss made of: CE 0.2172984927892685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/43, Loss=0.24351917654275895
Loss made of: CE 0.19798773527145386, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/43, Loss=0.24373492896556853
Loss made of: CE 0.2971106469631195, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/43, Loss=0.2586464092135429
Loss made of: CE 0.2073691338300705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2505705654621124, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.2505705654621124, Class Loss=0.2505705654621124, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/43, Loss=0.2118459016084671
Loss made of: CE 0.19725583493709564, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/43, Loss=0.200490365922451
Loss made of: CE 0.19003280997276306, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/43, Loss=0.19313285648822784
Loss made of: CE 0.19109758734703064, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/43, Loss=0.22717041075229644
Loss made of: CE 0.15189996361732483, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.20615483820438385, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.20615483820438385, Class Loss=0.20615483820438385, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/43, Loss=0.17757762968540192
Loss made of: CE 0.1979128122329712, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/43, Loss=0.19333782643079758
Loss made of: CE 0.22488538920879364, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/43, Loss=0.187186136841774
Loss made of: CE 0.2112794816493988, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/43, Loss=0.1959844008088112
Loss made of: CE 0.1357194185256958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1859477311372757, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.1859477311372757, Class Loss=0.1859477311372757, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/43, Loss=0.171478933095932
Loss made of: CE 0.12900710105895996, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/43, Loss=0.16602911651134492
Loss made of: CE 0.1929289549589157, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/43, Loss=0.1814970925450325
Loss made of: CE 0.13982349634170532, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/43, Loss=0.16235755532979965
Loss made of: CE 0.11932217329740524, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17247001826763153, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.17247001826763153, Class Loss=0.17247001826763153, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/43, Loss=0.1427866116166115
Loss made of: CE 0.13399207592010498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/43, Loss=0.1659359596669674
Loss made of: CE 0.18888549506664276, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/43, Loss=0.15237088203430177
Loss made of: CE 0.12414903938770294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/43, Loss=0.14439092501997947
Loss made of: CE 0.17430850863456726, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1518252044916153, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.1518252044916153, Class Loss=0.1518252044916153, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/34, Loss=0.3456552729010582
Loss made of: CE 0.3046557903289795, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.28300699293613435
Loss made of: CE 0.276336133480072, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.2384971410036087
Loss made of: CE 0.30146053433418274, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.284919410943985, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.284919410943985, Class Loss=0.284919410943985, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/34, Loss=0.22528256326913834
Loss made of: CE 0.1634516566991806, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.1889109045267105
Loss made of: CE 0.19278079271316528, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.19420466423034669
Loss made of: CE 0.2407921552658081, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.19869302213191986, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.19869302213191986, Class Loss=0.19869302213191986, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/34, Loss=0.16723050475120543
Loss made of: CE 0.22731351852416992, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.16056939959526062
Loss made of: CE 0.15852251648902893, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.1748884066939354
Loss made of: CE 0.2207120954990387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.167735293507576, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.167735293507576, Class Loss=0.167735293507576, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/34, Loss=0.16052489280700682
Loss made of: CE 0.14992085099220276, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.16254759281873704
Loss made of: CE 0.19781088829040527, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.16988651305437089
Loss made of: CE 0.16942737996578217, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1641148179769516, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.1641148179769516, Class Loss=0.1641148179769516, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/34, Loss=0.143867526948452
Loss made of: CE 0.15181736648082733, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.13986918702721596
Loss made of: CE 0.16080059111118317, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.16745375394821166
Loss made of: CE 0.20024394989013672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15384632349014282, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.15384632349014282, Class Loss=0.15384632349014282, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/34, Loss=0.15928568542003632
Loss made of: CE 0.18373267352581024, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.1521732583642006
Loss made of: CE 0.11195018887519836, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.17008434981107712
Loss made of: CE 0.2895849049091339, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1609129160642624, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.1609129160642624, Class Loss=0.1609129160642624, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/40, Loss=0.347312918305397
Loss made of: CE 0.37103185057640076, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/40, Loss=0.28235561549663546
Loss made of: CE 0.20938466489315033, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/40, Loss=0.28734731376171113
Loss made of: CE 0.2673221528530121, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/40, Loss=0.2571620598435402
Loss made of: CE 0.2641962766647339, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2935445010662079, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.2935445010662079, Class Loss=0.2935445010662079, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/40, Loss=0.233942212164402
Loss made of: CE 0.19067077338695526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/40, Loss=0.17780674546957015
Loss made of: CE 0.1478918492794037, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/40, Loss=0.20451368838548661
Loss made of: CE 0.21421346068382263, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/40, Loss=0.2087627023458481
Loss made of: CE 0.13161972165107727, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20625634491443634, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.20625634491443634, Class Loss=0.20625634491443634, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/40, Loss=0.159993989020586
Loss made of: CE 0.0995742529630661, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/40, Loss=0.14661063700914384
Loss made of: CE 0.128770112991333, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/40, Loss=0.1783993735909462
Loss made of: CE 0.1731952428817749, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/40, Loss=0.15473810136318206
Loss made of: CE 0.134025439620018, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15993551909923553, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.15993551909923553, Class Loss=0.15993551909923553, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/40, Loss=0.14491874873638153
Loss made of: CE 0.1657867580652237, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/40, Loss=0.16158634424209595
Loss made of: CE 0.15881025791168213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/40, Loss=0.15400373935699463
Loss made of: CE 0.14799675345420837, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/40, Loss=0.15895005986094474
Loss made of: CE 0.13108333945274353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15486472845077515, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.15486472845077515, Class Loss=0.15486472845077515, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/40, Loss=0.15826412960886954
Loss made of: CE 0.10342979431152344, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/40, Loss=0.15139711052179336
Loss made of: CE 0.2148725986480713, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/40, Loss=0.12374076768755912
Loss made of: CE 0.15216881036758423, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/40, Loss=0.12472868263721466
Loss made of: CE 0.13379859924316406, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.139532670378685, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.139532670378685, Class Loss=0.139532670378685, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/40, Loss=0.13422956094145774
Loss made of: CE 0.12591038644313812, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/40, Loss=0.13049884662032127
Loss made of: CE 0.1297195851802826, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/40, Loss=0.16090348958969117
Loss made of: CE 0.1531762331724167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/40, Loss=0.12565719336271286
Loss made of: CE 0.13453850150108337, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13782227039337158, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.13782227039337158, Class Loss=0.13782227039337158, Reg Loss=0.0
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/40, Loss=0.2905805468559265
Loss made of: CE 0.2640913128852844, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/40, Loss=0.3421921759843826
Loss made of: CE 0.2734517455101013, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/40, Loss=0.26297593414783477
Loss made of: CE 0.3484034538269043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/40, Loss=0.2994743466377258
Loss made of: CE 0.2733135223388672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.29880577325820923, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.29880577325820923, Class Loss=0.29880577325820923, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/40, Loss=0.23122406303882598
Loss made of: CE 0.13546958565711975, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/40, Loss=0.19929570108652114
Loss made of: CE 0.1455267369747162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/40, Loss=0.2214315041899681
Loss made of: CE 0.2316618412733078, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/40, Loss=0.18977832347154616
Loss made of: CE 0.24080543220043182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21043239533901215, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.21043239533901215, Class Loss=0.21043239533901215, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/40, Loss=0.1823046997189522
Loss made of: CE 0.13040831685066223, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/40, Loss=0.18094287365674971
Loss made of: CE 0.2172452211380005, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/40, Loss=0.16790317222476006
Loss made of: CE 0.15380921959877014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/40, Loss=0.19520000815391542
Loss made of: CE 0.14908674359321594, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18158768117427826, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.18158768117427826, Class Loss=0.18158768117427826, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/40, Loss=0.16524669528007507
Loss made of: CE 0.16288483142852783, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/40, Loss=0.16886478140950203
Loss made of: CE 0.10191001743078232, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/40, Loss=0.14060670956969262
Loss made of: CE 0.13992154598236084, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/40, Loss=0.16136811301112175
Loss made of: CE 0.20875859260559082, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15902158617973328, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.15902158617973328, Class Loss=0.15902158617973328, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/40, Loss=0.14038148000836373
Loss made of: CE 0.14031562209129333, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/40, Loss=0.1442842073738575
Loss made of: CE 0.16018438339233398, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/40, Loss=0.12955078408122062
Loss made of: CE 0.10548435151576996, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/40, Loss=0.1425569921731949
Loss made of: CE 0.12134164571762085, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1391933709383011, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.1391933709383011, Class Loss=0.1391933709383011, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/40, Loss=0.1433866761624813
Loss made of: CE 0.10148906707763672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/40, Loss=0.12621970400214194
Loss made of: CE 0.14231416583061218, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/40, Loss=0.15359196290373803
Loss made of: CE 0.14490348100662231, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/40, Loss=0.1366387389600277
Loss made of: CE 0.110064297914505, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13995927572250366, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.13995927572250366, Class Loss=0.13995927572250366, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4020560085773468, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.886891
Mean Acc: 0.411306
FreqW Acc: 0.791156
Mean IoU: 0.366291
Class IoU:
	class 0: 0.8924472
	class 1: 0.005327892
	class 2: 0.0
	class 3: 0.0
	class 4: 0.05937885
	class 5: 0.47419736
	class 6: 0.70306224
	class 7: 0.47948667
	class 8: 0.682719
Class Acc:
	class 0: 0.9954173
	class 1: 0.005327892
	class 2: 0.0
	class 3: 0.0
	class 4: 0.059383593
	class 5: 0.49687824
	class 6: 0.7405536
	class 7: 0.4888556
	class 8: 0.9153418

federated global round: 7, step: 1
select part of clients to conduct local training
[0, 6, 13, 5]
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/52, Loss=0.3421340137720108
Loss made of: CE 0.5069433450698853, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.2690828055143356
Loss made of: CE 0.20012310147285461, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.21401488035917282
Loss made of: CE 0.19767406582832336, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.20888205617666245
Loss made of: CE 0.24943330883979797, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.20489244014024735
Loss made of: CE 0.14367938041687012, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.24387769401073456, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.24387769401073456, Class Loss=0.24387769401073456, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/52, Loss=0.1878887116909027
Loss made of: CE 0.16622568666934967, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.17852608114480972
Loss made of: CE 0.1778654158115387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.17532268017530442
Loss made of: CE 0.21195833384990692, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.1935303181409836
Loss made of: CE 0.21272176504135132, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.17337851375341415
Loss made of: CE 0.1690715253353119, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1793140470981598, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.1793140470981598, Class Loss=0.1793140470981598, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/52, Loss=0.15196208879351616
Loss made of: CE 0.12416081875562668, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.18398880511522292
Loss made of: CE 0.18702976405620575, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.17187003344297408
Loss made of: CE 0.23094570636749268, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.18744732141494752
Loss made of: CE 0.16466139256954193, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.16941213384270667
Loss made of: CE 0.13411442935466766, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1720913201570511, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.1720913201570511, Class Loss=0.1720913201570511, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/52, Loss=0.15925830230116844
Loss made of: CE 0.2485823929309845, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.1521979197859764
Loss made of: CE 0.09965556114912033, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.15634141564369203
Loss made of: CE 0.14278310537338257, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.14982990026474
Loss made of: CE 0.10585759580135345, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.1345482163131237
Loss made of: CE 0.12076829373836517, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14904247224330902, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.14904247224330902, Class Loss=0.14904247224330902, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/52, Loss=0.14997873306274415
Loss made of: CE 0.214200958609581, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.13057441860437394
Loss made of: CE 0.09293477237224579, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.141437553614378
Loss made of: CE 0.14508216083049774, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.13859184756875037
Loss made of: CE 0.15632066130638123, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.13404741808772086
Loss made of: CE 0.15385901927947998, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14160896837711334, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.14160896837711334, Class Loss=0.14160896837711334, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/52, Loss=0.12609863355755807
Loss made of: CE 0.1281934678554535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.1423899859189987
Loss made of: CE 0.15693287551403046, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.18584990054368972
Loss made of: CE 0.19268298149108887, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.12039395123720169
Loss made of: CE 0.11976757645606995, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.14239726439118386
Loss made of: CE 0.15917764604091644, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14311277866363525, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.14311277866363525, Class Loss=0.14311277866363525, Reg Loss=0.0
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/34, Loss=0.33460821956396103
Loss made of: CE 0.41032764315605164, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.2577644646167755
Loss made of: CE 0.12913717329502106, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.23723497092723847
Loss made of: CE 0.2391543835401535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.26343458890914917, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.26343458890914917, Class Loss=0.26343458890914917, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/34, Loss=0.18190289735794068
Loss made of: CE 0.15992137789726257, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.1665517970919609
Loss made of: CE 0.17723576724529266, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.167909237742424
Loss made of: CE 0.13887444138526917, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.17092256247997284, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.17092256247997284, Class Loss=0.17092256247997284, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/34, Loss=0.15875550135970115
Loss made of: CE 0.16432791948318481, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.15014515891671182
Loss made of: CE 0.12423108518123627, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.18102395832538604
Loss made of: CE 0.20729917287826538, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16210007667541504, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.16210007667541504, Class Loss=0.16210007667541504, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/34, Loss=0.14754800796508788
Loss made of: CE 0.11862149089574814, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.16024690940976144
Loss made of: CE 0.17616990208625793, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.16550949662923814
Loss made of: CE 0.2766111195087433, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15509718656539917, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.15509718656539917, Class Loss=0.15509718656539917, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/34, Loss=0.15793971940875054
Loss made of: CE 0.09809564799070358, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.14497677162289618
Loss made of: CE 0.1786171793937683, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.1394336886703968
Loss made of: CE 0.14152731001377106, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14948327839374542, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.14948327839374542, Class Loss=0.14948327839374542, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/34, Loss=0.14556685462594032
Loss made of: CE 0.1531193107366562, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.1333213873207569
Loss made of: CE 0.2055351436138153, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.13873750120401382
Loss made of: CE 0.13909481465816498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14314283430576324, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.14314283430576324, Class Loss=0.14314283430576324, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=0.6876326918601989
Loss made of: CE 0.4708110988140106, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=0.49494796991348267
Loss made of: CE 0.48712044954299927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.3212918281555176
Loss made of: CE 0.24068152904510498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4829578697681427, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.4829578697681427, Class Loss=0.4829578697681427, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/33, Loss=0.24390261620283127
Loss made of: CE 0.2324252426624298, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.21790824234485626
Loss made of: CE 0.15790076553821564, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.2214940145611763
Loss made of: CE 0.37318453192710876, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22491644322872162, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.22491644322872162, Class Loss=0.22491644322872162, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/33, Loss=0.20523370653390885
Loss made of: CE 0.1836741417646408, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.17869410514831544
Loss made of: CE 0.14784207940101624, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.18031637668609618
Loss made of: CE 0.13499204814434052, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1886039823293686, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.1886039823293686, Class Loss=0.1886039823293686, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/33, Loss=0.16649071723222733
Loss made of: CE 0.12739914655685425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.16371815800666809
Loss made of: CE 0.20551973581314087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.15783759951591492
Loss made of: CE 0.19729673862457275, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1633804887533188, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.1633804887533188, Class Loss=0.1633804887533188, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/33, Loss=0.17660807073116302
Loss made of: CE 0.17624104022979736, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.16098829507827758
Loss made of: CE 0.13815763592720032, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.14911703243851662
Loss made of: CE 0.12469645589590073, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15991359949111938, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.15991359949111938, Class Loss=0.15991359949111938, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/33, Loss=0.19342787712812423
Loss made of: CE 0.20952372252941132, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.14393166527152063
Loss made of: CE 0.1271740198135376, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.13938883319497108
Loss made of: CE 0.14422912895679474, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1556989848613739, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.1556989848613739, Class Loss=0.1556989848613739, Reg Loss=0.0
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/34, Loss=0.3261974215507507
Loss made of: CE 0.3443319797515869, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.2606679707765579
Loss made of: CE 0.2427133172750473, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.23009788542985915
Loss made of: CE 0.25683465600013733, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2664635479450226, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.2664635479450226, Class Loss=0.2664635479450226, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000733
Epoch 2, Batch 10/34, Loss=0.20244148075580598
Loss made of: CE 0.13430218398571014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.16948517709970473
Loss made of: CE 0.18824701011180878, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.1763348549604416
Loss made of: CE 0.22938019037246704, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1797763556241989, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.1797763556241989, Class Loss=0.1797763556241989, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/34, Loss=0.1541906140744686
Loss made of: CE 0.18965458869934082, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.1512204550206661
Loss made of: CE 0.13881641626358032, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.15525517240166664
Loss made of: CE 0.17510633170604706, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15261274576187134, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.15261274576187134, Class Loss=0.15261274576187134, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000655
Epoch 4, Batch 10/34, Loss=0.15317754745483397
Loss made of: CE 0.15858270227909088, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.1453328788280487
Loss made of: CE 0.16742131114006042, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.1531013824045658
Loss made of: CE 0.21308767795562744, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15078997611999512, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.15078997611999512, Class Loss=0.15078997611999512, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000616
Epoch 5, Batch 10/34, Loss=0.14137178659439087
Loss made of: CE 0.18025252223014832, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.14168920144438743
Loss made of: CE 0.16433076560497284, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.14211440607905387
Loss made of: CE 0.14481543004512787, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14578808844089508, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.14578808844089508, Class Loss=0.14578808844089508, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000576
Epoch 6, Batch 10/34, Loss=0.15170205682516097
Loss made of: CE 0.17796681821346283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.14135476425290108
Loss made of: CE 0.1175537034869194, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.15680325031280518
Loss made of: CE 0.21122658252716064, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14912016689777374, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.14912016689777374, Class Loss=0.14912016689777374, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.39248496294021606, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.898192
Mean Acc: 0.429464
FreqW Acc: 0.811463
Mean IoU: 0.372430
Class IoU:
	class 0: 0.9076595
	class 1: 0.00010517554
	class 2: 0.0
	class 3: 0.0
	class 4: 0.027895784
	class 5: 0.16095069
	class 6: 0.835795
	class 7: 0.7359166
	class 8: 0.683551
Class Acc:
	class 0: 0.991982
	class 1: 0.00010517554
	class 2: 0.0
	class 3: 0.0
	class 4: 0.027895818
	class 5: 0.16204642
	class 6: 0.93340594
	class 7: 0.8305766
	class 8: 0.9191602

federated global round: 8, step: 1
select part of clients to conduct local training
[4, 11, 9, 6]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/25, Loss=0.5307263702154159
Loss made of: CE 0.39973998069763184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/25, Loss=0.32793652415275576
Loss made of: CE 0.2698709964752197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39803341031074524, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.39803341031074524, Class Loss=0.39803341031074524, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/25, Loss=0.2658774182200432
Loss made of: CE 0.26183435320854187, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/25, Loss=0.17945031970739364
Loss made of: CE 0.2647390365600586, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22471100091934204, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.22471100091934204, Class Loss=0.22471100091934204, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/25, Loss=0.17438892349600793
Loss made of: CE 0.17051123082637787, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/25, Loss=0.20018722489476204
Loss made of: CE 0.18966510891914368, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18533240258693695, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.18533240258693695, Class Loss=0.18533240258693695, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/25, Loss=0.16130878180265426
Loss made of: CE 0.16210758686065674, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/25, Loss=0.14097750782966614
Loss made of: CE 0.14274229109287262, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14738091826438904, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.14738091826438904, Class Loss=0.14738091826438904, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/25, Loss=0.15940671116113664
Loss made of: CE 0.11973953247070312, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/25, Loss=0.1859702117741108
Loss made of: CE 0.4330286383628845, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16699674725532532, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.16699674725532532, Class Loss=0.16699674725532532, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/25, Loss=0.12377942577004433
Loss made of: CE 0.16931413114070892, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/25, Loss=0.1330026775598526
Loss made of: CE 0.17084716260433197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1345779448747635, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.1345779448747635, Class Loss=0.1345779448747635, Reg Loss=0.0
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/43, Loss=0.46288096010684965
Loss made of: CE 0.29253000020980835, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/43, Loss=0.35507636368274687
Loss made of: CE 0.3467679023742676, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/43, Loss=0.2719848811626434
Loss made of: CE 0.19280406832695007, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/43, Loss=0.2332156240940094
Loss made of: CE 0.371093213558197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.32221201062202454, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.32221201062202454, Class Loss=0.32221201062202454, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/43, Loss=0.20100324898958205
Loss made of: CE 0.17952287197113037, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/43, Loss=0.1731366105377674
Loss made of: CE 0.14531871676445007, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/43, Loss=0.18644434809684754
Loss made of: CE 0.23904326558113098, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/43, Loss=0.19905112236738204
Loss made of: CE 0.15253329277038574, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1886896789073944, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.1886896789073944, Class Loss=0.1886896789073944, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/43, Loss=0.1720433309674263
Loss made of: CE 0.15683753788471222, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/43, Loss=0.16575212478637696
Loss made of: CE 0.16765855252742767, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/43, Loss=0.1633755996823311
Loss made of: CE 0.1598764955997467, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/43, Loss=0.18691077530384065
Loss made of: CE 0.15819188952445984, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1708352267742157, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.1708352267742157, Class Loss=0.1708352267742157, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/43, Loss=0.1495252728462219
Loss made of: CE 0.20992708206176758, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/43, Loss=0.1531685248017311
Loss made of: CE 0.17588743567466736, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/43, Loss=0.1530156336724758
Loss made of: CE 0.14885234832763672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/43, Loss=0.1629815600812435
Loss made of: CE 0.1110161691904068, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1530226320028305, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.1530226320028305, Class Loss=0.1530226320028305, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/43, Loss=0.1557232469320297
Loss made of: CE 0.1028522402048111, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/43, Loss=0.14800529479980468
Loss made of: CE 0.1758301705121994, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/43, Loss=0.16767165809869766
Loss made of: CE 0.13030895590782166, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/43, Loss=0.14854443296790124
Loss made of: CE 0.097269207239151, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15531250834465027, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.15531250834465027, Class Loss=0.15531250834465027, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/43, Loss=0.12992631569504737
Loss made of: CE 0.11429600417613983, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/43, Loss=0.1445933997631073
Loss made of: CE 0.13914191722869873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/43, Loss=0.1400757797062397
Loss made of: CE 0.12538766860961914, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/43, Loss=0.1309715263545513
Loss made of: CE 0.17495858669281006, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13878272473812103, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.13878272473812103, Class Loss=0.13878272473812103, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/52, Loss=0.2127036839723587
Loss made of: CE 0.258536159992218, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.20198366940021514
Loss made of: CE 0.15178140997886658, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.1669210210442543
Loss made of: CE 0.167545884847641, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.17368896678090096
Loss made of: CE 0.23739473521709442, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.17914940863847734
Loss made of: CE 0.17220479249954224, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.18696264922618866, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.18696264922618866, Class Loss=0.18696264922618866, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/52, Loss=0.15432333797216416
Loss made of: CE 0.16421619057655334, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.15787050426006316
Loss made of: CE 0.1536462903022766, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.18645382449030876
Loss made of: CE 0.18261122703552246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.16895090341567992
Loss made of: CE 0.10953335464000702, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.15231829285621643
Loss made of: CE 0.10981478542089462, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16914954781532288, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.16914954781532288, Class Loss=0.16914954781532288, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/52, Loss=0.1431530900299549
Loss made of: CE 0.1723245233297348, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.13753589987754822
Loss made of: CE 0.1248108372092247, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.13720409274101258
Loss made of: CE 0.14974451065063477, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.15381173938512802
Loss made of: CE 0.1590598076581955, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.14050495252013206
Loss made of: CE 0.14090266823768616, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14488641917705536, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.14488641917705536, Class Loss=0.14488641917705536, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/52, Loss=0.1295242540538311
Loss made of: CE 0.1254820078611374, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.15216482877731324
Loss made of: CE 0.1625097095966339, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.13731571063399314
Loss made of: CE 0.15134193003177643, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.144119244068861
Loss made of: CE 0.12164269387722015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.12860580384731293
Loss made of: CE 0.11394459009170532, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13836769759655, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.13836769759655, Class Loss=0.13836769759655, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/52, Loss=0.11095764935016632
Loss made of: CE 0.12734785676002502, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.1397311955690384
Loss made of: CE 0.13844643533229828, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.13303705230355262
Loss made of: CE 0.13544750213623047, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.14579671174287795
Loss made of: CE 0.13279053568840027, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.13489915505051614
Loss made of: CE 0.13221906125545502, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13446371257305145, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.13446371257305145, Class Loss=0.13446371257305145, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/52, Loss=0.11954562738537788
Loss made of: CE 0.0840439647436142, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.1215517871081829
Loss made of: CE 0.1031726598739624, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.1414218433201313
Loss made of: CE 0.09861204028129578, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.1379058837890625
Loss made of: CE 0.11999784409999847, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.12494171410799026
Loss made of: CE 0.11874046921730042, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1286846548318863, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.1286846548318863, Class Loss=0.1286846548318863, Reg Loss=0.0
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/34, Loss=0.2388110414147377
Loss made of: CE 0.3111876845359802, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.18977984562516212
Loss made of: CE 0.12690386176109314, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.21255481392145156
Loss made of: CE 0.1730128973722458, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.20405277609825134, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.20405277609825134, Class Loss=0.20405277609825134, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000525
Epoch 2, Batch 10/34, Loss=0.1643783926963806
Loss made of: CE 0.15562836825847626, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.151748438924551
Loss made of: CE 0.13821779191493988, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.14933907687664033
Loss made of: CE 0.11040237545967102, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1542244404554367, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.1542244404554367, Class Loss=0.1542244404554367, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/34, Loss=0.13893219754099845
Loss made of: CE 0.134019136428833, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.14835264310240745
Loss made of: CE 0.0998571440577507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.15223910808563232
Loss made of: CE 0.12916436791419983, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1455824375152588, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.1455824375152588, Class Loss=0.1455824375152588, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/34, Loss=0.13628988862037658
Loss made of: CE 0.11450761556625366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.1455265387892723
Loss made of: CE 0.16088524460792542, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.15598413869738578
Loss made of: CE 0.23914697766304016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14443932473659515, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.14443932473659515, Class Loss=0.14443932473659515, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000394
Epoch 5, Batch 10/34, Loss=0.1383632205426693
Loss made of: CE 0.08441150188446045, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.13731531724333762
Loss made of: CE 0.1954401135444641, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.121799336373806
Loss made of: CE 0.11299972236156464, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1343657225370407, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.1343657225370407, Class Loss=0.1343657225370407, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000350
Epoch 6, Batch 10/34, Loss=0.1517877086997032
Loss made of: CE 0.1643252670764923, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.12921048179268838
Loss made of: CE 0.19965969026088715, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.12645572945475578
Loss made of: CE 0.10069189965724945, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13914526998996735, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.13914526998996735, Class Loss=0.13914526998996735, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.39956265687942505, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.903645
Mean Acc: 0.463717
FreqW Acc: 0.820413
Mean IoU: 0.416278
Class IoU:
	class 0: 0.9068493
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.01632317
	class 5: 0.48880735
	class 6: 0.8763171
	class 7: 0.76936144
	class 8: 0.6888475
Class Acc:
	class 0: 0.9929419
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.01632317
	class 5: 0.5016943
	class 6: 0.9322647
	class 7: 0.8613296
	class 8: 0.86889744

federated global round: 9, step: 1
select part of clients to conduct local training
[5, 0, 9, 2]
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/34, Loss=0.290143883228302
Loss made of: CE 0.263785183429718, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.24995763450860978
Loss made of: CE 0.28316062688827515, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.20983387231826783
Loss made of: CE 0.3101867437362671, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.24989192187786102, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.24989192187786102, Class Loss=0.24989192187786102, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/34, Loss=0.1832311250269413
Loss made of: CE 0.12704947590827942, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.13842318579554558
Loss made of: CE 0.15905097126960754, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.18152680546045302
Loss made of: CE 0.22143429517745972, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16482999920845032, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.16482999920845032, Class Loss=0.16482999920845032, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/34, Loss=0.13838066160678864
Loss made of: CE 0.16566011309623718, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.1362089730799198
Loss made of: CE 0.128342404961586, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.15313228219747543
Loss made of: CE 0.22696886956691742, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14707857370376587, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.14707857370376587, Class Loss=0.14707857370376587, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/34, Loss=0.14420719891786576
Loss made of: CE 0.15394362807273865, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.1443668633699417
Loss made of: CE 0.21383127570152283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.1377698987722397
Loss made of: CE 0.16160236299037933, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14183901250362396, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.14183901250362396, Class Loss=0.14183901250362396, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/34, Loss=0.13666423559188842
Loss made of: CE 0.1311427652835846, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.1354528434574604
Loss made of: CE 0.1399332731962204, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.14018893912434577
Loss made of: CE 0.15791890025138855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13938872516155243, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.13938872516155243, Class Loss=0.13938872516155243, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/34, Loss=0.1524176299571991
Loss made of: CE 0.1706206053495407, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.1328894503414631
Loss made of: CE 0.0965697392821312, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.14643000438809395
Loss made of: CE 0.23656567931175232, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14422756433486938, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.14422756433486938, Class Loss=0.14422756433486938, Reg Loss=0.0
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/52, Loss=0.24362530410289765
Loss made of: CE 0.3229725956916809, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.17847805619239807
Loss made of: CE 0.15627172589302063, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.15812601298093795
Loss made of: CE 0.1445254385471344, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.1559259794652462
Loss made of: CE 0.1710759848356247, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.16854511871933936
Loss made of: CE 0.1410820186138153, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1795720010995865, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.1795720010995865, Class Loss=0.1795720010995865, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000482
Epoch 2, Batch 10/52, Loss=0.1589096814393997
Loss made of: CE 0.13878192007541656, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.14509703516960143
Loss made of: CE 0.13776534795761108, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.15442787557840348
Loss made of: CE 0.17582154273986816, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.15814754590392113
Loss made of: CE 0.1704862415790558, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.1314270831644535
Loss made of: CE 0.17062467336654663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.14790292084217072, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.14790292084217072, Class Loss=0.14790292084217072, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000394
Epoch 3, Batch 10/52, Loss=0.13412433564662934
Loss made of: CE 0.1257685124874115, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.1556737892329693
Loss made of: CE 0.16693958640098572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.1414550580084324
Loss made of: CE 0.16687974333763123, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.16811193898320198
Loss made of: CE 0.12713293731212616, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.1485107086598873
Loss made of: CE 0.12282931804656982, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14882515370845795, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.14882515370845795, Class Loss=0.14882515370845795, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000304
Epoch 4, Batch 10/52, Loss=0.13691052719950675
Loss made of: CE 0.19891902804374695, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.1318802170455456
Loss made of: CE 0.09140858054161072, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.13783583790063858
Loss made of: CE 0.14016859233379364, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.13516560047864914
Loss made of: CE 0.10281991958618164, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.12198650315403939
Loss made of: CE 0.10188265889883041, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13174007833003998, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.13174007833003998, Class Loss=0.13174007833003998, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000211
Epoch 5, Batch 10/52, Loss=0.14402600079774858
Loss made of: CE 0.17268243432044983, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.12478426471352577
Loss made of: CE 0.09478548169136047, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.13158725202083588
Loss made of: CE 0.14948363602161407, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.1330115854740143
Loss made of: CE 0.14237158000469208, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.13361410796642303
Loss made of: CE 0.1416168510913849, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1343853771686554, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.1343853771686554, Class Loss=0.1343853771686554, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000113
Epoch 6, Batch 10/52, Loss=0.12014819905161858
Loss made of: CE 0.11045520007610321, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.1344740182161331
Loss made of: CE 0.12648792564868927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.1663611799478531
Loss made of: CE 0.16023355722427368, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.11626288667321205
Loss made of: CE 0.10544698685407639, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.12867420315742492
Loss made of: CE 0.13068243861198425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13317450881004333, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.13317450881004333, Class Loss=0.13317450881004333, Reg Loss=0.0
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/52, Loss=0.20599508732557298
Loss made of: CE 0.24591681361198425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.23995175883173941
Loss made of: CE 0.1862010359764099, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.18244569301605223
Loss made of: CE 0.16000714898109436, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.16801307052373887
Loss made of: CE 0.2125634402036667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.17300955429673195
Loss made of: CE 0.15756016969680786, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.19490858912467957, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.19490858912467957, Class Loss=0.19490858912467957, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/52, Loss=0.15118201747536658
Loss made of: CE 0.16641780734062195, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.15721561685204505
Loss made of: CE 0.1798323094844818, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.1721598334610462
Loss made of: CE 0.15330958366394043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.15147491320967674
Loss made of: CE 0.10789810121059418, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.1510737307369709
Loss made of: CE 0.12502670288085938, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16030029952526093, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.16030029952526093, Class Loss=0.16030029952526093, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/52, Loss=0.14282714501023291
Loss made of: CE 0.15077677369117737, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.14201974347233773
Loss made of: CE 0.1303931176662445, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.1387953817844391
Loss made of: CE 0.1333773136138916, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.15080996602773666
Loss made of: CE 0.13558807969093323, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.1483910821378231
Loss made of: CE 0.1451006382703781, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14796899259090424, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.14796899259090424, Class Loss=0.14796899259090424, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/52, Loss=0.13400569260120393
Loss made of: CE 0.12339618057012558, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.15234526693820954
Loss made of: CE 0.17381082475185394, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.13230476900935173
Loss made of: CE 0.16447767615318298, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.16134144887328147
Loss made of: CE 0.13177326321601868, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.13540177419781685
Loss made of: CE 0.10067532956600189, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14249366521835327, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.14249366521835327, Class Loss=0.14249366521835327, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/52, Loss=0.11342803835868835
Loss made of: CE 0.1068062037229538, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.14885767921805382
Loss made of: CE 0.12556590139865875, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.13918948844075202
Loss made of: CE 0.15296180546283722, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.14661525562405586
Loss made of: CE 0.13190919160842896, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.14041420593857765
Loss made of: CE 0.1549597680568695, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13903355598449707, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.13903355598449707, Class Loss=0.13903355598449707, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/52, Loss=0.13294251412153243
Loss made of: CE 0.1069684624671936, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.1268594391644001
Loss made of: CE 0.10978733003139496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.1690892219543457
Loss made of: CE 0.1091410368680954, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.14983044043183327
Loss made of: CE 0.14795047044754028, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.13579643294215202
Loss made of: CE 0.14006435871124268, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14211176335811615, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.14211176335811615, Class Loss=0.14211176335811615, Reg Loss=0.0
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/25, Loss=0.3245470017194748
Loss made of: CE 0.27710583806037903, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/25, Loss=0.23371504694223405
Loss made of: CE 0.30286818742752075, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.26467055082321167, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.26467055082321167, Class Loss=0.26467055082321167, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/25, Loss=0.18576502203941345
Loss made of: CE 0.16547977924346924, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/25, Loss=0.1883940041065216
Loss made of: CE 0.12551945447921753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1740075647830963, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.1740075647830963, Class Loss=0.1740075647830963, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/25, Loss=0.1480318896472454
Loss made of: CE 0.10975933074951172, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/25, Loss=0.16102230176329613
Loss made of: CE 0.1420915126800537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15120863914489746, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.15120863914489746, Class Loss=0.15120863914489746, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/25, Loss=0.1418321520090103
Loss made of: CE 0.15361563861370087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/25, Loss=0.1408037707209587
Loss made of: CE 0.11912094056606293, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14107373356819153, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.14107373356819153, Class Loss=0.14107373356819153, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/25, Loss=0.12780708745121955
Loss made of: CE 0.07653599232435226, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/25, Loss=0.12854358181357384
Loss made of: CE 0.10989373922348022, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.12633247673511505, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.12633247673511505, Class Loss=0.12633247673511505, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/25, Loss=0.1402970626950264
Loss made of: CE 0.14961419999599457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/25, Loss=0.15139512568712235
Loss made of: CE 0.13392412662506104, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14069609344005585, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.14069609344005585, Class Loss=0.14069609344005585, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.39830252528190613, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.908441
Mean Acc: 0.485467
FreqW Acc: 0.829642
Mean IoU: 0.430936
Class IoU:
	class 0: 0.91449887
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0149366595
	class 5: 0.5886142
	class 6: 0.88179743
	class 7: 0.77230906
	class 8: 0.7062676
Class Acc:
	class 0: 0.9904043
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0149366595
	class 5: 0.61492765
	class 6: 0.936736
	class 7: 0.87627214
	class 8: 0.93592995

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[0, 15, 1, 4]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=1.641916823387146
Loss made of: CE 1.4112355709075928, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.4175822734832764, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=1.4175822734832764, Class Loss=1.4175822734832764, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=0.8517893016338348
Loss made of: CE 0.859125018119812, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8025085926055908, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.8025085926055908, Class Loss=0.8025085926055908, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=0.5898731648921967
Loss made of: CE 0.6156202554702759, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5439767241477966, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.5439767241477966, Class Loss=0.5439767241477966, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=0.43748160600662234
Loss made of: CE 0.5789057612419128, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4482114315032959, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.4482114315032959, Class Loss=0.4482114315032959, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=0.3967186897993088
Loss made of: CE 0.42427724599838257, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3950060307979584, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.3950060307979584, Class Loss=0.3950060307979584, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.37818045914173126
Loss made of: CE 0.3817235827445984, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.36678993701934814, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.36678993701934814, Class Loss=0.36678993701934814, Reg Loss=0.0
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=1.8075327277183533
Loss made of: CE 1.207248568534851, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.542621374130249, Reg Loss=0.0
Clinet index 15, End of Epoch 1/6, Average Loss=1.542621374130249, Class Loss=1.542621374130249, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=0.9618152439594269
Loss made of: CE 0.6733098030090332, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8556293845176697, Reg Loss=0.0
Clinet index 15, End of Epoch 2/6, Average Loss=0.8556293845176697, Class Loss=0.8556293845176697, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=0.5898983955383301
Loss made of: CE 0.5175668001174927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5732589960098267, Reg Loss=0.0
Clinet index 15, End of Epoch 3/6, Average Loss=0.5732589960098267, Class Loss=0.5732589960098267, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=0.4893091946840286
Loss made of: CE 0.4275386929512024, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46926990151405334, Reg Loss=0.0
Clinet index 15, End of Epoch 4/6, Average Loss=0.46926990151405334, Class Loss=0.46926990151405334, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=0.4221983104944229
Loss made of: CE 0.3692325949668884, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4082566201686859, Reg Loss=0.0
Clinet index 15, End of Epoch 5/6, Average Loss=0.4082566201686859, Class Loss=0.4082566201686859, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.39162278175354004
Loss made of: CE 0.41724300384521484, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3819233179092407, Reg Loss=0.0
Clinet index 15, End of Epoch 6/6, Average Loss=0.3819233179092407, Class Loss=0.3819233179092407, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/35, Loss=1.4005507230758667
Loss made of: CE 1.195243239402771, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=0.936005026102066
Loss made of: CE 0.5523180961608887, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=0.5600555300712585
Loss made of: CE 0.5724457502365112, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9022461175918579, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.9022461175918579, Class Loss=0.9022461175918579, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/35, Loss=0.3635162502527237
Loss made of: CE 0.31045570969581604, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=0.3876975178718567
Loss made of: CE 0.5231635570526123, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=0.3451915070414543
Loss made of: CE 0.28282076120376587, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36572396755218506, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.36572396755218506, Class Loss=0.36572396755218506, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/35, Loss=0.27103506624698637
Loss made of: CE 0.2699984908103943, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=0.31047439128160476
Loss made of: CE 0.26461347937583923, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.3027389571070671
Loss made of: CE 0.2646605372428894, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28875190019607544, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.28875190019607544, Class Loss=0.28875190019607544, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/35, Loss=0.27780715823173524
Loss made of: CE 0.21669697761535645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.22002990543842316
Loss made of: CE 0.14340010285377502, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.24834872633218766
Loss made of: CE 0.1973242461681366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2502155900001526, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.2502155900001526, Class Loss=0.2502155900001526, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/35, Loss=0.20975654274225236
Loss made of: CE 0.19277027249336243, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=0.25557673126459124
Loss made of: CE 0.21950992941856384, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.20789273530244828
Loss made of: CE 0.18179798126220703, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22986644506454468, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.22986644506454468, Class Loss=0.22986644506454468, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/35, Loss=0.18962708562612535
Loss made of: CE 0.1278221607208252, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.2007068783044815
Loss made of: CE 0.1578158438205719, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.22079335004091263
Loss made of: CE 0.2597216069698334, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2098323553800583, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.2098323553800583, Class Loss=0.2098323553800583, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=1.644644522666931
Loss made of: CE 1.27201247215271, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.4498404264450073, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=1.4498404264450073, Class Loss=1.4498404264450073, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=0.9493187129497528
Loss made of: CE 0.7407187819480896, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8177574872970581, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.8177574872970581, Class Loss=0.8177574872970581, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=0.60411137342453
Loss made of: CE 0.48070424795150757, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5514454245567322, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.5514454245567322, Class Loss=0.5514454245567322, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=0.4656069457530975
Loss made of: CE 0.3866330087184906, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4419591426849365, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.4419591426849365, Class Loss=0.4419591426849365, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=0.3977631688117981
Loss made of: CE 0.4385721683502197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39311283826828003, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.39311283826828003, Class Loss=0.39311283826828003, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.3361762255430222
Loss made of: CE 0.30071407556533813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3591124415397644, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.3591124415397644, Class Loss=0.3591124415397644, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.6681505441665649, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.792847
Mean Acc: 0.213460
FreqW Acc: 0.666368
Mean IoU: 0.142069
Class IoU:
	class 0: 0.84594506
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0010033895
	class 5: 0.038213562
	class 6: 0.42665878
	class 7: 0.118660174
	class 8: 0.060513422
	class 9: 0.0039963736
	class 10: 0.22164251
	class 11: 0.13026422
	class 12: 0.0
Class Acc:
	class 0: 0.9919781
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0010033895
	class 5: 0.038217086
	class 6: 0.43860412
	class 7: 0.11881579
	class 8: 0.060735207
	class 9: 0.004012691
	class 10: 0.8950309
	class 11: 0.22658226
	class 12: 0.0

federated global round: 11, step: 2
select part of clients to conduct local training
[1, 13, 11, 12]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/35, Loss=0.850969922542572
Loss made of: CE 0.6955302953720093, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=0.5977811336517334
Loss made of: CE 0.4221574664115906, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=0.40654038786888125
Loss made of: CE 0.46736621856689453, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5839470028877258, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.5839470028877258, Class Loss=0.5839470028877258, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/35, Loss=0.3088924214243889
Loss made of: CE 0.2585153579711914, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=0.287918421626091
Loss made of: CE 0.3663412928581238, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=0.28726866096258163
Loss made of: CE 0.25342291593551636, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.295293927192688, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.295293927192688, Class Loss=0.295293927192688, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/35, Loss=0.21753158271312714
Loss made of: CE 0.20404964685440063, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=0.2574908122420311
Loss made of: CE 0.2200976461172104, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.2498694986104965
Loss made of: CE 0.24338822066783905, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23903310298919678, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.23903310298919678, Class Loss=0.23903310298919678, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/35, Loss=0.22112367153167725
Loss made of: CE 0.2144710123538971, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.18867202177643777
Loss made of: CE 0.12391611188650131, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.2188374176621437
Loss made of: CE 0.16712014377117157, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21147049963474274, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.21147049963474274, Class Loss=0.21147049963474274, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/35, Loss=0.18459590375423432
Loss made of: CE 0.175751194357872, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=0.21836561411619188
Loss made of: CE 0.22449621558189392, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.18760181218385696
Loss made of: CE 0.16214129328727722, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2017521858215332, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.2017521858215332, Class Loss=0.2017521858215332, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/35, Loss=0.1784267395734787
Loss made of: CE 0.13123582303524017, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.18228115886449814
Loss made of: CE 0.17013749480247498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.19859139174222945
Loss made of: CE 0.2106652706861496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19241231679916382, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.19241231679916382, Class Loss=0.19241231679916382, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.45096306800842284
Loss made of: CE 0.4935465455055237, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.44583937525749207, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.44583937525749207, Class Loss=0.44583937525749207, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/19, Loss=0.4132098525762558
Loss made of: CE 0.5522298812866211, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.37929996848106384, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.37929996848106384, Class Loss=0.37929996848106384, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/19, Loss=0.3530393362045288
Loss made of: CE 0.2719250023365021, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3475740849971771, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.3475740849971771, Class Loss=0.3475740849971771, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/19, Loss=0.33627117425203323
Loss made of: CE 0.35046952962875366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.31673839688301086, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.31673839688301086, Class Loss=0.31673839688301086, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/19, Loss=0.31002176702022555
Loss made of: CE 0.2538546323776245, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3024495840072632, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.3024495840072632, Class Loss=0.3024495840072632, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/19, Loss=0.2900842845439911
Loss made of: CE 0.3299863040447235, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.28310880064964294, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.28310880064964294, Class Loss=0.28310880064964294, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=0.6522354811429978
Loss made of: CE 0.5777105093002319, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=0.5957278728485107
Loss made of: CE 0.5658894777297974, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.5070228964090348
Loss made of: CE 0.44041526317596436, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5834038257598877, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.5834038257598877, Class Loss=0.5834038257598877, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/33, Loss=0.47900956571102143
Loss made of: CE 0.5569865703582764, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.4152805984020233
Loss made of: CE 0.47541677951812744, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.4506676375865936
Loss made of: CE 0.46751779317855835, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4372624456882477, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.4372624456882477, Class Loss=0.4372624456882477, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/33, Loss=0.4012004494667053
Loss made of: CE 0.3345344066619873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.3770368665456772
Loss made of: CE 0.44666123390197754, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.3922756016254425
Loss made of: CE 0.4476490914821625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38636478781700134, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.38636478781700134, Class Loss=0.38636478781700134, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/33, Loss=0.3664793878793716
Loss made of: CE 0.37636980414390564, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.3588685870170593
Loss made of: CE 0.32945138216018677, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.3464133381843567
Loss made of: CE 0.39944547414779663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.35162800550460815, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.35162800550460815, Class Loss=0.35162800550460815, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/33, Loss=0.3645750880241394
Loss made of: CE 0.2513806223869324, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.31164388358592987
Loss made of: CE 0.2771892547607422, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.33561124205589293
Loss made of: CE 0.37051326036453247, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33339977264404297, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.33339977264404297, Class Loss=0.33339977264404297, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/33, Loss=0.3002356767654419
Loss made of: CE 0.31287556886672974, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.32206844389438627
Loss made of: CE 0.2674815356731415, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.29977424442768097
Loss made of: CE 0.2841467261314392, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3074091970920563, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.3074091970920563, Class Loss=0.3074091970920563, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=0.6117171227931977
Loss made of: CE 0.795482337474823, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=0.6273105591535568
Loss made of: CE 0.7457036972045898, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.5076372116804123
Loss made of: CE 0.37726932764053345, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.570378839969635, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.570378839969635, Class Loss=0.570378839969635, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/33, Loss=0.43682342767715454
Loss made of: CE 0.30557629466056824, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.4271551907062531
Loss made of: CE 0.6117149591445923, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.4289268314838409
Loss made of: CE 0.39458203315734863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.43380725383758545, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.43380725383758545, Class Loss=0.43380725383758545, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/33, Loss=0.3731071978807449
Loss made of: CE 0.36153125762939453, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.3812680274248123
Loss made of: CE 0.3390783667564392, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.37535236179828646
Loss made of: CE 0.4080283045768738, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38009151816368103, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.38009151816368103, Class Loss=0.38009151816368103, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/33, Loss=0.3501312047243118
Loss made of: CE 0.29203349351882935, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.33659715950489044
Loss made of: CE 0.33728358149528503, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.34399749636650084
Loss made of: CE 0.2972636818885803, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.34558385610580444, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.34558385610580444, Class Loss=0.34558385610580444, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/33, Loss=0.30924932211637496
Loss made of: CE 0.24051937460899353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.33241710662841795
Loss made of: CE 0.42529651522636414, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.3016679063439369
Loss made of: CE 0.39238405227661133, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.32034432888031006, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.32034432888031006, Class Loss=0.32034432888031006, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/33, Loss=0.3151614546775818
Loss made of: CE 0.413935124874115, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.3122719407081604
Loss made of: CE 0.26244786381721497, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.33798121511936186
Loss made of: CE 0.3261456787586212, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.31882020831108093, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.31882020831108093, Class Loss=0.31882020831108093, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.7889809608459473, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.783720
Mean Acc: 0.195907
FreqW Acc: 0.627833
Mean IoU: 0.132252
Class IoU:
	class 0: 0.80420595
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 4.5589604e-05
	class 5: 0.0
	class 6: 0.012919631
	class 7: 0.00019307125
	class 8: 0.00011162304
	class 9: 0.12949912
	class 10: 0.39367756
	class 11: 0.2627116
	class 12: 0.11591375
Class Acc:
	class 0: 0.99316376
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 4.5589604e-05
	class 5: 0.0
	class 6: 0.012919631
	class 7: 0.00019307125
	class 8: 0.00011162671
	class 9: 0.17209053
	class 10: 0.93777084
	class 11: 0.30531427
	class 12: 0.1251811

federated global round: 12, step: 2
select part of clients to conduct local training
[0, 16, 7, 4]
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/19, Loss=0.37023275196552274
Loss made of: CE 0.4081262946128845, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.36293119192123413, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.36293119192123413, Class Loss=0.36293119192123413, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/19, Loss=0.3004008859395981
Loss made of: CE 0.33385348320007324, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.30326181650161743, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.30326181650161743, Class Loss=0.30326181650161743, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/19, Loss=0.30350003242492674
Loss made of: CE 0.32152843475341797, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29477447271347046, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.29477447271347046, Class Loss=0.29477447271347046, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/19, Loss=0.265671306848526
Loss made of: CE 0.32173389196395874, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2742617130279541, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.2742617130279541, Class Loss=0.2742617130279541, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/19, Loss=0.25991591811180115
Loss made of: CE 0.27755865454673767, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26085880398750305, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.26085880398750305, Class Loss=0.26085880398750305, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/19, Loss=0.2585826426744461
Loss made of: CE 0.2596125602722168, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2610608637332916, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.2610608637332916, Class Loss=0.2610608637332916, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/42, Loss=0.668153601884842
Loss made of: CE 0.5797306299209595, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/42, Loss=0.48724124729633334
Loss made of: CE 0.3411804437637329, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/42, Loss=0.36731003820896146
Loss made of: CE 0.48159241676330566, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/42, Loss=0.29383218139410017
Loss made of: CE 0.21147577464580536, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.44707077741622925, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.44707077741622925, Class Loss=0.44707077741622925, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/42, Loss=0.2965383976697922
Loss made of: CE 0.2493894100189209, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/42, Loss=0.25894670337438586
Loss made of: CE 0.20363467931747437, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/42, Loss=0.2607207059860229
Loss made of: CE 0.21232518553733826, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/42, Loss=0.26937608420848846
Loss made of: CE 0.25547704100608826, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2719514071941376, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.2719514071941376, Class Loss=0.2719514071941376, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/42, Loss=0.23462834507226943
Loss made of: CE 0.26221856474876404, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/42, Loss=0.22669078558683395
Loss made of: CE 0.21868771314620972, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/42, Loss=0.23729660511016845
Loss made of: CE 0.2156621813774109, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/42, Loss=0.303239443898201
Loss made of: CE 0.22197207808494568, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25005030632019043, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.25005030632019043, Class Loss=0.25005030632019043, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/42, Loss=0.24891880750656128
Loss made of: CE 0.1995246708393097, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/42, Loss=0.23455315977334976
Loss made of: CE 0.28338074684143066, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/42, Loss=0.22703669518232344
Loss made of: CE 0.19955524802207947, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/42, Loss=0.2371171548962593
Loss made of: CE 0.21016260981559753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23646153509616852, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.23646153509616852, Class Loss=0.23646153509616852, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/42, Loss=0.20144444108009338
Loss made of: CE 0.2266516089439392, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/42, Loss=0.23013461977243424
Loss made of: CE 0.25537601113319397, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/42, Loss=0.22713556587696077
Loss made of: CE 0.26446419954299927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/42, Loss=0.20941319167613984
Loss made of: CE 0.20269589126110077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21661333739757538, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.21661333739757538, Class Loss=0.21661333739757538, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/42, Loss=0.23078453838825225
Loss made of: CE 0.15346388518810272, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/42, Loss=0.22023343294858932
Loss made of: CE 0.21978306770324707, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/42, Loss=0.2066377431154251
Loss made of: CE 0.2177693098783493, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/42, Loss=0.2323990762233734
Loss made of: CE 0.28726252913475037, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22038310766220093, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.22038310766220093, Class Loss=0.22038310766220093, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/31, Loss=0.5095177292823792
Loss made of: CE 0.5990420579910278, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/31, Loss=0.5195256680250168
Loss made of: CE 0.4922354221343994, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/31, Loss=0.4311032921075821
Loss made of: CE 0.43521201610565186, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4894171953201294, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.4894171953201294, Class Loss=0.4894171953201294, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/31, Loss=0.4239977777004242
Loss made of: CE 0.35527142882347107, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/31, Loss=0.3689997136592865
Loss made of: CE 0.41354963183403015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/31, Loss=0.3904060751199722
Loss made of: CE 0.3415549695491791, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3933411240577698, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.3933411240577698, Class Loss=0.3933411240577698, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/31, Loss=0.36102187633514404
Loss made of: CE 0.4808734357357025, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/31, Loss=0.35577675700187683
Loss made of: CE 0.36870861053466797, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/31, Loss=0.32563562244176864
Loss made of: CE 0.3107061982154846, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.34639936685562134, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.34639936685562134, Class Loss=0.34639936685562134, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/31, Loss=0.3393530875444412
Loss made of: CE 0.39363905787467957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/31, Loss=0.32485090792179105
Loss made of: CE 0.36994749307632446, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/31, Loss=0.3603594869375229
Loss made of: CE 0.5025155544281006, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.34159329533576965, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.34159329533576965, Class Loss=0.34159329533576965, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/31, Loss=0.32179519534111023
Loss made of: CE 0.2977573871612549, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/31, Loss=0.29571637958288194
Loss made of: CE 0.3105606436729431, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/31, Loss=0.3096722632646561
Loss made of: CE 0.2602594494819641, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.30916571617126465, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.30916571617126465, Class Loss=0.30916571617126465, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/31, Loss=0.28624068945646286
Loss made of: CE 0.2983250319957733, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/31, Loss=0.31022867262363435
Loss made of: CE 0.3449905812740326, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/31, Loss=0.2929540559649467
Loss made of: CE 0.3571271300315857, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29618486762046814, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.29618486762046814, Class Loss=0.29618486762046814, Reg Loss=0.0
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/19, Loss=0.3851278454065323
Loss made of: CE 0.3041071593761444, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3762296140193939, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.3762296140193939, Class Loss=0.3762296140193939, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/19, Loss=0.35884045660495756
Loss made of: CE 0.3015407919883728, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3215141296386719, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.3215141296386719, Class Loss=0.3215141296386719, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/19, Loss=0.2961089476943016
Loss made of: CE 0.2659035921096802, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28848105669021606, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.28848105669021606, Class Loss=0.28848105669021606, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/19, Loss=0.29606649577617644
Loss made of: CE 0.2806609570980072, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2824726998806, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.2824726998806, Class Loss=0.2824726998806, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/19, Loss=0.2694119304418564
Loss made of: CE 0.27568989992141724, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26375812292099, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.26375812292099, Class Loss=0.26375812292099, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/19, Loss=0.24650983810424804
Loss made of: CE 0.21917951107025146, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2585698366165161, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.2585698366165161, Class Loss=0.2585698366165161, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.8290998339653015, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.797258
Mean Acc: 0.251559
FreqW Acc: 0.645720
Mean IoU: 0.191753
Class IoU:
	class 0: 0.8024078
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0009646563
	class 7: 0.0
	class 8: 0.0
	class 9: 0.22412986
	class 10: 0.6832147
	class 11: 0.38939032
	class 12: 0.39268333
Class Acc:
	class 0: 0.98613983
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0009646563
	class 7: 0.0
	class 8: 0.0
	class 9: 0.284416
	class 10: 0.855047
	class 11: 0.655284
	class 12: 0.48841032

federated global round: 13, step: 2
select part of clients to conduct local training
[14, 13, 0, 1]
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.312441223859787
Loss made of: CE 0.3131551146507263, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3036508858203888, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.3036508858203888, Class Loss=0.3036508858203888, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/19, Loss=0.2715230792760849
Loss made of: CE 0.37273097038269043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2626030743122101, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.2626030743122101, Class Loss=0.2626030743122101, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/19, Loss=0.2589767575263977
Loss made of: CE 0.22337234020233154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2532123923301697, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.2532123923301697, Class Loss=0.2532123923301697, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/19, Loss=0.24668180495500563
Loss made of: CE 0.23271900415420532, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24207308888435364, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.24207308888435364, Class Loss=0.24207308888435364, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/19, Loss=0.23965952396392823
Loss made of: CE 0.2372841089963913, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24126321077346802, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.24126321077346802, Class Loss=0.24126321077346802, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/19, Loss=0.2419531986117363
Loss made of: CE 0.18995723128318787, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24007044732570648, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.24007044732570648, Class Loss=0.24007044732570648, Reg Loss=0.0
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/19, Loss=0.3070674747228622
Loss made of: CE 0.3063666522502899, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2976856231689453, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.2976856231689453, Class Loss=0.2976856231689453, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/19, Loss=0.28719871342182157
Loss made of: CE 0.3587333559989929, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26965558528900146, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.26965558528900146, Class Loss=0.26965558528900146, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/19, Loss=0.25925575494766234
Loss made of: CE 0.2015661597251892, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25790849328041077, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.25790849328041077, Class Loss=0.25790849328041077, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/19, Loss=0.2558724358677864
Loss made of: CE 0.2708452641963959, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24521538615226746, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.24521538615226746, Class Loss=0.24521538615226746, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/19, Loss=0.24766825884580612
Loss made of: CE 0.23033198714256287, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24293705821037292, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.24293705821037292, Class Loss=0.24293705821037292, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/19, Loss=0.22916978895664214
Loss made of: CE 0.2600667178630829, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23262827098369598, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.23262827098369598, Class Loss=0.23262827098369598, Reg Loss=0.0
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/19, Loss=0.3031361699104309
Loss made of: CE 0.26649853587150574, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2936824560165405, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.2936824560165405, Class Loss=0.2936824560165405, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000525
Epoch 2, Batch 10/19, Loss=0.2588587000966072
Loss made of: CE 0.30485451221466064, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2721893787384033, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.2721893787384033, Class Loss=0.2721893787384033, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/19, Loss=0.2677131354808807
Loss made of: CE 0.29068130254745483, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.257638543844223, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.257638543844223, Class Loss=0.257638543844223, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/19, Loss=0.23818429559469223
Loss made of: CE 0.3216037452220917, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2504532039165497, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.2504532039165497, Class Loss=0.2504532039165497, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000394
Epoch 5, Batch 10/19, Loss=0.23896031975746154
Loss made of: CE 0.24552547931671143, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24182015657424927, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.24182015657424927, Class Loss=0.24182015657424927, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000350
Epoch 6, Batch 10/19, Loss=0.25130157321691515
Loss made of: CE 0.2332172840833664, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24858815968036652, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.24858815968036652, Class Loss=0.24858815968036652, Reg Loss=0.0
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/35, Loss=0.6702118754386902
Loss made of: CE 0.6255835890769958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=0.4759454756975174
Loss made of: CE 0.3468642234802246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=0.35558691024780276
Loss made of: CE 0.42826133966445923, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.47196415066719055, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.47196415066719055, Class Loss=0.47196415066719055, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000584
Epoch 2, Batch 10/35, Loss=0.2882543057203293
Loss made of: CE 0.24534541368484497, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=0.2513207674026489
Loss made of: CE 0.32354357838630676, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=0.25242475867271424
Loss made of: CE 0.22496280074119568, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2623612880706787, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.2623612880706787, Class Loss=0.2623612880706787, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/35, Loss=0.20047785490751266
Loss made of: CE 0.21566134691238403, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=0.24073326885700225
Loss made of: CE 0.29312536120414734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.2082905262708664
Loss made of: CE 0.2277923822402954, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2149086594581604, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.2149086594581604, Class Loss=0.2149086594581604, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000487
Epoch 4, Batch 10/35, Loss=0.19393878132104875
Loss made of: CE 0.16289524734020233, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.17802657634019853
Loss made of: CE 0.13142696022987366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.19367422610521318
Loss made of: CE 0.153829887509346, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1898650825023651, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.1898650825023651, Class Loss=0.1898650825023651, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000438
Epoch 5, Batch 10/35, Loss=0.17439860552549363
Loss made of: CE 0.18129491806030273, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=0.20035368502140044
Loss made of: CE 0.1994459331035614, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.176303830742836
Loss made of: CE 0.17551682889461517, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18781082332134247, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.18781082332134247, Class Loss=0.18781082332134247, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000389
Epoch 6, Batch 10/35, Loss=0.16946712508797646
Loss made of: CE 0.12500867247581482, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.1718366801738739
Loss made of: CE 0.15797904133796692, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.18871403485536575
Loss made of: CE 0.16926780343055725, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18254844844341278, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.18254844844341278, Class Loss=0.18254844844341278, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.8474186658859253, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.802606
Mean Acc: 0.261129
FreqW Acc: 0.655399
Mean IoU: 0.186022
Class IoU:
	class 0: 0.8166111
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.00011211119
	class 7: 0.0
	class 8: 0.0
	class 9: 0.20727117
	class 10: 0.54295313
	class 11: 0.41540256
	class 12: 0.43593925
Class Acc:
	class 0: 0.9871078
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.00011211119
	class 7: 0.0
	class 8: 0.0
	class 9: 0.2430248
	class 10: 0.95125777
	class 11: 0.6252844
	class 12: 0.5878893

federated global round: 14, step: 2
select part of clients to conduct local training
[16, 9, 4, 0]
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/42, Loss=0.48019804060459137
Loss made of: CE 0.47277939319610596, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/42, Loss=0.39384354650974274
Loss made of: CE 0.2896588444709778, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/42, Loss=0.3106654226779938
Loss made of: CE 0.36787688732147217, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/42, Loss=0.254548205435276
Loss made of: CE 0.16707885265350342, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.35402676463127136, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.35402676463127136, Class Loss=0.35402676463127136, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/42, Loss=0.24833821207284928
Loss made of: CE 0.2373902052640915, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/42, Loss=0.23411705791950227
Loss made of: CE 0.21189945936203003, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/42, Loss=0.2258983939886093
Loss made of: CE 0.2119036614894867, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/42, Loss=0.24565370380878448
Loss made of: CE 0.22981026768684387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2385614812374115, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.2385614812374115, Class Loss=0.2385614812374115, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/42, Loss=0.21911171525716783
Loss made of: CE 0.27446091175079346, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/42, Loss=0.20620274990797044
Loss made of: CE 0.2242296189069748, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/42, Loss=0.22311652451753616
Loss made of: CE 0.21646134555339813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/42, Loss=0.26413751393556595
Loss made of: CE 0.21677345037460327, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22715125977993011, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.22715125977993011, Class Loss=0.22715125977993011, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/42, Loss=0.23323531150817872
Loss made of: CE 0.17377427220344543, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/42, Loss=0.21173549741506575
Loss made of: CE 0.2274271547794342, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/42, Loss=0.2058325380086899
Loss made of: CE 0.159610778093338, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/42, Loss=0.21336758583784105
Loss made of: CE 0.198500856757164, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21726810932159424, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.21726810932159424, Class Loss=0.21726810932159424, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/42, Loss=0.19810746759176254
Loss made of: CE 0.22129833698272705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/42, Loss=0.22947684973478316
Loss made of: CE 0.23545771837234497, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/42, Loss=0.22500189244747162
Loss made of: CE 0.2566990256309509, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/42, Loss=0.2108871892094612
Loss made of: CE 0.23394155502319336, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2151174545288086, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.2151174545288086, Class Loss=0.2151174545288086, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/42, Loss=0.22664090394973754
Loss made of: CE 0.1784641444683075, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/42, Loss=0.2134110227227211
Loss made of: CE 0.20134016871452332, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/42, Loss=0.20647655427455902
Loss made of: CE 0.2492797076702118, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/42, Loss=0.23136971592903138
Loss made of: CE 0.26457351446151733, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21800827980041504, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.21800827980041504, Class Loss=0.21800827980041504, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/35, Loss=0.5646670579910278
Loss made of: CE 0.5280017256736755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=0.3610077738761902
Loss made of: CE 0.21286386251449585, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=0.25549795776605605
Loss made of: CE 0.2524092197418213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.37198954820632935, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.37198954820632935, Class Loss=0.37198954820632935, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/35, Loss=0.24125606268644334
Loss made of: CE 0.2843713164329529, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=0.216124027967453
Loss made of: CE 0.197170227766037, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=0.21517276763916016
Loss made of: CE 0.16814079880714417, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2223292887210846, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.2223292887210846, Class Loss=0.2223292887210846, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/35, Loss=0.18967494815587999
Loss made of: CE 0.18088233470916748, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=0.2424078181385994
Loss made of: CE 0.16673395037651062, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.1895871102809906
Loss made of: CE 0.15434053540229797, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.20309023559093475, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.20309023559093475, Class Loss=0.20309023559093475, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/35, Loss=0.1985251300036907
Loss made of: CE 0.11672713607549667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.16097122877836229
Loss made of: CE 0.17629525065422058, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.1766560420393944
Loss made of: CE 0.18097679316997528, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17913945019245148, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.17913945019245148, Class Loss=0.17913945019245148, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/35, Loss=0.16431256085634233
Loss made of: CE 0.13416871428489685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=0.17946739941835405
Loss made of: CE 0.11757504940032959, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.18748925924301146
Loss made of: CE 0.2174115628004074, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17384472489356995, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.17384472489356995, Class Loss=0.17384472489356995, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/35, Loss=0.1677244521677494
Loss made of: CE 0.16942372918128967, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.174787674844265
Loss made of: CE 0.23158061504364014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.15454368144273758
Loss made of: CE 0.15230081975460052, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16661328077316284, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.16661328077316284, Class Loss=0.16661328077316284, Reg Loss=0.0
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/19, Loss=0.26516304165124893
Loss made of: CE 0.20692305266857147, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2667863070964813, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.2667863070964813, Class Loss=0.2667863070964813, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000482
Epoch 2, Batch 10/19, Loss=0.29178638458251954
Loss made of: CE 0.2657451331615448, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26442617177963257, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.26442617177963257, Class Loss=0.26442617177963257, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000394
Epoch 3, Batch 10/19, Loss=0.2534249097108841
Loss made of: CE 0.22710716724395752, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24556493759155273, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.24556493759155273, Class Loss=0.24556493759155273, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000304
Epoch 4, Batch 10/19, Loss=0.2547160118818283
Loss made of: CE 0.23151132464408875, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24804621934890747, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.24804621934890747, Class Loss=0.24804621934890747, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000211
Epoch 5, Batch 10/19, Loss=0.237265907227993
Loss made of: CE 0.27390801906585693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23800553381443024, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.23800553381443024, Class Loss=0.23800553381443024, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000113
Epoch 6, Batch 10/19, Loss=0.23261187225580215
Loss made of: CE 0.2086971253156662, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2412216067314148, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.2412216067314148, Class Loss=0.2412216067314148, Reg Loss=0.0
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000304
Epoch 1, Batch 10/19, Loss=0.2635468527674675
Loss made of: CE 0.2586805820465088, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2616920471191406, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.2616920471191406, Class Loss=0.2616920471191406, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000258
Epoch 2, Batch 10/19, Loss=0.24409767240285873
Loss made of: CE 0.29383695125579834, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2502577006816864, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.2502577006816864, Class Loss=0.2502577006816864, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000211
Epoch 3, Batch 10/19, Loss=0.2612800121307373
Loss made of: CE 0.29371821880340576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2524573802947998, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.2524573802947998, Class Loss=0.2524573802947998, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000163
Epoch 4, Batch 10/19, Loss=0.2368810549378395
Loss made of: CE 0.29782041907310486, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24661129713058472, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.24661129713058472, Class Loss=0.24661129713058472, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000113
Epoch 5, Batch 10/19, Loss=0.2371917799115181
Loss made of: CE 0.24959731101989746, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24095740914344788, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.24095740914344788, Class Loss=0.24095740914344788, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000061
Epoch 6, Batch 10/19, Loss=0.2467827871441841
Loss made of: CE 0.2373630702495575, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25023290514945984, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.25023290514945984, Class Loss=0.25023290514945984, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.8649031519889832, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.813102
Mean Acc: 0.276920
FreqW Acc: 0.673457
Mean IoU: 0.212869
Class IoU:
	class 0: 0.83069134
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 4.0660045e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.20228373
	class 10: 0.80897343
	class 11: 0.45394447
	class 12: 0.47136596
Class Acc:
	class 0: 0.9880675
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 4.0660045e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.22911717
	class 10: 0.8733566
	class 11: 0.59787726
	class 12: 0.91150284

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[11, 6, 10, 7]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=1.6868646025657654
Loss made of: CE 1.396388053894043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=1.301669216156006
Loss made of: CE 0.9101815223693848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.8906416475772858
Loss made of: CE 0.8649711608886719, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6175873428583145
Loss made of: CE 0.38517603278160095, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.47738429605960847
Loss made of: CE 0.33767515420913696, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.42936166524887087
Loss made of: CE 0.40699172019958496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.37901337444782257
Loss made of: CE 0.3703697621822357, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.3557270258665085
Loss made of: CE 0.3532261848449707, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.3379526257514954
Loss made of: CE 0.3257109522819519, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.31129030883312225
Loss made of: CE 0.3198535740375519, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6731330752372742, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.6731330752372742, Class Loss=0.6731330752372742, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/102, Loss=0.3089819893240929
Loss made of: CE 0.2221519947052002, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.3019766002893448
Loss made of: CE 0.23833012580871582, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.27034797668457033
Loss made of: CE 0.31549835205078125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.2954494386911392
Loss made of: CE 0.360452264547348, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.26485755741596223
Loss made of: CE 0.29193979501724243, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.319716614484787
Loss made of: CE 0.26938945055007935, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.24767459630966188
Loss made of: CE 0.24455398321151733, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.27765337377786636
Loss made of: CE 0.19195036590099335, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.24903227537870407
Loss made of: CE 0.4279201030731201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.2741507440805435
Loss made of: CE 0.2082233726978302, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.281186044216156, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.281186044216156, Class Loss=0.281186044216156, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/102, Loss=0.24568493366241456
Loss made of: CE 0.2903293967247009, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.27042816281318666
Loss made of: CE 0.30368682742118835, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.23608689159154891
Loss made of: CE 0.24221491813659668, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.22240481227636338
Loss made of: CE 0.22934839129447937, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.24543365687131882
Loss made of: CE 0.23100106418132782, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.22476287931203842
Loss made of: CE 0.2130931317806244, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.2477259635925293
Loss made of: CE 0.15291084349155426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.25163374096155167
Loss made of: CE 0.20636874437332153, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.22044967859983444
Loss made of: CE 0.23967091739177704, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.24905974864959718
Loss made of: CE 0.2059338092803955, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24101155996322632, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.24101155996322632, Class Loss=0.24101155996322632, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/102, Loss=0.2495410993695259
Loss made of: CE 0.24546340107917786, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.20478513538837434
Loss made of: CE 0.18900269269943237, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.24568568021059037
Loss made of: CE 0.3718695640563965, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.22309266924858093
Loss made of: CE 0.1916547268629074, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.23170911222696305
Loss made of: CE 0.3016993999481201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.2016647696495056
Loss made of: CE 0.20636731386184692, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.20376360416412354
Loss made of: CE 0.30977851152420044, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.2265834018588066
Loss made of: CE 0.3077728748321533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.22614843845367433
Loss made of: CE 0.15842902660369873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.24274181127548217
Loss made of: CE 0.3299531936645508, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2254313826560974, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.2254313826560974, Class Loss=0.2254313826560974, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/102, Loss=0.2146647870540619
Loss made of: CE 0.20462751388549805, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.23504222184419632
Loss made of: CE 0.18464016914367676, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.21466191112995148
Loss made of: CE 0.14911752939224243, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.21318074315786362
Loss made of: CE 0.25996631383895874, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.21744202077388763
Loss made of: CE 0.16973209381103516, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.21885679960250853
Loss made of: CE 0.24117636680603027, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.19766398519277573
Loss made of: CE 0.23104193806648254, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.17277886122465133
Loss made of: CE 0.15427030622959137, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.20126069635152816
Loss made of: CE 0.1975746601819992, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.19495833069086074
Loss made of: CE 0.19066274166107178, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20839086174964905, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.20839086174964905, Class Loss=0.20839086174964905, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/102, Loss=0.19387942552566528
Loss made of: CE 0.17621225118637085, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.19563815891742706
Loss made of: CE 0.21221362054347992, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.1976662680506706
Loss made of: CE 0.17711439728736877, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.21942897289991378
Loss made of: CE 0.2604537606239319, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.19728537946939467
Loss made of: CE 0.17489634454250336, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.2024344027042389
Loss made of: CE 0.18055838346481323, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.21036914587020875
Loss made of: CE 0.230173259973526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.19029309302568437
Loss made of: CE 0.18709072470664978, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.19612792134284973
Loss made of: CE 0.20535433292388916, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.17988827526569368
Loss made of: CE 0.19463913142681122, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19786670804023743, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.19786670804023743, Class Loss=0.19786670804023743, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=1.7610801935195923
Loss made of: CE 1.4040149450302124, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.3161984145641328
Loss made of: CE 1.238860845565796, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.464271068572998, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=1.464271068572998, Class Loss=1.464271068572998, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/23, Loss=0.9125796735286713
Loss made of: CE 0.9835821390151978, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.6967729061841965
Loss made of: CE 0.4985567033290863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7753375768661499, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.7753375768661499, Class Loss=0.7753375768661499, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/23, Loss=0.5747160643339158
Loss made of: CE 0.580704927444458, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.49822044670581817
Loss made of: CE 0.505365252494812, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5256286859512329, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.5256286859512329, Class Loss=0.5256286859512329, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/23, Loss=0.4190218985080719
Loss made of: CE 0.4813011884689331, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.411040136218071
Loss made of: CE 0.3495450019836426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41091352701187134, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.41091352701187134, Class Loss=0.41091352701187134, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/23, Loss=0.3594619005918503
Loss made of: CE 0.40659627318382263, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.3344857931137085
Loss made of: CE 0.2849167585372925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34944239258766174, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.34944239258766174, Class Loss=0.34944239258766174, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/23, Loss=0.3521639883518219
Loss made of: CE 0.37657779455184937, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.29172157049179076
Loss made of: CE 0.30534815788269043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32191723585128784, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.32191723585128784, Class Loss=0.32191723585128784, Reg Loss=0.0
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=1.681998872756958
Loss made of: CE 1.647135615348816, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.356442403793335
Loss made of: CE 1.0254229307174683, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.4583854675292969, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=1.4583854675292969, Class Loss=1.4583854675292969, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/23, Loss=0.8887764751911164
Loss made of: CE 0.8270620107650757, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.6448660314083099
Loss made of: CE 0.5920844078063965, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7602259516716003, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.7602259516716003, Class Loss=0.7602259516716003, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/23, Loss=0.5698266923427582
Loss made of: CE 0.42798417806625366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.4743847131729126
Loss made of: CE 0.3693166673183441, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5161100029945374, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.5161100029945374, Class Loss=0.5161100029945374, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/23, Loss=0.43873284161090853
Loss made of: CE 0.3481321334838867, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.3870704352855682
Loss made of: CE 0.36962541937828064, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4034646451473236, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.4034646451473236, Class Loss=0.4034646451473236, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/23, Loss=0.346865177154541
Loss made of: CE 0.27548569440841675, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.35988145172595976
Loss made of: CE 0.4092390537261963, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3521437644958496, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.3521437644958496, Class Loss=0.3521437644958496, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/23, Loss=0.3115159451961517
Loss made of: CE 0.2654864490032196, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.32338218092918397
Loss made of: CE 0.32686179876327515, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.31455662846565247, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.31455662846565247, Class Loss=0.31455662846565247, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=1.8085499167442323
Loss made of: CE 1.575537919998169, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=1.2108909130096435
Loss made of: CE 1.1452531814575195, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.8277772307395935
Loss made of: CE 0.6858252286911011, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6579335689544678
Loss made of: CE 0.4476313591003418, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.4466566026210785
Loss made of: CE 0.4381701350212097, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.3993738055229187
Loss made of: CE 0.42563411593437195, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.39989246279001234
Loss made of: CE 0.45163506269454956, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.386337023973465
Loss made of: CE 0.43421655893325806, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.33679474592208863
Loss made of: CE 0.29583314061164856, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.3456847220659256
Loss made of: CE 0.3739926815032959, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6744269132614136, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.6744269132614136, Class Loss=0.6744269132614136, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/102, Loss=0.2898206800222397
Loss made of: CE 0.32320499420166016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.282659187912941
Loss made of: CE 0.3164028823375702, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.31503309309482574
Loss made of: CE 0.27238720655441284, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.2978909805417061
Loss made of: CE 0.24506239593029022, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.26978187561035155
Loss made of: CE 0.22199372947216034, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.27013653963804246
Loss made of: CE 0.23826152086257935, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.28461098819971087
Loss made of: CE 0.30704984068870544, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.24680868089199065
Loss made of: CE 0.23454535007476807, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.2414665326476097
Loss made of: CE 0.20104381442070007, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.2504253938794136
Loss made of: CE 0.2435026466846466, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2735547125339508, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.2735547125339508, Class Loss=0.2735547125339508, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/102, Loss=0.2588029280304909
Loss made of: CE 0.2769070863723755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.22720145136117936
Loss made of: CE 0.20338866114616394, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.23519512712955476
Loss made of: CE 0.2082040011882782, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.24808167815208435
Loss made of: CE 0.18591365218162537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.237297323346138
Loss made of: CE 0.2566474378108978, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.24693289697170256
Loss made of: CE 0.1989210546016693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.24202005565166473
Loss made of: CE 0.19973477721214294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.22967879921197892
Loss made of: CE 0.16516739130020142, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.2676098495721817
Loss made of: CE 0.24299165606498718, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.22951051592826843
Loss made of: CE 0.17335957288742065, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2414940744638443, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.2414940744638443, Class Loss=0.2414940744638443, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/102, Loss=0.20310457795858383
Loss made of: CE 0.20895008742809296, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.2389560878276825
Loss made of: CE 0.22553691267967224, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.2148890346288681
Loss made of: CE 0.20614081621170044, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.23472292870283126
Loss made of: CE 0.23637700080871582, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.2284279003739357
Loss made of: CE 0.25360628962516785, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.2478064626455307
Loss made of: CE 0.299377977848053, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.21468503922224044
Loss made of: CE 0.21631550788879395, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.23070159554481506
Loss made of: CE 0.21933579444885254, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.2139564961194992
Loss made of: CE 0.187482088804245, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.2197154715657234
Loss made of: CE 0.20826193690299988, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22488857805728912, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.22488857805728912, Class Loss=0.22488857805728912, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/102, Loss=0.22885656207799912
Loss made of: CE 0.22919651865959167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.21658594757318497
Loss made of: CE 0.23953241109848022, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.21836423575878144
Loss made of: CE 0.2767963111400604, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.19569418132305144
Loss made of: CE 0.1826144903898239, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.2146160736680031
Loss made of: CE 0.28868556022644043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.19540804624557495
Loss made of: CE 0.1802709549665451, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.1876356765627861
Loss made of: CE 0.1762920320034027, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.21058714538812637
Loss made of: CE 0.17931824922561646, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.22233960926532745
Loss made of: CE 0.29102909564971924, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.20299351066350937
Loss made of: CE 0.18464389443397522, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20897276699543, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.20897276699543, Class Loss=0.20897276699543, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/102, Loss=0.19915298372507095
Loss made of: CE 0.2204546332359314, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.2235172525048256
Loss made of: CE 0.1814982146024704, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.1919579789042473
Loss made of: CE 0.1689005345106125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.20481391996145248
Loss made of: CE 0.18184971809387207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.18878736197948456
Loss made of: CE 0.26996445655822754, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.1708870932459831
Loss made of: CE 0.1772843599319458, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.19207455664873124
Loss made of: CE 0.1675632894039154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.18017720580101013
Loss made of: CE 0.1362602412700653, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.18471576869487763
Loss made of: CE 0.17685025930404663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.20398241132497788
Loss made of: CE 0.3039224147796631, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1953440010547638, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.1953440010547638, Class Loss=0.1953440010547638, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.23814058303833, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.767176
Mean Acc: 0.160355
FreqW Acc: 0.591704
Mean IoU: 0.125770
Class IoU:
	class 0: 0.7608702
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.008876391
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00023973502
	class 14: 0.69111246
	class 15: 0.67697495
	class 16: 1.4109301e-05
Class Acc:
	class 0: 0.99082047
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.00887945
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00023973502
	class 14: 0.88977486
	class 15: 0.83630604
	class 16: 1.4109301e-05

federated global round: 16, step: 3
select part of clients to conduct local training
[7, 11, 16, 18]
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/102, Loss=0.3058141678571701
Loss made of: CE 0.3293563425540924, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.25344853699207304
Loss made of: CE 0.31686100363731384, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.22884403467178344
Loss made of: CE 0.20514950156211853, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.2762513279914856
Loss made of: CE 0.22863638401031494, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.22667315155267714
Loss made of: CE 0.2590416669845581, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.2369440034031868
Loss made of: CE 0.22699110209941864, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.2693556174635887
Loss made of: CE 0.30943557620048523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.2492096945643425
Loss made of: CE 0.3105534315109253, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.22926996052265167
Loss made of: CE 0.22216451168060303, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.24325335174798965
Loss made of: CE 0.2519044876098633, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2512464225292206, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.2512464225292206, Class Loss=0.2512464225292206, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/102, Loss=0.19993380457162857
Loss made of: CE 0.2023608386516571, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.21841910034418105
Loss made of: CE 0.22836679220199585, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.23398174345493317
Loss made of: CE 0.1897195428609848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.2257049262523651
Loss made of: CE 0.2016931027173996, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.20998508036136626
Loss made of: CE 0.1788390576839447, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.21150512099266053
Loss made of: CE 0.18838028609752655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.223309488594532
Loss made of: CE 0.23523199558258057, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.19047214984893798
Loss made of: CE 0.18796446919441223, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.20730179399251938
Loss made of: CE 0.1585172712802887, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.208326256275177
Loss made of: CE 0.19712629914283752, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21200840175151825, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.21200840175151825, Class Loss=0.21200840175151825, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/102, Loss=0.20224152207374574
Loss made of: CE 0.20543818175792694, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.19109122604131698
Loss made of: CE 0.17379292845726013, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.19184330850839615
Loss made of: CE 0.20671314001083374, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.19926899224519729
Loss made of: CE 0.1869553178548813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.19890438318252562
Loss made of: CE 0.24105983972549438, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.20862917453050614
Loss made of: CE 0.16104814410209656, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.1894809350371361
Loss made of: CE 0.17061352729797363, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.20288273245096206
Loss made of: CE 0.14440502226352692, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.22134332209825516
Loss made of: CE 0.2357545793056488, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.19212244302034379
Loss made of: CE 0.16007989645004272, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19940349459648132, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.19940349459648132, Class Loss=0.19940349459648132, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/102, Loss=0.1765827029943466
Loss made of: CE 0.1976909637451172, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.1998485654592514
Loss made of: CE 0.20437906682491302, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.2072366788983345
Loss made of: CE 0.17878985404968262, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.19667659550905228
Loss made of: CE 0.19673094153404236, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.19362854063510895
Loss made of: CE 0.1846970021724701, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.2092854782938957
Loss made of: CE 0.29958376288414, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.18950977623462678
Loss made of: CE 0.17910811305046082, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.18934343457221986
Loss made of: CE 0.19642679393291473, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.18491896390914916
Loss made of: CE 0.1697373390197754, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.1817551225423813
Loss made of: CE 0.183988556265831, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.19331766664981842, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.19331766664981842, Class Loss=0.19331766664981842, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/102, Loss=0.19503064453601837
Loss made of: CE 0.21327786147594452, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.18746356219053267
Loss made of: CE 0.19117188453674316, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.18510952740907669
Loss made of: CE 0.20633816719055176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.17119178920984268
Loss made of: CE 0.1560421735048294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.1835484117269516
Loss made of: CE 0.236692413687706, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.17167331874370576
Loss made of: CE 0.1476319134235382, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.17249300330877304
Loss made of: CE 0.18253189325332642, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.18719835877418517
Loss made of: CE 0.15330296754837036, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.19854874461889266
Loss made of: CE 0.2722562253475189, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.16608627438545226
Loss made of: CE 0.15657109022140503, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18163658678531647, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.18163658678531647, Class Loss=0.18163658678531647, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/102, Loss=0.1749316468834877
Loss made of: CE 0.20112906396389008, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.19585027247667314
Loss made of: CE 0.1641930341720581, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.18421829640865325
Loss made of: CE 0.15475130081176758, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.18172473087906837
Loss made of: CE 0.15424597263336182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.1657021388411522
Loss made of: CE 0.23463469743728638, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.15417254716157913
Loss made of: CE 0.12072008848190308, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.168015493452549
Loss made of: CE 0.1589450240135193, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.17344795167446136
Loss made of: CE 0.12528982758522034, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.1667889401316643
Loss made of: CE 0.15424875915050507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.1809277579188347
Loss made of: CE 0.2788218855857849, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17625339329242706, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.17625339329242706, Class Loss=0.17625339329242706, Reg Loss=0.0
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/102, Loss=0.2700544446706772
Loss made of: CE 0.3651304244995117, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.29653194844722747
Loss made of: CE 0.2862529158592224, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.26417856216430663
Loss made of: CE 0.23458819091320038, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.25859826654195783
Loss made of: CE 0.18984560668468475, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.2664411038160324
Loss made of: CE 0.2017533779144287, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.26245037019252776
Loss made of: CE 0.23743079602718353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.2494909420609474
Loss made of: CE 0.2413070648908615, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.24452419430017472
Loss made of: CE 0.24860194325447083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.22097012251615525
Loss made of: CE 0.22450511157512665, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.21541251242160797
Loss made of: CE 0.21968023478984833, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.25504162907600403, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.25504162907600403, Class Loss=0.25504162907600403, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/102, Loss=0.23090502470731736
Loss made of: CE 0.1674022674560547, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.22393743693828583
Loss made of: CE 0.2094552218914032, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.2043601766228676
Loss made of: CE 0.2562929689884186, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.2260970041155815
Loss made of: CE 0.24315747618675232, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.2062900960445404
Loss made of: CE 0.22712016105651855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.23841714411973952
Loss made of: CE 0.2132236659526825, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.19209877103567125
Loss made of: CE 0.1896059215068817, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.21701323091983796
Loss made of: CE 0.15659624338150024, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.2075730413198471
Loss made of: CE 0.3302677571773529, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.2100916624069214
Loss made of: CE 0.1829211413860321, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2164425253868103, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.2164425253868103, Class Loss=0.2164425253868103, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/102, Loss=0.20070638209581376
Loss made of: CE 0.19890742003917694, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.22260746061801912
Loss made of: CE 0.24190422892570496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.19641173481941224
Loss made of: CE 0.2031436413526535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.19094510972499848
Loss made of: CE 0.20027196407318115, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.20049690455198288
Loss made of: CE 0.2125200480222702, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.18302317708730698
Loss made of: CE 0.1605679839849472, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.20620400011539458
Loss made of: CE 0.14942406117916107, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.2056937336921692
Loss made of: CE 0.18920306861400604, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.19575692117214202
Loss made of: CE 0.1950145959854126, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.20388944149017335
Loss made of: CE 0.1648821085691452, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.20043222606182098, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.20043222606182098, Class Loss=0.20043222606182098, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/102, Loss=0.20600570887327194
Loss made of: CE 0.20117907226085663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.17308249771595002
Loss made of: CE 0.15961703658103943, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.2137747198343277
Loss made of: CE 0.31514662504196167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.1879196658730507
Loss made of: CE 0.15819600224494934, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.20456153601408006
Loss made of: CE 0.3017406165599823, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.17835916578769684
Loss made of: CE 0.1567881554365158, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.17434879541397094
Loss made of: CE 0.25099843740463257, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.19741863906383514
Loss made of: CE 0.24364344775676727, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.19977183789014816
Loss made of: CE 0.13997960090637207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.20501070022583007
Loss made of: CE 0.28491687774658203, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.19349735975265503, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.19349735975265503, Class Loss=0.19349735975265503, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/102, Loss=0.18229837268590926
Loss made of: CE 0.1696050763130188, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.20681602358818055
Loss made of: CE 0.18457363545894623, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.18706125319004058
Loss made of: CE 0.15644571185112, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.18385342955589296
Loss made of: CE 0.19498257339000702, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.18934203088283538
Loss made of: CE 0.16770264506340027, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.18654977679252624
Loss made of: CE 0.18991665542125702, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.16332516074180603
Loss made of: CE 0.1687909960746765, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.1478842429816723
Loss made of: CE 0.13011479377746582, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.1776798829436302
Loss made of: CE 0.21082523465156555, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.16842222213745117
Loss made of: CE 0.18601004779338837, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17936165630817413, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.17936165630817413, Class Loss=0.17936165630817413, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/102, Loss=0.16882653832435607
Loss made of: CE 0.14575281739234924, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.16917947977781295
Loss made of: CE 0.1664092242717743, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.17128862589597701
Loss made of: CE 0.17429010570049286, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.19350053369998932
Loss made of: CE 0.22337839007377625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.1728280544281006
Loss made of: CE 0.1700044870376587, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.17711804509162904
Loss made of: CE 0.14521978795528412, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.1816539376974106
Loss made of: CE 0.18775057792663574, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.18184239119291307
Loss made of: CE 0.1961410492658615, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.17061376720666885
Loss made of: CE 0.17359855771064758, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.1684650719165802
Loss made of: CE 0.19895398616790771, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17533870041370392, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.17533870041370392, Class Loss=0.17533870041370392, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/105, Loss=0.3648126110434532
Loss made of: CE 0.5601352453231812, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/105, Loss=0.31547378897666933
Loss made of: CE 0.31236279010772705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/105, Loss=0.2811423748731613
Loss made of: CE 0.28755635023117065, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/105, Loss=0.278423111140728
Loss made of: CE 0.18889515101909637, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/105, Loss=0.25258585065603256
Loss made of: CE 0.24178999662399292, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/105, Loss=0.24304728209972382
Loss made of: CE 0.3623013496398926, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/105, Loss=0.29055400043725965
Loss made of: CE 0.21709772944450378, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/105, Loss=0.27036373913288114
Loss made of: CE 0.3526615500450134, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/105, Loss=0.25597836822271347
Loss made of: CE 0.2567085921764374, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/105, Loss=0.24421258121728898
Loss made of: CE 0.22682148218154907, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.27837803959846497, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.27837803959846497, Class Loss=0.27837803959846497, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/105, Loss=0.23260729908943176
Loss made of: CE 0.19533151388168335, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/105, Loss=0.24169186353683472
Loss made of: CE 0.2847534120082855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/105, Loss=0.23158399164676666
Loss made of: CE 0.2584126591682434, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/105, Loss=0.23657347410917282
Loss made of: CE 0.1801750659942627, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/105, Loss=0.22376956939697265
Loss made of: CE 0.26266202330589294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/105, Loss=0.2098824366927147
Loss made of: CE 0.14842650294303894, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/105, Loss=0.20169162452220918
Loss made of: CE 0.17906320095062256, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/105, Loss=0.22189775854349136
Loss made of: CE 0.20942102372646332, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/105, Loss=0.23349512368440628
Loss made of: CE 0.19401490688323975, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/105, Loss=0.21446049511432647
Loss made of: CE 0.23468509316444397, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22380462288856506, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.22380462288856506, Class Loss=0.22380462288856506, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/105, Loss=0.19276743978261948
Loss made of: CE 0.17020270228385925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/105, Loss=0.2142386645078659
Loss made of: CE 0.21128076314926147, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/105, Loss=0.20067058950662614
Loss made of: CE 0.1494394838809967, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/105, Loss=0.2088286757469177
Loss made of: CE 0.2959350347518921, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/105, Loss=0.18508933782577514
Loss made of: CE 0.18837396800518036, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/105, Loss=0.2043374165892601
Loss made of: CE 0.2997978925704956, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/105, Loss=0.19617561995983124
Loss made of: CE 0.21054862439632416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/105, Loss=0.19395310431718826
Loss made of: CE 0.23145508766174316, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/105, Loss=0.18680870532989502
Loss made of: CE 0.2130911946296692, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/105, Loss=0.22466069161891938
Loss made of: CE 0.19413761794567108, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.20061112940311432, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.20061112940311432, Class Loss=0.20061112940311432, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/105, Loss=0.1815155878663063
Loss made of: CE 0.14423154294490814, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/105, Loss=0.18338074833154677
Loss made of: CE 0.1624474823474884, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/105, Loss=0.17488277703523636
Loss made of: CE 0.15219227969646454, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/105, Loss=0.174586284160614
Loss made of: CE 0.13118019700050354, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/105, Loss=0.18754007071256637
Loss made of: CE 0.19580626487731934, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/105, Loss=0.2038738414645195
Loss made of: CE 0.18629097938537598, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/105, Loss=0.19253870844841003
Loss made of: CE 0.17863580584526062, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/105, Loss=0.21091975271701813
Loss made of: CE 0.18936023116111755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/105, Loss=0.20312367826700212
Loss made of: CE 0.2045607566833496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/105, Loss=0.19433270990848542
Loss made of: CE 0.17974364757537842, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18886978924274445, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.18886978924274445, Class Loss=0.18886978924274445, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/105, Loss=0.18974127620458603
Loss made of: CE 0.2502088248729706, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/105, Loss=0.19974115788936614
Loss made of: CE 0.17650549113750458, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/105, Loss=0.17124190479516982
Loss made of: CE 0.14092719554901123, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/105, Loss=0.2049081653356552
Loss made of: CE 0.20620815455913544, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/105, Loss=0.17034320235252381
Loss made of: CE 0.28777003288269043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/105, Loss=0.16867104023694993
Loss made of: CE 0.18015798926353455, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/105, Loss=0.16405607610940934
Loss made of: CE 0.1420760452747345, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/105, Loss=0.1869828924536705
Loss made of: CE 0.17228657007217407, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/105, Loss=0.18366722762584686
Loss made of: CE 0.16872982680797577, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/105, Loss=0.18080025315284728
Loss made of: CE 0.1758468598127365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18090322613716125, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.18090322613716125, Class Loss=0.18090322613716125, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/105, Loss=0.19674188792705535
Loss made of: CE 0.1478973776102066, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/105, Loss=0.19376400709152222
Loss made of: CE 0.3819821774959564, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/105, Loss=0.1679605782032013
Loss made of: CE 0.18120649456977844, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/105, Loss=0.1714133784174919
Loss made of: CE 0.16841208934783936, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/105, Loss=0.1591477170586586
Loss made of: CE 0.1605907678604126, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/105, Loss=0.1657536134123802
Loss made of: CE 0.1438150405883789, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/105, Loss=0.16490011364221574
Loss made of: CE 0.15276813507080078, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/105, Loss=0.18526917845010757
Loss made of: CE 0.16394257545471191, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/105, Loss=0.17159606367349625
Loss made of: CE 0.14674970507621765, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/105, Loss=0.15457785427570342
Loss made of: CE 0.14059486985206604, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17331500351428986, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.17331500351428986, Class Loss=0.17331500351428986, Reg Loss=0.0
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.3010666862130165
Loss made of: CE 0.33685821294784546, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.29039007276296613
Loss made of: CE 0.24177305400371552, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.24975084364414216
Loss made of: CE 0.23620274662971497, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.26993086785078046
Loss made of: CE 0.20319555699825287, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.24314635545015334
Loss made of: CE 0.19440528750419617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.2579283595085144
Loss made of: CE 0.302328884601593, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.23279115408658982
Loss made of: CE 0.27618154883384705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.22713708281517028
Loss made of: CE 0.23360595107078552, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.23534486442804337
Loss made of: CE 0.2204369306564331, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.2316742494702339
Loss made of: CE 0.20720802247524261, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2545103132724762, Reg Loss=0.0
Clinet index 18, End of Epoch 1/6, Average Loss=0.2545103132724762, Class Loss=0.2545103132724762, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/102, Loss=0.21391931772232056
Loss made of: CE 0.165094792842865, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.217847640812397
Loss made of: CE 0.34534165263175964, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.2225898966193199
Loss made of: CE 0.2336706817150116, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.1994519501924515
Loss made of: CE 0.19847947359085083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.22441770285367965
Loss made of: CE 0.2515641152858734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.21328894942998886
Loss made of: CE 0.21548256278038025, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.19657862782478333
Loss made of: CE 0.13723395764827728, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.22734344378113747
Loss made of: CE 0.32112646102905273, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.1921777680516243
Loss made of: CE 0.2248988002538681, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.21452305763959884
Loss made of: CE 0.1915842592716217, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21282804012298584, Reg Loss=0.0
Clinet index 18, End of Epoch 2/6, Average Loss=0.21282804012298584, Class Loss=0.21282804012298584, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/102, Loss=0.2079487606883049
Loss made of: CE 0.1761372685432434, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.19483630061149598
Loss made of: CE 0.20486801862716675, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.21730797588825226
Loss made of: CE 0.17059418559074402, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.2011110544204712
Loss made of: CE 0.19185714423656464, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.20342544019222258
Loss made of: CE 0.19155947864055634, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.1871957316994667
Loss made of: CE 0.18016432225704193, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.19393431544303893
Loss made of: CE 0.16491666436195374, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.19861936271190644
Loss made of: CE 0.1923314929008484, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.19626352190971375
Loss made of: CE 0.130056232213974, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.18225790709257125
Loss made of: CE 0.1750771403312683, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19830013811588287, Reg Loss=0.0
Clinet index 18, End of Epoch 3/6, Average Loss=0.19830013811588287, Class Loss=0.19830013811588287, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/102, Loss=0.1862143024802208
Loss made of: CE 0.16703924536705017, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.19672904014587403
Loss made of: CE 0.20797237753868103, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.19572581350803375
Loss made of: CE 0.17350122332572937, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.18181748390197755
Loss made of: CE 0.19858789443969727, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.2201856255531311
Loss made of: CE 0.19218552112579346, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.17612823694944382
Loss made of: CE 0.19548723101615906, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.1764152690768242
Loss made of: CE 0.13524362444877625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.16563254296779634
Loss made of: CE 0.15898630023002625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.18052562028169633
Loss made of: CE 0.2027168720960617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.18598912209272384
Loss made of: CE 0.16260989010334015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18580082058906555, Reg Loss=0.0
Clinet index 18, End of Epoch 4/6, Average Loss=0.18580082058906555, Class Loss=0.18580082058906555, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/102, Loss=0.1818331614136696
Loss made of: CE 0.1705659031867981, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.1790747180581093
Loss made of: CE 0.15834219753742218, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.17926108688116074
Loss made of: CE 0.16004693508148193, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.1844346046447754
Loss made of: CE 0.17077206075191498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.17216980457305908
Loss made of: CE 0.17298582196235657, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.18382468372583388
Loss made of: CE 0.1725349873304367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.1759406015276909
Loss made of: CE 0.2368011474609375, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.18269478231668473
Loss made of: CE 0.18230029940605164, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.19206595569849014
Loss made of: CE 0.18761596083641052, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.17589251846075057
Loss made of: CE 0.12565234303474426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18065103888511658, Reg Loss=0.0
Clinet index 18, End of Epoch 5/6, Average Loss=0.18065103888511658, Class Loss=0.18065103888511658, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/102, Loss=0.16860257387161254
Loss made of: CE 0.17240068316459656, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.16994281858205795
Loss made of: CE 0.13051287829875946, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.1828881487250328
Loss made of: CE 0.141952782869339, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.15621478259563445
Loss made of: CE 0.1777557134628296, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.16714171841740608
Loss made of: CE 0.13463245332241058, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.1821116253733635
Loss made of: CE 0.1791708916425705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.1752152219414711
Loss made of: CE 0.1628940999507904, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.18314409106969834
Loss made of: CE 0.14885938167572021, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.1677294723689556
Loss made of: CE 0.1448008269071579, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.17550344169139862
Loss made of: CE 0.17154483497142792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1736336052417755, Reg Loss=0.0
Clinet index 18, End of Epoch 6/6, Average Loss=0.1736336052417755, Class Loss=0.1736336052417755, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.5133206844329834, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.779769
Mean Acc: 0.198886
FreqW Acc: 0.612525
Mean IoU: 0.159698
Class IoU:
	class 0: 0.7718398
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.4097329
	class 14: 0.7736926
	class 15: 0.7595937
	class 16: 1.4109301e-05
Class Acc:
	class 0: 0.9897509
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.6007018
	class 14: 0.89391184
	class 15: 0.89668506
	class 16: 1.4109301e-05

federated global round: 17, step: 3
select part of clients to conduct local training
[5, 3, 17, 11]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.19348828494548798
Loss made of: CE 0.18950901925563812, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.18332410156726836
Loss made of: CE 0.16892075538635254, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.17849114835262297
Loss made of: CE 0.1630869358778, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.1759973481297493
Loss made of: CE 0.18195810914039612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.16112801134586335
Loss made of: CE 0.23219478130340576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.19251834899187087
Loss made of: CE 0.356580913066864, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.1735981747508049
Loss made of: CE 0.21378707885742188, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.18673881143331528
Loss made of: CE 0.20299822092056274, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.1891037255525589
Loss made of: CE 0.1381428837776184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.16357595175504686
Loss made of: CE 0.14256948232650757, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1796427220106125, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.1796427220106125, Class Loss=0.1796427220106125, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/102, Loss=0.18892356902360916
Loss made of: CE 0.1557101607322693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.1731097273528576
Loss made of: CE 0.15343749523162842, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.16636088043451308
Loss made of: CE 0.1463562697172165, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.17296814918518066
Loss made of: CE 0.1579897254705429, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.18778323084115983
Loss made of: CE 0.13771341741085052, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.16277297139167785
Loss made of: CE 0.14728429913520813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.15929628759622574
Loss made of: CE 0.16475367546081543, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.199206380546093
Loss made of: CE 0.2259913682937622, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.15734114721417428
Loss made of: CE 0.14718352258205414, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.16852683275938035
Loss made of: CE 0.11907297372817993, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1730392575263977, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.1730392575263977, Class Loss=0.1730392575263977, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/102, Loss=0.16227374821901322
Loss made of: CE 0.14194312691688538, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.16533832848072053
Loss made of: CE 0.12248788774013519, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.16472336798906326
Loss made of: CE 0.18118427693843842, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.19249738603830338
Loss made of: CE 0.15899980068206787, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.175210802257061
Loss made of: CE 0.2305610179901123, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.16738453209400178
Loss made of: CE 0.18360909819602966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.15946442410349845
Loss made of: CE 0.20565634965896606, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.16949260383844375
Loss made of: CE 0.15309548377990723, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.16175012439489364
Loss made of: CE 0.14627516269683838, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.14811521098017694
Loss made of: CE 0.12651894986629486, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16609741747379303, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.16609741747379303, Class Loss=0.16609741747379303, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/102, Loss=0.18228188157081604
Loss made of: CE 0.1803273856639862, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.14879164174199105
Loss made of: CE 0.15003998577594757, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.16245292201638223
Loss made of: CE 0.16563475131988525, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.17849305346608163
Loss made of: CE 0.1717594563961029, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.14238884150981904
Loss made of: CE 0.1480083018541336, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.16673726290464402
Loss made of: CE 0.20506426692008972, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.1636913850903511
Loss made of: CE 0.12049758434295654, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.1541303053498268
Loss made of: CE 0.1506471335887909, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.15636153519153595
Loss made of: CE 0.17323808372020721, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.14558870419859887
Loss made of: CE 0.14758732914924622, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1598530411720276, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.1598530411720276, Class Loss=0.1598530411720276, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/102, Loss=0.14353200644254685
Loss made of: CE 0.16369721293449402, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.1644568383693695
Loss made of: CE 0.15207675099372864, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.17319339513778687
Loss made of: CE 0.14925318956375122, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.15391950756311418
Loss made of: CE 0.16528116166591644, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.14814570993185044
Loss made of: CE 0.15190543234348297, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.15141065269708634
Loss made of: CE 0.14811581373214722, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.14472214579582215
Loss made of: CE 0.11362167447805405, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.1545919172465801
Loss made of: CE 0.18384727835655212, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.16457617059350013
Loss made of: CE 0.1118035763502121, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.14668721407651902
Loss made of: CE 0.12063716351985931, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15395759046077728, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.15395759046077728, Class Loss=0.15395759046077728, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/102, Loss=0.14724478572607042
Loss made of: CE 0.12729257345199585, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.13752852454781533
Loss made of: CE 0.11565792560577393, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.16408538147807122
Loss made of: CE 0.16766856610774994, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.14642181918025016
Loss made of: CE 0.1522766351699829, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.16163405850529672
Loss made of: CE 0.23862415552139282, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.14117771312594413
Loss made of: CE 0.11771953105926514, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.167311829328537
Loss made of: CE 0.1973688304424286, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.1473821818828583
Loss made of: CE 0.14739489555358887, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.15526022315025328
Loss made of: CE 0.11132057756185532, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.1531709536910057
Loss made of: CE 0.13479562103748322, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15205518901348114, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.15205518901348114, Class Loss=0.15205518901348114, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.17969987392425538
Loss made of: CE 0.20897988975048065, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.18333653062582017
Loss made of: CE 0.16033610701560974, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.18778972327709198
Loss made of: CE 0.17380914092063904, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.1665353462100029
Loss made of: CE 0.2406877875328064, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.16494527757167815
Loss made of: CE 0.19197845458984375, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.17138439416885376
Loss made of: CE 0.18167667090892792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.18311728537082672
Loss made of: CE 0.1801433265209198, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.1605376794934273
Loss made of: CE 0.17942768335342407, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.2055944859981537
Loss made of: CE 0.19585436582565308, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.18227692693471909
Loss made of: CE 0.19734081625938416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.17930221557617188, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.17930221557617188, Class Loss=0.17930221557617188, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/102, Loss=0.1725511685013771
Loss made of: CE 0.22994516789913177, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.18985891342163086
Loss made of: CE 0.2091083526611328, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.1697309546172619
Loss made of: CE 0.19352738559246063, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.18321032971143722
Loss made of: CE 0.12980517745018005, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.18808376789093018
Loss made of: CE 0.16523925960063934, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.15479618534445763
Loss made of: CE 0.15644147992134094, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.1681808814406395
Loss made of: CE 0.12650883197784424, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.1614734299480915
Loss made of: CE 0.13664761185646057, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.16005714237689972
Loss made of: CE 0.14599154889583588, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.1728483334183693
Loss made of: CE 0.1413005292415619, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1715361475944519, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.1715361475944519, Class Loss=0.1715361475944519, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/102, Loss=0.1757109619677067
Loss made of: CE 0.12110098451375961, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.1599244147539139
Loss made of: CE 0.13503721356391907, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.15655332207679748
Loss made of: CE 0.15383535623550415, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.17909337729215621
Loss made of: CE 0.17602913081645966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.17216019183397294
Loss made of: CE 0.13896986842155457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.16216579526662828
Loss made of: CE 0.1733996868133545, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.1544135607779026
Loss made of: CE 0.10130530595779419, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.1495942495763302
Loss made of: CE 0.14500927925109863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.16552552729845046
Loss made of: CE 0.14384034276008606, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.15968342274427413
Loss made of: CE 0.22285811603069305, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16367778182029724, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.16367778182029724, Class Loss=0.16367778182029724, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/102, Loss=0.17315800189971925
Loss made of: CE 0.15110109746456146, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.1703165054321289
Loss made of: CE 0.18761764466762543, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.15455286502838134
Loss made of: CE 0.15843066573143005, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.14088265523314475
Loss made of: CE 0.1628016084432602, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.17221204191446304
Loss made of: CE 0.18039266765117645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.1556036114692688
Loss made of: CE 0.13224053382873535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.1506409041583538
Loss made of: CE 0.2234981507062912, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.15623674988746644
Loss made of: CE 0.11186017096042633, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.15252259075641633
Loss made of: CE 0.14801517128944397, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.16070572957396506
Loss made of: CE 0.18065938353538513, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15855926275253296, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.15855926275253296, Class Loss=0.15855926275253296, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/102, Loss=0.14240813329815866
Loss made of: CE 0.12370821833610535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.16847223341464995
Loss made of: CE 0.1560199111700058, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.1556834265589714
Loss made of: CE 0.15238729119300842, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.15447356700897216
Loss made of: CE 0.14202046394348145, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.14927423670887946
Loss made of: CE 0.1249304860830307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.1496899589896202
Loss made of: CE 0.10016891360282898, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.1554940603673458
Loss made of: CE 0.10200612246990204, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.16013724952936173
Loss made of: CE 0.1316245198249817, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.14913955107331275
Loss made of: CE 0.13779059052467346, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.16826828569173813
Loss made of: CE 0.13212734460830688, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15537990629673004, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.15537990629673004, Class Loss=0.15537990629673004, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/102, Loss=0.1512145608663559
Loss made of: CE 0.14679937064647675, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.1527707114815712
Loss made of: CE 0.13153652846813202, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.13848664984107018
Loss made of: CE 0.11648299545049667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.14183111414313315
Loss made of: CE 0.10810953378677368, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.1352662429213524
Loss made of: CE 0.13620993494987488, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.1786540523171425
Loss made of: CE 0.1838497817516327, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.15147330164909362
Loss made of: CE 0.12416698038578033, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.1607063092291355
Loss made of: CE 0.1761956661939621, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.14456465616822242
Loss made of: CE 0.16777148842811584, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.16318428069353103
Loss made of: CE 0.12669968605041504, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15201860666275024, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.15201860666275024, Class Loss=0.15201860666275024, Reg Loss=0.0
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=0.7805190324783325
Loss made of: CE 0.5249474048614502, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=0.5236415088176727
Loss made of: CE 0.4966122806072235, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6217240691184998, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.6217240691184998, Class Loss=0.6217240691184998, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/23, Loss=0.34339033663272855
Loss made of: CE 0.2502865493297577, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.3192497819662094
Loss made of: CE 0.2674749791622162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32769447565078735, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.32769447565078735, Class Loss=0.32769447565078735, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/23, Loss=0.27961494624614713
Loss made of: CE 0.18949465453624725, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.26181048452854155
Loss made of: CE 0.26593178510665894, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26554813981056213, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.26554813981056213, Class Loss=0.26554813981056213, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/23, Loss=0.26085603386163714
Loss made of: CE 0.3339768350124359, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.22170064598321915
Loss made of: CE 0.24286529421806335, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23955275118350983, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.23955275118350983, Class Loss=0.23955275118350983, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/23, Loss=0.2377336636185646
Loss made of: CE 0.28937309980392456, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.21349699497222902
Loss made of: CE 0.18019354343414307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2260572463274002, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.2260572463274002, Class Loss=0.2260572463274002, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/23, Loss=0.22479199171066283
Loss made of: CE 0.22062063217163086, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.21197274178266526
Loss made of: CE 0.24080899357795715, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21401193737983704, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.21401193737983704, Class Loss=0.21401193737983704, Reg Loss=0.0
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/102, Loss=0.1574123077094555
Loss made of: CE 0.19088909029960632, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.1784755542874336
Loss made of: CE 0.14928627014160156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.16899804174900054
Loss made of: CE 0.17722545564174652, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.18286855071783065
Loss made of: CE 0.11492860317230225, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.18536969721317292
Loss made of: CE 0.14293162524700165, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.1864377647638321
Loss made of: CE 0.16178351640701294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.18122774362564087
Loss made of: CE 0.17445549368858337, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.1756615474820137
Loss made of: CE 0.2009013593196869, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.16127399653196334
Loss made of: CE 0.13682593405246735, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.1693590134382248
Loss made of: CE 0.17330561578273773, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.17544782161712646, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.17544782161712646, Class Loss=0.17544782161712646, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000600
Epoch 2, Batch 10/102, Loss=0.18109819442033767
Loss made of: CE 0.12493178248405457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.16606846153736116
Loss made of: CE 0.16215819120407104, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.1608004316687584
Loss made of: CE 0.1682528853416443, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.164688315987587
Loss made of: CE 0.17050695419311523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.1644985184073448
Loss made of: CE 0.17529812455177307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.1871343657374382
Loss made of: CE 0.18908321857452393, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.14414338544011115
Loss made of: CE 0.14333102107048035, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.17317894846200943
Loss made of: CE 0.13285128772258759, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.16753815859556198
Loss made of: CE 0.28724342584609985, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.16029828488826753
Loss made of: CE 0.1506378948688507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16786764562129974, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.16786764562129974, Class Loss=0.16786764562129974, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/102, Loss=0.1688183218240738
Loss made of: CE 0.1567920744419098, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.18215980678796767
Loss made of: CE 0.17947256565093994, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.15852393507957457
Loss made of: CE 0.18979063630104065, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.1611938774585724
Loss made of: CE 0.16653957962989807, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.16540004163980485
Loss made of: CE 0.1662638783454895, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.15243419930338858
Loss made of: CE 0.12244947254657745, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.16809209287166596
Loss made of: CE 0.12956030666828156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.16786724030971528
Loss made of: CE 0.17093589901924133, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.16286139488220214
Loss made of: CE 0.18800215423107147, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.16376332566142082
Loss made of: CE 0.12348025292158127, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16518382728099823, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.16518382728099823, Class Loss=0.16518382728099823, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/102, Loss=0.17308058738708496
Loss made of: CE 0.161777526140213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.14811214059591293
Loss made of: CE 0.12912407517433167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.16809020936489105
Loss made of: CE 0.24769604206085205, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.15977611988782883
Loss made of: CE 0.1255134791135788, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.1654573366045952
Loss made of: CE 0.19966968894004822, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.15062111020088195
Loss made of: CE 0.1296987235546112, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.14631479680538179
Loss made of: CE 0.19981513917446136, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.1598769098520279
Loss made of: CE 0.19469422101974487, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.17001608312129973
Loss made of: CE 0.1320415586233139, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.18737978488206863
Loss made of: CE 0.25378620624542236, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1624065786600113, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.1624065786600113, Class Loss=0.1624065786600113, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000504
Epoch 5, Batch 10/102, Loss=0.1579306408762932
Loss made of: CE 0.14566859602928162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.17352224588394166
Loss made of: CE 0.1480330228805542, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.15762471705675124
Loss made of: CE 0.12578336894512177, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.16145721524953843
Loss made of: CE 0.15851643681526184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.17063549309968948
Loss made of: CE 0.16819560527801514, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.16730901896953582
Loss made of: CE 0.17417173087596893, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.14396680518984795
Loss made of: CE 0.15776346623897552, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.12924770787358283
Loss made of: CE 0.11188950389623642, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.15350379645824433
Loss made of: CE 0.16308380663394928, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.15768992453813552
Loss made of: CE 0.1719823181629181, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15738020837306976, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.15738020837306976, Class Loss=0.15738020837306976, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000471
Epoch 6, Batch 10/102, Loss=0.14570900648832322
Loss made of: CE 0.1643146276473999, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.15173247158527375
Loss made of: CE 0.14641161262989044, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.15614039450883865
Loss made of: CE 0.1480550765991211, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.17248115986585616
Loss made of: CE 0.23122632503509521, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.14841307774186135
Loss made of: CE 0.14489537477493286, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.15881207063794137
Loss made of: CE 0.13549837470054626, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.1566731944680214
Loss made of: CE 0.18548868596553802, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.15454182773828506
Loss made of: CE 0.13047920167446136, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.155856454372406
Loss made of: CE 0.13083122670650482, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.14854468181729316
Loss made of: CE 0.16649770736694336, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15474843978881836, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.15474843978881836, Class Loss=0.15474843978881836, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.5757477283477783, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.783670
Mean Acc: 0.217398
FreqW Acc: 0.619133
Mean IoU: 0.172394
Class IoU:
	class 0: 0.77650297
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.44484812
	class 14: 0.76339835
	class 15: 0.7863296
	class 16: 0.15961453
Class Acc:
	class 0: 0.9904263
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.748874
	class 14: 0.89934653
	class 15: 0.89646304
	class 16: 0.16065791

federated global round: 18, step: 3
select part of clients to conduct local training
[9, 11, 13, 10]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.1770037516951561
Loss made of: CE 0.15735255181789398, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.14765816181898117
Loss made of: CE 0.17220596969127655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.191602723300457
Loss made of: CE 0.19946658611297607, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.15521692484617233
Loss made of: CE 0.17133180797100067, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.16195855736732484
Loss made of: CE 0.18008065223693848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.16241777539253235
Loss made of: CE 0.20374199748039246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.16498474553227424
Loss made of: CE 0.18078093230724335, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.15522556006908417
Loss made of: CE 0.16609147191047668, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.1668591395020485
Loss made of: CE 0.17162933945655823, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.1492501102387905
Loss made of: CE 0.1726871132850647, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.16307519376277924, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.16307519376277924, Class Loss=0.16307519376277924, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/102, Loss=0.1449921503663063
Loss made of: CE 0.12631843984127045, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.15076765418052673
Loss made of: CE 0.1647450029850006, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.1900907501578331
Loss made of: CE 0.2694973945617676, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.15275774076581
Loss made of: CE 0.1414310336112976, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.17330034524202348
Loss made of: CE 0.15245670080184937, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.15265081226825714
Loss made of: CE 0.14619538187980652, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.1485435001552105
Loss made of: CE 0.11675089597702026, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.1525113731622696
Loss made of: CE 0.13535605370998383, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.16247363090515138
Loss made of: CE 0.1929345577955246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.1532510757446289
Loss made of: CE 0.16910824179649353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.15772120654582977, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.15772120654582977, Class Loss=0.15772120654582977, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/102, Loss=0.15791322141885758
Loss made of: CE 0.12270620465278625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.14725561290979386
Loss made of: CE 0.18667815625667572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.14769397303462029
Loss made of: CE 0.11639021337032318, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.1360398143529892
Loss made of: CE 0.1121637225151062, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.1392043948173523
Loss made of: CE 0.176425501704216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.17408009022474288
Loss made of: CE 0.17269229888916016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.16633757650852204
Loss made of: CE 0.2060393989086151, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.14916038289666175
Loss made of: CE 0.14346621930599213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.1416801244020462
Loss made of: CE 0.11775152385234833, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.1553021714091301
Loss made of: CE 0.13886061310768127, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1508226990699768, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.1508226990699768, Class Loss=0.1508226990699768, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/102, Loss=0.1584811218082905
Loss made of: CE 0.16079355776309967, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.13266769498586656
Loss made of: CE 0.17904379963874817, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.134797403216362
Loss made of: CE 0.12958011031150818, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.16664258092641832
Loss made of: CE 0.14472797513008118, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.14374600052833558
Loss made of: CE 0.12475606054067612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.14723000824451446
Loss made of: CE 0.12335020303726196, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.14583783969283104
Loss made of: CE 0.1088629812002182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.16096162050962448
Loss made of: CE 0.17403459548950195, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.15826659351587297
Loss made of: CE 0.12780126929283142, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.14089285284280778
Loss made of: CE 0.1388421356678009, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1487276405096054, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.1487276405096054, Class Loss=0.1487276405096054, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/102, Loss=0.14663263112306596
Loss made of: CE 0.10518072545528412, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.15255303233861922
Loss made of: CE 0.15467636287212372, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.14803261309862137
Loss made of: CE 0.10426803678274155, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.14003464579582214
Loss made of: CE 0.14086414873600006, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.1366070531308651
Loss made of: CE 0.09789329767227173, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.15730808973312377
Loss made of: CE 0.2312162220478058, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.13572577089071275
Loss made of: CE 0.14742320775985718, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.1375392757356167
Loss made of: CE 0.10672410577535629, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.1329367958009243
Loss made of: CE 0.11741428077220917, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.15731532052159308
Loss made of: CE 0.11847337335348129, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14444948732852936, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.14444948732852936, Class Loss=0.14444948732852936, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/102, Loss=0.13664958775043487
Loss made of: CE 0.12973305583000183, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.12814390063285827
Loss made of: CE 0.11126270890235901, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.14188189804553986
Loss made of: CE 0.18931636214256287, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.12819071337580681
Loss made of: CE 0.1094735786318779, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.1642294242978096
Loss made of: CE 0.12541571259498596, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.14098560586571693
Loss made of: CE 0.10890845954418182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.134449353069067
Loss made of: CE 0.14404135942459106, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.15490612387657166
Loss made of: CE 0.20058505237102509, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.14050640016794205
Loss made of: CE 0.15511244535446167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.13329601809382438
Loss made of: CE 0.13156163692474365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1403389722108841, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.1403389722108841, Class Loss=0.1403389722108841, Reg Loss=0.0
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000438
Epoch 1, Batch 10/102, Loss=0.15281159356236457
Loss made of: CE 0.16927072405815125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.16332173645496367
Loss made of: CE 0.13836079835891724, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.16112365275621415
Loss made of: CE 0.16689857840538025, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.17454168051481248
Loss made of: CE 0.13016143441200256, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.1717201992869377
Loss made of: CE 0.12521399557590485, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.18900171518325806
Loss made of: CE 0.15843498706817627, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.1619423970580101
Loss made of: CE 0.16530871391296387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.16583812087774277
Loss made of: CE 0.2039247453212738, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.1492402233183384
Loss made of: CE 0.13244754076004028, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.15633086934685708
Loss made of: CE 0.1637878268957138, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1648073047399521, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.1648073047399521, Class Loss=0.1648073047399521, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000405
Epoch 2, Batch 10/102, Loss=0.1659643217921257
Loss made of: CE 0.12674444913864136, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.15659524649381637
Loss made of: CE 0.17514410614967346, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.15107732117176056
Loss made of: CE 0.1586073338985443, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.15313986837863922
Loss made of: CE 0.15228180587291718, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.1427759975194931
Loss made of: CE 0.12303076684474945, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.17137159407138824
Loss made of: CE 0.1565975546836853, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.1322651021182537
Loss made of: CE 0.1395784169435501, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.16921958178281785
Loss made of: CE 0.12671563029289246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.15325390845537185
Loss made of: CE 0.26314279437065125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.14848060682415962
Loss made of: CE 0.13435058295726776, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.15512177348136902, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.15512177348136902, Class Loss=0.15512177348136902, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/102, Loss=0.15820964872837068
Loss made of: CE 0.16207462549209595, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.15873735398054123
Loss made of: CE 0.15527550876140594, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.14993543028831482
Loss made of: CE 0.16947214305400848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.14659352973103523
Loss made of: CE 0.14537331461906433, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.14880156517028809
Loss made of: CE 0.16424228250980377, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.14451772943139077
Loss made of: CE 0.12510597705841064, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.1567583680152893
Loss made of: CE 0.12826409935951233, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.15097083449363707
Loss made of: CE 0.1548287719488144, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.15569946318864822
Loss made of: CE 0.14752480387687683, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.15417259633541108
Loss made of: CE 0.14103055000305176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.152616947889328, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.152616947889328, Class Loss=0.152616947889328, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/102, Loss=0.1594314306974411
Loss made of: CE 0.15567368268966675, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.13980360627174376
Loss made of: CE 0.114194855093956, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.1581190511584282
Loss made of: CE 0.221586674451828, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.16202387809753419
Loss made of: CE 0.13922539353370667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.15976858735084534
Loss made of: CE 0.22414568066596985, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.14580883085727692
Loss made of: CE 0.1328810304403305, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.14353608712553978
Loss made of: CE 0.20354613661766052, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.1527231179177761
Loss made of: CE 0.17549753189086914, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.15962066650390624
Loss made of: CE 0.11961646378040314, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.17723648846149445
Loss made of: CE 0.23681066930294037, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15528371930122375, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.15528371930122375, Class Loss=0.15528371930122375, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/102, Loss=0.14936070740222931
Loss made of: CE 0.1500226855278015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.1652227446436882
Loss made of: CE 0.13707131147384644, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.1470585733652115
Loss made of: CE 0.12111811339855194, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.15210068970918655
Loss made of: CE 0.15085333585739136, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.15748955607414244
Loss made of: CE 0.1661868542432785, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.15208605974912642
Loss made of: CE 0.1562333106994629, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.13396383300423623
Loss made of: CE 0.12383946031332016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.12818782404065132
Loss made of: CE 0.10480716079473495, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.14576321914792062
Loss made of: CE 0.15778636932373047, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.13844107016921042
Loss made of: CE 0.15924420952796936, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14734305441379547, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.14734305441379547, Class Loss=0.14734305441379547, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000270
Epoch 6, Batch 10/102, Loss=0.13932992815971373
Loss made of: CE 0.11759549379348755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.14679787158966065
Loss made of: CE 0.14099165797233582, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.14483038783073426
Loss made of: CE 0.14045889675617218, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.17137806713581086
Loss made of: CE 0.22938060760498047, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.14744633585214614
Loss made of: CE 0.1444515585899353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.1548958033323288
Loss made of: CE 0.12862622737884521, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.14773132130503655
Loss made of: CE 0.17932459712028503, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.14357906952500343
Loss made of: CE 0.14889052510261536, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.1498619057238102
Loss made of: CE 0.1638220250606537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.1401454985141754
Loss made of: CE 0.14294710755348206, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1483350247144699, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.1483350247144699, Class Loss=0.1483350247144699, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=0.6156688511371613
Loss made of: CE 0.4306653141975403, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=0.38571652472019197
Loss made of: CE 0.38720130920410156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.47496485710144043, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.47496485710144043, Class Loss=0.47496485710144043, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/23, Loss=0.31560864448547366
Loss made of: CE 0.29776549339294434, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.2607205227017403
Loss made of: CE 0.306046724319458, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2779969871044159, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.2779969871044159, Class Loss=0.2779969871044159, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/23, Loss=0.2582867622375488
Loss made of: CE 0.20992669463157654, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.23445485383272172
Loss made of: CE 0.2428017109632492, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23791207373142242, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.23791207373142242, Class Loss=0.23791207373142242, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/23, Loss=0.22506292164325714
Loss made of: CE 0.20856992900371552, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.2224014788866043
Loss made of: CE 0.1798824965953827, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21982942521572113, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.21982942521572113, Class Loss=0.21982942521572113, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/23, Loss=0.21288715302944183
Loss made of: CE 0.21672505140304565, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.19661548882722854
Loss made of: CE 0.1833818405866623, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2145846039056778, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.2145846039056778, Class Loss=0.2145846039056778, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/23, Loss=0.22284504920244216
Loss made of: CE 0.30481478571891785, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.19390617161989213
Loss made of: CE 0.15779849886894226, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20378640294075012, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.20378640294075012, Class Loss=0.20378640294075012, Reg Loss=0.0
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/23, Loss=0.6111132293939591
Loss made of: CE 0.5141650438308716, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=0.39240304529666903
Loss made of: CE 0.3798254132270813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.48290109634399414, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.48290109634399414, Class Loss=0.48290109634399414, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/23, Loss=0.3122578561306
Loss made of: CE 0.3382719159126282, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.23633505403995514
Loss made of: CE 0.19889800250530243, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27361148595809937, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.27361148595809937, Class Loss=0.27361148595809937, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/23, Loss=0.2320442095398903
Loss made of: CE 0.1955832540988922, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.22952740043401718
Loss made of: CE 0.17003843188285828, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23427797853946686, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.23427797853946686, Class Loss=0.23427797853946686, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/23, Loss=0.21783069670200347
Loss made of: CE 0.20313118398189545, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.22296337634325028
Loss made of: CE 0.21984320878982544, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21937060356140137, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.21937060356140137, Class Loss=0.21937060356140137, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/23, Loss=0.22753870338201523
Loss made of: CE 0.20832714438438416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.21261978447437285
Loss made of: CE 0.24263200163841248, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21765565872192383, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.21765565872192383, Class Loss=0.21765565872192383, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/23, Loss=0.19856901615858077
Loss made of: CE 0.18633273243904114, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.21130123734474182
Loss made of: CE 0.22199255228042603, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20362615585327148, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.20362615585327148, Class Loss=0.20362615585327148, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.5618733167648315, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.785064
Mean Acc: 0.242253
FreqW Acc: 0.622476
Mean IoU: 0.187025
Class IoU:
	class 0: 0.7780937
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.44879544
	class 14: 0.76004523
	class 15: 0.7949625
	class 16: 0.39752364
Class Acc:
	class 0: 0.9867691
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.8003603
	class 14: 0.9029474
	class 15: 0.90602773
	class 16: 0.5221904

federated global round: 19, step: 3
select part of clients to conduct local training
[4, 7, 17, 15]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/105, Loss=0.2210771694779396
Loss made of: CE 0.3408307731151581, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/105, Loss=0.21737949848175048
Loss made of: CE 0.27047544717788696, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/105, Loss=0.17710937112569808
Loss made of: CE 0.2157837152481079, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/105, Loss=0.16358308643102645
Loss made of: CE 0.14604035019874573, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/105, Loss=0.1478760488331318
Loss made of: CE 0.12028100341558456, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/105, Loss=0.16647145450115203
Loss made of: CE 0.18884532153606415, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/105, Loss=0.18584142923355101
Loss made of: CE 0.15400820970535278, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/105, Loss=0.16016851216554642
Loss made of: CE 0.11531676352024078, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/105, Loss=0.17650317251682282
Loss made of: CE 0.1232890635728836, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/105, Loss=0.1643204376101494
Loss made of: CE 0.18030159175395966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.17709432542324066, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.17709432542324066, Class Loss=0.17709432542324066, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/105, Loss=0.14832967072725295
Loss made of: CE 0.151871919631958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/105, Loss=0.15991190150380136
Loss made of: CE 0.16688624024391174, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/105, Loss=0.17507788091897963
Loss made of: CE 0.1473412662744522, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/105, Loss=0.1712159037590027
Loss made of: CE 0.1693647801876068, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/105, Loss=0.1698177143931389
Loss made of: CE 0.2057669758796692, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/105, Loss=0.15714553222060204
Loss made of: CE 0.1490057110786438, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/105, Loss=0.15069397166371346
Loss made of: CE 0.1217467412352562, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/105, Loss=0.15015164762735367
Loss made of: CE 0.12721803784370422, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/105, Loss=0.1340832643210888
Loss made of: CE 0.1136055439710617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/105, Loss=0.17967108637094498
Loss made of: CE 0.17260503768920898, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.15843290090560913, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.15843290090560913, Class Loss=0.15843290090560913, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/105, Loss=0.15945415198802948
Loss made of: CE 0.205750972032547, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/105, Loss=0.1604108288884163
Loss made of: CE 0.16107049584388733, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/105, Loss=0.14718194752931596
Loss made of: CE 0.12965382635593414, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/105, Loss=0.1625283770263195
Loss made of: CE 0.1323026865720749, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/105, Loss=0.15733624622225761
Loss made of: CE 0.21702973544597626, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/105, Loss=0.14524638429284095
Loss made of: CE 0.1345127671957016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/105, Loss=0.16059016287326813
Loss made of: CE 0.15104687213897705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/105, Loss=0.14431102126836776
Loss made of: CE 0.13279977440834045, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/105, Loss=0.15649699196219444
Loss made of: CE 0.19715945422649384, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/105, Loss=0.15629872381687165
Loss made of: CE 0.15582025051116943, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15505757927894592, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.15505757927894592, Class Loss=0.15505757927894592, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/105, Loss=0.13386949449777602
Loss made of: CE 0.17408517003059387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/105, Loss=0.14280666559934616
Loss made of: CE 0.16287939250469208, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/105, Loss=0.15597601979970932
Loss made of: CE 0.12941615283489227, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/105, Loss=0.14110509008169175
Loss made of: CE 0.15321052074432373, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/105, Loss=0.15464149713516234
Loss made of: CE 0.13441511988639832, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/105, Loss=0.15014671981334687
Loss made of: CE 0.246170312166214, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/105, Loss=0.15122010558843613
Loss made of: CE 0.1356278955936432, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/105, Loss=0.1604684039950371
Loss made of: CE 0.1410616636276245, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/105, Loss=0.16456808298826217
Loss made of: CE 0.14829471707344055, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/105, Loss=0.14071716964244843
Loss made of: CE 0.13576075434684753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14892907440662384, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.14892907440662384, Class Loss=0.14892907440662384, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/105, Loss=0.1426522970199585
Loss made of: CE 0.15494415163993835, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/105, Loss=0.15167290568351746
Loss made of: CE 0.18199913203716278, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/105, Loss=0.1459969162940979
Loss made of: CE 0.11407274007797241, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/105, Loss=0.15458585023880006
Loss made of: CE 0.12752145528793335, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/105, Loss=0.14387399777770044
Loss made of: CE 0.14009305834770203, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/105, Loss=0.1702536016702652
Loss made of: CE 0.16683731973171234, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/105, Loss=0.14180774688720704
Loss made of: CE 0.13537687063217163, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/105, Loss=0.14786557257175445
Loss made of: CE 0.13922595977783203, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/105, Loss=0.15583420246839524
Loss made of: CE 0.15206675231456757, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/105, Loss=0.13844799101352692
Loss made of: CE 0.12657946348190308, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14877507090568542, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.14877507090568542, Class Loss=0.14877507090568542, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/105, Loss=0.14606722593307495
Loss made of: CE 0.13959310948848724, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/105, Loss=0.1516812726855278
Loss made of: CE 0.13646867871284485, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/105, Loss=0.1294162355363369
Loss made of: CE 0.11494933068752289, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/105, Loss=0.1494475394487381
Loss made of: CE 0.1266903132200241, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/105, Loss=0.1448355197906494
Loss made of: CE 0.1451134979724884, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/105, Loss=0.14726776331663133
Loss made of: CE 0.17117397487163544, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/105, Loss=0.14583319947123527
Loss made of: CE 0.123451828956604, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/105, Loss=0.1471514567732811
Loss made of: CE 0.11804234981536865, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/105, Loss=0.1531670793890953
Loss made of: CE 0.14166657626628876, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/105, Loss=0.14174884036183358
Loss made of: CE 0.10428818315267563, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14546416699886322, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.14546416699886322, Class Loss=0.14546416699886322, Reg Loss=0.0
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/102, Loss=0.1900091513991356
Loss made of: CE 0.1879349648952484, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.1706104211509228
Loss made of: CE 0.2260635793209076, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.1559121087193489
Loss made of: CE 0.14940603077411652, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.17097695618867875
Loss made of: CE 0.15228866040706635, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.14978109449148178
Loss made of: CE 0.15089017152786255, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.15381240248680114
Loss made of: CE 0.10555826127529144, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.1749449908733368
Loss made of: CE 0.19319510459899902, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.16343033462762832
Loss made of: CE 0.14545178413391113, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.16249621659517288
Loss made of: CE 0.16188079118728638, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.15789450332522392
Loss made of: CE 0.17855846881866455, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.16432255506515503, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.16432255506515503, Class Loss=0.16432255506515503, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000536
Epoch 2, Batch 10/102, Loss=0.14110321402549744
Loss made of: CE 0.14397740364074707, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.1468962773680687
Loss made of: CE 0.16995462775230408, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.16098930388689042
Loss made of: CE 0.14180681109428406, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.1540196418762207
Loss made of: CE 0.1412709653377533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.14859594032168388
Loss made of: CE 0.12786327302455902, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.14719654321670533
Loss made of: CE 0.14283393323421478, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.15583219304680823
Loss made of: CE 0.15630212426185608, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.13877717927098274
Loss made of: CE 0.15048488974571228, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.15001334846019745
Loss made of: CE 0.15173330903053284, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.15073107853531836
Loss made of: CE 0.14251092076301575, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.14949539303779602, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.14949539303779602, Class Loss=0.14949539303779602, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000438
Epoch 3, Batch 10/102, Loss=0.14855913668870926
Loss made of: CE 0.1542634665966034, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.14223186671733856
Loss made of: CE 0.1376471221446991, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.14159257113933563
Loss made of: CE 0.13653042912483215, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.14274034574627875
Loss made of: CE 0.128476083278656, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.144509394466877
Loss made of: CE 0.16636519134044647, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.155089271068573
Loss made of: CE 0.12534195184707642, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.1428130105137825
Loss made of: CE 0.13749536871910095, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.15067090317606927
Loss made of: CE 0.11413606256246567, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.17274261862039567
Loss made of: CE 0.1737442910671234, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.1393915221095085
Loss made of: CE 0.12700258195400238, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14799188077449799, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.14799188077449799, Class Loss=0.14799188077449799, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/102, Loss=0.13112883642315865
Loss made of: CE 0.14493142068386078, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.1611869141459465
Loss made of: CE 0.19501659274101257, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.15127039030194284
Loss made of: CE 0.13533668220043182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.1533709168434143
Loss made of: CE 0.13964027166366577, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.15477639958262443
Loss made of: CE 0.15894128382205963, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.15845496207475662
Loss made of: CE 0.20213386416435242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.14816226735711097
Loss made of: CE 0.1614353060722351, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.1520886927843094
Loss made of: CE 0.13947533071041107, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.14363614320755005
Loss made of: CE 0.14435772597789764, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.13356634378433227
Loss made of: CE 0.1390797346830368, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1490173041820526, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.1490173041820526, Class Loss=0.1490173041820526, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000235
Epoch 5, Batch 10/102, Loss=0.1579820320010185
Loss made of: CE 0.21555380523204803, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.14668841883540154
Loss made of: CE 0.15698739886283875, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.14397879987955092
Loss made of: CE 0.17596325278282166, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.13701239079236985
Loss made of: CE 0.124457448720932, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.15515116304159166
Loss made of: CE 0.226022869348526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.13183868750929834
Loss made of: CE 0.11308115720748901, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.13320555910468102
Loss made of: CE 0.13323450088500977, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.15021985694766044
Loss made of: CE 0.13181240856647491, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.1587613418698311
Loss made of: CE 0.1958213895559311, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.1380845434963703
Loss made of: CE 0.11491196602582932, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14530760049819946, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.14530760049819946, Class Loss=0.14530760049819946, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000126
Epoch 6, Batch 10/102, Loss=0.14303539618849753
Loss made of: CE 0.15651987493038177, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.15873733833432196
Loss made of: CE 0.12658530473709106, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.1388047806918621
Loss made of: CE 0.12331241369247437, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.14849315360188484
Loss made of: CE 0.13862363994121552, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.1331422060728073
Loss made of: CE 0.18319234251976013, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.1305147796869278
Loss made of: CE 0.12089084833860397, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.14291548281908034
Loss made of: CE 0.11941957473754883, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.1413162223994732
Loss made of: CE 0.12164168804883957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.14371052384376526
Loss made of: CE 0.13577131927013397, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.14133441224694251
Loss made of: CE 0.17204627394676208, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1431310623884201, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.1431310623884201, Class Loss=0.1431310623884201, Reg Loss=0.0
Current Client Index:  17
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/23, Loss=0.3756153494119644
Loss made of: CE 0.3276605010032654, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=0.3302882432937622
Loss made of: CE 0.3535492420196533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3462156653404236, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.3462156653404236, Class Loss=0.3462156653404236, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/23, Loss=0.2668513849377632
Loss made of: CE 0.20802699029445648, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.26321475207805634
Loss made of: CE 0.22351686656475067, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.264598548412323, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.264598548412323, Class Loss=0.264598548412323, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/23, Loss=0.24060418605804443
Loss made of: CE 0.15473727881908417, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.23216866999864577
Loss made of: CE 0.24619309604167938, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2321973443031311, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.2321973443031311, Class Loss=0.2321973443031311, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/23, Loss=0.2468881294131279
Loss made of: CE 0.3333595395088196, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.22070720344781875
Loss made of: CE 0.22594714164733887, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22918950021266937, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.22918950021266937, Class Loss=0.22918950021266937, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/23, Loss=0.2344997391104698
Loss made of: CE 0.29657477140426636, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.20886138826608658
Loss made of: CE 0.16462290287017822, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22128404676914215, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.22128404676914215, Class Loss=0.22128404676914215, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/23, Loss=0.23401757180690766
Loss made of: CE 0.23632529377937317, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.21810663044452666
Loss made of: CE 0.25421297550201416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21990574896335602, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.21990574896335602, Class Loss=0.21990574896335602, Reg Loss=0.0
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/103, Loss=0.19047427773475648
Loss made of: CE 0.1473134607076645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/103, Loss=0.16598015949130057
Loss made of: CE 0.15941858291625977, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/103, Loss=0.1694357931613922
Loss made of: CE 0.17512038350105286, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/103, Loss=0.17324317917227744
Loss made of: CE 0.16350947320461273, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/103, Loss=0.15674980282783507
Loss made of: CE 0.23447346687316895, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/103, Loss=0.16492800563573837
Loss made of: CE 0.17685925960540771, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/103, Loss=0.1479668140411377
Loss made of: CE 0.16394461691379547, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/103, Loss=0.19086598604917526
Loss made of: CE 0.1734497994184494, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/103, Loss=0.15547668784856797
Loss made of: CE 0.10010413825511932, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/103, Loss=0.16431011408567428
Loss made of: CE 0.132063627243042, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1694721132516861, Reg Loss=0.0
Clinet index 15, End of Epoch 1/6, Average Loss=0.1694721132516861, Class Loss=0.1694721132516861, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/103, Loss=0.15600980073213577
Loss made of: CE 0.13825540244579315, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/103, Loss=0.15216056108474732
Loss made of: CE 0.14340999722480774, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/103, Loss=0.16067546457052231
Loss made of: CE 0.1798708736896515, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/103, Loss=0.15449194014072418
Loss made of: CE 0.20054319500923157, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/103, Loss=0.1487807735800743
Loss made of: CE 0.13518592715263367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/103, Loss=0.1666186809539795
Loss made of: CE 0.1509866565465927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/103, Loss=0.14750885143876075
Loss made of: CE 0.13453152775764465, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/103, Loss=0.12701452448964118
Loss made of: CE 0.13950663805007935, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/103, Loss=0.13844880610704421
Loss made of: CE 0.08867864310741425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/103, Loss=0.17178168445825576
Loss made of: CE 0.18656286597251892, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1524084210395813, Reg Loss=0.0
Clinet index 15, End of Epoch 2/6, Average Loss=0.1524084210395813, Class Loss=0.1524084210395813, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/103, Loss=0.16383202373981476
Loss made of: CE 0.12059879302978516, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/103, Loss=0.14361701235175134
Loss made of: CE 0.1878463476896286, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/103, Loss=0.14918450340628625
Loss made of: CE 0.22519247233867645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/103, Loss=0.1519410066306591
Loss made of: CE 0.12175017595291138, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/103, Loss=0.14412580281496049
Loss made of: CE 0.16124509274959564, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/103, Loss=0.13754822686314583
Loss made of: CE 0.14086738228797913, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/103, Loss=0.14396760389208793
Loss made of: CE 0.13114696741104126, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/103, Loss=0.14704528898000718
Loss made of: CE 0.12195553630590439, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/103, Loss=0.1372155413031578
Loss made of: CE 0.1359976828098297, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/103, Loss=0.1404545672237873
Loss made of: CE 0.19333675503730774, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1460348218679428, Reg Loss=0.0
Clinet index 15, End of Epoch 3/6, Average Loss=0.1460348218679428, Class Loss=0.1460348218679428, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/103, Loss=0.1493615187704563
Loss made of: CE 0.1444302797317505, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/103, Loss=0.14361261576414108
Loss made of: CE 0.22842702269554138, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/103, Loss=0.14457258209586143
Loss made of: CE 0.1358845829963684, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/103, Loss=0.13416321724653243
Loss made of: CE 0.1414167284965515, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/103, Loss=0.14647585898637772
Loss made of: CE 0.11214089393615723, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/103, Loss=0.1275496542453766
Loss made of: CE 0.11916177719831467, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/103, Loss=0.13625256940722466
Loss made of: CE 0.1439363807439804, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/103, Loss=0.14008673578500747
Loss made of: CE 0.11168339848518372, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/103, Loss=0.1347215585410595
Loss made of: CE 0.15017646551132202, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/103, Loss=0.1523413434624672
Loss made of: CE 0.14854532480239868, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1417059302330017, Reg Loss=0.0
Clinet index 15, End of Epoch 4/6, Average Loss=0.1417059302330017, Class Loss=0.1417059302330017, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/103, Loss=0.1440553605556488
Loss made of: CE 0.09770366549491882, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/103, Loss=0.1375259667634964
Loss made of: CE 0.2005513310432434, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/103, Loss=0.1538034439086914
Loss made of: CE 0.11504495143890381, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/103, Loss=0.1403796538710594
Loss made of: CE 0.13195237517356873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/103, Loss=0.1383107677102089
Loss made of: CE 0.10706119984388351, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/103, Loss=0.14249013662338256
Loss made of: CE 0.1815742701292038, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/103, Loss=0.13633053302764891
Loss made of: CE 0.16057361662387848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/103, Loss=0.15551012381911278
Loss made of: CE 0.12888453900814056, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/103, Loss=0.1616244062781334
Loss made of: CE 0.14366208016872406, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/103, Loss=0.1472475729882717
Loss made of: CE 0.12117721140384674, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14544104039669037, Reg Loss=0.0
Clinet index 15, End of Epoch 5/6, Average Loss=0.14544104039669037, Class Loss=0.14544104039669037, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/103, Loss=0.1369113080203533
Loss made of: CE 0.09513455629348755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/103, Loss=0.13924756348133088
Loss made of: CE 0.1163276731967926, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/103, Loss=0.14005180895328523
Loss made of: CE 0.15921390056610107, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/103, Loss=0.13948026895523072
Loss made of: CE 0.1434958279132843, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/103, Loss=0.13083420023322107
Loss made of: CE 0.10269981622695923, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/103, Loss=0.13901352733373643
Loss made of: CE 0.10507939755916595, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/103, Loss=0.14601518958806992
Loss made of: CE 0.12766163051128387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/103, Loss=0.14079175367951394
Loss made of: CE 0.17656967043876648, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/103, Loss=0.129032451659441
Loss made of: CE 0.1837676614522934, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/103, Loss=0.17491656243801118
Loss made of: CE 0.14172914624214172, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14083345234394073, Reg Loss=0.0
Clinet index 15, End of Epoch 6/6, Average Loss=0.14083345234394073, Class Loss=0.14083345234394073, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.620642066001892, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.785506
Mean Acc: 0.246175
FreqW Acc: 0.622903
Mean IoU: 0.190158
Class IoU:
	class 0: 0.7779891
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.46458507
	class 14: 0.7681183
	class 15: 0.7939994
	class 16: 0.42799613
Class Acc:
	class 0: 0.98664737
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.8073748
	class 14: 0.90245795
	class 15: 0.9063326
	class 16: 0.5821549

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[19, 23, 1, 8]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=2.3915225744247435
Loss made of: CE 2.440673351287842, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=1.7434011816978454
Loss made of: CE 1.4907569885253906, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9283649921417236, Reg Loss=0.0
Clinet index 19, End of Epoch 1/6, Average Loss=1.9283649921417236, Class Loss=1.9283649921417236, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/24, Loss=0.8797681450843811
Loss made of: CE 0.6001784801483154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.7889025568962097
Loss made of: CE 0.5870300531387329, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7994279265403748, Reg Loss=0.0
Clinet index 19, End of Epoch 2/6, Average Loss=0.7994279265403748, Class Loss=0.7994279265403748, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/24, Loss=0.43298385441303255
Loss made of: CE 0.3162383437156677, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.39365248680114745
Loss made of: CE 0.329611599445343, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4074101150035858, Reg Loss=0.0
Clinet index 19, End of Epoch 3/6, Average Loss=0.4074101150035858, Class Loss=0.4074101150035858, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/24, Loss=0.32696561217308046
Loss made of: CE 0.2851649224758148, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.2902702927589417
Loss made of: CE 0.23798701167106628, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3167927861213684, Reg Loss=0.0
Clinet index 19, End of Epoch 4/6, Average Loss=0.3167927861213684, Class Loss=0.3167927861213684, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/24, Loss=0.27414724230766296
Loss made of: CE 0.31507232785224915, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.2741705998778343
Loss made of: CE 0.30207300186157227, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27953940629959106, Reg Loss=0.0
Clinet index 19, End of Epoch 5/6, Average Loss=0.27953940629959106, Class Loss=0.27953940629959106, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/24, Loss=0.27420768439769744
Loss made of: CE 0.30253392457962036, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.2558955684304237
Loss made of: CE 0.2351437509059906, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2640339136123657, Reg Loss=0.0
Clinet index 19, End of Epoch 6/6, Average Loss=0.2640339136123657, Class Loss=0.2640339136123657, Reg Loss=0.0
Current Client Index:  23
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/21, Loss=1.8541085839271545
Loss made of: CE 1.4806711673736572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=1.4480844616889954
Loss made of: CE 1.2994940280914307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6160285472869873, Reg Loss=0.0
Clinet index 23, End of Epoch 1/6, Average Loss=1.6160285472869873, Class Loss=1.6160285472869873, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/21, Loss=1.0754933118820191
Loss made of: CE 0.9382774233818054, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.8006108820438385
Loss made of: CE 0.6041566133499146, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9264089465141296, Reg Loss=0.0
Clinet index 23, End of Epoch 2/6, Average Loss=0.9264089465141296, Class Loss=0.9264089465141296, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/21, Loss=0.6574080407619476
Loss made of: CE 0.5377437472343445, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.5379536420106887
Loss made of: CE 0.6814537048339844, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5840885043144226, Reg Loss=0.0
Clinet index 23, End of Epoch 3/6, Average Loss=0.5840885043144226, Class Loss=0.5840885043144226, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/21, Loss=0.44768732190132143
Loss made of: CE 0.4637736678123474, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.37450531125068665
Loss made of: CE 0.3358426094055176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41176706552505493, Reg Loss=0.0
Clinet index 23, End of Epoch 4/6, Average Loss=0.41176706552505493, Class Loss=0.41176706552505493, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/21, Loss=0.34962611049413683
Loss made of: CE 0.32640722393989563, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.320331846177578
Loss made of: CE 0.44093263149261475, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.333301305770874, Reg Loss=0.0
Clinet index 23, End of Epoch 5/6, Average Loss=0.333301305770874, Class Loss=0.333301305770874, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/21, Loss=0.29822343587875366
Loss made of: CE 0.279875248670578, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.2852102443575859
Loss made of: CE 0.22784654796123505, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2943330705165863, Reg Loss=0.0
Clinet index 23, End of Epoch 6/6, Average Loss=0.2943330705165863, Class Loss=0.2943330705165863, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=2.0996744871139525
Loss made of: CE 2.207608699798584, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.8460370302200317, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=1.8460370302200317, Class Loss=1.8460370302200317, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=1.0006285607814789
Loss made of: CE 0.5836686491966248, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8325194120407104, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.8325194120407104, Class Loss=0.8325194120407104, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=0.45098374485969545
Loss made of: CE 0.4561792016029358, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4013814330101013, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.4013814330101013, Class Loss=0.4013814330101013, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=0.301434189081192
Loss made of: CE 0.2889346778392792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2776946723461151, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.2776946723461151, Class Loss=0.2776946723461151, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=0.20665786862373353
Loss made of: CE 0.19335874915122986, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20542603731155396, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.20542603731155396, Class Loss=0.20542603731155396, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.17589144557714462
Loss made of: CE 0.1702999770641327, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16628649830818176, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.16628649830818176, Class Loss=0.16628649830818176, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=2.2255993127822875
Loss made of: CE 2.1385984420776367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=1.4956833362579345
Loss made of: CE 1.3066115379333496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.7627028226852417, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=1.7627028226852417, Class Loss=1.7627028226852417, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/24, Loss=1.163188523054123
Loss made of: CE 1.1969027519226074, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.9568170189857483
Loss made of: CE 0.7599717974662781, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.008432388305664, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=1.008432388305664, Class Loss=1.008432388305664, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/24, Loss=0.7105669200420379
Loss made of: CE 0.5758551955223083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.551916190981865
Loss made of: CE 0.6045610308647156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6161171793937683, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.6161171793937683, Class Loss=0.6161171793937683, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/24, Loss=0.4383645534515381
Loss made of: CE 0.4285401701927185, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.4415696680545807
Loss made of: CE 0.48042258620262146, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.44184422492980957, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.44184422492980957, Class Loss=0.44184422492980957, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/24, Loss=0.3809244155883789
Loss made of: CE 0.4766612946987152, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.3834989547729492
Loss made of: CE 0.3306175470352173, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.37693676352500916, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.37693676352500916, Class Loss=0.37693676352500916, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/24, Loss=0.35182984471321105
Loss made of: CE 0.3127686083316803, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.33229202032089233
Loss made of: CE 0.2560333013534546, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34205615520477295, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.34205615520477295, Class Loss=0.34205615520477295, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.321104884147644, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.704961
Mean Acc: 0.116682
FreqW Acc: 0.501909
Mean IoU: 0.091921
Class IoU:
	class 0: 0.70783955
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.30718526
	class 14: 0.47010988
	class 15: 0.00067054154
	class 16: 0.13067007
	class 17: 0.00012230942
	class 18: 0.027496245
	class 19: 0.19679445
	class 20: 0.08945887
Class Acc:
	class 0: 0.99869305
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.42085025
	class 14: 0.52122307
	class 15: 0.0006724222
	class 16: 0.13422884
	class 17: 0.00012402242
	class 18: 0.027679885
	class 19: 0.25720546
	class 20: 0.08964584

federated global round: 21, step: 4
select part of clients to conduct local training
[23, 14, 4, 11]
Current Client Index:  23
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/21, Loss=0.6337912142276764
Loss made of: CE 0.5434845685958862, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=0.5481362909078598
Loss made of: CE 0.47630172967910767, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.578134298324585, Reg Loss=0.0
Clinet index 23, End of Epoch 1/6, Average Loss=0.578134298324585, Class Loss=0.578134298324585, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/21, Loss=0.41608104705810545
Loss made of: CE 0.4074045419692993, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.3290277510881424
Loss made of: CE 0.27767789363861084, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36681798100471497, Reg Loss=0.0
Clinet index 23, End of Epoch 2/6, Average Loss=0.36681798100471497, Class Loss=0.36681798100471497, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/21, Loss=0.3204842984676361
Loss made of: CE 0.3148702383041382, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.29698722511529924
Loss made of: CE 0.3702664375305176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3054434359073639, Reg Loss=0.0
Clinet index 23, End of Epoch 3/6, Average Loss=0.3054434359073639, Class Loss=0.3054434359073639, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/21, Loss=0.2824195444583893
Loss made of: CE 0.3275860548019409, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.2574618935585022
Loss made of: CE 0.22683194279670715, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2738335132598877, Reg Loss=0.0
Clinet index 23, End of Epoch 4/6, Average Loss=0.2738335132598877, Class Loss=0.2738335132598877, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/21, Loss=0.2586912870407104
Loss made of: CE 0.23721647262573242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.24219749569892884
Loss made of: CE 0.2689772844314575, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24783086776733398, Reg Loss=0.0
Clinet index 23, End of Epoch 5/6, Average Loss=0.24783086776733398, Class Loss=0.24783086776733398, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/21, Loss=0.24197995513677598
Loss made of: CE 0.19973640143871307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.2142186239361763
Loss made of: CE 0.17259638011455536, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22912219166755676, Reg Loss=0.0
Clinet index 23, End of Epoch 6/6, Average Loss=0.22912219166755676, Class Loss=0.22912219166755676, Reg Loss=0.0
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/26, Loss=0.6552380919456482
Loss made of: CE 0.5063394904136658, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=0.5273911416530609
Loss made of: CE 0.47056901454925537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.56791752576828, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.56791752576828, Class Loss=0.56791752576828, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/26, Loss=0.4090526819229126
Loss made of: CE 0.3816194236278534, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.3527846455574036
Loss made of: CE 0.2985752522945404, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36762768030166626, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.36762768030166626, Class Loss=0.36762768030166626, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/26, Loss=0.3299475580453873
Loss made of: CE 0.4519868791103363, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.2946573033928871
Loss made of: CE 0.24649803340435028, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29659631848335266, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.29659631848335266, Class Loss=0.29659631848335266, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/26, Loss=0.2334473669528961
Loss made of: CE 0.23975567519664764, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.2531485974788666
Loss made of: CE 0.25638604164123535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24161681532859802, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.24161681532859802, Class Loss=0.24161681532859802, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/26, Loss=0.2171528607606888
Loss made of: CE 0.2750295102596283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.23177943527698516
Loss made of: CE 0.21912924945354462, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22178915143013, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.22178915143013, Class Loss=0.22178915143013, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/26, Loss=0.1930624797940254
Loss made of: CE 0.24190549552440643, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.21476650089025498
Loss made of: CE 0.14815747737884521, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20684103667736053, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.20684103667736053, Class Loss=0.20684103667736053, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/26, Loss=0.6435972154140472
Loss made of: CE 0.864184558391571, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=0.529609414935112
Loss made of: CE 0.3978983759880066, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5680265426635742, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.5680265426635742, Class Loss=0.5680265426635742, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/26, Loss=0.41345069110393523
Loss made of: CE 0.5065356492996216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.3451913416385651
Loss made of: CE 0.3263556659221649, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36325761675834656, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.36325761675834656, Class Loss=0.36325761675834656, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/26, Loss=0.3059704452753067
Loss made of: CE 0.2513468861579895, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.2936250180006027
Loss made of: CE 0.32885420322418213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2891582250595093, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.2891582250595093, Class Loss=0.2891582250595093, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/26, Loss=0.2594522267580032
Loss made of: CE 0.233223557472229, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.2342962235212326
Loss made of: CE 0.2227068394422531, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.249015673995018, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.249015673995018, Class Loss=0.249015673995018, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/26, Loss=0.24051560163497926
Loss made of: CE 0.18245026469230652, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.23446006774902345
Loss made of: CE 0.2335343360900879, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23766198754310608, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.23766198754310608, Class Loss=0.23766198754310608, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/26, Loss=0.2016245186328888
Loss made of: CE 0.22444820404052734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.21773245334625244
Loss made of: CE 0.1916026771068573, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2084207683801651, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.2084207683801651, Class Loss=0.2084207683801651, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.753110408782959
Loss made of: CE 0.6768974661827087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.6720480442047119
Loss made of: CE 0.5787219405174255, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6827139258384705, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.6827139258384705, Class Loss=0.6827139258384705, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/24, Loss=0.4310123771429062
Loss made of: CE 0.5104290246963501, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.421722999215126
Loss made of: CE 0.4212390184402466, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.42530304193496704, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.42530304193496704, Class Loss=0.42530304193496704, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/24, Loss=0.35804460644721986
Loss made of: CE 0.43221744894981384, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.342039093375206
Loss made of: CE 0.36781319975852966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.36428147554397583, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.36428147554397583, Class Loss=0.36428147554397583, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/24, Loss=0.28558097034692764
Loss made of: CE 0.2912011742591858, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.32755308747291567
Loss made of: CE 0.3514503836631775, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3110812306404114, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.3110812306404114, Class Loss=0.3110812306404114, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/24, Loss=0.28916580229997635
Loss made of: CE 0.26435038447380066, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.2896528884768486
Loss made of: CE 0.23545730113983154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.28717976808547974, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.28717976808547974, Class Loss=0.28717976808547974, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/24, Loss=0.24588003009557724
Loss made of: CE 0.35093575716018677, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.27231423407793043
Loss made of: CE 0.3137843608856201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2601039707660675, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.2601039707660675, Class Loss=0.2601039707660675, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.541877269744873, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.707213
Mean Acc: 0.144142
FreqW Acc: 0.511127
Mean IoU: 0.092119
Class IoU:
	class 0: 0.7199663
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.025450813
	class 14: 0.20253798
	class 15: 0.0
	class 16: 0.0067696427
	class 17: 0.004042267
	class 18: 0.37090316
	class 19: 0.3029176
	class 20: 0.30191863
Class Acc:
	class 0: 0.9901334
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.026009588
	class 14: 0.20348115
	class 15: 0.0
	class 16: 0.0067696427
	class 17: 0.004121337
	class 18: 0.41681597
	class 19: 0.6240216
	class 20: 0.75562537

federated global round: 22, step: 4
select part of clients to conduct local training
[0, 8, 16, 14]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.42115658223629
Loss made of: CE 0.4810999035835266, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.38813459873199463
Loss made of: CE 0.3521336019039154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39286792278289795, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.39286792278289795, Class Loss=0.39286792278289795, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/24, Loss=0.29187686592340467
Loss made of: CE 0.2723499536514282, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.3118429571390152
Loss made of: CE 0.279569149017334, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3002323508262634, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.3002323508262634, Class Loss=0.3002323508262634, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/24, Loss=0.27551437020301817
Loss made of: CE 0.3312457799911499, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.254561810195446
Loss made of: CE 0.24785828590393066, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26609906554222107, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.26609906554222107, Class Loss=0.26609906554222107, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/24, Loss=0.2504387736320496
Loss made of: CE 0.26286745071411133, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.24941082149744034
Loss made of: CE 0.18051549792289734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2568751275539398, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.2568751275539398, Class Loss=0.2568751275539398, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/24, Loss=0.24491853564977645
Loss made of: CE 0.21060942113399506, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.24055376201868056
Loss made of: CE 0.2723792791366577, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2370026558637619, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.2370026558637619, Class Loss=0.2370026558637619, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/24, Loss=0.2170994222164154
Loss made of: CE 0.2660701870918274, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.22124850302934645
Loss made of: CE 0.20354941487312317, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22079919278621674, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.22079919278621674, Class Loss=0.22079919278621674, Reg Loss=0.0
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/24, Loss=0.49772455990314485
Loss made of: CE 0.5507338047027588, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.37469200491905214
Loss made of: CE 0.331798255443573, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.42698705196380615, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.42698705196380615, Class Loss=0.42698705196380615, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/24, Loss=0.3400250166654587
Loss made of: CE 0.3348763883113861, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.3631495535373688
Loss made of: CE 0.33091580867767334, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3374510407447815, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.3374510407447815, Class Loss=0.3374510407447815, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/24, Loss=0.31691675782203677
Loss made of: CE 0.2535930573940277, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.25767819583415985
Loss made of: CE 0.3319281041622162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28972387313842773, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.28972387313842773, Class Loss=0.28972387313842773, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/24, Loss=0.261132125556469
Loss made of: CE 0.2821815609931946, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.27358459681272507
Loss made of: CE 0.3230295777320862, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27210545539855957, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.27210545539855957, Class Loss=0.27210545539855957, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/24, Loss=0.2642007291316986
Loss made of: CE 0.3164042830467224, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.26558873504400254
Loss made of: CE 0.22884643077850342, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2620716989040375, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.2620716989040375, Class Loss=0.2620716989040375, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/24, Loss=0.24396588057279586
Loss made of: CE 0.219630628824234, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.24253918826580048
Loss made of: CE 0.18742230534553528, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2479599565267563, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.2479599565267563, Class Loss=0.2479599565267563, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.719097912311554
Loss made of: CE 0.5391896963119507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5748116374015808, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.5748116374015808, Class Loss=0.5748116374015808, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/19, Loss=0.28955878019332887
Loss made of: CE 0.2808871269226074, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28284576535224915, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.28284576535224915, Class Loss=0.28284576535224915, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/19, Loss=0.20825414955615998
Loss made of: CE 0.18493887782096863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19976714253425598, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.19976714253425598, Class Loss=0.19976714253425598, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/19, Loss=0.1652056336402893
Loss made of: CE 0.22078005969524384, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1762724071741104, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.1762724071741104, Class Loss=0.1762724071741104, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/19, Loss=0.17272583693265914
Loss made of: CE 0.12000932544469833, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17591358721256256, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.17591358721256256, Class Loss=0.17591358721256256, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/19, Loss=0.14448012560606002
Loss made of: CE 0.12056702375411987, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15422788262367249, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.15422788262367249, Class Loss=0.15422788262367249, Reg Loss=0.0
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/26, Loss=0.3372527793049812
Loss made of: CE 0.27535152435302734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=0.2724343121051788
Loss made of: CE 0.3277100920677185, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.30178317427635193, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.30178317427635193, Class Loss=0.30178317427635193, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000733
Epoch 2, Batch 10/26, Loss=0.24532379657030107
Loss made of: CE 0.32154199481010437, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.23323500156402588
Loss made of: CE 0.1905899941921234, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.236240416765213, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.236240416765213, Class Loss=0.236240416765213, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/26, Loss=0.23685973435640334
Loss made of: CE 0.2930850386619568, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.21204192638397218
Loss made of: CE 0.16925875842571259, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21572376787662506, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.21572376787662506, Class Loss=0.21572376787662506, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000655
Epoch 4, Batch 10/26, Loss=0.17650117576122284
Loss made of: CE 0.18576256930828094, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.19932834655046464
Loss made of: CE 0.20570051670074463, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1902708113193512, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.1902708113193512, Class Loss=0.1902708113193512, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000616
Epoch 5, Batch 10/26, Loss=0.18213202208280563
Loss made of: CE 0.21733127534389496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.19214649274945259
Loss made of: CE 0.18248698115348816, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1842697262763977, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.1842697262763977, Class Loss=0.1842697262763977, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000576
Epoch 6, Batch 10/26, Loss=0.16931465417146682
Loss made of: CE 0.22405225038528442, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.18346872925758362
Loss made of: CE 0.13396373391151428, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18191905319690704, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.18191905319690704, Class Loss=0.18191905319690704, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.627547025680542, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.706413
Mean Acc: 0.142370
FreqW Acc: 0.512826
Mean IoU: 0.086856
Class IoU:
	class 0: 0.7256066
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00071407954
	class 14: 0.040320225
	class 15: 0.0
	class 16: 0.0
	class 17: 0.017580213
	class 18: 0.37166524
	class 19: 0.27293786
	class 20: 0.39515188
Class Acc:
	class 0: 0.98840225
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00071484246
	class 14: 0.040353365
	class 15: 0.0
	class 16: 0.0
	class 17: 0.020364663
	class 18: 0.48793194
	class 19: 0.71854943
	class 20: 0.73346347

federated global round: 23, step: 4
select part of clients to conduct local training
[12, 10, 9, 6]
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/26, Loss=0.2985030308365822
Loss made of: CE 0.22662481665611267, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=0.2838987231254578
Loss made of: CE 0.21900403499603271, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2808699309825897, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.2808699309825897, Class Loss=0.2808699309825897, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/26, Loss=0.23264485150575637
Loss made of: CE 0.2729547917842865, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.2019483342766762
Loss made of: CE 0.1791931390762329, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21463747322559357, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.21463747322559357, Class Loss=0.21463747322559357, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/26, Loss=0.2033836230635643
Loss made of: CE 0.18784964084625244, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.18427042067050933
Loss made of: CE 0.18732903897762299, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19992847740650177, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.19992847740650177, Class Loss=0.19992847740650177, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/26, Loss=0.17479799389839173
Loss made of: CE 0.2013869732618332, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.1816634327173233
Loss made of: CE 0.17335015535354614, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17722053825855255, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.17722053825855255, Class Loss=0.17722053825855255, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/26, Loss=0.17062887996435167
Loss made of: CE 0.14884880185127258, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.16270633935928344
Loss made of: CE 0.18957757949829102, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16842561960220337, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.16842561960220337, Class Loss=0.16842561960220337, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/26, Loss=0.1519496940076351
Loss made of: CE 0.13113783299922943, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.17279810458421707
Loss made of: CE 0.15531519055366516, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16209056973457336, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.16209056973457336, Class Loss=0.16209056973457336, Reg Loss=0.0
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.6550279915332794
Loss made of: CE 0.5510144829750061, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5785053968429565, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.5785053968429565, Class Loss=0.5785053968429565, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/19, Loss=0.3601161390542984
Loss made of: CE 0.2649804949760437, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36766642332077026, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.36766642332077026, Class Loss=0.36766642332077026, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/19, Loss=0.28468924313783645
Loss made of: CE 0.2862013578414917, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2995639443397522, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.2995639443397522, Class Loss=0.2995639443397522, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/19, Loss=0.2513429135084152
Loss made of: CE 0.2809731960296631, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24804268777370453, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.24804268777370453, Class Loss=0.24804268777370453, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/19, Loss=0.2582278594374657
Loss made of: CE 0.19425472617149353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24590030312538147, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.24590030312538147, Class Loss=0.24590030312538147, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/19, Loss=0.23978225737810135
Loss made of: CE 0.2871710956096649, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23498721420764923, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.23498721420764923, Class Loss=0.23498721420764923, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/21, Loss=0.3769981384277344
Loss made of: CE 0.37958288192749023, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=0.2812874346971512
Loss made of: CE 0.2800562083721161, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3281146287918091, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.3281146287918091, Class Loss=0.3281146287918091, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/21, Loss=0.2624694868922234
Loss made of: CE 0.24164390563964844, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.22156345546245576
Loss made of: CE 0.19983187317848206, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24056196212768555, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.24056196212768555, Class Loss=0.24056196212768555, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/21, Loss=0.20839686393737794
Loss made of: CE 0.19840213656425476, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.21412869542837143
Loss made of: CE 0.2170853465795517, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2098398655653, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.2098398655653, Class Loss=0.2098398655653, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/21, Loss=0.17194609493017196
Loss made of: CE 0.187569722533226, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.20112734138965607
Loss made of: CE 0.19310466945171356, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18805691599845886, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.18805691599845886, Class Loss=0.18805691599845886, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/21, Loss=0.1715932384133339
Loss made of: CE 0.1439773589372635, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.1636480450630188
Loss made of: CE 0.13135185837745667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16708597540855408, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.16708597540855408, Class Loss=0.16708597540855408, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/21, Loss=0.17413250356912613
Loss made of: CE 0.17547520995140076, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.1656629577279091
Loss made of: CE 0.18791556358337402, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16862548887729645, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.16862548887729645, Class Loss=0.16862548887729645, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.39602082669734956
Loss made of: CE 0.34387168288230896, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.2955699622631073
Loss made of: CE 0.31574422121047974, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33873867988586426, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.33873867988586426, Class Loss=0.33873867988586426, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/24, Loss=0.2765995815396309
Loss made of: CE 0.27937328815460205, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.24768196046352386
Loss made of: CE 0.266601026058197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26158520579338074, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.26158520579338074, Class Loss=0.26158520579338074, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/24, Loss=0.22776340544223786
Loss made of: CE 0.18664073944091797, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.23686359971761703
Loss made of: CE 0.24405460059642792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23810705542564392, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.23810705542564392, Class Loss=0.23810705542564392, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/24, Loss=0.23748303204774857
Loss made of: CE 0.2286275327205658, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.23537598550319672
Loss made of: CE 0.25933733582496643, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23450712859630585, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.23450712859630585, Class Loss=0.23450712859630585, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/24, Loss=0.23646775782108306
Loss made of: CE 0.3583202362060547, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.21138650476932525
Loss made of: CE 0.1719418466091156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22327135503292084, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.22327135503292084, Class Loss=0.22327135503292084, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/24, Loss=0.21883822977542877
Loss made of: CE 0.21885967254638672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.19564668834209442
Loss made of: CE 0.19157755374908447, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20848099887371063, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.20848099887371063, Class Loss=0.20848099887371063, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.6872252225875854, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.706806
Mean Acc: 0.170636
FreqW Acc: 0.518487
Mean IoU: 0.093670
Class IoU:
	class 0: 0.7313833
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0004149102
	class 14: 0.016861023
	class 15: 0.0
	class 16: 0.0
	class 17: 0.18128543
	class 18: 0.39814198
	class 19: 0.30072597
	class 20: 0.33825895
Class Acc:
	class 0: 0.98014283
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00041527755
	class 14: 0.016867587
	class 15: 0.0
	class 16: 0.0
	class 17: 0.46653622
	class 18: 0.6634423
	class 19: 0.6816679
	class 20: 0.77428865

federated global round: 24, step: 4
select part of clients to conduct local training
[18, 24, 25, 10]
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.4042135179042816
Loss made of: CE 0.30300042033195496, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3902049660682678, Reg Loss=0.0
Clinet index 18, End of Epoch 1/6, Average Loss=0.3902049660682678, Class Loss=0.3902049660682678, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/19, Loss=0.3239652723073959
Loss made of: CE 0.36317333579063416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2947651147842407, Reg Loss=0.0
Clinet index 18, End of Epoch 2/6, Average Loss=0.2947651147842407, Class Loss=0.2947651147842407, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/19, Loss=0.26215261220932007
Loss made of: CE 0.32028767466545105, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2516818344593048, Reg Loss=0.0
Clinet index 18, End of Epoch 3/6, Average Loss=0.2516818344593048, Class Loss=0.2516818344593048, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/19, Loss=0.23412082344293594
Loss made of: CE 0.21335232257843018, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23445327579975128, Reg Loss=0.0
Clinet index 18, End of Epoch 4/6, Average Loss=0.23445327579975128, Class Loss=0.23445327579975128, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/19, Loss=0.24018395692110062
Loss made of: CE 0.1772242784500122, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22931495308876038, Reg Loss=0.0
Clinet index 18, End of Epoch 5/6, Average Loss=0.22931495308876038, Class Loss=0.22931495308876038, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/19, Loss=0.22724955379962922
Loss made of: CE 0.21940664947032928, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2176467329263687, Reg Loss=0.0
Clinet index 18, End of Epoch 6/6, Average Loss=0.2176467329263687, Class Loss=0.2176467329263687, Reg Loss=0.0
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/21, Loss=0.2710557162761688
Loss made of: CE 0.20468172430992126, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=0.25272693037986754
Loss made of: CE 0.2652396857738495, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2578045427799225, Reg Loss=0.0
Clinet index 24, End of Epoch 1/6, Average Loss=0.2578045427799225, Class Loss=0.2578045427799225, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/21, Loss=0.20391591638326645
Loss made of: CE 0.1736491322517395, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.21174442917108535
Loss made of: CE 0.2702653408050537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20676521956920624, Reg Loss=0.0
Clinet index 24, End of Epoch 2/6, Average Loss=0.20676521956920624, Class Loss=0.20676521956920624, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/21, Loss=0.16914112865924835
Loss made of: CE 0.19296300411224365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.1957208275794983
Loss made of: CE 0.2083955705165863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18440547585487366, Reg Loss=0.0
Clinet index 24, End of Epoch 3/6, Average Loss=0.18440547585487366, Class Loss=0.18440547585487366, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/21, Loss=0.17562340050935746
Loss made of: CE 0.2580660283565521, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.16039056330919266
Loss made of: CE 0.15242160856723785, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17178621888160706, Reg Loss=0.0
Clinet index 24, End of Epoch 4/6, Average Loss=0.17178621888160706, Class Loss=0.17178621888160706, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/21, Loss=0.18008072823286056
Loss made of: CE 0.1347927749156952, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.16691380813717843
Loss made of: CE 0.13938972353935242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17338059842586517, Reg Loss=0.0
Clinet index 24, End of Epoch 5/6, Average Loss=0.17338059842586517, Class Loss=0.17338059842586517, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/21, Loss=0.1867220662534237
Loss made of: CE 0.22169899940490723, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.14309799820184707
Loss made of: CE 0.14518806338310242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16361835598945618, Reg Loss=0.0
Clinet index 24, End of Epoch 6/6, Average Loss=0.16361835598945618, Class Loss=0.16361835598945618, Reg Loss=0.0
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.30787292718887327
Loss made of: CE 0.3231252133846283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.28615918159484866
Loss made of: CE 0.2960328459739685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2973771095275879, Reg Loss=0.0
Clinet index 25, End of Epoch 1/6, Average Loss=0.2973771095275879, Class Loss=0.2973771095275879, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/24, Loss=0.28322668969631193
Loss made of: CE 0.3145499527454376, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.23532613664865493
Loss made of: CE 0.2743198871612549, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2604873776435852, Reg Loss=0.0
Clinet index 25, End of Epoch 2/6, Average Loss=0.2604873776435852, Class Loss=0.2604873776435852, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/24, Loss=0.22880567908287047
Loss made of: CE 0.20674940943717957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.24275364428758622
Loss made of: CE 0.19119998812675476, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23683935403823853, Reg Loss=0.0
Clinet index 25, End of Epoch 3/6, Average Loss=0.23683935403823853, Class Loss=0.23683935403823853, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/24, Loss=0.2397209569811821
Loss made of: CE 0.30069097876548767, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.22173173874616622
Loss made of: CE 0.27265602350234985, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22922168672084808, Reg Loss=0.0
Clinet index 25, End of Epoch 4/6, Average Loss=0.22922168672084808, Class Loss=0.22922168672084808, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/24, Loss=0.21749462187290192
Loss made of: CE 0.260586678981781, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.22781723141670226
Loss made of: CE 0.2556903064250946, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21923504769802094, Reg Loss=0.0
Clinet index 25, End of Epoch 5/6, Average Loss=0.21923504769802094, Class Loss=0.21923504769802094, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/24, Loss=0.21410350501537323
Loss made of: CE 0.24422010779380798, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.20976667404174804
Loss made of: CE 0.24008183181285858, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2191947102546692, Reg Loss=0.0
Clinet index 25, End of Epoch 6/6, Average Loss=0.2191947102546692, Class Loss=0.2191947102546692, Reg Loss=0.0
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/19, Loss=0.47247733175754547
Loss made of: CE 0.40770143270492554, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.43236130475997925, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.43236130475997925, Class Loss=0.43236130475997925, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/19, Loss=0.3533877328038216
Loss made of: CE 0.23672544956207275, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3527073860168457, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.3527073860168457, Class Loss=0.3527073860168457, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/19, Loss=0.27472907602787017
Loss made of: CE 0.32549262046813965, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3105457127094269, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.3105457127094269, Class Loss=0.3105457127094269, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/19, Loss=0.27800903022289275
Loss made of: CE 0.3179212212562561, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2694421708583832, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.2694421708583832, Class Loss=0.2694421708583832, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/19, Loss=0.2752324640750885
Loss made of: CE 0.21428975462913513, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27401790022850037, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.27401790022850037, Class Loss=0.27401790022850037, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/19, Loss=0.2683283358812332
Loss made of: CE 0.29386454820632935, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2616569995880127, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.2616569995880127, Class Loss=0.2616569995880127, Reg Loss=0.0
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=1.737423300743103, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.701952
Mean Acc: 0.185431
FreqW Acc: 0.517789
Mean IoU: 0.090862
Class IoU:
	class 0: 0.7312732
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 7.943886e-05
	class 14: 0.005090176
	class 15: 0.0
	class 16: 0.0
	class 17: 0.20057602
	class 18: 0.3443775
	class 19: 0.3228118
	class 20: 0.3038971
Class Acc:
	class 0: 0.97041416
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 7.9565434e-05
	class 14: 0.005090183
	class 15: 0.0
	class 16: 0.0
	class 17: 0.87968594
	class 18: 0.72193015
	class 19: 0.5414811
	class 20: 0.7753615

voc_4-4_FT On GPUs 0
Run in 40731s
