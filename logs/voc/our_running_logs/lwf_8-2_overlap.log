nohup: ignoring input
35
kvoc_8-2_LWF On GPUs 2\Writing in results/seed_2023-ov/2023-03-12_voc_8-2_LWF.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[4, 3, 1, 2]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[0, 4, 7, 2]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  4
Current Client Index:  7
Current Client Index:  2
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[1, 9, 3, 8]
Current Client Index:  1
Current Client Index:  9
Current Client Index:  3
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[5, 9, 0, 4]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Current Client Index:  0
Current Client Index:  4
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.11884414404630661, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.959771
Mean Acc: 0.898867
FreqW Acc: 0.927997
Mean IoU: 0.803600
Class IoU:
	class 0: 0.9505860659032771
	class 1: 0.9002121543757099
	class 2: 0.3911996045853578
	class 3: 0.7886755539422873
	class 4: 0.7227948650191602
	class 5: 0.777020491034379
	class 6: 0.9452273228283382
	class 7: 0.8680230685934628
	class 8: 0.8886579855388657
Class Acc:
	class 0: 0.9742031520387592
	class 1: 0.9505188705401268
	class 2: 0.8333169681087177
	class 3: 0.7954920085182839
	class 4: 0.8649138231019398
	class 5: 0.839701567241524
	class 6: 0.9766569231687022
	class 7: 0.9440467027150332
	class 8: 0.910953836504121

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[5, 11, 7, 1]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Epoch 1, Batch 10/27, Loss=2.6361877620220184
Loss made of: CE 0.7861010432243347, LKD 0.5995274782180786, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.7826798260211945
Loss made of: CE 0.6781702041625977, LKD 1.787363052368164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9807109236717224, Reg Loss=1.1094967126846313
Clinet index 5, End of Epoch 1/6, Average Loss=2.090207576751709, Class Loss=0.9807109236717224, Reg Loss=1.1094967126846313
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=1.499138703942299
Loss made of: CE 0.5417813062667847, LKD 0.9052942395210266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=1.559889030456543
Loss made of: CE 0.45746463537216187, LKD 0.6442579627037048, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6636324524879456, Reg Loss=0.7905874848365784
Clinet index 5, End of Epoch 2/6, Average Loss=1.454219937324524, Class Loss=0.6636324524879456, Reg Loss=0.7905874848365784
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=1.2300864309072495
Loss made of: CE 0.6428328156471252, LKD 0.6486795544624329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=1.090084183216095
Loss made of: CE 0.3212582468986511, LKD 0.8708529472351074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.43715667724609375, Reg Loss=0.7311164736747742
Clinet index 5, End of Epoch 3/6, Average Loss=1.1682732105255127, Class Loss=0.43715667724609375, Reg Loss=0.7311164736747742
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=1.0551618695259095
Loss made of: CE 0.3316890299320221, LKD 0.5313969254493713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=1.0587785944342614
Loss made of: CE 0.26542341709136963, LKD 0.5400854349136353, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.34958741068840027, Reg Loss=0.6869922280311584
Clinet index 5, End of Epoch 4/6, Average Loss=1.0365796089172363, Class Loss=0.34958741068840027, Reg Loss=0.6869922280311584
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=1.1001852333545685
Loss made of: CE 0.25030481815338135, LKD 0.6933002471923828, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.8320653334259986
Loss made of: CE 0.22435621917247772, LKD 0.5976937413215637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.31426751613616943, Reg Loss=0.6770650148391724
Clinet index 5, End of Epoch 5/6, Average Loss=0.9913325309753418, Class Loss=0.31426751613616943, Reg Loss=0.6770650148391724
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=1.0383080497384072
Loss made of: CE 0.43508070707321167, LKD 1.1952261924743652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9908834427595139
Loss made of: CE 0.2527656555175781, LKD 0.34997954964637756, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3005889356136322, Reg Loss=0.6773577332496643
Clinet index 5, End of Epoch 6/6, Average Loss=0.9779466390609741, Class Loss=0.3005889356136322, Reg Loss=0.6773577332496643
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.3721054792404175, Reg Loss=2.2367172241210938
Clinet index 11, End of Epoch 1/6, Average Loss=3.608822822570801, Class Loss=1.3721054792404175, Reg Loss=2.2367172241210938
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.5446999073028564, Reg Loss=1.0801609754562378
Clinet index 11, End of Epoch 2/6, Average Loss=2.6248607635498047, Class Loss=1.5446999073028564, Reg Loss=1.0801609754562378
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.1713281869888306, Reg Loss=0.8854870796203613
Clinet index 11, End of Epoch 3/6, Average Loss=2.0568151473999023, Class Loss=1.1713281869888306, Reg Loss=0.8854870796203613
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8406189680099487, Reg Loss=0.8921710848808289
Clinet index 11, End of Epoch 4/6, Average Loss=1.7327899932861328, Class Loss=0.8406189680099487, Reg Loss=0.8921710848808289
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.6323994994163513, Reg Loss=0.817785918712616
Clinet index 11, End of Epoch 5/6, Average Loss=1.4501854181289673, Class Loss=0.6323994994163513, Reg Loss=0.817785918712616
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.522329568862915, Reg Loss=0.7723216414451599
Clinet index 11, End of Epoch 6/6, Average Loss=1.2946512699127197, Class Loss=0.522329568862915, Reg Loss=0.7723216414451599
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/27, Loss=2.6849817752838137
Loss made of: CE 0.8856922388076782, LKD 0.5541074275970459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.9192135155200958
Loss made of: CE 0.9918441772460938, LKD 0.6778731942176819, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9792357683181763, Reg Loss=1.1101816892623901
Clinet index 7, End of Epoch 1/6, Average Loss=2.0894174575805664, Class Loss=0.9792357683181763, Reg Loss=1.1101816892623901
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=1.6780030846595764
Loss made of: CE 1.2090740203857422, LKD 1.0189062356948853, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=1.49520802795887
Loss made of: CE 0.5069782733917236, LKD 0.6956647634506226, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6596704721450806, Reg Loss=0.8915125727653503
Clinet index 7, End of Epoch 2/6, Average Loss=1.5511829853057861, Class Loss=0.6596704721450806, Reg Loss=0.8915125727653503
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=1.169336125254631
Loss made of: CE 0.42658114433288574, LKD 0.625868022441864, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=1.2321460217237472
Loss made of: CE 0.4061095714569092, LKD 0.6509780287742615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.446818470954895, Reg Loss=0.7682865262031555
Clinet index 7, End of Epoch 3/6, Average Loss=1.2151050567626953, Class Loss=0.446818470954895, Reg Loss=0.7682865262031555
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=1.133217343688011
Loss made of: CE 0.3938966691493988, LKD 0.4808603823184967, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=1.2294705390930176
Loss made of: CE 0.45621585845947266, LKD 1.0220776796340942, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3538278341293335, Reg Loss=0.7863311767578125
Clinet index 7, End of Epoch 4/6, Average Loss=1.140159010887146, Class Loss=0.3538278341293335, Reg Loss=0.7863311767578125
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.9558970123529434
Loss made of: CE 0.2584095001220703, LKD 0.5201146006584167, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=1.0784603014588356
Loss made of: CE 0.29616230726242065, LKD 0.7042437791824341, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3157745599746704, Reg Loss=0.7251814603805542
Clinet index 7, End of Epoch 5/6, Average Loss=1.0409560203552246, Class Loss=0.3157745599746704, Reg Loss=0.7251814603805542
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=1.1130915760993958
Loss made of: CE 0.4052188992500305, LKD 0.7267735004425049, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9834745556116105
Loss made of: CE 0.22181233763694763, LKD 0.6634145975112915, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3063504993915558, Reg Loss=0.7097902894020081
Clinet index 7, End of Epoch 6/6, Average Loss=1.0161408185958862, Class Loss=0.3063504993915558, Reg Loss=0.7097902894020081
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/27, Loss=2.6940331518650056
Loss made of: CE 0.8201695680618286, LKD 0.5048104524612427, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.7254642605781556
Loss made of: CE 0.8313989639282227, LKD 1.0140280723571777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9537743330001831, Reg Loss=1.1350730657577515
Clinet index 1, End of Epoch 1/6, Average Loss=2.0888473987579346, Class Loss=0.9537743330001831, Reg Loss=1.1350730657577515
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=1.4485283017158508
Loss made of: CE 0.6021327972412109, LKD 0.649401068687439, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=1.6564161330461502
Loss made of: CE 0.4819504916667938, LKD 0.555449366569519, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6331989169120789, Reg Loss=0.8782156705856323
Clinet index 1, End of Epoch 2/6, Average Loss=1.5114145278930664, Class Loss=0.6331989169120789, Reg Loss=0.8782156705856323
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=1.1830424398183823
Loss made of: CE 0.4344778060913086, LKD 0.4406112730503082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=1.24872827231884
Loss made of: CE 0.4010889232158661, LKD 0.7963539958000183, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.42509573698043823, Reg Loss=0.757676899433136
Clinet index 1, End of Epoch 3/6, Average Loss=1.1827726364135742, Class Loss=0.42509573698043823, Reg Loss=0.757676899433136
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=1.1239878743886949
Loss made of: CE 0.3220919668674469, LKD 0.518164336681366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.9178749918937683
Loss made of: CE 0.28720220923423767, LKD 0.37259426712989807, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.33849427103996277, Reg Loss=0.7087851762771606
Clinet index 1, End of Epoch 4/6, Average Loss=1.0472794771194458, Class Loss=0.33849427103996277, Reg Loss=0.7087851762771606
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=1.0341537117958068
Loss made of: CE 0.29091179370880127, LKD 0.4197005033493042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.8781054347753525
Loss made of: CE 0.2733796238899231, LKD 0.4521293640136719, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2955215573310852, Reg Loss=0.6448901295661926
Clinet index 1, End of Epoch 5/6, Average Loss=0.9404116868972778, Class Loss=0.2955215573310852, Reg Loss=0.6448901295661926
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.9003876119852066
Loss made of: CE 0.26613885164260864, LKD 0.37893056869506836, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9742278933525086
Loss made of: CE 0.3870426118373871, LKD 1.9057972431182861, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2917465269565582, Reg Loss=0.6615532040596008
Clinet index 1, End of Epoch 6/6, Average Loss=0.9532997608184814, Class Loss=0.2917465269565582, Reg Loss=0.6615532040596008
federated aggregation...
Validation, Class Loss=0.38522985577583313, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.882511
Mean Acc: 0.508219
FreqW Acc: 0.797675
Mean IoU: 0.464756
Class IoU:
	class 0: 0.8836567
	class 1: 0.69445926
	class 2: 0.31727162
	class 3: 0.08383683
	class 4: 0.60837966
	class 5: 0.43861714
	class 6: 0.5456155
	class 7: 0.7270619
	class 8: 0.7948065
	class 9: 0.018611241
	class 10: 0.0
Class Acc:
	class 0: 0.98734176
	class 1: 0.6975059
	class 2: 0.58859617
	class 3: 0.083841145
	class 4: 0.6555287
	class 5: 0.4454163
	class 6: 0.5469124
	class 7: 0.7325976
	class 8: 0.811441
	class 9: 0.041229814
	class 10: 0.0

federated global round: 6, step: 1
select part of clients to conduct local training
[1, 6, 7, 3]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=1.1342279076576234
Loss made of: CE 0.3418043255805969, LKD 0.4559040069580078, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.9551713556051254
Loss made of: CE 0.3409181237220764, LKD 0.6777088046073914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.34525007009506226, Reg Loss=0.6718921065330505
Clinet index 1, End of Epoch 1/6, Average Loss=1.0171421766281128, Class Loss=0.34525007009506226, Reg Loss=0.6718921065330505
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=0.9389466986060142
Loss made of: CE 0.3044309914112091, LKD 0.5258373022079468, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.9833797961473465
Loss made of: CE 0.21572217345237732, LKD 0.39911288022994995, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29257911443710327, Reg Loss=0.6507686972618103
Clinet index 1, End of Epoch 2/6, Average Loss=0.9433478116989136, Class Loss=0.29257911443710327, Reg Loss=0.6507686972618103
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=0.8759823203086853
Loss made of: CE 0.2947830557823181, LKD 0.4618847668170929, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.9662349373102188
Loss made of: CE 0.270626425743103, LKD 0.49884915351867676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28288307785987854, Reg Loss=0.6246541142463684
Clinet index 1, End of Epoch 3/6, Average Loss=0.9075372219085693, Class Loss=0.28288307785987854, Reg Loss=0.6246541142463684
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=0.9602047398686409
Loss made of: CE 0.20991389453411102, LKD 0.5268434286117554, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.8314874917268753
Loss made of: CE 0.24850760400295258, LKD 0.25609394907951355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27404236793518066, Reg Loss=0.6289265751838684
Clinet index 1, End of Epoch 4/6, Average Loss=0.9029689431190491, Class Loss=0.27404236793518066, Reg Loss=0.6289265751838684
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.98137226998806
Loss made of: CE 0.25126829743385315, LKD 0.41469085216522217, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.814784973859787
Loss made of: CE 0.23180073499679565, LKD 0.4164028465747833, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2655006945133209, Reg Loss=0.6325174570083618
Clinet index 1, End of Epoch 5/6, Average Loss=0.8980181217193604, Class Loss=0.2655006945133209, Reg Loss=0.6325174570083618
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=0.8335769981145859
Loss made of: CE 0.23049399256706238, LKD 0.33391889929771423, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9645243123173713
Loss made of: CE 0.3168695271015167, LKD 1.9742980003356934, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2515842318534851, Reg Loss=0.6461747288703918
Clinet index 1, End of Epoch 6/6, Average Loss=0.897758960723877, Class Loss=0.2515842318534851, Reg Loss=0.6461747288703918
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=1.2245755523443222
Loss made of: CE 0.2661787271499634, LKD 0.8924872875213623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.0630429327487945
Loss made of: CE 0.3563254773616791, LKD 0.7384068965911865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3732556700706482, Reg Loss=0.724926233291626
Clinet index 6, End of Epoch 1/6, Average Loss=1.098181962966919, Class Loss=0.3732556700706482, Reg Loss=0.724926233291626
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/27, Loss=1.05262461155653
Loss made of: CE 0.27435311675071716, LKD 0.5073935985565186, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=1.0606484442949295
Loss made of: CE 0.3540409505367279, LKD 0.519037127494812, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3264584243297577, Reg Loss=0.7280711531639099
Clinet index 6, End of Epoch 2/6, Average Loss=1.0545295476913452, Class Loss=0.3264584243297577, Reg Loss=0.7280711531639099
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/27, Loss=1.0411765694618225
Loss made of: CE 0.3067861795425415, LKD 0.44663119316101074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.8802436247467995
Loss made of: CE 0.2618846893310547, LKD 0.6756879091262817, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29984602332115173, Reg Loss=0.6809718012809753
Clinet index 6, End of Epoch 3/6, Average Loss=0.9808177947998047, Class Loss=0.29984602332115173, Reg Loss=0.6809718012809753
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/27, Loss=1.0030283391475678
Loss made of: CE 0.36049729585647583, LKD 1.1949199438095093, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.8894031926989555
Loss made of: CE 0.20691752433776855, LKD 0.6500975489616394, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28954559564590454, Reg Loss=0.6687926650047302
Clinet index 6, End of Epoch 4/6, Average Loss=0.9583382606506348, Class Loss=0.28954559564590454, Reg Loss=0.6687926650047302
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/27, Loss=0.97600277364254
Loss made of: CE 0.24488183856010437, LKD 0.7786540389060974, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.8965712413191795
Loss made of: CE 0.2803928256034851, LKD 0.49954819679260254, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2780492901802063, Reg Loss=0.6874621510505676
Clinet index 6, End of Epoch 5/6, Average Loss=0.9655114412307739, Class Loss=0.2780492901802063, Reg Loss=0.6874621510505676
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/27, Loss=1.0579073891043662
Loss made of: CE 0.24317839741706848, LKD 0.6299558281898499, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9087000966072083
Loss made of: CE 0.24692778289318085, LKD 0.6480427384376526, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.279716819524765, Reg Loss=0.6791637539863586
Clinet index 6, End of Epoch 6/6, Average Loss=0.9588805437088013, Class Loss=0.279716819524765, Reg Loss=0.6791637539863586
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=1.1897268891334534
Loss made of: CE 0.2631036639213562, LKD 0.5059747099876404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.0763367220759392
Loss made of: CE 0.343575119972229, LKD 0.4533442556858063, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.36002030968666077, Reg Loss=0.6996108889579773
Clinet index 7, End of Epoch 1/6, Average Loss=1.0596312284469604, Class Loss=0.36002030968666077, Reg Loss=0.6996108889579773
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=1.0553470700979233
Loss made of: CE 0.5519477128982544, LKD 1.1055941581726074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.9326273009181023
Loss made of: CE 0.2632807195186615, LKD 0.5628371238708496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32309457659721375, Reg Loss=0.6741626262664795
Clinet index 7, End of Epoch 2/6, Average Loss=0.9972572326660156, Class Loss=0.32309457659721375, Reg Loss=0.6741626262664795
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=0.8827898323535919
Loss made of: CE 0.2911660373210907, LKD 0.49122685194015503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=1.0210727587342263
Loss made of: CE 0.291448175907135, LKD 0.537058413028717, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.30415013432502747, Reg Loss=0.6730824708938599
Clinet index 7, End of Epoch 3/6, Average Loss=0.9772325754165649, Class Loss=0.30415013432502747, Reg Loss=0.6730824708938599
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=0.931174923479557
Loss made of: CE 0.3414927124977112, LKD 0.4293808341026306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=1.0323386758565902
Loss made of: CE 0.34775257110595703, LKD 1.069137454032898, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.29111552238464355, Reg Loss=0.6626304984092712
Clinet index 7, End of Epoch 4/6, Average Loss=0.9537460207939148, Class Loss=0.29111552238464355, Reg Loss=0.6626304984092712
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.87989392131567
Loss made of: CE 0.2283058613538742, LKD 0.6209648847579956, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=1.021321988105774
Loss made of: CE 0.32057344913482666, LKD 0.8970520496368408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2816295027732849, Reg Loss=0.6842241883277893
Clinet index 7, End of Epoch 5/6, Average Loss=0.9658536911010742, Class Loss=0.2816295027732849, Reg Loss=0.6842241883277893
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=1.0033947467803954
Loss made of: CE 0.3842798173427582, LKD 0.7064409255981445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9464026346802712
Loss made of: CE 0.21009711921215057, LKD 0.7350024580955505, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.27027422189712524, Reg Loss=0.6654755473136902
Clinet index 7, End of Epoch 6/6, Average Loss=0.9357497692108154, Class Loss=0.27027422189712524, Reg Loss=0.6654755473136902
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.1968283653259277, Reg Loss=0.9558612704277039
Clinet index 3, End of Epoch 1/6, Average Loss=2.1526896953582764, Class Loss=1.1968283653259277, Reg Loss=0.9558612704277039
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9793726205825806, Reg Loss=0.7942447662353516
Clinet index 3, End of Epoch 2/6, Average Loss=1.7736173868179321, Class Loss=0.9793726205825806, Reg Loss=0.7942447662353516
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.8050479888916016, Reg Loss=0.8118733167648315
Clinet index 3, End of Epoch 3/6, Average Loss=1.616921305656433, Class Loss=0.8050479888916016, Reg Loss=0.8118733167648315
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6404259204864502, Reg Loss=0.7292139530181885
Clinet index 3, End of Epoch 4/6, Average Loss=1.3696398735046387, Class Loss=0.6404259204864502, Reg Loss=0.7292139530181885
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.4972018599510193, Reg Loss=0.8239070177078247
Clinet index 3, End of Epoch 5/6, Average Loss=1.3211088180541992, Class Loss=0.4972018599510193, Reg Loss=0.8239070177078247
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.3173079192638397, Reg Loss=0.719443678855896
Clinet index 3, End of Epoch 6/6, Average Loss=1.036751627922058, Class Loss=0.3173079192638397, Reg Loss=0.719443678855896
federated aggregation...
Validation, Class Loss=0.39042115211486816, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.873167
Mean Acc: 0.497260
FreqW Acc: 0.802365
Mean IoU: 0.446752
Class IoU:
	class 0: 0.89430875
	class 1: 0.639501
	class 2: 0.28753984
	class 3: 0.00754314
	class 4: 0.60191905
	class 5: 0.3447358
	class 6: 0.600567
	class 7: 0.7419632
	class 8: 0.74094445
	class 9: 0.055251967
	class 10: 0.0
Class Acc:
	class 0: 0.97792035
	class 1: 0.64288235
	class 2: 0.51197255
	class 3: 0.00754314
	class 4: 0.64664125
	class 5: 0.34756643
	class 6: 0.60222805
	class 7: 0.74940765
	class 8: 0.7520076
	class 9: 0.2316952
	class 10: 0.0

federated global round: 7, step: 1
select part of clients to conduct local training
[13, 8, 0, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.0451092720031738, Reg Loss=0.8653426170349121
Clinet index 13, End of Epoch 1/6, Average Loss=1.910451889038086, Class Loss=1.0451092720031738, Reg Loss=0.8653426170349121
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.8820568323135376, Reg Loss=0.8127033114433289
Clinet index 13, End of Epoch 2/6, Average Loss=1.6947600841522217, Class Loss=0.8820568323135376, Reg Loss=0.8127033114433289
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6503623723983765, Reg Loss=0.7590298652648926
Clinet index 13, End of Epoch 3/6, Average Loss=1.409392237663269, Class Loss=0.6503623723983765, Reg Loss=0.7590298652648926
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.4736224412918091, Reg Loss=0.7094904184341431
Clinet index 13, End of Epoch 4/6, Average Loss=1.1831128597259521, Class Loss=0.4736224412918091, Reg Loss=0.7094904184341431
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.3590356111526489, Reg Loss=0.707245945930481
Clinet index 13, End of Epoch 5/6, Average Loss=1.0662815570831299, Class Loss=0.3590356111526489, Reg Loss=0.707245945930481
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.293054461479187, Reg Loss=0.662203848361969
Clinet index 13, End of Epoch 6/6, Average Loss=0.955258309841156, Class Loss=0.293054461479187, Reg Loss=0.662203848361969
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.16776704788208, Reg Loss=0.8487792015075684
Clinet index 8, End of Epoch 1/6, Average Loss=2.0165462493896484, Class Loss=1.16776704788208, Reg Loss=0.8487792015075684
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.9418617486953735, Reg Loss=0.7611953020095825
Clinet index 8, End of Epoch 2/6, Average Loss=1.703057050704956, Class Loss=0.9418617486953735, Reg Loss=0.7611953020095825
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.7239875793457031, Reg Loss=0.7399696707725525
Clinet index 8, End of Epoch 3/6, Average Loss=1.4639573097229004, Class Loss=0.7239875793457031, Reg Loss=0.7399696707725525
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.5349935293197632, Reg Loss=0.751006543636322
Clinet index 8, End of Epoch 4/6, Average Loss=1.2860000133514404, Class Loss=0.5349935293197632, Reg Loss=0.751006543636322
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.3648512363433838, Reg Loss=0.7718066573143005
Clinet index 8, End of Epoch 5/6, Average Loss=1.136657953262329, Class Loss=0.3648512363433838, Reg Loss=0.7718066573143005
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.272466242313385, Reg Loss=0.7107077836990356
Clinet index 8, End of Epoch 6/6, Average Loss=0.9831740260124207, Class Loss=0.272466242313385, Reg Loss=0.7107077836990356
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.1261427402496338, Reg Loss=0.7537762522697449
Clinet index 0, End of Epoch 1/6, Average Loss=1.8799190521240234, Class Loss=1.1261427402496338, Reg Loss=0.7537762522697449
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.9237467646598816, Reg Loss=0.8072066307067871
Clinet index 0, End of Epoch 2/6, Average Loss=1.7309534549713135, Class Loss=0.9237467646598816, Reg Loss=0.8072066307067871
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6811833381652832, Reg Loss=0.8347854614257812
Clinet index 0, End of Epoch 3/6, Average Loss=1.5159687995910645, Class Loss=0.6811833381652832, Reg Loss=0.8347854614257812
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.4943130910396576, Reg Loss=0.7249065637588501
Clinet index 0, End of Epoch 4/6, Average Loss=1.21921968460083, Class Loss=0.4943130910396576, Reg Loss=0.7249065637588501
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.34711647033691406, Reg Loss=0.7286466956138611
Clinet index 0, End of Epoch 5/6, Average Loss=1.07576322555542, Class Loss=0.34711647033691406, Reg Loss=0.7286466956138611
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.29018038511276245, Reg Loss=0.6640511155128479
Clinet index 0, End of Epoch 6/6, Average Loss=0.9542315006256104, Class Loss=0.29018038511276245, Reg Loss=0.6640511155128479
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.8877573534846306
Loss made of: CE 0.22636786103248596, LKD 0.3959130644798279, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.9920417562127113
Loss made of: CE 0.32770684361457825, LKD 1.230103850364685, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2847004234790802, Reg Loss=0.6402263641357422
Clinet index 5, End of Epoch 1/6, Average Loss=0.9249267578125, Class Loss=0.2847004234790802, Reg Loss=0.6402263641357422
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/27, Loss=0.8955451816320419
Loss made of: CE 0.23665904998779297, LKD 0.8063834309577942, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=1.0382568299770356
Loss made of: CE 0.27170872688293457, LKD 0.4350402355194092, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27563169598579407, Reg Loss=0.635800838470459
Clinet index 5, End of Epoch 2/6, Average Loss=0.9114325046539307, Class Loss=0.27563169598579407, Reg Loss=0.635800838470459
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/27, Loss=0.9287709504365921
Loss made of: CE 0.4109322726726532, LKD 0.6817772388458252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.8968908846378326
Loss made of: CE 0.22402644157409668, LKD 0.7409579753875732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26733583211898804, Reg Loss=0.6615284085273743
Clinet index 5, End of Epoch 3/6, Average Loss=0.9288642406463623, Class Loss=0.26733583211898804, Reg Loss=0.6615284085273743
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/27, Loss=0.8308729812502861
Loss made of: CE 0.2533326745033264, LKD 0.4057427942752838, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.9512599289417267
Loss made of: CE 0.1887138932943344, LKD 0.5479968190193176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2554740905761719, Reg Loss=0.6252354979515076
Clinet index 5, End of Epoch 4/6, Average Loss=0.8807095885276794, Class Loss=0.2554740905761719, Reg Loss=0.6252354979515076
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/27, Loss=1.0067020013928414
Loss made of: CE 0.23428437113761902, LKD 0.6362494826316833, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.7474674239754677
Loss made of: CE 0.19943103194236755, LKD 0.6826597452163696, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2494574636220932, Reg Loss=0.6276633143424988
Clinet index 5, End of Epoch 5/6, Average Loss=0.8771207928657532, Class Loss=0.2494574636220932, Reg Loss=0.6276633143424988
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/27, Loss=0.8929535791277885
Loss made of: CE 0.3591580390930176, LKD 0.8425302505493164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.8512570530176162
Loss made of: CE 0.21302029490470886, LKD 0.352913498878479, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24373199045658112, Reg Loss=0.6223174929618835
Clinet index 5, End of Epoch 6/6, Average Loss=0.8660494685173035, Class Loss=0.24373199045658112, Reg Loss=0.6223174929618835
federated aggregation...
Validation, Class Loss=0.34587180614471436, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.871117
Mean Acc: 0.482398
FreqW Acc: 0.789737
Mean IoU: 0.428727
Class IoU:
	class 0: 0.8904551
	class 1: 0.53806096
	class 2: 0.31819308
	class 3: 0.03889671
	class 4: 0.5637705
	class 5: 0.37082243
	class 6: 0.56764054
	class 7: 0.74859786
	class 8: 0.5132013
	class 9: 0.03685164
	class 10: 0.12951083
Class Acc:
	class 0: 0.98600745
	class 1: 0.5390921
	class 2: 0.5719603
	class 3: 0.03889671
	class 4: 0.60840625
	class 5: 0.376302
	class 6: 0.5688289
	class 7: 0.75825286
	class 8: 0.51534826
	class 9: 0.06244471
	class 10: 0.28083852

federated global round: 8, step: 1
select part of clients to conduct local training
[12, 9, 4, 13]
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=1.1046248450875282
Loss made of: CE 0.33952459692955017, LKD 0.7877650856971741, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.9238744586706161
Loss made of: CE 0.2546160817146301, LKD 0.41755998134613037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.322497695684433, Reg Loss=0.6856493949890137
Clinet index 12, End of Epoch 1/6, Average Loss=1.008147120475769, Class Loss=0.322497695684433, Reg Loss=0.6856493949890137
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=0.851277208328247
Loss made of: CE 0.22758063673973083, LKD 0.5165867805480957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.9886997222900391
Loss made of: CE 0.32331812381744385, LKD 0.7959502935409546, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27289918065071106, Reg Loss=0.6498167514801025
Clinet index 12, End of Epoch 2/6, Average Loss=0.9227159023284912, Class Loss=0.27289918065071106, Reg Loss=0.6498167514801025
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=0.8490039274096489
Loss made of: CE 0.2920858860015869, LKD 0.7763157486915588, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.9545979514718056
Loss made of: CE 0.2307320237159729, LKD 0.5073981285095215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2571336030960083, Reg Loss=0.6424959897994995
Clinet index 12, End of Epoch 3/6, Average Loss=0.8996295928955078, Class Loss=0.2571336030960083, Reg Loss=0.6424959897994995
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=0.8404129013419152
Loss made of: CE 0.19211743772029877, LKD 0.6844862103462219, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.9211168363690376
Loss made of: CE 0.20806758105754852, LKD 0.6879353523254395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2525695264339447, Reg Loss=0.6533827185630798
Clinet index 12, End of Epoch 4/6, Average Loss=0.9059522151947021, Class Loss=0.2525695264339447, Reg Loss=0.6533827185630798
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.8062453463673591
Loss made of: CE 0.25346171855926514, LKD 0.47838589549064636, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.9076595798134803
Loss made of: CE 0.2561035752296448, LKD 0.4396664798259735, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2468799352645874, Reg Loss=0.6430572867393494
Clinet index 12, End of Epoch 5/6, Average Loss=0.8899372220039368, Class Loss=0.2468799352645874, Reg Loss=0.6430572867393494
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=0.8034857213497162
Loss made of: CE 0.23470014333724976, LKD 0.7407866716384888, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9215139389038086
Loss made of: CE 0.2895796000957489, LKD 0.6607399582862854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24484555423259735, Reg Loss=0.6273900270462036
Clinet index 12, End of Epoch 6/6, Average Loss=0.8722355961799622, Class Loss=0.24484555423259735, Reg Loss=0.6273900270462036
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.39129042625427246, Reg Loss=0.7952267527580261
Clinet index 9, End of Epoch 1/6, Average Loss=1.1865172386169434, Class Loss=0.39129042625427246, Reg Loss=0.7952267527580261
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.29830655455589294, Reg Loss=0.7475830912590027
Clinet index 9, End of Epoch 2/6, Average Loss=1.0458896160125732, Class Loss=0.29830655455589294, Reg Loss=0.7475830912590027
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.23400740325450897, Reg Loss=0.7859292030334473
Clinet index 9, End of Epoch 3/6, Average Loss=1.0199365615844727, Class Loss=0.23400740325450897, Reg Loss=0.7859292030334473
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.19865457713603973, Reg Loss=0.732934832572937
Clinet index 9, End of Epoch 4/6, Average Loss=0.9315894246101379, Class Loss=0.19865457713603973, Reg Loss=0.732934832572937
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.19052532315254211, Reg Loss=0.7862663269042969
Clinet index 9, End of Epoch 5/6, Average Loss=0.9767916202545166, Class Loss=0.19052532315254211, Reg Loss=0.7862663269042969
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.15421366691589355, Reg Loss=0.7359654307365417
Clinet index 9, End of Epoch 6/6, Average Loss=0.8901790976524353, Class Loss=0.15421366691589355, Reg Loss=0.7359654307365417
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.9154327362775803
Loss made of: CE 0.40864893794059753, LKD 0.6433257460594177, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.0683722376823426
Loss made of: CE 0.3054039180278778, LKD 0.6434556841850281, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3313375413417816, Reg Loss=0.6472458243370056
Clinet index 4, End of Epoch 1/6, Average Loss=0.9785833358764648, Class Loss=0.3313375413417816, Reg Loss=0.6472458243370056
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=0.8869387149810791
Loss made of: CE 0.2599978446960449, LKD 0.7255218029022217, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.917872029542923
Loss made of: CE 0.3393828868865967, LKD 0.675627589225769, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.280189573764801, Reg Loss=0.6571216583251953
Clinet index 4, End of Epoch 2/6, Average Loss=0.9373112320899963, Class Loss=0.280189573764801, Reg Loss=0.6571216583251953
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=0.9909340217709541
Loss made of: CE 0.2088642716407776, LKD 0.6552865505218506, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.8605023413896561
Loss made of: CE 0.27144575119018555, LKD 0.6418824195861816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26351457834243774, Reg Loss=0.627234160900116
Clinet index 4, End of Epoch 3/6, Average Loss=0.8907487392425537, Class Loss=0.26351457834243774, Reg Loss=0.627234160900116
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=0.9405180633068084
Loss made of: CE 0.3091656565666199, LKD 1.028478980064392, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.8144102990627289
Loss made of: CE 0.23156428337097168, LKD 0.6784546375274658, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2514197826385498, Reg Loss=0.647873044013977
Clinet index 4, End of Epoch 4/6, Average Loss=0.8992928266525269, Class Loss=0.2514197826385498, Reg Loss=0.647873044013977
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.9133321672677994
Loss made of: CE 0.2436550110578537, LKD 0.8451392650604248, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.7713665217161179
Loss made of: CE 0.27459976077079773, LKD 0.4933909475803375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2524937689304352, Reg Loss=0.6434828042984009
Clinet index 4, End of Epoch 5/6, Average Loss=0.8959765434265137, Class Loss=0.2524937689304352, Reg Loss=0.6434828042984009
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=0.7715424627065659
Loss made of: CE 0.2120300978422165, LKD 0.32580140233039856, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.9398409813642502
Loss made of: CE 0.19984500110149384, LKD 0.6554791331291199, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24298445880413055, Reg Loss=0.6317984461784363
Clinet index 4, End of Epoch 6/6, Average Loss=0.874782919883728, Class Loss=0.24298445880413055, Reg Loss=0.6317984461784363
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.3618476390838623, Reg Loss=0.7800280451774597
Clinet index 13, End of Epoch 1/6, Average Loss=1.1418757438659668, Class Loss=0.3618476390838623, Reg Loss=0.7800280451774597
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.3291662037372589, Reg Loss=0.6981138586997986
Clinet index 13, End of Epoch 2/6, Average Loss=1.0272800922393799, Class Loss=0.3291662037372589, Reg Loss=0.6981138586997986
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.26268458366394043, Reg Loss=0.7040826678276062
Clinet index 13, End of Epoch 3/6, Average Loss=0.9667672514915466, Class Loss=0.26268458366394043, Reg Loss=0.7040826678276062
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.25027722120285034, Reg Loss=0.7279701232910156
Clinet index 13, End of Epoch 4/6, Average Loss=0.978247344493866, Class Loss=0.25027722120285034, Reg Loss=0.7279701232910156
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.21701256930828094, Reg Loss=0.6586662530899048
Clinet index 13, End of Epoch 5/6, Average Loss=0.8756788372993469, Class Loss=0.21701256930828094, Reg Loss=0.6586662530899048
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.21121816337108612, Reg Loss=0.6860847473144531
Clinet index 13, End of Epoch 6/6, Average Loss=0.8973029255867004, Class Loss=0.21121816337108612, Reg Loss=0.6860847473144531
federated aggregation...
Validation, Class Loss=0.3236341178417206, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.879786
Mean Acc: 0.520774
FreqW Acc: 0.803635
Mean IoU: 0.464647
Class IoU:
	class 0: 0.8930475
	class 1: 0.6269835
	class 2: 0.32159078
	class 3: 0.031718876
	class 4: 0.5830713
	class 5: 0.42131448
	class 6: 0.562468
	class 7: 0.781956
	class 8: 0.69706815
	class 9: 0.08170394
	class 10: 0.110189214
Class Acc:
	class 0: 0.9822122
	class 1: 0.62910706
	class 2: 0.59624434
	class 3: 0.031718876
	class 4: 0.6285355
	class 5: 0.4280157
	class 6: 0.56374204
	class 7: 0.79384816
	class 8: 0.7050982
	class 9: 0.19194986
	class 10: 0.17804134

federated global round: 9, step: 1
select part of clients to conduct local training
[4, 6, 13, 12]
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=0.8786892801523208
Loss made of: CE 0.3573073744773865, LKD 0.5037778615951538, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=1.01453378200531
Loss made of: CE 0.27241629362106323, LKD 0.7473170161247253, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2945898175239563, Reg Loss=0.6350429058074951
Clinet index 4, End of Epoch 1/6, Average Loss=0.9296327233314514, Class Loss=0.2945898175239563, Reg Loss=0.6350429058074951
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=0.8534056425094605
Loss made of: CE 0.2568085193634033, LKD 0.5297294855117798, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.9379826322197914
Loss made of: CE 0.32220548391342163, LKD 0.6621453166007996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28137728571891785, Reg Loss=0.6363767981529236
Clinet index 4, End of Epoch 2/6, Average Loss=0.917754054069519, Class Loss=0.28137728571891785, Reg Loss=0.6363767981529236
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=0.9455283597111702
Loss made of: CE 0.23564952611923218, LKD 0.6499714255332947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.8705416083335876
Loss made of: CE 0.2785065770149231, LKD 0.5761250853538513, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26446184515953064, Reg Loss=0.6250159740447998
Clinet index 4, End of Epoch 3/6, Average Loss=0.8894778490066528, Class Loss=0.26446184515953064, Reg Loss=0.6250159740447998
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=0.933792670071125
Loss made of: CE 0.3602713346481323, LKD 0.9517507553100586, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.7576175555586815
Loss made of: CE 0.20934197306632996, LKD 0.5821711421012878, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25688421726226807, Reg Loss=0.60776287317276
Clinet index 4, End of Epoch 4/6, Average Loss=0.8646470904350281, Class Loss=0.25688421726226807, Reg Loss=0.60776287317276
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=0.8886183738708496
Loss made of: CE 0.24017438292503357, LKD 0.758956253528595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.7536911219358444
Loss made of: CE 0.27302777767181396, LKD 0.46096864342689514, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25755494832992554, Reg Loss=0.618736207485199
Clinet index 4, End of Epoch 5/6, Average Loss=0.8762911558151245, Class Loss=0.25755494832992554, Reg Loss=0.618736207485199
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=0.7822010576725006
Loss made of: CE 0.24545399844646454, LKD 0.3103858232498169, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.93938757032156
Loss made of: CE 0.22748249769210815, LKD 0.7256448268890381, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25526899099349976, Reg Loss=0.6513611674308777
Clinet index 4, End of Epoch 6/6, Average Loss=0.9066301584243774, Class Loss=0.25526899099349976, Reg Loss=0.6513611674308777
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/27, Loss=0.9795893266797066
Loss made of: CE 0.24939624965190887, LKD 0.7944653630256653, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.9518658578395843
Loss made of: CE 0.3339059054851532, LKD 0.7057657241821289, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3125966787338257, Reg Loss=0.6275021433830261
Clinet index 6, End of Epoch 1/6, Average Loss=0.9400988221168518, Class Loss=0.3125966787338257, Reg Loss=0.6275021433830261
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/27, Loss=0.9039639383554459
Loss made of: CE 0.22398900985717773, LKD 0.4618784487247467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.9509808003902436
Loss made of: CE 0.34513914585113525, LKD 0.4817372262477875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28145313262939453, Reg Loss=0.6418945789337158
Clinet index 6, End of Epoch 2/6, Average Loss=0.9233477115631104, Class Loss=0.28145313262939453, Reg Loss=0.6418945789337158
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/27, Loss=0.9606268495321274
Loss made of: CE 0.2710597515106201, LKD 0.458392858505249, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.8450843557715416
Loss made of: CE 0.22808092832565308, LKD 0.604354977607727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2658071219921112, Reg Loss=0.6506487131118774
Clinet index 6, End of Epoch 3/6, Average Loss=0.916455864906311, Class Loss=0.2658071219921112, Reg Loss=0.6506487131118774
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/27, Loss=0.9593334347009659
Loss made of: CE 0.2758895754814148, LKD 1.3241151571273804, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.9050509691238403
Loss made of: CE 0.2125793695449829, LKD 0.5384887456893921, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26426252722740173, Reg Loss=0.6702612638473511
Clinet index 6, End of Epoch 4/6, Average Loss=0.9345238208770752, Class Loss=0.26426252722740173, Reg Loss=0.6702612638473511
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/27, Loss=0.9198698475956917
Loss made of: CE 0.24780260026454926, LKD 0.7263672351837158, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.8805665984749794
Loss made of: CE 0.2529994249343872, LKD 0.5516383647918701, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.264810711145401, Reg Loss=0.6352576017379761
Clinet index 6, End of Epoch 5/6, Average Loss=0.9000682830810547, Class Loss=0.264810711145401, Reg Loss=0.6352576017379761
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/27, Loss=0.9865096405148506
Loss made of: CE 0.23528549075126648, LKD 0.7366746068000793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.8707115173339843
Loss made of: CE 0.2369556874036789, LKD 0.6710807085037231, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2623043358325958, Reg Loss=0.6394206285476685
Clinet index 6, End of Epoch 6/6, Average Loss=0.9017249345779419, Class Loss=0.2623043358325958, Reg Loss=0.6394206285476685
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000372
Epoch 1, Class Loss=0.40486952662467957, Reg Loss=0.7161226272583008
Clinet index 13, End of Epoch 1/6, Average Loss=1.1209921836853027, Class Loss=0.40486952662467957, Reg Loss=0.7161226272583008
Pseudo labeling is: None
Epoch 2, lr = 0.000316
Epoch 2, Class Loss=0.35614651441574097, Reg Loss=0.7148582935333252
Clinet index 13, End of Epoch 2/6, Average Loss=1.071004867553711, Class Loss=0.35614651441574097, Reg Loss=0.7148582935333252
Pseudo labeling is: None
Epoch 3, lr = 0.000258
Epoch 3, Class Loss=0.32806748151779175, Reg Loss=0.6724750995635986
Clinet index 13, End of Epoch 3/6, Average Loss=1.0005426406860352, Class Loss=0.32806748151779175, Reg Loss=0.6724750995635986
Pseudo labeling is: None
Epoch 4, lr = 0.000199
Epoch 4, Class Loss=0.30361372232437134, Reg Loss=0.670414924621582
Clinet index 13, End of Epoch 4/6, Average Loss=0.9740286469459534, Class Loss=0.30361372232437134, Reg Loss=0.670414924621582
Pseudo labeling is: None
Epoch 5, lr = 0.000138
Epoch 5, Class Loss=0.2985473871231079, Reg Loss=0.6860818862915039
Clinet index 13, End of Epoch 5/6, Average Loss=0.9846292734146118, Class Loss=0.2985473871231079, Reg Loss=0.6860818862915039
Pseudo labeling is: None
Epoch 6, lr = 0.000074
Epoch 6, Class Loss=0.30736052989959717, Reg Loss=0.6218940019607544
Clinet index 13, End of Epoch 6/6, Average Loss=0.9292545318603516, Class Loss=0.30736052989959717, Reg Loss=0.6218940019607544
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=1.0022312313318253
Loss made of: CE 0.3309270143508911, LKD 0.9405935406684875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.9605035245418548
Loss made of: CE 0.23858176171779633, LKD 0.44539710879325867, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.30005261301994324, Reg Loss=0.677095353603363
Clinet index 12, End of Epoch 1/6, Average Loss=0.9771479368209839, Class Loss=0.30005261301994324, Reg Loss=0.677095353603363
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=0.8533630430698395
Loss made of: CE 0.23115384578704834, LKD 0.4576452970504761, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.9890539929270744
Loss made of: CE 0.2963235378265381, LKD 0.7508776187896729, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27038395404815674, Reg Loss=0.6454848647117615
Clinet index 12, End of Epoch 2/6, Average Loss=0.9158688187599182, Class Loss=0.27038395404815674, Reg Loss=0.6454848647117615
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=0.8496861755847931
Loss made of: CE 0.3114224076271057, LKD 0.8324756026268005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.9247678458690644
Loss made of: CE 0.22602778673171997, LKD 0.5144432187080383, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26011717319488525, Reg Loss=0.6223762035369873
Clinet index 12, End of Epoch 3/6, Average Loss=0.8824933767318726, Class Loss=0.26011717319488525, Reg Loss=0.6223762035369873
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=0.798585732281208
Loss made of: CE 0.1873166561126709, LKD 0.4839736819267273, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.8825979694724083
Loss made of: CE 0.19821736216545105, LKD 0.5606809258460999, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25328782200813293, Reg Loss=0.6249109506607056
Clinet index 12, End of Epoch 4/6, Average Loss=0.8781987428665161, Class Loss=0.25328782200813293, Reg Loss=0.6249109506607056
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=0.7872832134366036
Loss made of: CE 0.2618713974952698, LKD 0.4285326302051544, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.927973122894764
Loss made of: CE 0.25786301493644714, LKD 0.542884111404419, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25457173585891724, Reg Loss=0.6359853148460388
Clinet index 12, End of Epoch 5/6, Average Loss=0.890557050704956, Class Loss=0.25457173585891724, Reg Loss=0.6359853148460388
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=0.8158635839819908
Loss made of: CE 0.23893332481384277, LKD 0.6974455118179321, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.991136422753334
Loss made of: CE 0.28080955147743225, LKD 0.6011390089988708, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25434425473213196, Reg Loss=0.6579146981239319
Clinet index 12, End of Epoch 6/6, Average Loss=0.9122589826583862, Class Loss=0.25434425473213196, Reg Loss=0.6579146981239319
federated aggregation...
Validation, Class Loss=0.3328588306903839, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.878567
Mean Acc: 0.542313
FreqW Acc: 0.808560
Mean IoU: 0.474282
Class IoU:
	class 0: 0.89444876
	class 1: 0.6629357
	class 2: 0.31398806
	class 3: 0.016404055
	class 4: 0.58949965
	class 5: 0.4535094
	class 6: 0.58950186
	class 7: 0.79232424
	class 8: 0.76641655
	class 9: 0.10443551
	class 10: 0.03363374
Class Acc:
	class 0: 0.9737511
	class 1: 0.6666862
	class 2: 0.5985594
	class 3: 0.016404055
	class 4: 0.63417983
	class 5: 0.46281454
	class 6: 0.5909834
	class 7: 0.8056348
	class 8: 0.7795675
	class 9: 0.39991868
	class 10: 0.0369484

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[10, 14, 16, 7]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=6.486633276939392
Loss made of: CE 1.1697361469268799, LKD 3.573391914367676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=5.495690226554871
Loss made of: CE 1.0760196447372437, LKD 4.296119689941406, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.2994461059570312, Reg Loss=4.456512928009033
Clinet index 10, End of Epoch 1/6, Average Loss=5.7559590339660645, Class Loss=1.2994461059570312, Reg Loss=4.456512928009033
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=4.643753680586815
Loss made of: CE 0.36046767234802246, LKD 4.295493125915527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.656404128670692
Loss made of: CE 0.32715529203414917, LKD 3.976017713546753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3837505280971527, Reg Loss=4.211800575256348
Clinet index 10, End of Epoch 2/6, Average Loss=4.595551013946533, Class Loss=0.3837505280971527, Reg Loss=4.211800575256348
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=4.517322823405266
Loss made of: CE 0.29817602038383484, LKD 3.673654079437256, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.433185195922851
Loss made of: CE 0.22532515227794647, LKD 3.9821994304656982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2734426259994507, Reg Loss=4.2051849365234375
Clinet index 10, End of Epoch 3/6, Average Loss=4.478627681732178, Class Loss=0.2734426259994507, Reg Loss=4.2051849365234375
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=4.388980436325073
Loss made of: CE 0.27139756083488464, LKD 4.75327205657959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.1988598361611364
Loss made of: CE 0.19635066390037537, LKD 4.304937839508057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25409549474716187, Reg Loss=4.120520114898682
Clinet index 10, End of Epoch 4/6, Average Loss=4.374615669250488, Class Loss=0.25409549474716187, Reg Loss=4.120520114898682
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=4.43769111931324
Loss made of: CE 0.28018322587013245, LKD 3.8133769035339355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.178734174370765
Loss made of: CE 0.1862259954214096, LKD 4.16329288482666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24420741200447083, Reg Loss=4.109252452850342
Clinet index 10, End of Epoch 5/6, Average Loss=4.35345983505249, Class Loss=0.24420741200447083, Reg Loss=4.109252452850342
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=4.2904121488332745
Loss made of: CE 0.17567257583141327, LKD 4.089386940002441, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.100137685239315
Loss made of: CE 0.21984677016735077, LKD 4.171304225921631, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2271067202091217, Reg Loss=4.051182746887207
Clinet index 10, End of Epoch 6/6, Average Loss=4.278289318084717, Class Loss=0.2271067202091217, Reg Loss=4.051182746887207
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=3.8211050152778627
Loss made of: CE 1.5968880653381348, LKD 2.4889862537384033, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.7053602933883667, Reg Loss=2.1042802333831787
Clinet index 14, End of Epoch 1/6, Average Loss=3.809640407562256, Class Loss=1.7053602933883667, Reg Loss=2.1042802333831787
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=3.244564896821976
Loss made of: CE 1.079858660697937, LKD 1.9841879606246948, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2221940755844116, Reg Loss=2.0591132640838623
Clinet index 14, End of Epoch 2/6, Average Loss=3.2813072204589844, Class Loss=1.2221940755844116, Reg Loss=2.0591132640838623
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=2.940303474664688
Loss made of: CE 0.8130526542663574, LKD 2.011597156524658, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8769278526306152, Reg Loss=2.042407751083374
Clinet index 14, End of Epoch 3/6, Average Loss=2.9193356037139893, Class Loss=0.8769278526306152, Reg Loss=2.042407751083374
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=2.7406150817871096
Loss made of: CE 0.5139865279197693, LKD 1.6716920137405396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6350865364074707, Reg Loss=1.9980483055114746
Clinet index 14, End of Epoch 4/6, Average Loss=2.6331348419189453, Class Loss=0.6350865364074707, Reg Loss=1.9980483055114746
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=2.5151460736989977
Loss made of: CE 0.5380253195762634, LKD 2.256347894668579, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.49136269092559814, Reg Loss=2.016327381134033
Clinet index 14, End of Epoch 5/6, Average Loss=2.507689952850342, Class Loss=0.49136269092559814, Reg Loss=2.016327381134033
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=2.407173919677734
Loss made of: CE 0.36167559027671814, LKD 1.63972008228302, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.42796626687049866, Reg Loss=1.955641746520996
Clinet index 14, End of Epoch 6/6, Average Loss=2.383608102798462, Class Loss=0.42796626687049866, Reg Loss=1.955641746520996
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=6.636993932723999
Loss made of: CE 1.5389360189437866, LKD 4.197729587554932, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=5.532963132858276
Loss made of: CE 1.0427958965301514, LKD 5.040947914123535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.311543345451355, Reg Loss=4.519468307495117
Clinet index 16, End of Epoch 1/6, Average Loss=5.831011772155762, Class Loss=1.311543345451355, Reg Loss=4.519468307495117
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=4.829253894090653
Loss made of: CE 0.37119007110595703, LKD 4.32643985748291, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.60442813038826
Loss made of: CE 0.2599029541015625, LKD 4.215854644775391, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3792250156402588, Reg Loss=4.278131008148193
Clinet index 16, End of Epoch 2/6, Average Loss=4.657356262207031, Class Loss=0.3792250156402588, Reg Loss=4.278131008148193
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=4.569456794857979
Loss made of: CE 0.2952796518802643, LKD 4.779528617858887, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.274806547164917
Loss made of: CE 0.19650444388389587, LKD 3.253042221069336, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2664644420146942, Reg Loss=4.20476770401001
Clinet index 16, End of Epoch 3/6, Average Loss=4.471231937408447, Class Loss=0.2664644420146942, Reg Loss=4.20476770401001
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=4.383715710043907
Loss made of: CE 0.3094560503959656, LKD 3.829911231994629, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.500012697279454
Loss made of: CE 0.26579734683036804, LKD 4.4440460205078125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24728836119174957, Reg Loss=4.187288761138916
Clinet index 16, End of Epoch 4/6, Average Loss=4.434576988220215, Class Loss=0.24728836119174957, Reg Loss=4.187288761138916
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=4.571638576686382
Loss made of: CE 0.2482287585735321, LKD 4.378204822540283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=3.989565961062908
Loss made of: CE 0.16238752007484436, LKD 2.8539440631866455, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24168872833251953, Reg Loss=4.124713897705078
Clinet index 16, End of Epoch 5/6, Average Loss=4.366402626037598, Class Loss=0.24168872833251953, Reg Loss=4.124713897705078
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=4.364074410498143
Loss made of: CE 0.2295699119567871, LKD 4.332127571105957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.3609496533870695
Loss made of: CE 0.20067530870437622, LKD 3.9021599292755127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23269745707511902, Reg Loss=4.154175281524658
Clinet index 16, End of Epoch 6/6, Average Loss=4.3868727684021, Class Loss=0.23269745707511902, Reg Loss=4.154175281524658
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=3.7901103496551514
Loss made of: CE 1.4401497840881348, LKD 1.9878194332122803, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6587865352630615, Reg Loss=2.021454334259033
Clinet index 7, End of Epoch 1/6, Average Loss=3.6802408695220947, Class Loss=1.6587865352630615, Reg Loss=2.021454334259033
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=3.1728705406188964
Loss made of: CE 1.1995805501937866, LKD 1.969154953956604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2142466306686401, Reg Loss=2.01066255569458
Clinet index 7, End of Epoch 2/6, Average Loss=3.2249093055725098, Class Loss=1.2142466306686401, Reg Loss=2.01066255569458
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=2.990381395816803
Loss made of: CE 0.7186979055404663, LKD 2.1948978900909424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8903531432151794, Reg Loss=2.0423264503479004
Clinet index 7, End of Epoch 3/6, Average Loss=2.9326796531677246, Class Loss=0.8903531432151794, Reg Loss=2.0423264503479004
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=2.6619769811630247
Loss made of: CE 0.5485348701477051, LKD 2.1298866271972656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6303102374076843, Reg Loss=2.005131483078003
Clinet index 7, End of Epoch 4/6, Average Loss=2.635441780090332, Class Loss=0.6303102374076843, Reg Loss=2.005131483078003
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=2.4885282039642336
Loss made of: CE 0.4299670159816742, LKD 1.6630446910858154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.500275731086731, Reg Loss=1.9469367265701294
Clinet index 7, End of Epoch 5/6, Average Loss=2.4472124576568604, Class Loss=0.500275731086731, Reg Loss=1.9469367265701294
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=2.4177812308073046
Loss made of: CE 0.39384564757347107, LKD 1.503273606300354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4382837414741516, Reg Loss=1.9340676069259644
Clinet index 7, End of Epoch 6/6, Average Loss=2.3723514080047607, Class Loss=0.4382837414741516, Reg Loss=1.9340676069259644
federated aggregation...
Validation, Class Loss=0.4415683448314667, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.853901
Mean Acc: 0.470972
FreqW Acc: 0.746132
Mean IoU: 0.419821
Class IoU:
	class 0: 0.8516467
	class 1: 0.750658
	class 2: 0.32576194
	class 3: 0.0629193
	class 4: 0.58425474
	class 5: 0.45138028
	class 6: 0.64566296
	class 7: 0.79137236
	class 8: 0.72129434
	class 9: 0.12485969
	class 10: 9.684726e-07
	class 11: 0.0
	class 12: 0.1478567
Class Acc:
	class 0: 0.9865348
	class 1: 0.75615746
	class 2: 0.6253405
	class 3: 0.062921286
	class 4: 0.63229936
	class 5: 0.4586795
	class 6: 0.64778835
	class 7: 0.8054384
	class 8: 0.73233134
	class 9: 0.24050237
	class 10: 9.816104e-07
	class 11: 0.0
	class 12: 0.17463715

federated global round: 11, step: 2
select part of clients to conduct local training
[10, 13, 6, 1]
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=4.927665454149246
Loss made of: CE 0.42573994398117065, LKD 3.6476829051971436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.4973958164453505
Loss made of: CE 0.3668217658996582, LKD 4.046379566192627, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.47070544958114624, Reg Loss=4.190454006195068
Clinet index 10, End of Epoch 1/6, Average Loss=4.661159515380859, Class Loss=0.47070544958114624, Reg Loss=4.190454006195068
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/29, Loss=4.330985434353352
Loss made of: CE 0.2622905373573303, LKD 4.254640102386475, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.3833920255303385
Loss made of: CE 0.2964108884334564, LKD 3.6486783027648926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2642233371734619, Reg Loss=4.075994491577148
Clinet index 10, End of Epoch 2/6, Average Loss=4.340217590332031, Class Loss=0.2642233371734619, Reg Loss=4.075994491577148
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/29, Loss=4.4158309862017635
Loss made of: CE 0.23833638429641724, LKD 3.716356039047241, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.315262408554554
Loss made of: CE 0.20998871326446533, LKD 3.6959118843078613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24517852067947388, Reg Loss=4.094178199768066
Clinet index 10, End of Epoch 3/6, Average Loss=4.339356899261475, Class Loss=0.24517852067947388, Reg Loss=4.094178199768066
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/29, Loss=4.342347937822342
Loss made of: CE 0.24908193945884705, LKD 4.4159393310546875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.1456894993782045
Loss made of: CE 0.19538109004497528, LKD 4.0801920890808105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2406078577041626, Reg Loss=4.086294651031494
Clinet index 10, End of Epoch 4/6, Average Loss=4.326902389526367, Class Loss=0.2406078577041626, Reg Loss=4.086294651031494
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=4.310241417586804
Loss made of: CE 0.25591176748275757, LKD 3.599838972091675, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.0813989117741585
Loss made of: CE 0.184565469622612, LKD 4.173877239227295, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22989848256111145, Reg Loss=4.044035911560059
Clinet index 10, End of Epoch 5/6, Average Loss=4.273934364318848, Class Loss=0.22989848256111145, Reg Loss=4.044035911560059
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/29, Loss=4.300253401696682
Loss made of: CE 0.17525158822536469, LKD 4.385594844818115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.074938505887985
Loss made of: CE 0.2232450246810913, LKD 4.038771152496338, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22924663126468658, Reg Loss=4.045593738555908
Clinet index 10, End of Epoch 6/6, Average Loss=4.274840354919434, Class Loss=0.22924663126468658, Reg Loss=4.045593738555908
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=5.243425899744034
Loss made of: CE 0.4239116311073303, LKD 3.6868090629577637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.695645120739937
Loss made of: CE 0.3089638352394104, LKD 4.590134143829346, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4545617699623108, Reg Loss=4.324773788452148
Clinet index 13, End of Epoch 1/6, Average Loss=4.7793354988098145, Class Loss=0.4545617699623108, Reg Loss=4.324773788452148
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/29, Loss=4.561770509183407
Loss made of: CE 0.3513117730617523, LKD 4.463022232055664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.590059208869934
Loss made of: CE 0.21750423312187195, LKD 4.959535121917725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2572745084762573, Reg Loss=4.262878894805908
Clinet index 13, End of Epoch 2/6, Average Loss=4.520153522491455, Class Loss=0.2572745084762573, Reg Loss=4.262878894805908
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/29, Loss=4.500543603301049
Loss made of: CE 0.18553762137889862, LKD 4.730278015136719, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.498941296339035
Loss made of: CE 0.21003656089305878, LKD 4.373096466064453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24256908893585205, Reg Loss=4.204375267028809
Clinet index 13, End of Epoch 3/6, Average Loss=4.446944236755371, Class Loss=0.24256908893585205, Reg Loss=4.204375267028809
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/29, Loss=4.583288699388504
Loss made of: CE 0.2031014859676361, LKD 4.377684116363525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.388715776801109
Loss made of: CE 0.219827800989151, LKD 4.378310680389404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23224003612995148, Reg Loss=4.194755554199219
Clinet index 13, End of Epoch 4/6, Average Loss=4.426995754241943, Class Loss=0.23224003612995148, Reg Loss=4.194755554199219
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/29, Loss=4.218800523877144
Loss made of: CE 0.1682024449110031, LKD 4.649975299835205, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.287598142027855
Loss made of: CE 0.2074141949415207, LKD 3.9914817810058594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22623392939567566, Reg Loss=4.158217906951904
Clinet index 13, End of Epoch 5/6, Average Loss=4.384451866149902, Class Loss=0.22623392939567566, Reg Loss=4.158217906951904
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/29, Loss=4.204519234597683
Loss made of: CE 0.19446539878845215, LKD 3.674431085586548, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.4615008071064945
Loss made of: CE 0.26936835050582886, LKD 4.813103199005127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22061680257320404, Reg Loss=4.1161417961120605
Clinet index 13, End of Epoch 6/6, Average Loss=4.336758613586426, Class Loss=0.22061680257320404, Reg Loss=4.1161417961120605
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=2.8850746035575865
Loss made of: CE 0.8968480825424194, LKD 1.825230598449707, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8259317278862, Reg Loss=2.1017889976501465
Clinet index 6, End of Epoch 1/6, Average Loss=2.927720785140991, Class Loss=0.8259317278862, Reg Loss=2.1017889976501465
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=2.81728817820549
Loss made of: CE 0.527002215385437, LKD 1.9996060132980347, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6181623339653015, Reg Loss=2.096874713897705
Clinet index 6, End of Epoch 2/6, Average Loss=2.7150371074676514, Class Loss=0.6181623339653015, Reg Loss=2.096874713897705
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=2.405357551574707
Loss made of: CE 0.33629533648490906, LKD 1.9090126752853394, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.45483681559562683, Reg Loss=2.053554058074951
Clinet index 6, End of Epoch 3/6, Average Loss=2.5083909034729004, Class Loss=0.45483681559562683, Reg Loss=2.053554058074951
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=2.446131816506386
Loss made of: CE 0.4024061858654022, LKD 1.7653952836990356, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.42762237787246704, Reg Loss=2.0258331298828125
Clinet index 6, End of Epoch 4/6, Average Loss=2.4534554481506348, Class Loss=0.42762237787246704, Reg Loss=2.0258331298828125
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=2.4165711402893066
Loss made of: CE 0.41817688941955566, LKD 1.9548730850219727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39335528016090393, Reg Loss=2.020787477493286
Clinet index 6, End of Epoch 5/6, Average Loss=2.4141428470611572, Class Loss=0.39335528016090393, Reg Loss=2.020787477493286
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=2.3894809633493423
Loss made of: CE 0.32238149642944336, LKD 1.9253164529800415, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3667040765285492, Reg Loss=2.013343095779419
Clinet index 6, End of Epoch 6/6, Average Loss=2.380047082901001, Class Loss=0.3667040765285492, Reg Loss=2.013343095779419
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=2.7691334426403045
Loss made of: CE 0.8950908184051514, LKD 2.4143126010894775, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7796918749809265, Reg Loss=1.947160243988037
Clinet index 1, End of Epoch 1/6, Average Loss=2.7268521785736084, Class Loss=0.7796918749809265, Reg Loss=1.947160243988037
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=2.465471488237381
Loss made of: CE 0.3908039927482605, LKD 1.9118574857711792, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5591447353363037, Reg Loss=1.9242037534713745
Clinet index 1, End of Epoch 2/6, Average Loss=2.4833483695983887, Class Loss=0.5591447353363037, Reg Loss=1.9242037534713745
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=2.33094037771225
Loss made of: CE 0.4399523437023163, LKD 1.9670062065124512, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.42103129625320435, Reg Loss=1.862934947013855
Clinet index 1, End of Epoch 3/6, Average Loss=2.283966302871704, Class Loss=0.42103129625320435, Reg Loss=1.862934947013855
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=2.2786307454109194
Loss made of: CE 0.40033766627311707, LKD 2.1505684852600098, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3864520192146301, Reg Loss=1.8377389907836914
Clinet index 1, End of Epoch 4/6, Average Loss=2.2241909503936768, Class Loss=0.3864520192146301, Reg Loss=1.8377389907836914
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=2.2311473071575163
Loss made of: CE 0.3216952085494995, LKD 2.062943458557129, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3478119969367981, Reg Loss=1.9432390928268433
Clinet index 1, End of Epoch 5/6, Average Loss=2.291051149368286, Class Loss=0.3478119969367981, Reg Loss=1.9432390928268433
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=2.200935792922974
Loss made of: CE 0.35252976417541504, LKD 1.7602674961090088, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3444567620754242, Reg Loss=1.8690359592437744
Clinet index 1, End of Epoch 6/6, Average Loss=2.2134926319122314, Class Loss=0.3444567620754242, Reg Loss=1.8690359592437744
federated aggregation...
Validation, Class Loss=0.4862373471260071, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.838227
Mean Acc: 0.418860
FreqW Acc: 0.745861
Mean IoU: 0.342620
Class IoU:
	class 0: 0.8916659
	class 1: 0.69278383
	class 2: 0.2994916
	class 3: 0.0041759512
	class 4: 0.50113666
	class 5: 0.3279803
	class 6: 0.35819623
	class 7: 0.74261034
	class 8: 0.15944017
	class 9: 0.15741082
	class 10: 0.0
	class 11: 0.025244648
	class 12: 0.2939287
Class Acc:
	class 0: 0.9835504
	class 1: 0.6959261
	class 2: 0.54516625
	class 3: 0.0041759512
	class 4: 0.5287758
	class 5: 0.33186918
	class 6: 0.3588191
	class 7: 0.7505398
	class 8: 0.15957308
	class 9: 0.22675546
	class 10: 0.0
	class 11: 0.032598067
	class 12: 0.8274287

federated global round: 12, step: 2
select part of clients to conduct local training
[11, 0, 8, 14]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=2.627460151910782
Loss made of: CE 0.5978184342384338, LKD 1.6670562028884888, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6279303431510925, Reg Loss=2.0065085887908936
Clinet index 11, End of Epoch 1/6, Average Loss=2.634438991546631, Class Loss=0.6279303431510925, Reg Loss=2.0065085887908936
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=2.5365594416856765
Loss made of: CE 0.41887912154197693, LKD 1.8114354610443115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.48866742849349976, Reg Loss=1.9723401069641113
Clinet index 11, End of Epoch 2/6, Average Loss=2.461007595062256, Class Loss=0.48866742849349976, Reg Loss=1.9723401069641113
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=2.3542631775140763
Loss made of: CE 0.41318023204803467, LKD 2.1582257747650146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.39178919792175293, Reg Loss=1.9417670965194702
Clinet index 11, End of Epoch 3/6, Average Loss=2.3335561752319336, Class Loss=0.39178919792175293, Reg Loss=1.9417670965194702
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=2.351887947320938
Loss made of: CE 0.3221544921398163, LKD 1.696906566619873, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.37261733412742615, Reg Loss=1.929358959197998
Clinet index 11, End of Epoch 4/6, Average Loss=2.301976203918457, Class Loss=0.37261733412742615, Reg Loss=1.929358959197998
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=2.257432448863983
Loss made of: CE 0.2933311462402344, LKD 1.620276689529419, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3559528887271881, Reg Loss=1.915001630783081
Clinet index 11, End of Epoch 5/6, Average Loss=2.2709546089172363, Class Loss=0.3559528887271881, Reg Loss=1.915001630783081
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=2.2552467197179795
Loss made of: CE 0.3262244164943695, LKD 1.991051197052002, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3473721742630005, Reg Loss=1.920436143875122
Clinet index 11, End of Epoch 6/6, Average Loss=2.267808437347412, Class Loss=0.3473721742630005, Reg Loss=1.920436143875122
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=4.540299761295318
Loss made of: CE 0.37049996852874756, LKD 3.7539851665496826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.472481268644333
Loss made of: CE 0.2773241102695465, LKD 3.9890706539154053, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3155742883682251, Reg Loss=4.159832954406738
Clinet index 0, End of Epoch 1/6, Average Loss=4.475407123565674, Class Loss=0.3155742883682251, Reg Loss=4.159832954406738
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=4.566777676343918
Loss made of: CE 0.21792249381542206, LKD 4.051285266876221, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.353640335798263
Loss made of: CE 0.2421858012676239, LKD 4.347228527069092, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24507220089435577, Reg Loss=4.14072847366333
Clinet index 0, End of Epoch 2/6, Average Loss=4.385800838470459, Class Loss=0.24507220089435577, Reg Loss=4.14072847366333
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=4.354364258050919
Loss made of: CE 0.1794893443584442, LKD 3.6927261352539062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.314871847629547
Loss made of: CE 0.26099488139152527, LKD 3.78914737701416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23201337456703186, Reg Loss=4.087571620941162
Clinet index 0, End of Epoch 3/6, Average Loss=4.319584846496582, Class Loss=0.23201337456703186, Reg Loss=4.087571620941162
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=4.286693152785301
Loss made of: CE 0.2773399353027344, LKD 5.608954906463623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.299345543980598
Loss made of: CE 0.2146717756986618, LKD 4.183509349822998, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2253299504518509, Reg Loss=4.041057586669922
Clinet index 0, End of Epoch 4/6, Average Loss=4.266387462615967, Class Loss=0.2253299504518509, Reg Loss=4.041057586669922
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=4.168685922026635
Loss made of: CE 0.17038163542747498, LKD 3.4541780948638916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.449777276813984
Loss made of: CE 0.23903512954711914, LKD 4.0911359786987305, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21814949810504913, Reg Loss=4.111148834228516
Clinet index 0, End of Epoch 5/6, Average Loss=4.329298496246338, Class Loss=0.21814949810504913, Reg Loss=4.111148834228516
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=4.0106280341744425
Loss made of: CE 0.2674069404602051, LKD 4.410103797912598, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.401108124852181
Loss made of: CE 0.19332408905029297, LKD 4.776066303253174, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20838965475559235, Reg Loss=4.036342144012451
Clinet index 0, End of Epoch 6/6, Average Loss=4.244731903076172, Class Loss=0.20838965475559235, Reg Loss=4.036342144012451
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=4.575979164242744
Loss made of: CE 0.41328299045562744, LKD 4.175987243652344, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.313032518327236
Loss made of: CE 0.2568281888961792, LKD 3.3433854579925537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3250482678413391, Reg Loss=4.093664169311523
Clinet index 8, End of Epoch 1/6, Average Loss=4.418712615966797, Class Loss=0.3250482678413391, Reg Loss=4.093664169311523
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=4.345215320587158
Loss made of: CE 0.22921034693717957, LKD 4.5808210372924805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.14957115650177
Loss made of: CE 0.25091272592544556, LKD 4.264069557189941, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23907266557216644, Reg Loss=4.01755952835083
Clinet index 8, End of Epoch 2/6, Average Loss=4.256632328033447, Class Loss=0.23907266557216644, Reg Loss=4.01755952835083
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=4.330885247886181
Loss made of: CE 0.2973751425743103, LKD 4.451801776885986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.238302093744278
Loss made of: CE 0.2485768049955368, LKD 4.277286052703857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24216261506080627, Reg Loss=4.028735637664795
Clinet index 8, End of Epoch 3/6, Average Loss=4.270898342132568, Class Loss=0.24216261506080627, Reg Loss=4.028735637664795
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=4.322392271459103
Loss made of: CE 0.2558332085609436, LKD 3.7347536087036133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.4609741732478145
Loss made of: CE 0.1987130343914032, LKD 4.787356853485107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22701376676559448, Reg Loss=4.067075729370117
Clinet index 8, End of Epoch 4/6, Average Loss=4.294089317321777, Class Loss=0.22701376676559448, Reg Loss=4.067075729370117
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=4.390646387636662
Loss made of: CE 0.21163181960582733, LKD 4.366459846496582, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.132325512170792
Loss made of: CE 0.30083176493644714, LKD 4.552180767059326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21341055631637573, Reg Loss=4.033039569854736
Clinet index 8, End of Epoch 5/6, Average Loss=4.246449947357178, Class Loss=0.21341055631637573, Reg Loss=4.033039569854736
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=4.26756264269352
Loss made of: CE 0.28277555108070374, LKD 3.965973377227783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.2323641493916515
Loss made of: CE 0.19168412685394287, LKD 3.9573616981506348, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2047284096479416, Reg Loss=3.9741573333740234
Clinet index 8, End of Epoch 6/6, Average Loss=4.1788859367370605, Class Loss=0.2047284096479416, Reg Loss=3.9741573333740234
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=2.6466549783945084
Loss made of: CE 0.6508225202560425, LKD 2.198239326477051, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6451424956321716, Reg Loss=2.0154011249542236
Clinet index 14, End of Epoch 1/6, Average Loss=2.66054368019104, Class Loss=0.6451424956321716, Reg Loss=2.0154011249542236
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/13, Loss=2.514039766788483
Loss made of: CE 0.4754462242126465, LKD 1.9405286312103271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.49853232502937317, Reg Loss=2.0364830493927
Clinet index 14, End of Epoch 2/6, Average Loss=2.535015344619751, Class Loss=0.49853232502937317, Reg Loss=2.0364830493927
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/13, Loss=2.3688007473945616
Loss made of: CE 0.4072042405605316, LKD 2.014793872833252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4059196710586548, Reg Loss=1.9368172883987427
Clinet index 14, End of Epoch 3/6, Average Loss=2.3427369594573975, Class Loss=0.4059196710586548, Reg Loss=1.9368172883987427
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/13, Loss=2.436809667944908
Loss made of: CE 0.3176102638244629, LKD 1.5444673299789429, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3694007694721222, Reg Loss=1.9941115379333496
Clinet index 14, End of Epoch 4/6, Average Loss=2.3635122776031494, Class Loss=0.3694007694721222, Reg Loss=1.9941115379333496
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/13, Loss=2.3389588952064515
Loss made of: CE 0.3722500205039978, LKD 2.226522207260132, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.369006872177124, Reg Loss=1.9535170793533325
Clinet index 14, End of Epoch 5/6, Average Loss=2.322524070739746, Class Loss=0.369006872177124, Reg Loss=1.9535170793533325
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/13, Loss=2.352671217918396
Loss made of: CE 0.29261288046836853, LKD 1.5908899307250977, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3552107810974121, Reg Loss=1.9794740676879883
Clinet index 14, End of Epoch 6/6, Average Loss=2.3346848487854004, Class Loss=0.3552107810974121, Reg Loss=1.9794740676879883
federated aggregation...
Validation, Class Loss=0.5120269060134888, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.832010
Mean Acc: 0.405602
FreqW Acc: 0.745947
Mean IoU: 0.322675
Class IoU:
	class 0: 0.9025213
	class 1: 0.6392435
	class 2: 0.27924067
	class 3: 0.00013419396
	class 4: 0.48828745
	class 5: 0.3241114
	class 6: 0.16585992
	class 7: 0.73052895
	class 8: 0.12042501
	class 9: 0.16962792
	class 10: 0.0
	class 11: 0.09710524
	class 12: 0.27769473
Class Acc:
	class 0: 0.98088026
	class 1: 0.6417068
	class 2: 0.4912599
	class 3: 0.00013419396
	class 4: 0.51377976
	class 5: 0.3274709
	class 6: 0.16603628
	class 7: 0.73795664
	class 8: 0.120472796
	class 9: 0.25210938
	class 10: 0.0
	class 11: 0.13603018
	class 12: 0.90499276

federated global round: 13, step: 2
select part of clients to conduct local training
[13, 5, 15, 7]
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/29, Loss=4.846796703338623
Loss made of: CE 0.32235416769981384, LKD 3.5243167877197266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.477578419446945
Loss made of: CE 0.2896191477775574, LKD 4.84163236618042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.30987095832824707, Reg Loss=4.225049018859863
Clinet index 13, End of Epoch 1/6, Average Loss=4.534919738769531, Class Loss=0.30987095832824707, Reg Loss=4.225049018859863
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/29, Loss=4.507077242434025
Loss made of: CE 0.3075750470161438, LKD 4.684308052062988, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.497590784728527
Loss made of: CE 0.20853585004806519, LKD 4.470592498779297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2482530176639557, Reg Loss=4.179370403289795
Clinet index 13, End of Epoch 2/6, Average Loss=4.427623271942139, Class Loss=0.2482530176639557, Reg Loss=4.179370403289795
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/29, Loss=4.441906753182411
Loss made of: CE 0.19575545191764832, LKD 4.506218433380127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.456577950716019
Loss made of: CE 0.20305582880973816, LKD 4.04605770111084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23971772193908691, Reg Loss=4.159460544586182
Clinet index 13, End of Epoch 3/6, Average Loss=4.399178504943848, Class Loss=0.23971772193908691, Reg Loss=4.159460544586182
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/29, Loss=4.5062704205513
Loss made of: CE 0.20110973715782166, LKD 4.079872131347656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.306098884344101
Loss made of: CE 0.19486670196056366, LKD 4.321358680725098, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22360171377658844, Reg Loss=4.159821033477783
Clinet index 13, End of Epoch 4/6, Average Loss=4.3834228515625, Class Loss=0.22360171377658844, Reg Loss=4.159821033477783
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/29, Loss=4.210237294435501
Loss made of: CE 0.18070070445537567, LKD 4.587622165679932, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.180141389369965
Loss made of: CE 0.20644307136535645, LKD 3.8000717163085938, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21860112249851227, Reg Loss=4.112155914306641
Clinet index 13, End of Epoch 5/6, Average Loss=4.330757141113281, Class Loss=0.21860112249851227, Reg Loss=4.112155914306641
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/29, Loss=4.126343335211277
Loss made of: CE 0.1944175660610199, LKD 3.622337818145752, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.4025796234607695
Loss made of: CE 0.24589815735816956, LKD 4.937863349914551, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21492746472358704, Reg Loss=4.058281421661377
Clinet index 13, End of Epoch 6/6, Average Loss=4.273209095001221, Class Loss=0.21492746472358704, Reg Loss=4.058281421661377
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=4.254427175223827
Loss made of: CE 0.26158154010772705, LKD 3.2259225845336914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.221779233217239
Loss made of: CE 0.2665984630584717, LKD 3.891993284225464, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.28731632232666016, Reg Loss=4.055163383483887
Clinet index 5, End of Epoch 1/6, Average Loss=4.342479705810547, Class Loss=0.28731632232666016, Reg Loss=4.055163383483887
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/29, Loss=4.152505400776863
Loss made of: CE 0.2021126002073288, LKD 4.176396369934082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.24374894797802
Loss made of: CE 0.23580364882946014, LKD 4.234915733337402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23353765904903412, Reg Loss=3.9943203926086426
Clinet index 5, End of Epoch 2/6, Average Loss=4.227858066558838, Class Loss=0.23353765904903412, Reg Loss=3.9943203926086426
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/29, Loss=4.387811003625393
Loss made of: CE 0.20646247267723083, LKD 3.7391529083251953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.0116237416863445
Loss made of: CE 0.2028798758983612, LKD 2.874122142791748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2222684621810913, Reg Loss=4.004520416259766
Clinet index 5, End of Epoch 3/6, Average Loss=4.2267889976501465, Class Loss=0.2222684621810913, Reg Loss=4.004520416259766
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/29, Loss=4.250353983044624
Loss made of: CE 0.19860157370567322, LKD 4.162083625793457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.090078608691693
Loss made of: CE 0.2816217839717865, LKD 3.78419828414917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21413636207580566, Reg Loss=3.9782941341400146
Clinet index 5, End of Epoch 4/6, Average Loss=4.19243049621582, Class Loss=0.21413636207580566, Reg Loss=3.9782941341400146
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=3.924623841047287
Loss made of: CE 0.250199556350708, LKD 3.7974681854248047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.6331260859966275
Loss made of: CE 0.20857815444469452, LKD 4.033691883087158, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.212663933634758, Reg Loss=3.9817051887512207
Clinet index 5, End of Epoch 5/6, Average Loss=4.194369316101074, Class Loss=0.212663933634758, Reg Loss=3.9817051887512207
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/29, Loss=4.1549371346831325
Loss made of: CE 0.20323406159877777, LKD 4.6328840255737305, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=3.957904849946499
Loss made of: CE 0.18078431487083435, LKD 3.115680694580078, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20160815119743347, Reg Loss=3.915367603302002
Clinet index 5, End of Epoch 6/6, Average Loss=4.116975784301758, Class Loss=0.20160815119743347, Reg Loss=3.915367603302002
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=2.4469090819358827
Loss made of: CE 0.4638809859752655, LKD 1.5676591396331787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.516340434551239, Reg Loss=1.9455785751342773
Clinet index 15, End of Epoch 1/6, Average Loss=2.461919069290161, Class Loss=0.516340434551239, Reg Loss=1.9455785751342773
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=2.416781210899353
Loss made of: CE 0.33935248851776123, LKD 1.6014280319213867, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4123196303844452, Reg Loss=1.9200422763824463
Clinet index 15, End of Epoch 2/6, Average Loss=2.332361936569214, Class Loss=0.4123196303844452, Reg Loss=1.9200422763824463
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=2.231893536448479
Loss made of: CE 0.32447749376296997, LKD 2.085496187210083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.35209789872169495, Reg Loss=1.868180751800537
Clinet index 15, End of Epoch 3/6, Average Loss=2.220278739929199, Class Loss=0.35209789872169495, Reg Loss=1.868180751800537
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=2.1860176622867584
Loss made of: CE 0.34952256083488464, LKD 2.1854054927825928, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3217175602912903, Reg Loss=1.876946210861206
Clinet index 15, End of Epoch 4/6, Average Loss=2.1986637115478516, Class Loss=0.3217175602912903, Reg Loss=1.876946210861206
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=2.1626408994197845
Loss made of: CE 0.2780822515487671, LKD 1.9448611736297607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.31976792216300964, Reg Loss=1.872602939605713
Clinet index 15, End of Epoch 5/6, Average Loss=2.192370891571045, Class Loss=0.31976792216300964, Reg Loss=1.872602939605713
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=2.1989524364471436
Loss made of: CE 0.2721744179725647, LKD 1.6004860401153564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3172645568847656, Reg Loss=1.8612133264541626
Clinet index 15, End of Epoch 6/6, Average Loss=2.1784777641296387, Class Loss=0.3172645568847656, Reg Loss=1.8612133264541626
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=2.6034689009189607
Loss made of: CE 0.5268340110778809, LKD 2.033353805541992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5688155293464661, Reg Loss=1.9766160249710083
Clinet index 7, End of Epoch 1/6, Average Loss=2.545431613922119, Class Loss=0.5688155293464661, Reg Loss=1.9766160249710083
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/13, Loss=2.400800085067749
Loss made of: CE 0.4096348285675049, LKD 2.0332024097442627, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.44329598546028137, Reg Loss=1.9478108882904053
Clinet index 7, End of Epoch 2/6, Average Loss=2.3911068439483643, Class Loss=0.44329598546028137, Reg Loss=1.9478108882904053
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=2.280848628282547
Loss made of: CE 0.35050806403160095, LKD 1.9278843402862549, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38154837489128113, Reg Loss=1.8962048292160034
Clinet index 7, End of Epoch 3/6, Average Loss=2.2777531147003174, Class Loss=0.38154837489128113, Reg Loss=1.8962048292160034
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/13, Loss=2.22858549952507
Loss made of: CE 0.4015633463859558, LKD 2.090388536453247, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36083078384399414, Reg Loss=1.8984068632125854
Clinet index 7, End of Epoch 4/6, Average Loss=2.259237766265869, Class Loss=0.36083078384399414, Reg Loss=1.8984068632125854
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/13, Loss=2.2863004744052886
Loss made of: CE 0.3076907992362976, LKD 1.6884453296661377, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3422418534755707, Reg Loss=1.9367246627807617
Clinet index 7, End of Epoch 5/6, Average Loss=2.2789664268493652, Class Loss=0.3422418534755707, Reg Loss=1.9367246627807617
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/13, Loss=2.2621005058288572
Loss made of: CE 0.3306107223033905, LKD 1.625309944152832, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.33509519696235657, Reg Loss=1.8778927326202393
Clinet index 7, End of Epoch 6/6, Average Loss=2.2129878997802734, Class Loss=0.33509519696235657, Reg Loss=1.8778927326202393
federated aggregation...
Validation, Class Loss=0.5285073518753052, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.829464
Mean Acc: 0.398918
FreqW Acc: 0.745776
Mean IoU: 0.313135
Class IoU:
	class 0: 0.90603644
	class 1: 0.576888
	class 2: 0.26575783
	class 3: 2.2108583e-05
	class 4: 0.4542428
	class 5: 0.33569866
	class 6: 0.09046064
	class 7: 0.7196423
	class 8: 0.12257778
	class 9: 0.16655977
	class 10: 0.0
	class 11: 0.16088188
	class 12: 0.2719826
Class Acc:
	class 0: 0.9791807
	class 1: 0.57852745
	class 2: 0.45885387
	class 3: 2.2108583e-05
	class 4: 0.47411388
	class 5: 0.33886644
	class 6: 0.090522155
	class 7: 0.72686756
	class 8: 0.1226344
	class 9: 0.2425902
	class 10: 0.0
	class 11: 0.24672136
	class 12: 0.9270312

federated global round: 14, step: 2
select part of clients to conduct local training
[17, 3, 12, 16]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=4.471644893288612
Loss made of: CE 0.24701589345932007, LKD 3.40956449508667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.805593410134316
Loss made of: CE 0.2947154641151428, LKD 4.147969722747803, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2971719205379486, Reg Loss=4.271528720855713
Clinet index 17, End of Epoch 1/6, Average Loss=4.568700790405273, Class Loss=0.2971719205379486, Reg Loss=4.271528720855713
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=4.2090980291366575
Loss made of: CE 0.17885124683380127, LKD 4.730696201324463, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.5753873273730274
Loss made of: CE 0.2215244472026825, LKD 4.3159894943237305, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2291267365217209, Reg Loss=4.1679463386535645
Clinet index 17, End of Epoch 2/6, Average Loss=4.397073268890381, Class Loss=0.2291267365217209, Reg Loss=4.1679463386535645
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=4.301271599531174
Loss made of: CE 0.2675870656967163, LKD 3.860199451446533, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.534508448839188
Loss made of: CE 0.17033986747264862, LKD 4.422687530517578, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2306324988603592, Reg Loss=4.1806488037109375
Clinet index 17, End of Epoch 3/6, Average Loss=4.411281108856201, Class Loss=0.2306324988603592, Reg Loss=4.1806488037109375
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=4.314425425231457
Loss made of: CE 0.24917659163475037, LKD 4.813040733337402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.269016247987747
Loss made of: CE 0.15711921453475952, LKD 4.218137264251709, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21837280690670013, Reg Loss=4.162387847900391
Clinet index 17, End of Epoch 4/6, Average Loss=4.380760669708252, Class Loss=0.21837280690670013, Reg Loss=4.162387847900391
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=4.464807465672493
Loss made of: CE 0.21219146251678467, LKD 3.73760986328125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.377254748344422
Loss made of: CE 0.17827826738357544, LKD 4.316691875457764, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21818238496780396, Reg Loss=4.177015781402588
Clinet index 17, End of Epoch 5/6, Average Loss=4.395198345184326, Class Loss=0.21818238496780396, Reg Loss=4.177015781402588
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=4.314271964132786
Loss made of: CE 0.23836128413677216, LKD 3.912261486053467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.208402779698372
Loss made of: CE 0.21567291021347046, LKD 3.898221254348755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2162049561738968, Reg Loss=4.128615856170654
Clinet index 17, End of Epoch 6/6, Average Loss=4.344820976257324, Class Loss=0.2162049561738968, Reg Loss=4.128615856170654
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=4.456748978793621
Loss made of: CE 0.26660892367362976, LKD 3.4564807415008545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.280239844322205
Loss made of: CE 0.22957271337509155, LKD 4.1047773361206055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.27456143498420715, Reg Loss=4.116166591644287
Clinet index 3, End of Epoch 1/6, Average Loss=4.390727996826172, Class Loss=0.27456143498420715, Reg Loss=4.116166591644287
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=4.4219548285007475
Loss made of: CE 0.18730127811431885, LKD 3.912536859512329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.17919892668724
Loss made of: CE 0.2695532441139221, LKD 3.8473174571990967, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22702641785144806, Reg Loss=4.110342979431152
Clinet index 3, End of Epoch 2/6, Average Loss=4.337369441986084, Class Loss=0.22702641785144806, Reg Loss=4.110342979431152
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=4.6641841128468515
Loss made of: CE 0.2953800857067108, LKD 4.361682891845703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=3.983143925666809
Loss made of: CE 0.1699533462524414, LKD 3.4034833908081055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Class Loss=0.22861908376216888, Reg Loss=4.1920695304870605
Clinet index 3, End of Epoch 3/6, Average Loss=4.420688629150391, Class Loss=0.22861908376216888, Reg Loss=4.1920695304870605
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=4.464450350403785
Loss made of: CE 0.19643399119377136, LKD 3.9623260498046875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.2803165599703785
Loss made of: CE 0.1581423282623291, LKD 3.8786895275115967, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21802914142608643, Reg Loss=4.101733207702637
Clinet index 3, End of Epoch 4/6, Average Loss=4.319762229919434, Class Loss=0.21802914142608643, Reg Loss=4.101733207702637
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=4.242125788331032
Loss made of: CE 0.1678287386894226, LKD 3.7462399005889893, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=4.280605062842369
Loss made of: CE 0.18226605653762817, LKD 3.8668882846832275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21121883392333984, Reg Loss=4.063674449920654
Clinet index 3, End of Epoch 5/6, Average Loss=4.274893283843994, Class Loss=0.21121883392333984, Reg Loss=4.063674449920654
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=4.509936715662479
Loss made of: CE 0.2271113395690918, LKD 4.196152210235596, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.154329487681389
Loss made of: CE 0.2320806235074997, LKD 3.8149330615997314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21274131536483765, Reg Loss=4.100032806396484
Clinet index 3, End of Epoch 6/6, Average Loss=4.312774181365967, Class Loss=0.21274131536483765, Reg Loss=4.100032806396484
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=2.4971001893281937
Loss made of: CE 0.3958073854446411, LKD 1.7239218950271606, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5313884019851685, Reg Loss=1.9408894777297974
Clinet index 12, End of Epoch 1/6, Average Loss=2.472277879714966, Class Loss=0.5313884019851685, Reg Loss=1.9408894777297974
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=2.3024224668741224
Loss made of: CE 0.3627736568450928, LKD 1.6988892555236816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4014224708080292, Reg Loss=1.9068747758865356
Clinet index 12, End of Epoch 2/6, Average Loss=2.3082971572875977, Class Loss=0.4014224708080292, Reg Loss=1.9068747758865356
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=2.276336580514908
Loss made of: CE 0.3093686103820801, LKD 1.5820821523666382, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.36631208658218384, Reg Loss=1.92826247215271
Clinet index 12, End of Epoch 3/6, Average Loss=2.294574499130249, Class Loss=0.36631208658218384, Reg Loss=1.92826247215271
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=2.2916856318712235
Loss made of: CE 0.30828559398651123, LKD 1.6779935359954834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3487909436225891, Reg Loss=1.8987406492233276
Clinet index 12, End of Epoch 4/6, Average Loss=2.2475316524505615, Class Loss=0.3487909436225891, Reg Loss=1.8987406492233276
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=2.2874761909246444
Loss made of: CE 0.3567851483821869, LKD 1.5701549053192139, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3398360013961792, Reg Loss=1.8685778379440308
Clinet index 12, End of Epoch 5/6, Average Loss=2.20841383934021, Class Loss=0.3398360013961792, Reg Loss=1.8685778379440308
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=2.190208101272583
Loss made of: CE 0.29315993189811707, LKD 1.657418131828308, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32939019799232483, Reg Loss=1.871443271636963
Clinet index 12, End of Epoch 6/6, Average Loss=2.200833559036255, Class Loss=0.32939019799232483, Reg Loss=1.871443271636963
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=4.718547335267067
Loss made of: CE 0.2577266991138458, LKD 4.044508457183838, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=4.373996479809284
Loss made of: CE 0.28429263830184937, LKD 5.10479211807251, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2921372652053833, Reg Loss=4.219456195831299
Clinet index 16, End of Epoch 1/6, Average Loss=4.511593341827393, Class Loss=0.2921372652053833, Reg Loss=4.219456195831299
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/29, Loss=4.477630873024464
Loss made of: CE 0.2778280973434448, LKD 4.162802219390869, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=4.331259997189045
Loss made of: CE 0.18183356523513794, LKD 4.3119354248046875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24436266720294952, Reg Loss=4.11888313293457
Clinet index 16, End of Epoch 2/6, Average Loss=4.363245964050293, Class Loss=0.24436266720294952, Reg Loss=4.11888313293457
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/29, Loss=4.290432953834534
Loss made of: CE 0.2338239997625351, LKD 4.672420978546143, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=4.125216694176197
Loss made of: CE 0.17959722876548767, LKD 3.240072011947632, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22744907438755035, Reg Loss=4.045103073120117
Clinet index 16, End of Epoch 3/6, Average Loss=4.272552013397217, Class Loss=0.22744907438755035, Reg Loss=4.045103073120117
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/29, Loss=4.219277483224869
Loss made of: CE 0.25997328758239746, LKD 3.5541625022888184, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=4.399447797238826
Loss made of: CE 0.22253505885601044, LKD 4.107911109924316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22089742124080658, Reg Loss=4.100419998168945
Clinet index 16, End of Epoch 4/6, Average Loss=4.321317195892334, Class Loss=0.22089742124080658, Reg Loss=4.100419998168945
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/29, Loss=4.556859643757344
Loss made of: CE 0.24552977085113525, LKD 4.320751667022705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=3.9754046857357026
Loss made of: CE 0.1683500111103058, LKD 2.8417251110076904, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22097648680210114, Reg Loss=4.094296932220459
Clinet index 16, End of Epoch 5/6, Average Loss=4.315273284912109, Class Loss=0.22097648680210114, Reg Loss=4.094296932220459
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/29, Loss=4.37824389487505
Loss made of: CE 0.19627392292022705, LKD 4.16359806060791, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=4.327742621302605
Loss made of: CE 0.1877048909664154, LKD 3.7196621894836426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21712465584278107, Reg Loss=4.125319957733154
Clinet index 16, End of Epoch 6/6, Average Loss=4.34244441986084, Class Loss=0.21712465584278107, Reg Loss=4.125319957733154
federated aggregation...
Validation, Class Loss=0.5428224205970764, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.825967
Mean Acc: 0.385087
FreqW Acc: 0.742804
Mean IoU: 0.299815
Class IoU:
	class 0: 0.90786
	class 1: 0.53609794
	class 2: 0.27004385
	class 3: 0.0
	class 4: 0.4420039
	class 5: 0.3063858
	class 6: 0.07163335
	class 7: 0.76102144
	class 8: 0.05791533
	class 9: 0.15579018
	class 10: 0.0
	class 11: 0.12948743
	class 12: 0.25935286
Class Acc:
	class 0: 0.979637
	class 1: 0.53723913
	class 2: 0.46818995
	class 3: 0.0
	class 4: 0.46034834
	class 5: 0.30994177
	class 6: 0.07167208
	class 7: 0.77203834
	class 8: 0.057925917
	class 9: 0.25242794
	class 10: 0.0
	class 11: 0.14646901
	class 12: 0.9502401

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[13, 9, 6, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=5.08437557220459
Loss made of: CE 1.4312512874603271, LKD 3.6198229789733887, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.7750146389007568, Reg Loss=3.215327262878418
Clinet index 13, End of Epoch 1/6, Average Loss=4.990342140197754, Class Loss=1.7750146389007568, Reg Loss=3.215327262878418
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=4.32636633515358
Loss made of: CE 0.823377788066864, LKD 2.7901439666748047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.1271896362304688, Reg Loss=3.121633529663086
Clinet index 13, End of Epoch 2/6, Average Loss=4.248823165893555, Class Loss=1.1271896362304688, Reg Loss=3.121633529663086
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=3.71137777864933
Loss made of: CE 0.4807320237159729, LKD 3.122101306915283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5787002444267273, Reg Loss=3.1444106101989746
Clinet index 13, End of Epoch 3/6, Average Loss=3.7231109142303467, Class Loss=0.5787002444267273, Reg Loss=3.1444106101989746
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=3.448233240842819
Loss made of: CE 0.2625436782836914, LKD 3.55081844329834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.29946038126945496, Reg Loss=3.1125946044921875
Clinet index 13, End of Epoch 4/6, Average Loss=3.412055015563965, Class Loss=0.29946038126945496, Reg Loss=3.1125946044921875
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=3.2810192868113517
Loss made of: CE 0.24816463887691498, LKD 2.9710886478424072, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23513163626194, Reg Loss=3.04475474357605
Clinet index 13, End of Epoch 5/6, Average Loss=3.279886484146118, Class Loss=0.23513163626194, Reg Loss=3.04475474357605
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=3.242615620791912
Loss made of: CE 0.2303495705127716, LKD 3.271328926086426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2105565369129181, Reg Loss=3.021617889404297
Clinet index 13, End of Epoch 6/6, Average Loss=3.2321743965148926, Class Loss=0.2105565369129181, Reg Loss=3.021617889404297
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=7.1207638621330265
Loss made of: CE 2.0136337280273438, LKD 4.910541534423828, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.8896880149841309, Reg Loss=4.888045310974121
Clinet index 9, End of Epoch 1/6, Average Loss=6.777733325958252, Class Loss=1.8896880149841309, Reg Loss=4.888045310974121
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=5.2704929411411285
Loss made of: CE 0.8764650821685791, LKD 3.4142916202545166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2164692878723145, Reg Loss=4.0350422859191895
Clinet index 9, End of Epoch 2/6, Average Loss=5.251511573791504, Class Loss=1.2164692878723145, Reg Loss=4.0350422859191895
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.669126987457275
Loss made of: CE 0.6417672038078308, LKD 3.854198694229126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7177574634552002, Reg Loss=3.897541046142578
Clinet index 9, End of Epoch 3/6, Average Loss=4.615298271179199, Class Loss=0.7177574634552002, Reg Loss=3.897541046142578
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.374006721377373
Loss made of: CE 0.3275357782840729, LKD 3.8946337699890137, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.43952101469039917, Reg Loss=3.860156774520874
Clinet index 9, End of Epoch 4/6, Average Loss=4.299677848815918, Class Loss=0.43952101469039917, Reg Loss=3.860156774520874
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=4.055775126814842
Loss made of: CE 0.26123470067977905, LKD 3.2925777435302734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3003719449043274, Reg Loss=3.8202996253967285
Clinet index 9, End of Epoch 5/6, Average Loss=4.12067174911499, Class Loss=0.3003719449043274, Reg Loss=3.8202996253967285
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=4.0596813842654225
Loss made of: CE 0.2156360149383545, LKD 3.4983315467834473, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2719471752643585, Reg Loss=3.8229575157165527
Clinet index 9, End of Epoch 6/6, Average Loss=4.094904899597168, Class Loss=0.2719471752643585, Reg Loss=3.8229575157165527
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=5.018053126335144
Loss made of: CE 1.6457877159118652, LKD 3.1170642375946045, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.7658674716949463, Reg Loss=3.1906402111053467
Clinet index 6, End of Epoch 1/6, Average Loss=4.956507682800293, Class Loss=1.7658674716949463, Reg Loss=3.1906402111053467
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=4.224020797014236
Loss made of: CE 1.1283637285232544, LKD 3.330401659011841, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.110870122909546, Reg Loss=3.085315704345703
Clinet index 6, End of Epoch 2/6, Average Loss=4.196186065673828, Class Loss=1.110870122909546, Reg Loss=3.085315704345703
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=3.6956448376178743
Loss made of: CE 0.48313045501708984, LKD 3.225342273712158, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5878584980964661, Reg Loss=3.0543549060821533
Clinet index 6, End of Epoch 3/6, Average Loss=3.6422133445739746, Class Loss=0.5878584980964661, Reg Loss=3.0543549060821533
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=3.311548615992069
Loss made of: CE 0.26266855001449585, LKD 2.7774205207824707, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.29882916808128357, Reg Loss=3.00292706489563
Clinet index 6, End of Epoch 4/6, Average Loss=3.3017561435699463, Class Loss=0.29882916808128357, Reg Loss=3.00292706489563
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=3.2076265260577204
Loss made of: CE 0.27888187766075134, LKD 2.771541118621826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2348756045103073, Reg Loss=2.9856483936309814
Clinet index 6, End of Epoch 5/6, Average Loss=3.2205240726470947, Class Loss=0.2348756045103073, Reg Loss=2.9856483936309814
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=3.1089482977986336
Loss made of: CE 0.18711596727371216, LKD 2.8145945072174072, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2080719769001007, Reg Loss=2.9478917121887207
Clinet index 6, End of Epoch 6/6, Average Loss=3.155963659286499, Class Loss=0.2080719769001007, Reg Loss=2.9478917121887207
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=6.6720135569572445
Loss made of: CE 1.8747928142547607, LKD 3.580950975418091, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.864884614944458, Reg Loss=4.748224258422852
Clinet index 5, End of Epoch 1/6, Average Loss=6.6131086349487305, Class Loss=1.864884614944458, Reg Loss=4.748224258422852
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=5.349555826187133
Loss made of: CE 1.0954618453979492, LKD 3.803929328918457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.233620524406433, Reg Loss=4.139458656311035
Clinet index 5, End of Epoch 2/6, Average Loss=5.373079299926758, Class Loss=1.233620524406433, Reg Loss=4.139458656311035
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.590394413471222
Loss made of: CE 0.6961354613304138, LKD 3.9939663410186768, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7390174865722656, Reg Loss=3.8713483810424805
Clinet index 5, End of Epoch 3/6, Average Loss=4.610365867614746, Class Loss=0.7390174865722656, Reg Loss=3.8713483810424805
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.361444014310837
Loss made of: CE 0.42550310492515564, LKD 3.9132044315338135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.44034451246261597, Reg Loss=3.871124744415283
Clinet index 5, End of Epoch 4/6, Average Loss=4.311469078063965, Class Loss=0.44034451246261597, Reg Loss=3.871124744415283
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=4.119893234968186
Loss made of: CE 0.3429087996482849, LKD 3.371375322341919, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.31473609805107117, Reg Loss=3.816669225692749
Clinet index 5, End of Epoch 5/6, Average Loss=4.131405353546143, Class Loss=0.31473609805107117, Reg Loss=3.816669225692749
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=4.098564714193344
Loss made of: CE 0.2296135425567627, LKD 4.713601112365723, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26224827766418457, Reg Loss=3.8455073833465576
Clinet index 5, End of Epoch 6/6, Average Loss=4.107755661010742, Class Loss=0.26224827766418457, Reg Loss=3.8455073833465576
federated aggregation...
Validation, Class Loss=0.5879442691802979, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.811446
Mean Acc: 0.289052
FreqW Acc: 0.698336
Mean IoU: 0.239451
Class IoU:
	class 0: 0.8624975
	class 1: 0.33552364
	class 2: 0.22545622
	class 3: 0.0011303655
	class 4: 0.39591393
	class 5: 0.3847323
	class 6: 0.114270896
	class 7: 0.6895318
	class 8: 0.2251105
	class 9: 0.043094765
	class 10: 0.0
	class 11: 0.00030293202
	class 12: 0.24614318
	class 13: 0.006735076
	class 14: 0.061319515
Class Acc:
	class 0: 0.9918015
	class 1: 0.3358307
	class 2: 0.34965652
	class 3: 0.0011303655
	class 4: 0.40998563
	class 5: 0.3881097
	class 6: 0.11435039
	class 7: 0.69761837
	class 8: 0.22529821
	class 9: 0.047688115
	class 10: 0.0
	class 11: 0.00030312635
	class 12: 0.6911199
	class 13: 0.010208266
	class 14: 0.072680205

federated global round: 16, step: 3
select part of clients to conduct local training
[18, 5, 20, 0]
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.45673516690731
Loss made of: CE 0.5358741283416748, LKD 3.6182940006256104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6574431657791138, Reg Loss=3.8665480613708496
Clinet index 18, End of Epoch 1/6, Average Loss=4.523991107940674, Class Loss=0.6574431657791138, Reg Loss=3.8665480613708496
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=4.265222609043121
Loss made of: CE 0.3389570713043213, LKD 4.1354851722717285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4062371253967285, Reg Loss=3.7665228843688965
Clinet index 18, End of Epoch 2/6, Average Loss=4.172760009765625, Class Loss=0.4062371253967285, Reg Loss=3.7665228843688965
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=3.9754653468728067
Loss made of: CE 0.22867588698863983, LKD 2.85830020904541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27328914403915405, Reg Loss=3.728768825531006
Clinet index 18, End of Epoch 3/6, Average Loss=4.002058029174805, Class Loss=0.27328914403915405, Reg Loss=3.728768825531006
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=4.02752419412136
Loss made of: CE 0.24256286025047302, LKD 3.549348831176758, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24159452319145203, Reg Loss=3.6884231567382812
Clinet index 18, End of Epoch 4/6, Average Loss=3.9300177097320557, Class Loss=0.24159452319145203, Reg Loss=3.6884231567382812
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=3.7323822408914564
Loss made of: CE 0.24684850871562958, LKD 2.8937582969665527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2296447604894638, Reg Loss=3.680450201034546
Clinet index 18, End of Epoch 5/6, Average Loss=3.910094976425171, Class Loss=0.2296447604894638, Reg Loss=3.680450201034546
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.833026687800884
Loss made of: CE 0.2215077131986618, LKD 3.210263729095459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2233118861913681, Reg Loss=3.650242328643799
Clinet index 18, End of Epoch 6/6, Average Loss=3.873554229736328, Class Loss=0.2233118861913681, Reg Loss=3.650242328643799
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=4.546502739191055
Loss made of: CE 0.6650264263153076, LKD 3.326003313064575, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6654531955718994, Reg Loss=3.9086170196533203
Clinet index 5, End of Epoch 1/6, Average Loss=4.574069976806641, Class Loss=0.6654531955718994, Reg Loss=3.9086170196533203
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=4.1365712732076645
Loss made of: CE 0.4039956033229828, LKD 3.4322798252105713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.44547039270401, Reg Loss=3.726572036743164
Clinet index 5, End of Epoch 2/6, Average Loss=4.172042369842529, Class Loss=0.44547039270401, Reg Loss=3.726572036743164
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=4.119359409809112
Loss made of: CE 0.2926720380783081, LKD 4.060445785522461, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3165610134601593, Reg Loss=3.8546721935272217
Clinet index 5, End of Epoch 3/6, Average Loss=4.171233177185059, Class Loss=0.3165610134601593, Reg Loss=3.8546721935272217
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=4.098704153299332
Loss made of: CE 0.3530328869819641, LKD 3.7975101470947266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27491405606269836, Reg Loss=3.777980327606201
Clinet index 5, End of Epoch 4/6, Average Loss=4.052894592285156, Class Loss=0.27491405606269836, Reg Loss=3.777980327606201
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=4.068325592577457
Loss made of: CE 0.35083240270614624, LKD 3.649636745452881, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2571677565574646, Reg Loss=3.816317081451416
Clinet index 5, End of Epoch 5/6, Average Loss=4.073484897613525, Class Loss=0.2571677565574646, Reg Loss=3.816317081451416
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=4.031639660894871
Loss made of: CE 0.21973609924316406, LKD 4.400839805603027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24990573525428772, Reg Loss=3.80775785446167
Clinet index 5, End of Epoch 6/6, Average Loss=4.057663440704346, Class Loss=0.24990573525428772, Reg Loss=3.80775785446167
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.729405742883682
Loss made of: CE 0.763934850692749, LKD 4.516628265380859, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6520416140556335, Reg Loss=4.000967025756836
Clinet index 20, End of Epoch 1/6, Average Loss=4.653008460998535, Class Loss=0.6520416140556335, Reg Loss=4.000967025756836
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=4.376533889770508
Loss made of: CE 0.3420078456401825, LKD 4.142852783203125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3947334289550781, Reg Loss=3.8985390663146973
Clinet index 20, End of Epoch 2/6, Average Loss=4.293272495269775, Class Loss=0.3947334289550781, Reg Loss=3.8985390663146973
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=4.114685089886189
Loss made of: CE 0.296100378036499, LKD 4.4094557762146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28178325295448303, Reg Loss=3.883509635925293
Clinet index 20, End of Epoch 3/6, Average Loss=4.165292739868164, Class Loss=0.28178325295448303, Reg Loss=3.883509635925293
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=4.065681199729442
Loss made of: CE 0.22289584577083588, LKD 4.139016628265381, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24741235375404358, Reg Loss=3.8335728645324707
Clinet index 20, End of Epoch 4/6, Average Loss=4.080985069274902, Class Loss=0.24741235375404358, Reg Loss=3.8335728645324707
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=4.132288494706154
Loss made of: CE 0.22797845304012299, LKD 3.9529926776885986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23094388842582703, Reg Loss=3.8732428550720215
Clinet index 20, End of Epoch 5/6, Average Loss=4.104186534881592, Class Loss=0.23094388842582703, Reg Loss=3.8732428550720215
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.891147384047508
Loss made of: CE 0.24248580634593964, LKD 3.494166135787964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22314152121543884, Reg Loss=3.7933425903320312
Clinet index 20, End of Epoch 6/6, Average Loss=4.016484260559082, Class Loss=0.22314152121543884, Reg Loss=3.7933425903320312
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=3.5762532591819762
Loss made of: CE 0.49529922008514404, LKD 2.820754051208496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5399606823921204, Reg Loss=3.00871205329895
Clinet index 0, End of Epoch 1/6, Average Loss=3.548672676086426, Class Loss=0.5399606823921204, Reg Loss=3.00871205329895
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/11, Loss=3.306369757652283
Loss made of: CE 0.22622275352478027, LKD 2.604459047317505, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3435554504394531, Reg Loss=2.9115004539489746
Clinet index 0, End of Epoch 2/6, Average Loss=3.2550559043884277, Class Loss=0.3435554504394531, Reg Loss=2.9115004539489746
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/11, Loss=3.1879879787564276
Loss made of: CE 0.2512371838092804, LKD 2.805473566055298, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2496267557144165, Reg Loss=2.9493255615234375
Clinet index 0, End of Epoch 3/6, Average Loss=3.1989521980285645, Class Loss=0.2496267557144165, Reg Loss=2.9493255615234375
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/11, Loss=3.1892406806349753
Loss made of: CE 0.2335924208164215, LKD 3.101889133453369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22856175899505615, Reg Loss=2.9531071186065674
Clinet index 0, End of Epoch 4/6, Average Loss=3.181668758392334, Class Loss=0.22856175899505615, Reg Loss=2.9531071186065674
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/11, Loss=3.1458870634436606
Loss made of: CE 0.21581535041332245, LKD 2.8060059547424316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2302844375371933, Reg Loss=2.939070701599121
Clinet index 0, End of Epoch 5/6, Average Loss=3.1693551540374756, Class Loss=0.2302844375371933, Reg Loss=2.939070701599121
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/11, Loss=3.1174590602517127
Loss made of: CE 0.18446366488933563, LKD 2.2592005729675293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21762368083000183, Reg Loss=2.8683454990386963
Clinet index 0, End of Epoch 6/6, Average Loss=3.0859692096710205, Class Loss=0.21762368083000183, Reg Loss=2.8683454990386963
federated aggregation...
Validation, Class Loss=0.6971490383148193, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.774520
Mean Acc: 0.199765
FreqW Acc: 0.686997
Mean IoU: 0.136704
Class IoU:
	class 0: 0.8805161
	class 1: 0.016063575
	class 2: 0.0
	class 3: 0.0
	class 4: 0.18721266
	class 5: 0.07746646
	class 6: 0.07898507
	class 7: 0.44198802
	class 8: 0.097034834
	class 9: 0.0038821476
	class 10: 0.0
	class 11: 0.00035435238
	class 12: 0.12647104
	class 13: 0.029273385
	class 14: 0.111317694
Class Acc:
	class 0: 0.9773488
	class 1: 0.01606372
	class 2: 0.0
	class 3: 0.0
	class 4: 0.19059885
	class 5: 0.07747037
	class 6: 0.07901207
	class 7: 0.4445225
	class 8: 0.09705388
	class 9: 0.00390179
	class 10: 0.0
	class 11: 0.00035435238
	class 12: 0.16819157
	class 13: 0.058769565
	class 14: 0.88318896

federated global round: 17, step: 3
select part of clients to conduct local training
[1, 16, 6, 21]
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=3.686483180522919
Loss made of: CE 0.5056540966033936, LKD 2.7979209423065186, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6257172226905823, Reg Loss=3.1149206161499023
Clinet index 1, End of Epoch 1/6, Average Loss=3.74063777923584, Class Loss=0.6257172226905823, Reg Loss=3.1149206161499023
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=3.218191196024418
Loss made of: CE 0.2434704750776291, LKD 2.7640318870544434, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3465331792831421, Reg Loss=2.8554553985595703
Clinet index 1, End of Epoch 2/6, Average Loss=3.201988697052002, Class Loss=0.3465331792831421, Reg Loss=2.8554553985595703
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=3.1121508479118347
Loss made of: CE 0.2011343240737915, LKD 2.5679399967193604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23576511442661285, Reg Loss=2.8430700302124023
Clinet index 1, End of Epoch 3/6, Average Loss=3.0788352489471436, Class Loss=0.23576511442661285, Reg Loss=2.8430700302124023
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=3.0227826058864595
Loss made of: CE 0.2077917754650116, LKD 3.1047310829162598, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21779553592205048, Reg Loss=2.8389713764190674
Clinet index 1, End of Epoch 4/6, Average Loss=3.056766986846924, Class Loss=0.21779553592205048, Reg Loss=2.8389713764190674
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=3.0843013688921928
Loss made of: CE 0.20451590418815613, LKD 2.808340549468994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22524116933345795, Reg Loss=2.8905532360076904
Clinet index 1, End of Epoch 5/6, Average Loss=3.1157944202423096, Class Loss=0.22524116933345795, Reg Loss=2.8905532360076904
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=3.0819355979561807
Loss made of: CE 0.21160829067230225, LKD 2.838008165359497, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21676482260227203, Reg Loss=2.8729686737060547
Clinet index 1, End of Epoch 6/6, Average Loss=3.089733600616455, Class Loss=0.21676482260227203, Reg Loss=2.8729686737060547
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=3.923653131723404
Loss made of: CE 0.5287407040596008, LKD 3.1350276470184326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6373121738433838, Reg Loss=3.2498433589935303
Clinet index 16, End of Epoch 1/6, Average Loss=3.887155532836914, Class Loss=0.6373121738433838, Reg Loss=3.2498433589935303
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=3.3487364917993547
Loss made of: CE 0.29420235753059387, LKD 3.036193370819092, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3450334668159485, Reg Loss=2.9436581134796143
Clinet index 16, End of Epoch 2/6, Average Loss=3.288691520690918, Class Loss=0.3450334668159485, Reg Loss=2.9436581134796143
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=3.137554460763931
Loss made of: CE 0.22651633620262146, LKD 2.8503072261810303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2337329089641571, Reg Loss=2.9332053661346436
Clinet index 16, End of Epoch 3/6, Average Loss=3.166938304901123, Class Loss=0.2337329089641571, Reg Loss=2.9332053661346436
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=3.1869150578975676
Loss made of: CE 0.2486969530582428, LKD 2.54850435256958, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23008446395397186, Reg Loss=2.965261697769165
Clinet index 16, End of Epoch 4/6, Average Loss=3.1953461170196533, Class Loss=0.23008446395397186, Reg Loss=2.965261697769165
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=3.1292177245020865
Loss made of: CE 0.20364515483379364, LKD 3.127946615219116, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22090932726860046, Reg Loss=2.916827440261841
Clinet index 16, End of Epoch 5/6, Average Loss=3.1377367973327637, Class Loss=0.22090932726860046, Reg Loss=2.916827440261841
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=3.1067978754639625
Loss made of: CE 0.16762003302574158, LKD 2.8341867923736572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20552973449230194, Reg Loss=2.897003412246704
Clinet index 16, End of Epoch 6/6, Average Loss=3.1025331020355225, Class Loss=0.20552973449230194, Reg Loss=2.897003412246704
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/11, Loss=4.106311112642288
Loss made of: CE 0.6351308822631836, LKD 3.104409694671631, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6701329350471497, Reg Loss=3.3700520992279053
Clinet index 6, End of Epoch 1/6, Average Loss=4.04018497467041, Class Loss=0.6701329350471497, Reg Loss=3.3700520992279053
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/11, Loss=3.538839066028595
Loss made of: CE 0.4073440730571747, LKD 3.239454984664917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.42842912673950195, Reg Loss=3.08243465423584
Clinet index 6, End of Epoch 2/6, Average Loss=3.510863780975342, Class Loss=0.42842912673950195, Reg Loss=3.08243465423584
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/11, Loss=3.2924909070134163
Loss made of: CE 0.30549025535583496, LKD 3.141648292541504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27130526304244995, Reg Loss=2.9883008003234863
Clinet index 6, End of Epoch 3/6, Average Loss=3.259606122970581, Class Loss=0.27130526304244995, Reg Loss=2.9883008003234863
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/11, Loss=3.1757236525416372
Loss made of: CE 0.22993263602256775, LKD 2.791105270385742, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2354213446378708, Reg Loss=2.939379930496216
Clinet index 6, End of Epoch 4/6, Average Loss=3.1748013496398926, Class Loss=0.2354213446378708, Reg Loss=2.939379930496216
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/11, Loss=3.1925353720784186
Loss made of: CE 0.2902189791202545, LKD 2.616943120956421, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23395276069641113, Reg Loss=2.9809529781341553
Clinet index 6, End of Epoch 5/6, Average Loss=3.2149057388305664, Class Loss=0.23395276069641113, Reg Loss=2.9809529781341553
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/11, Loss=3.1141717985272406
Loss made of: CE 0.19990043342113495, LKD 2.7775368690490723, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22028620541095734, Reg Loss=2.9354732036590576
Clinet index 6, End of Epoch 6/6, Average Loss=3.155759334564209, Class Loss=0.22028620541095734, Reg Loss=2.9354732036590576
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.038283854722977
Loss made of: CE 0.23143546283245087, LKD 3.6053404808044434, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2769699692726135, Reg Loss=3.8322315216064453
Clinet index 21, End of Epoch 1/6, Average Loss=4.109201431274414, Class Loss=0.2769699692726135, Reg Loss=3.8322315216064453
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=4.0773256659507755
Loss made of: CE 0.29097437858581543, LKD 3.743762969970703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2564777731895447, Reg Loss=3.8476099967956543
Clinet index 21, End of Epoch 2/6, Average Loss=4.104087829589844, Class Loss=0.2564777731895447, Reg Loss=3.8476099967956543
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=4.153335583209992
Loss made of: CE 0.24649262428283691, LKD 4.564052104949951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25374943017959595, Reg Loss=3.863619804382324
Clinet index 21, End of Epoch 3/6, Average Loss=4.117369174957275, Class Loss=0.25374943017959595, Reg Loss=3.863619804382324
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=3.9779920145869254
Loss made of: CE 0.18561172485351562, LKD 3.4991939067840576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23364582657814026, Reg Loss=3.7668254375457764
Clinet index 21, End of Epoch 4/6, Average Loss=4.000471115112305, Class Loss=0.23364582657814026, Reg Loss=3.7668254375457764
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=3.9080595135688783
Loss made of: CE 0.21894395351409912, LKD 3.582202911376953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22583679854869843, Reg Loss=3.7466979026794434
Clinet index 21, End of Epoch 5/6, Average Loss=3.972534656524658, Class Loss=0.22583679854869843, Reg Loss=3.7466979026794434
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=4.007150135934353
Loss made of: CE 0.1864835023880005, LKD 3.487492799758911, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2216378152370453, Reg Loss=3.761441707611084
Clinet index 21, End of Epoch 6/6, Average Loss=3.983079433441162, Class Loss=0.2216378152370453, Reg Loss=3.761441707611084
federated aggregation...
Validation, Class Loss=0.7998537421226501, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.770373
Mean Acc: 0.224035
FreqW Acc: 0.702437
Mean IoU: 0.149018
Class IoU:
	class 0: 0.90223575
	class 1: 0.002955271
	class 2: 0.0032327608
	class 3: 0.0
	class 4: 0.2665507
	class 5: 0.064052194
	class 6: 0.044503417
	class 7: 0.63023114
	class 8: 0.0
	class 9: 0.015408981
	class 10: 0.0
	class 11: 0.0004988661
	class 12: 0.008563358
	class 13: 0.09404593
	class 14: 0.20299642
Class Acc:
	class 0: 0.9685478
	class 1: 0.002955296
	class 2: 0.0032510653
	class 3: 0.0
	class 4: 0.27084324
	class 5: 0.06408427
	class 6: 0.044518802
	class 7: 0.63676983
	class 8: 0.0
	class 9: 0.015528403
	class 10: 0.0
	class 11: 0.0004988661
	class 12: 0.009138309
	class 13: 0.9482891
	class 14: 0.39610028

federated global round: 18, step: 3
select part of clients to conduct local training
[8, 2, 17, 14]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=3.226708336174488
Loss made of: CE 0.2309577316045761, LKD 2.7452375888824463, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.25915008783340454, Reg Loss=2.9654042720794678
Clinet index 8, End of Epoch 1/6, Average Loss=3.2245543003082275, Class Loss=0.25915008783340454, Reg Loss=2.9654042720794678
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=3.217327617108822
Loss made of: CE 0.20833373069763184, LKD 3.1641454696655273, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23155668377876282, Reg Loss=2.9547054767608643
Clinet index 8, End of Epoch 2/6, Average Loss=3.1862621307373047, Class Loss=0.23155668377876282, Reg Loss=2.9547054767608643
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=3.1253466814756394
Loss made of: CE 0.2303149402141571, LKD 2.9562692642211914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2255137711763382, Reg Loss=2.9260778427124023
Clinet index 8, End of Epoch 3/6, Average Loss=3.1515915393829346, Class Loss=0.2255137711763382, Reg Loss=2.9260778427124023
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=3.0683254569768907
Loss made of: CE 0.1874403953552246, LKD 2.4591565132141113, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21993446350097656, Reg Loss=2.8383288383483887
Clinet index 8, End of Epoch 4/6, Average Loss=3.0582633018493652, Class Loss=0.21993446350097656, Reg Loss=2.8383288383483887
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=3.0383952140808104
Loss made of: CE 0.21722786128520966, LKD 2.703150749206543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2091531604528427, Reg Loss=2.8428993225097656
Clinet index 8, End of Epoch 5/6, Average Loss=3.0520524978637695, Class Loss=0.2091531604528427, Reg Loss=2.8428993225097656
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=3.1253715723752977
Loss made of: CE 0.18762646615505219, LKD 2.86513090133667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20426715910434723, Reg Loss=2.8944029808044434
Clinet index 8, End of Epoch 6/6, Average Loss=3.098670244216919, Class Loss=0.20426715910434723, Reg Loss=2.8944029808044434
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=3.129978874325752
Loss made of: CE 0.2736038565635681, LKD 2.9964778423309326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.26195549964904785, Reg Loss=2.906916618347168
Clinet index 2, End of Epoch 1/6, Average Loss=3.168872117996216, Class Loss=0.26195549964904785, Reg Loss=2.906916618347168
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=3.171259564161301
Loss made of: CE 0.19128835201263428, LKD 2.592909812927246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24554355442523956, Reg Loss=2.8952438831329346
Clinet index 2, End of Epoch 2/6, Average Loss=3.140787363052368, Class Loss=0.24554355442523956, Reg Loss=2.8952438831329346
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=3.156788854300976
Loss made of: CE 0.20402348041534424, LKD 2.975886106491089, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22529204189777374, Reg Loss=2.9186911582946777
Clinet index 2, End of Epoch 3/6, Average Loss=3.1439831256866455, Class Loss=0.22529204189777374, Reg Loss=2.9186911582946777
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=3.096868984401226
Loss made of: CE 0.20826679468154907, LKD 2.9735419750213623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21910226345062256, Reg Loss=2.8792564868927
Clinet index 2, End of Epoch 4/6, Average Loss=3.098358631134033, Class Loss=0.21910226345062256, Reg Loss=2.8792564868927
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=3.1298920318484305
Loss made of: CE 0.20899486541748047, LKD 2.5832672119140625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.211903378367424, Reg Loss=2.8877627849578857
Clinet index 2, End of Epoch 5/6, Average Loss=3.099666118621826, Class Loss=0.211903378367424, Reg Loss=2.8877627849578857
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=3.085706527531147
Loss made of: CE 0.22946159541606903, LKD 2.774118185043335, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2194662094116211, Reg Loss=2.8678646087646484
Clinet index 2, End of Epoch 6/6, Average Loss=3.0873308181762695, Class Loss=0.2194662094116211, Reg Loss=2.8678646087646484
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.56117035150528
Loss made of: CE 0.470530241727829, LKD 4.963639259338379, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5186702609062195, Reg Loss=3.9824376106262207
Clinet index 17, End of Epoch 1/6, Average Loss=4.501107692718506, Class Loss=0.5186702609062195, Reg Loss=3.9824376106262207
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=4.215047898888588
Loss made of: CE 0.21258783340454102, LKD 4.177680015563965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3073328137397766, Reg Loss=3.875657081604004
Clinet index 17, End of Epoch 2/6, Average Loss=4.182990074157715, Class Loss=0.3073328137397766, Reg Loss=3.875657081604004
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=3.99785663485527
Loss made of: CE 0.2562295198440552, LKD 4.087279319763184, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2535165250301361, Reg Loss=3.8276374340057373
Clinet index 17, End of Epoch 3/6, Average Loss=4.081153869628906, Class Loss=0.2535165250301361, Reg Loss=3.8276374340057373
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=4.223520900309086
Loss made of: CE 0.17530183494091034, LKD 3.2933402061462402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24656489491462708, Reg Loss=3.852961540222168
Clinet index 17, End of Epoch 4/6, Average Loss=4.099526405334473, Class Loss=0.24656489491462708, Reg Loss=3.852961540222168
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=3.864500293135643
Loss made of: CE 0.3051983118057251, LKD 3.737912654876709, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2511458396911621, Reg Loss=3.83504056930542
Clinet index 17, End of Epoch 5/6, Average Loss=4.086186408996582, Class Loss=0.2511458396911621, Reg Loss=3.83504056930542
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=4.0525133684277534
Loss made of: CE 0.2183549404144287, LKD 3.114382028579712, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24543628096580505, Reg Loss=3.856959342956543
Clinet index 17, End of Epoch 6/6, Average Loss=4.102395534515381, Class Loss=0.24543628096580505, Reg Loss=3.856959342956543
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=3.1953587576746942
Loss made of: CE 0.2606757879257202, LKD 2.7010080814361572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.255913645029068, Reg Loss=2.9303271770477295
Clinet index 14, End of Epoch 1/6, Average Loss=3.1862409114837646, Class Loss=0.255913645029068, Reg Loss=2.9303271770477295
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=3.1907304361462594
Loss made of: CE 0.2121288776397705, LKD 3.0175764560699463, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2481965720653534, Reg Loss=2.959419012069702
Clinet index 14, End of Epoch 2/6, Average Loss=3.207615613937378, Class Loss=0.2481965720653534, Reg Loss=2.959419012069702
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=3.180968514084816
Loss made of: CE 0.21242877840995789, LKD 2.936049461364746, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2264583855867386, Reg Loss=2.9534788131713867
Clinet index 14, End of Epoch 3/6, Average Loss=3.1799371242523193, Class Loss=0.2264583855867386, Reg Loss=2.9534788131713867
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=3.2193133518099786
Loss made of: CE 0.21810436248779297, LKD 2.8167567253112793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2307588756084442, Reg Loss=2.9737308025360107
Clinet index 14, End of Epoch 4/6, Average Loss=3.2044897079467773, Class Loss=0.2307588756084442, Reg Loss=2.9737308025360107
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=3.1479779526591303
Loss made of: CE 0.21535944938659668, LKD 2.8326263427734375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20743684470653534, Reg Loss=2.9436185359954834
Clinet index 14, End of Epoch 5/6, Average Loss=3.151055335998535, Class Loss=0.20743684470653534, Reg Loss=2.9436185359954834
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=3.0940572693943977
Loss made of: CE 0.20446562767028809, LKD 2.5666918754577637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20442068576812744, Reg Loss=2.918450117111206
Clinet index 14, End of Epoch 6/6, Average Loss=3.122870922088623, Class Loss=0.20442068576812744, Reg Loss=2.918450117111206
federated aggregation...
Validation, Class Loss=0.8378430604934692, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.769436
Mean Acc: 0.223084
FreqW Acc: 0.701669
Mean IoU: 0.146015
Class IoU:
	class 0: 0.90215373
	class 1: 0.0014137189
	class 2: 0.001991178
	class 3: 0.0
	class 4: 0.23504063
	class 5: 0.04609276
	class 6: 0.031310845
	class 7: 0.6194903
	class 8: 0.0
	class 9: 0.020197632
	class 10: 0.0
	class 11: 0.0005752351
	class 12: 0.0032519586
	class 13: 0.09344454
	class 14: 0.23525733
Class Acc:
	class 0: 0.9675342
	class 1: 0.0014137231
	class 2: 0.001997513
	class 3: 0.0
	class 4: 0.23810613
	class 5: 0.046100125
	class 6: 0.031319287
	class 7: 0.62610006
	class 8: 0.0
	class 9: 0.020429268
	class 10: 0.0
	class 11: 0.0005752351
	class 12: 0.0034255863
	class 13: 0.95627123
	class 14: 0.45298734

federated global round: 19, step: 3
select part of clients to conduct local training
[1, 9, 8, 0]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/11, Loss=2.9897326201200487
Loss made of: CE 0.20713727176189423, LKD 2.6401758193969727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.23681344091892242, Reg Loss=2.82441782951355
Clinet index 1, End of Epoch 1/6, Average Loss=3.0612313747406006, Class Loss=0.23681344091892242, Reg Loss=2.82441782951355
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/11, Loss=3.0679967269301414
Loss made of: CE 0.2200256586074829, LKD 2.8531761169433594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23216445744037628, Reg Loss=2.8204586505889893
Clinet index 1, End of Epoch 2/6, Average Loss=3.0526230335235596, Class Loss=0.23216445744037628, Reg Loss=2.8204586505889893
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/11, Loss=3.0929680466651917
Loss made of: CE 0.19607901573181152, LKD 2.5216550827026367, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22760465741157532, Reg Loss=2.828091859817505
Clinet index 1, End of Epoch 3/6, Average Loss=3.055696487426758, Class Loss=0.22760465741157532, Reg Loss=2.828091859817505
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/11, Loss=2.9818850249052047
Loss made of: CE 0.20624175667762756, LKD 2.9232633113861084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21543335914611816, Reg Loss=2.8224503993988037
Clinet index 1, End of Epoch 4/6, Average Loss=3.037883758544922, Class Loss=0.21543335914611816, Reg Loss=2.8224503993988037
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/11, Loss=3.0048069462180136
Loss made of: CE 0.22255650162696838, LKD 2.76240611076355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2150937020778656, Reg Loss=2.8205559253692627
Clinet index 1, End of Epoch 5/6, Average Loss=3.035649538040161, Class Loss=0.2150937020778656, Reg Loss=2.8205559253692627
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/11, Loss=3.03969092965126
Loss made of: CE 0.21917393803596497, LKD 2.833514928817749, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2215423583984375, Reg Loss=2.8466975688934326
Clinet index 1, End of Epoch 6/6, Average Loss=3.06823992729187, Class Loss=0.2215423583984375, Reg Loss=2.8466975688934326
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=4.604108399152755
Loss made of: CE 0.5209716558456421, LKD 4.387121677398682, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5410075783729553, Reg Loss=3.9439072608947754
Clinet index 9, End of Epoch 1/6, Average Loss=4.484914779663086, Class Loss=0.5410075783729553, Reg Loss=3.9439072608947754
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/12, Loss=4.001630413532257
Loss made of: CE 0.2576230764389038, LKD 3.2204818725585938, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.340533971786499, Reg Loss=3.7452163696289062
Clinet index 9, End of Epoch 2/6, Average Loss=4.085750579833984, Class Loss=0.340533971786499, Reg Loss=3.7452163696289062
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/12, Loss=4.060583855211735
Loss made of: CE 0.2885645627975464, LKD 3.8357059955596924, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28007155656814575, Reg Loss=3.763355255126953
Clinet index 9, End of Epoch 3/6, Average Loss=4.043426990509033, Class Loss=0.28007155656814575, Reg Loss=3.763355255126953
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/12, Loss=4.062232783436775
Loss made of: CE 0.2819628119468689, LKD 3.6094882488250732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2613902986049652, Reg Loss=3.7583720684051514
Clinet index 9, End of Epoch 4/6, Average Loss=4.0197625160217285, Class Loss=0.2613902986049652, Reg Loss=3.7583720684051514
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/12, Loss=3.9221252635121346
Loss made of: CE 0.22337552905082703, LKD 3.315204381942749, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2487311214208603, Reg Loss=3.762401580810547
Clinet index 9, End of Epoch 5/6, Average Loss=4.011132717132568, Class Loss=0.2487311214208603, Reg Loss=3.762401580810547
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/12, Loss=4.031944821774959
Loss made of: CE 0.22224509716033936, LKD 3.4134409427642822, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2536158561706543, Reg Loss=3.8478922843933105
Clinet index 9, End of Epoch 6/6, Average Loss=4.101508140563965, Class Loss=0.2536158561706543, Reg Loss=3.8478922843933105
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/11, Loss=3.1047114327549936
Loss made of: CE 0.21246235072612762, LKD 2.6644344329833984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2373875081539154, Reg Loss=2.8701703548431396
Clinet index 8, End of Epoch 1/6, Average Loss=3.107557773590088, Class Loss=0.2373875081539154, Reg Loss=2.8701703548431396
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/11, Loss=3.148563839495182
Loss made of: CE 0.21754370629787445, LKD 2.997907876968384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23019739985466003, Reg Loss=2.887057304382324
Clinet index 8, End of Epoch 2/6, Average Loss=3.1172547340393066, Class Loss=0.23019739985466003, Reg Loss=2.887057304382324
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/11, Loss=3.090764507651329
Loss made of: CE 0.2380412220954895, LKD 2.7387282848358154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2255035787820816, Reg Loss=2.890880584716797
Clinet index 8, End of Epoch 3/6, Average Loss=3.116384267807007, Class Loss=0.2255035787820816, Reg Loss=2.890880584716797
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/11, Loss=3.165879064798355
Loss made of: CE 0.18114838004112244, LKD 2.4922385215759277, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22305218875408173, Reg Loss=2.9176504611968994
Clinet index 8, End of Epoch 4/6, Average Loss=3.140702724456787, Class Loss=0.22305218875408173, Reg Loss=2.9176504611968994
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/11, Loss=3.0789127364754676
Loss made of: CE 0.2202470898628235, LKD 2.6579625606536865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21870306134223938, Reg Loss=2.888982057571411
Clinet index 8, End of Epoch 5/6, Average Loss=3.107685089111328, Class Loss=0.21870306134223938, Reg Loss=2.888982057571411
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/11, Loss=3.089363919198513
Loss made of: CE 0.1893552988767624, LKD 2.8630592823028564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21346648037433624, Reg Loss=2.851147174835205
Clinet index 8, End of Epoch 6/6, Average Loss=3.0646135807037354, Class Loss=0.21346648037433624, Reg Loss=2.851147174835205
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/11, Loss=3.188771811127663
Loss made of: CE 0.2383730411529541, LKD 2.782977819442749, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2532476484775543, Reg Loss=2.9242241382598877
Clinet index 0, End of Epoch 1/6, Average Loss=3.177471876144409, Class Loss=0.2532476484775543, Reg Loss=2.9242241382598877
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/11, Loss=3.154072467982769
Loss made of: CE 0.2092229425907135, LKD 2.4541399478912354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24695754051208496, Reg Loss=2.865891218185425
Clinet index 0, End of Epoch 2/6, Average Loss=3.1128487586975098, Class Loss=0.24695754051208496, Reg Loss=2.865891218185425
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/11, Loss=3.1339472055435182
Loss made of: CE 0.2469790279865265, LKD 2.6605422496795654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2332589477300644, Reg Loss=2.9121663570404053
Clinet index 0, End of Epoch 3/6, Average Loss=3.145425319671631, Class Loss=0.2332589477300644, Reg Loss=2.9121663570404053
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/11, Loss=3.086149647831917
Loss made of: CE 0.2379654496908188, LKD 3.0933127403259277, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22664985060691833, Reg Loss=2.8733012676239014
Clinet index 0, End of Epoch 4/6, Average Loss=3.0999510288238525, Class Loss=0.22664985060691833, Reg Loss=2.8733012676239014
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/11, Loss=3.000128135085106
Loss made of: CE 0.20174460113048553, LKD 2.551351308822632, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22509883344173431, Reg Loss=2.8194148540496826
Clinet index 0, End of Epoch 5/6, Average Loss=3.044513702392578, Class Loss=0.22509883344173431, Reg Loss=2.8194148540496826
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/11, Loss=3.1319026336073876
Loss made of: CE 0.19958817958831787, LKD 2.3002207279205322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22496771812438965, Reg Loss=2.8778083324432373
Clinet index 0, End of Epoch 6/6, Average Loss=3.102776050567627, Class Loss=0.22496771812438965, Reg Loss=2.8778083324432373
federated aggregation...
Validation, Class Loss=0.8453139066696167, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.771765
Mean Acc: 0.232166
FreqW Acc: 0.702362
Mean IoU: 0.146304
Class IoU:
	class 0: 0.9028579
	class 1: 0.0015202587
	class 2: 0.00058561884
	class 3: 0.0
	class 4: 0.22118114
	class 5: 0.042496387
	class 6: 0.03428734
	class 7: 0.603185
	class 8: 0.0
	class 9: 0.018735908
	class 10: 0.0
	class 11: 0.0008670824
	class 12: 0.0040602963
	class 13: 0.09855272
	class 14: 0.26622593
Class Acc:
	class 0: 0.96749973
	class 1: 0.0015202645
	class 2: 0.0005862812
	class 3: 0.0
	class 4: 0.2239148
	class 5: 0.042501938
	class 6: 0.034298524
	class 7: 0.61049545
	class 8: 0.0
	class 9: 0.018930014
	class 10: 0.0
	class 11: 0.0008670824
	class 12: 0.0043768175
	class 13: 0.9553989
	class 14: 0.62210053

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[11, 2, 15, 6]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.54636470079422
Loss made of: CE 1.9816968441009521, LKD 3.951472759246826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6661248207092285, Reg Loss=3.7508440017700195
Clinet index 11, End of Epoch 1/6, Average Loss=5.416968822479248, Class Loss=1.6661248207092285, Reg Loss=3.7508440017700195
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=4.7397915601730345
Loss made of: CE 1.156394362449646, LKD 3.7250335216522217, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2790040969848633, Reg Loss=3.567046880722046
Clinet index 11, End of Epoch 2/6, Average Loss=4.846051216125488, Class Loss=1.2790040969848633, Reg Loss=3.567046880722046
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.3914450883865355
Loss made of: CE 1.0246586799621582, LKD 3.2104499340057373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.051501750946045, Reg Loss=3.4565043449401855
Clinet index 11, End of Epoch 3/6, Average Loss=4.5080060958862305, Class Loss=1.051501750946045, Reg Loss=3.4565043449401855
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.43781270980835
Loss made of: CE 0.7955189943313599, LKD 3.510227680206299, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.9009807109832764, Reg Loss=3.444159984588623
Clinet index 11, End of Epoch 4/6, Average Loss=4.34514045715332, Class Loss=0.9009807109832764, Reg Loss=3.444159984588623
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=4.284689450263977
Loss made of: CE 0.6077972650527954, LKD 3.689534902572632, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7574906349182129, Reg Loss=3.4486279487609863
Clinet index 11, End of Epoch 5/6, Average Loss=4.206118583679199, Class Loss=0.7574906349182129, Reg Loss=3.4486279487609863
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=4.154479867219925
Loss made of: CE 0.9114882946014404, LKD 3.898939609527588, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6810521483421326, Reg Loss=3.405280828475952
Clinet index 11, End of Epoch 6/6, Average Loss=4.08633279800415, Class Loss=0.6810521483421326, Reg Loss=3.405280828475952
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.55191924571991
Loss made of: CE 1.8167909383773804, LKD 4.092530250549316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6609015464782715, Reg Loss=3.8337810039520264
Clinet index 2, End of Epoch 1/6, Average Loss=5.494682312011719, Class Loss=1.6609015464782715, Reg Loss=3.8337810039520264
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=4.939478504657745
Loss made of: CE 1.1133136749267578, LKD 3.334355354309082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2493946552276611, Reg Loss=3.5798349380493164
Clinet index 2, End of Epoch 2/6, Average Loss=4.829229354858398, Class Loss=1.2493946552276611, Reg Loss=3.5798349380493164
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.665414035320282
Loss made of: CE 0.934852123260498, LKD 3.2455124855041504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.0355007648468018, Reg Loss=3.585045337677002
Clinet index 2, End of Epoch 3/6, Average Loss=4.620546340942383, Class Loss=1.0355007648468018, Reg Loss=3.585045337677002
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.326380354166031
Loss made of: CE 0.794217586517334, LKD 3.8269169330596924, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.8694217205047607, Reg Loss=3.484114170074463
Clinet index 2, End of Epoch 4/6, Average Loss=4.3535356521606445, Class Loss=0.8694217205047607, Reg Loss=3.484114170074463
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=4.308160972595215
Loss made of: CE 0.7736136317253113, LKD 4.0138349533081055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7287224531173706, Reg Loss=3.546440601348877
Clinet index 2, End of Epoch 5/6, Average Loss=4.275163173675537, Class Loss=0.7287224531173706, Reg Loss=3.546440601348877
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=4.176190078258514
Loss made of: CE 0.7416383028030396, LKD 3.6233320236206055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6726163625717163, Reg Loss=3.532670021057129
Clinet index 2, End of Epoch 6/6, Average Loss=4.205286502838135, Class Loss=0.6726163625717163, Reg Loss=3.532670021057129
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=5.715156817436219
Loss made of: CE 1.9823297262191772, LKD 4.398374080657959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6409180164337158, Reg Loss=3.925511360168457
Clinet index 15, End of Epoch 1/6, Average Loss=5.566429138183594, Class Loss=1.6409180164337158, Reg Loss=3.925511360168457
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=5.005062299966812
Loss made of: CE 1.2303881645202637, LKD 3.6613755226135254, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2584017515182495, Reg Loss=3.5819883346557617
Clinet index 15, End of Epoch 2/6, Average Loss=4.840390205383301, Class Loss=1.2584017515182495, Reg Loss=3.5819883346557617
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.3841762244701385
Loss made of: CE 1.1332499980926514, LKD 3.0861313343048096, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.041447639465332, Reg Loss=3.4831199645996094
Clinet index 15, End of Epoch 3/6, Average Loss=4.524567604064941, Class Loss=1.041447639465332, Reg Loss=3.4831199645996094
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.131827944517136
Loss made of: CE 0.6668898463249207, LKD 2.82063364982605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.8910176753997803, Reg Loss=3.401562213897705
Clinet index 15, End of Epoch 4/6, Average Loss=4.292579650878906, Class Loss=0.8910176753997803, Reg Loss=3.401562213897705
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=4.190401846170426
Loss made of: CE 0.792244553565979, LKD 2.9204394817352295, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7767453193664551, Reg Loss=3.4016053676605225
Clinet index 15, End of Epoch 5/6, Average Loss=4.178350448608398, Class Loss=0.7767453193664551, Reg Loss=3.4016053676605225
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=3.8735744535923002
Loss made of: CE 0.5696574449539185, LKD 2.827631711959839, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6367979645729065, Reg Loss=3.2707223892211914
Clinet index 15, End of Epoch 6/6, Average Loss=3.907520294189453, Class Loss=0.6367979645729065, Reg Loss=3.2707223892211914
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=5.619919121265411
Loss made of: CE 1.5841110944747925, LKD 3.518527030944824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=5.117289519309997
Loss made of: CE 1.4758479595184326, LKD 3.290095806121826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=4.894265496730805
Loss made of: CE 1.116894245147705, LKD 3.967754602432251, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=4.524129313230515
Loss made of: CE 0.7781791090965271, LKD 3.0533783435821533, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=4.083052039146423
Loss made of: CE 0.6304723620414734, LKD 3.327641010284424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=4.0912701964378355
Loss made of: CE 0.6397249102592468, LKD 4.4615888595581055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=4.188005161285401
Loss made of: CE 0.5325607657432556, LKD 3.377403974533081, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.8228043407201766
Loss made of: CE 0.5337340831756592, LKD 3.132199764251709, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.9575078219175337
Loss made of: CE 0.48339566588401794, LKD 3.0054564476013184, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9073344469070435, Reg Loss=3.5283758640289307
Clinet index 6, End of Epoch 1/6, Average Loss=4.435710430145264, Class Loss=0.9073344469070435, Reg Loss=3.5283758640289307
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/97, Loss=3.819679579138756
Loss made of: CE 0.39520686864852905, LKD 3.1704835891723633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.622173008322716
Loss made of: CE 0.44278010725975037, LKD 3.2850379943847656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.9251020669937136
Loss made of: CE 0.4064675271511078, LKD 3.4066121578216553, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.883902835845947
Loss made of: CE 0.40351471304893494, LKD 3.6789822578430176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.903070813417435
Loss made of: CE 0.4296824634075165, LKD 2.7898504734039307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.8563883662223817
Loss made of: CE 0.4360552728176117, LKD 3.2999866008758545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.63371856212616
Loss made of: CE 0.37274548411369324, LKD 3.0857245922088623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.8089176028966905
Loss made of: CE 0.3939598500728607, LKD 3.108642101287842, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=4.163215017318725
Loss made of: CE 0.437103807926178, LKD 3.36075496673584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.43930476903915405, Reg Loss=3.402421712875366
Clinet index 6, End of Epoch 2/6, Average Loss=3.841726541519165, Class Loss=0.43930476903915405, Reg Loss=3.402421712875366
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/97, Loss=3.5754816204309465
Loss made of: CE 0.40164899826049805, LKD 3.2975873947143555, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.7958903819322587
Loss made of: CE 0.4201248586177826, LKD 2.930396556854248, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.570094358921051
Loss made of: CE 0.2844502031803131, LKD 3.2337658405303955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.9431660026311874
Loss made of: CE 0.39404985308647156, LKD 3.501741647720337, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=4.021426656842232
Loss made of: CE 0.39511987566947937, LKD 3.286647081375122, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.8356305778026583
Loss made of: CE 0.4469992518424988, LKD 3.776930332183838, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.7017282098531723
Loss made of: CE 0.40454646944999695, LKD 3.4951419830322266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.6069410651922227
Loss made of: CE 0.410925030708313, LKD 3.385902166366577, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.9106286972761155
Loss made of: CE 0.34569454193115234, LKD 2.774235248565674, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.40392962098121643, Reg Loss=3.386348247528076
Clinet index 6, End of Epoch 3/6, Average Loss=3.7902779579162598, Class Loss=0.40392962098121643, Reg Loss=3.386348247528076
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/97, Loss=3.942125380039215
Loss made of: CE 0.35891085863113403, LKD 3.2426648139953613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.7653757721185683
Loss made of: CE 0.3558388352394104, LKD 3.1560890674591064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.6941168040037153
Loss made of: CE 0.37223851680755615, LKD 3.780141830444336, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.777889448404312
Loss made of: CE 0.34703773260116577, LKD 3.058054208755493, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.69986073076725
Loss made of: CE 0.33762991428375244, LKD 2.8796989917755127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.6814092487096786
Loss made of: CE 0.37666070461273193, LKD 3.695936441421509, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.5262338370084763
Loss made of: CE 0.3257424533367157, LKD 2.852775812149048, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.9379225581884385
Loss made of: CE 0.3498559892177582, LKD 2.628258228302002, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.9133153915405274
Loss made of: CE 0.4581138491630554, LKD 3.8234527111053467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.391486793756485, Reg Loss=3.359323263168335
Clinet index 6, End of Epoch 4/6, Average Loss=3.750810146331787, Class Loss=0.391486793756485, Reg Loss=3.359323263168335
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/97, Loss=3.8531951785087584
Loss made of: CE 0.39623117446899414, LKD 3.3001861572265625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.801183956861496
Loss made of: CE 0.37014254927635193, LKD 3.1976912021636963, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.8726307451725006
Loss made of: CE 0.3516624867916107, LKD 4.310133457183838, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.6752356350421906
Loss made of: CE 0.3616407513618469, LKD 3.088531970977783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.761639741063118
Loss made of: CE 0.3633902668952942, LKD 2.915677070617676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.5934207171201704
Loss made of: CE 0.2831631600856781, LKD 3.4399356842041016, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.7707389324903486
Loss made of: CE 0.38629764318466187, LKD 3.619929313659668, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.7060315728187563
Loss made of: CE 0.3356422781944275, LKD 3.1731526851654053, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.692858409881592
Loss made of: CE 0.34642812609672546, LKD 3.547935962677002, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3778533935546875, Reg Loss=3.3577499389648438
Clinet index 6, End of Epoch 5/6, Average Loss=3.7356033325195312, Class Loss=0.3778533935546875, Reg Loss=3.3577499389648438
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/97, Loss=3.5639917492866515
Loss made of: CE 0.30081838369369507, LKD 2.9555368423461914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.4312385469675064
Loss made of: CE 0.32414698600769043, LKD 3.354238748550415, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.8993523001670836
Loss made of: CE 0.3825407028198242, LKD 3.593386650085449, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.648816150426865
Loss made of: CE 0.35196956992149353, LKD 3.3028364181518555, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.8390105694532393
Loss made of: CE 0.3519798219203949, LKD 3.211273193359375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.8320246607065203
Loss made of: CE 0.3587769865989685, LKD 3.6567444801330566, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.7679816484451294
Loss made of: CE 0.4028054177761078, LKD 3.547173023223877, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.926981097459793
Loss made of: CE 0.38200753927230835, LKD 2.9222872257232666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.7154749542474748
Loss made of: CE 0.3689413070678711, LKD 2.987767457962036, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.36921262741088867, Reg Loss=3.3520548343658447
Clinet index 6, End of Epoch 6/6, Average Loss=3.7212674617767334, Class Loss=0.36921262741088867, Reg Loss=3.3520548343658447
federated aggregation...
Validation, Class Loss=0.887135922908783, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.726558
Mean Acc: 0.194718
FreqW Acc: 0.589570
Mean IoU: 0.133028
Class IoU:
	class 0: 0.80769134
	class 1: 0.07370124
	class 2: 0.0058301073
	class 3: 0.0
	class 4: 0.26542756
	class 5: 0.093631364
	class 6: 0.056659784
	class 7: 0.5918529
	class 8: 9.158071e-06
	class 9: 0.003624192
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0002975615
	class 13: 0.10337811
	class 14: 0.16667959
	class 15: 0.012442991
	class 16: 0.08024697
Class Acc:
	class 0: 0.98416084
	class 1: 0.07370565
	class 2: 0.0058728456
	class 3: 0.0
	class 4: 0.26872018
	class 5: 0.09372634
	class 6: 0.056681026
	class 7: 0.59676063
	class 8: 9.158071e-06
	class 9: 0.0036259836
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0003025555
	class 13: 0.81797296
	class 14: 0.2925269
	class 15: 0.012456034
	class 16: 0.103688784

federated global round: 21, step: 4
select part of clients to conduct local training
[20, 2, 24, 4]
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=4.4523812413215635
Loss made of: CE 0.6950383186340332, LKD 3.1567435264587402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=4.262554031610489
Loss made of: CE 0.694391667842865, LKD 3.926414966583252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=4.120565447211265
Loss made of: CE 0.44664883613586426, LKD 3.115551233291626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.939247328042984
Loss made of: CE 0.4703923463821411, LKD 3.6085779666900635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=4.006528785824775
Loss made of: CE 0.5220069289207458, LKD 3.801955223083496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.7348486721515655
Loss made of: CE 0.3864459693431854, LKD 2.973463296890259, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=4.03484066426754
Loss made of: CE 0.5328288674354553, LKD 3.3097174167633057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.5693832099437715
Loss made of: CE 0.41661256551742554, LKD 3.0177206993103027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.905242085456848
Loss made of: CE 0.45195841789245605, LKD 4.137634754180908, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5326537489891052, Reg Loss=3.4583301544189453
Clinet index 20, End of Epoch 1/6, Average Loss=3.9909839630126953, Class Loss=0.5326537489891052, Reg Loss=3.4583301544189453
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/97, Loss=3.716204214096069
Loss made of: CE 0.38154327869415283, LKD 3.457564115524292, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.8513930797576905
Loss made of: CE 0.49981412291526794, LKD 4.109460353851318, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.9053296953439713
Loss made of: CE 0.4510246217250824, LKD 4.804642677307129, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.7828458994627
Loss made of: CE 0.44119924306869507, LKD 3.9246418476104736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.906531721353531
Loss made of: CE 0.4552932679653168, LKD 3.5573954582214355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.8713398218154906
Loss made of: CE 0.3658812940120697, LKD 3.1083617210388184, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.92311477959156
Loss made of: CE 0.4331331253051758, LKD 2.9357564449310303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.916628035902977
Loss made of: CE 0.39893102645874023, LKD 3.27601957321167, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.6226029634475707
Loss made of: CE 0.3656036853790283, LKD 3.74251389503479, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.40807774662971497, Reg Loss=3.420781373977661
Clinet index 20, End of Epoch 2/6, Average Loss=3.8288590908050537, Class Loss=0.40807774662971497, Reg Loss=3.420781373977661
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/97, Loss=4.007198086380958
Loss made of: CE 0.43058571219444275, LKD 3.1107335090637207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.9601144790649414
Loss made of: CE 0.39158958196640015, LKD 2.6375577449798584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.787580242753029
Loss made of: CE 0.394562691450119, LKD 3.1266465187072754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.588999569416046
Loss made of: CE 0.34268468618392944, LKD 2.607865333557129, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.606628304719925
Loss made of: CE 0.3046687841415405, LKD 3.444639205932617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.9106708437204363
Loss made of: CE 0.37515467405319214, LKD 3.493123769760132, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.908665379881859
Loss made of: CE 0.38474273681640625, LKD 2.990718126296997, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.6185325384140015
Loss made of: CE 0.3578152656555176, LKD 3.445786952972412, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.6877173244953156
Loss made of: CE 0.40043291449546814, LKD 2.7692768573760986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3929128646850586, Reg Loss=3.395127296447754
Clinet index 20, End of Epoch 3/6, Average Loss=3.7880401611328125, Class Loss=0.3929128646850586, Reg Loss=3.395127296447754
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/97, Loss=3.8205966651439667
Loss made of: CE 0.3920414447784424, LKD 3.7857017517089844, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.8354560643434525
Loss made of: CE 0.39951345324516296, LKD 3.911616325378418, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.9369204938411713
Loss made of: CE 0.3526046872138977, LKD 2.977307081222534, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.827357739210129
Loss made of: CE 0.349714457988739, LKD 3.2479233741760254, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.5577681422233582
Loss made of: CE 0.36485379934310913, LKD 3.300537109375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.786653083562851
Loss made of: CE 0.4268396496772766, LKD 3.442373037338257, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.754903995990753
Loss made of: CE 0.3415100574493408, LKD 3.7823684215545654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.649593913555145
Loss made of: CE 0.3488566279411316, LKD 2.656320333480835, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.6561121881008147
Loss made of: CE 0.41792821884155273, LKD 3.897270679473877, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3790963292121887, Reg Loss=3.3620429039001465
Clinet index 20, End of Epoch 4/6, Average Loss=3.7411391735076904, Class Loss=0.3790963292121887, Reg Loss=3.3620429039001465
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/97, Loss=4.004346382617951
Loss made of: CE 0.435380220413208, LKD 3.607929229736328, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.8216619312763216
Loss made of: CE 0.349004864692688, LKD 3.500086545944214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.5371299266815184
Loss made of: CE 0.3496231436729431, LKD 3.1109139919281006, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.799430841207504
Loss made of: CE 0.3263428807258606, LKD 3.847412347793579, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.864421287178993
Loss made of: CE 0.4222467541694641, LKD 4.156015872955322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.6748045563697813
Loss made of: CE 0.41424667835235596, LKD 3.1988658905029297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.7999857157468795
Loss made of: CE 0.35516318678855896, LKD 3.586303472518921, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.631902891397476
Loss made of: CE 0.32130464911460876, LKD 2.7932872772216797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.6552566200494767
Loss made of: CE 0.3537936210632324, LKD 3.0228700637817383, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3748590350151062, Reg Loss=3.3787038326263428
Clinet index 20, End of Epoch 5/6, Average Loss=3.7535629272460938, Class Loss=0.3748590350151062, Reg Loss=3.3787038326263428
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/97, Loss=3.7340990245342254
Loss made of: CE 0.373439759016037, LKD 3.2372653484344482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.696990841627121
Loss made of: CE 0.4177744388580322, LKD 3.6183371543884277, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.609515795111656
Loss made of: CE 0.33536672592163086, LKD 2.9703927040100098, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.6243006944656373
Loss made of: CE 0.3499239385128021, LKD 3.174622058868408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.797131687402725
Loss made of: CE 0.2886480689048767, LKD 3.004714012145996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.823317235708237
Loss made of: CE 0.37310606241226196, LKD 3.476536273956299, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=4.057682010531425
Loss made of: CE 0.4099135994911194, LKD 3.186225414276123, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.849928167462349
Loss made of: CE 0.39911147952079773, LKD 3.7642385959625244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.6735970228910446
Loss made of: CE 0.3689430356025696, LKD 3.089500904083252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.36833977699279785, Reg Loss=3.3757286071777344
Clinet index 20, End of Epoch 6/6, Average Loss=3.7440683841705322, Class Loss=0.36833977699279785, Reg Loss=3.3757286071777344
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=4.126159203052521
Loss made of: CE 0.6963121891021729, LKD 3.838432550430298, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6405595541000366, Reg Loss=3.4641194343566895
Clinet index 2, End of Epoch 1/6, Average Loss=4.104679107666016, Class Loss=0.6405595541000366, Reg Loss=3.4641194343566895
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=4.047415161132813
Loss made of: CE 0.6366235017776489, LKD 3.1349029541015625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5805681347846985, Reg Loss=3.4306466579437256
Clinet index 2, End of Epoch 2/6, Average Loss=4.011214733123779, Class Loss=0.5805681347846985, Reg Loss=3.4306466579437256
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=3.981737008690834
Loss made of: CE 0.5286867618560791, LKD 3.113727569580078, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5127125382423401, Reg Loss=3.4305973052978516
Clinet index 2, End of Epoch 3/6, Average Loss=3.943309783935547, Class Loss=0.5127125382423401, Reg Loss=3.4305973052978516
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=3.9586028069257737
Loss made of: CE 0.43086370825767517, LKD 4.0582780838012695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4922187924385071, Reg Loss=3.527944326400757
Clinet index 2, End of Epoch 4/6, Average Loss=4.020163059234619, Class Loss=0.4922187924385071, Reg Loss=3.527944326400757
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=4.014527702331543
Loss made of: CE 0.513695240020752, LKD 4.023070812225342, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4780542850494385, Reg Loss=3.4860570430755615
Clinet index 2, End of Epoch 5/6, Average Loss=3.964111328125, Class Loss=0.4780542850494385, Reg Loss=3.4860570430755615
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=3.941474807262421
Loss made of: CE 0.40777748823165894, LKD 3.7416088581085205, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4687926471233368, Reg Loss=3.4892044067382812
Clinet index 2, End of Epoch 6/6, Average Loss=3.9579970836639404, Class Loss=0.4687926471233368, Reg Loss=3.4892044067382812
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.971498876810074
Loss made of: CE 0.5617133378982544, LKD 3.347912073135376, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6176033020019531, Reg Loss=3.3280701637268066
Clinet index 24, End of Epoch 1/6, Average Loss=3.9456734657287598, Class Loss=0.6176033020019531, Reg Loss=3.3280701637268066
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=3.9803842306137085
Loss made of: CE 0.5466157793998718, LKD 3.899660587310791, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.527758002281189, Reg Loss=3.34619402885437
Clinet index 24, End of Epoch 2/6, Average Loss=3.8739519119262695, Class Loss=0.527758002281189, Reg Loss=3.34619402885437
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=3.6325303971767426
Loss made of: CE 0.4777224659919739, LKD 3.3880085945129395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.47800540924072266, Reg Loss=3.2353672981262207
Clinet index 24, End of Epoch 3/6, Average Loss=3.7133727073669434, Class Loss=0.47800540924072266, Reg Loss=3.2353672981262207
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=3.717624545097351
Loss made of: CE 0.36333411931991577, LKD 2.5816473960876465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4720132052898407, Reg Loss=3.2694664001464844
Clinet index 24, End of Epoch 4/6, Average Loss=3.7414796352386475, Class Loss=0.4720132052898407, Reg Loss=3.2694664001464844
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=3.8062801390886305
Loss made of: CE 0.4327780604362488, LKD 2.86419677734375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.44901081919670105, Reg Loss=3.3053159713745117
Clinet index 24, End of Epoch 5/6, Average Loss=3.754326820373535, Class Loss=0.44901081919670105, Reg Loss=3.3053159713745117
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.8094859212636947
Loss made of: CE 0.4696267545223236, LKD 2.9451241493225098, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4542078375816345, Reg Loss=3.2944979667663574
Clinet index 24, End of Epoch 6/6, Average Loss=3.7487058639526367, Class Loss=0.4542078375816345, Reg Loss=3.2944979667663574
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.8724894732236863
Loss made of: CE 0.5318547487258911, LKD 2.696465492248535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6301851272583008, Reg Loss=3.217961072921753
Clinet index 4, End of Epoch 1/6, Average Loss=3.8481462001800537, Class Loss=0.6301851272583008, Reg Loss=3.217961072921753
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=3.759214296936989
Loss made of: CE 0.66237872838974, LKD 4.118579387664795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5399400591850281, Reg Loss=3.2409331798553467
Clinet index 4, End of Epoch 2/6, Average Loss=3.7808732986450195, Class Loss=0.5399400591850281, Reg Loss=3.2409331798553467
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=3.610514608025551
Loss made of: CE 0.5742518305778503, LKD 3.4976117610931396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4994138479232788, Reg Loss=3.1703667640686035
Clinet index 4, End of Epoch 3/6, Average Loss=3.669780731201172, Class Loss=0.4994138479232788, Reg Loss=3.1703667640686035
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=3.5261064410209655
Loss made of: CE 0.5857046842575073, LKD 2.8847415447235107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.47232159972190857, Reg Loss=3.1657302379608154
Clinet index 4, End of Epoch 4/6, Average Loss=3.638051748275757, Class Loss=0.47232159972190857, Reg Loss=3.1657302379608154
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=3.547391352057457
Loss made of: CE 0.4603821635246277, LKD 3.523425340652466, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4620039165019989, Reg Loss=3.2485570907592773
Clinet index 4, End of Epoch 5/6, Average Loss=3.7105610370635986, Class Loss=0.4620039165019989, Reg Loss=3.2485570907592773
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.5711126893758776
Loss made of: CE 0.41889119148254395, LKD 2.832724094390869, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4469691514968872, Reg Loss=3.2080295085906982
Clinet index 4, End of Epoch 6/6, Average Loss=3.654998779296875, Class Loss=0.4469691514968872, Reg Loss=3.2080295085906982
federated aggregation...
Validation, Class Loss=0.8255711197853088, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.770845
Mean Acc: 0.249983
FreqW Acc: 0.669088
Mean IoU: 0.171472
Class IoU:
	class 0: 0.85571885
	class 1: 0.048967615
	class 2: 0.00121903
	class 3: 0.0
	class 4: 0.22079904
	class 5: 0.0562638
	class 6: 0.05664981
	class 7: 0.56723666
	class 8: 0.0
	class 9: 0.0031600532
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0001513174
	class 13: 0.114191554
	class 14: 0.20741217
	class 15: 0.67773986
	class 16: 0.10552006
Class Acc:
	class 0: 0.9708957
	class 1: 0.048968364
	class 2: 0.0012198662
	class 3: 0.0
	class 4: 0.22306909
	class 5: 0.056266826
	class 6: 0.056671683
	class 7: 0.57092786
	class 8: 0.0
	class 9: 0.0031611633
	class 10: 0.0
	class 11: 0.0
	class 12: 0.00015280252
	class 13: 0.8575791
	class 14: 0.33099195
	class 15: 0.7608034
	class 16: 0.36900762

federated global round: 22, step: 4
select part of clients to conduct local training
[21, 0, 25, 23]
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=3.934586873650551
Loss made of: CE 0.5618552565574646, LKD 2.8768763542175293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=4.09684037566185
Loss made of: CE 0.5890796780586243, LKD 4.343690872192383, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=3.7316225707530974
Loss made of: CE 0.3984619081020355, LKD 2.555591344833374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.7377616256475448
Loss made of: CE 0.40528520941734314, LKD 3.7452921867370605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.9600294470787047
Loss made of: CE 0.4053308665752411, LKD 4.085938453674316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.9653309375047683
Loss made of: CE 0.4759267568588257, LKD 4.258245468139648, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.762697646021843
Loss made of: CE 0.3836027979850769, LKD 2.5089328289031982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.6978928804397584
Loss made of: CE 0.3551639914512634, LKD 3.7997167110443115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.854856091737747
Loss made of: CE 0.4347829818725586, LKD 3.413179874420166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.44522812962532043, Reg Loss=3.3974812030792236
Clinet index 21, End of Epoch 1/6, Average Loss=3.8427093029022217, Class Loss=0.44522812962532043, Reg Loss=3.3974812030792236
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=3.8706530779600143
Loss made of: CE 0.359668105840683, LKD 2.9445245265960693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.848248702287674
Loss made of: CE 0.4209165573120117, LKD 4.108226299285889, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.7111455738544463
Loss made of: CE 0.38941532373428345, LKD 3.720273494720459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.984102466702461
Loss made of: CE 0.3674256205558777, LKD 2.8684940338134766, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.65489462018013
Loss made of: CE 0.41490817070007324, LKD 3.7490289211273193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.7971340239048006
Loss made of: CE 0.3704977035522461, LKD 3.4715850353240967, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.560237613320351
Loss made of: CE 0.35405203700065613, LKD 3.8182482719421387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.6561338126659395
Loss made of: CE 0.42731350660324097, LKD 3.458566188812256, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.975637125968933
Loss made of: CE 0.4183506667613983, LKD 3.1707167625427246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.38950905203819275, Reg Loss=3.392137050628662
Clinet index 21, End of Epoch 2/6, Average Loss=3.7816460132598877, Class Loss=0.38950905203819275, Reg Loss=3.392137050628662
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=3.68151496052742
Loss made of: CE 0.4107391834259033, LKD 3.068728446960449, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.9278393357992174
Loss made of: CE 0.41652417182922363, LKD 3.639925718307495, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.618841600418091
Loss made of: CE 0.32840463519096375, LKD 2.8258955478668213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.6219069570302964
Loss made of: CE 0.31305691599845886, LKD 3.335516929626465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.9197520315647125
Loss made of: CE 0.40483030676841736, LKD 3.4064502716064453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.6065794080495834
Loss made of: CE 0.36975178122520447, LKD 3.2208621501922607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.6709180533885957
Loss made of: CE 0.3507920205593109, LKD 3.097503662109375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.7538568049669268
Loss made of: CE 0.4241858422756195, LKD 2.851135730743408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.815580153465271
Loss made of: CE 0.3903217315673828, LKD 3.08731746673584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3741779923439026, Reg Loss=3.367861270904541
Clinet index 21, End of Epoch 3/6, Average Loss=3.742039203643799, Class Loss=0.3741779923439026, Reg Loss=3.367861270904541
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=3.9098603159189222
Loss made of: CE 0.3889581561088562, LKD 3.9466307163238525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.4146151036024093
Loss made of: CE 0.3021990656852722, LKD 3.435349464416504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.8182913064956665
Loss made of: CE 0.351593017578125, LKD 2.7531678676605225, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.632214766740799
Loss made of: CE 0.35737019777297974, LKD 3.13608455657959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.8595742285251617
Loss made of: CE 0.37532734870910645, LKD 3.660634994506836, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.5764352560043333
Loss made of: CE 0.4195672869682312, LKD 2.7465593814849854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.7617711454629896
Loss made of: CE 0.39459753036499023, LKD 3.560401439666748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.7119159400463104
Loss made of: CE 0.321167916059494, LKD 3.1264238357543945, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.781992754340172
Loss made of: CE 0.45058631896972656, LKD 3.488243818283081, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3687388002872467, Reg Loss=3.363469362258911
Clinet index 21, End of Epoch 4/6, Average Loss=3.732208251953125, Class Loss=0.3687388002872467, Reg Loss=3.363469362258911
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=3.674434220790863
Loss made of: CE 0.3827230930328369, LKD 3.868396520614624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.698262667655945
Loss made of: CE 0.4011579155921936, LKD 3.520461082458496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.704961511492729
Loss made of: CE 0.3819633424282074, LKD 3.4040443897247314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.5972636699676515
Loss made of: CE 0.2929590940475464, LKD 2.791102170944214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.7848994374275207
Loss made of: CE 0.3605266511440277, LKD 3.74289870262146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.780636805295944
Loss made of: CE 0.3723028302192688, LKD 3.686828136444092, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.886886739730835
Loss made of: CE 0.38454386591911316, LKD 2.992983102798462, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.821899926662445
Loss made of: CE 0.3741266131401062, LKD 3.4573569297790527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.6274723261594772
Loss made of: CE 0.3730493485927582, LKD 3.4594435691833496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3626084327697754, Reg Loss=3.3517885208129883
Clinet index 21, End of Epoch 5/6, Average Loss=3.7143969535827637, Class Loss=0.3626084327697754, Reg Loss=3.3517885208129883
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=3.675524553656578
Loss made of: CE 0.319928377866745, LKD 3.074843168258667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.565752696990967
Loss made of: CE 0.3748515546321869, LKD 3.483804225921631, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.65380297601223
Loss made of: CE 0.3418463468551636, LKD 3.105112075805664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.6109519451856613
Loss made of: CE 0.37812691926956177, LKD 4.4686737060546875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.598239263892174
Loss made of: CE 0.32065916061401367, LKD 2.956124782562256, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.75404055416584
Loss made of: CE 0.3993038535118103, LKD 3.994041681289673, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.5452186077833177
Loss made of: CE 0.37291523814201355, LKD 3.1278927326202393, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.8447731524705886
Loss made of: CE 0.38060733675956726, LKD 3.158276081085205, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.8714480310678483
Loss made of: CE 0.37610989809036255, LKD 3.509305000305176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3531883656978607, Reg Loss=3.332211494445801
Clinet index 21, End of Epoch 6/6, Average Loss=3.6853997707366943, Class Loss=0.3531883656978607, Reg Loss=3.332211494445801
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=3.843223270773888
Loss made of: CE 0.6774098873138428, LKD 3.113280773162842, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=4.038605552911759
Loss made of: CE 0.4893507957458496, LKD 3.350393533706665, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=4.047463765740394
Loss made of: CE 0.39480066299438477, LKD 3.6477293968200684, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.9367106199264525
Loss made of: CE 0.41642826795578003, LKD 3.210475206375122, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.863296890258789
Loss made of: CE 0.4724663197994232, LKD 3.494194984436035, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.732695597410202
Loss made of: CE 0.38982534408569336, LKD 3.63226318359375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.6612133592367173
Loss made of: CE 0.4470226466655731, LKD 3.6318042278289795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.8510017156600953
Loss made of: CE 0.3844071328639984, LKD 3.0597567558288574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.7260292947292326
Loss made of: CE 0.3580113351345062, LKD 2.926919937133789, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.44491738080978394, Reg Loss=3.3971333503723145
Clinet index 0, End of Epoch 1/6, Average Loss=3.842050790786743, Class Loss=0.44491738080978394, Reg Loss=3.3971333503723145
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=3.903674212098122
Loss made of: CE 0.39964959025382996, LKD 2.864931583404541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.8066823184490204
Loss made of: CE 0.4254953861236572, LKD 2.998056650161743, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.800904506444931
Loss made of: CE 0.3902953565120697, LKD 3.4769036769866943, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.742965078353882
Loss made of: CE 0.3308626115322113, LKD 3.014615774154663, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.8081037759780885
Loss made of: CE 0.34407922625541687, LKD 3.24375581741333, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.7496437221765517
Loss made of: CE 0.40169596672058105, LKD 4.123903274536133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.728423261642456
Loss made of: CE 0.393783301115036, LKD 3.455605983734131, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.4209881365299224
Loss made of: CE 0.3197802007198334, LKD 2.7836945056915283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.8712496936321257
Loss made of: CE 0.36296534538269043, LKD 3.25575590133667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.38428008556365967, Reg Loss=3.3631131649017334
Clinet index 0, End of Epoch 2/6, Average Loss=3.7473931312561035, Class Loss=0.38428008556365967, Reg Loss=3.3631131649017334
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=3.5953041940927504
Loss made of: CE 0.36293548345565796, LKD 3.101388692855835, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.9048610866069793
Loss made of: CE 0.3955385088920593, LKD 3.9812419414520264, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.9093418538570406
Loss made of: CE 0.4527845084667206, LKD 3.7211596965789795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.628993484377861
Loss made of: CE 0.35705119371414185, LKD 2.9604179859161377, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.8048397094011306
Loss made of: CE 0.41434264183044434, LKD 4.179897785186768, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.7875763297080995
Loss made of: CE 0.3643403947353363, LKD 3.180009126663208, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.708751749992371
Loss made of: CE 0.3605775237083435, LKD 4.058629035949707, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.5609598994255065
Loss made of: CE 0.36540740728378296, LKD 3.55226469039917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.6708593010902404
Loss made of: CE 0.34498438239097595, LKD 3.3843226432800293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37373417615890503, Reg Loss=3.353651523590088
Clinet index 0, End of Epoch 3/6, Average Loss=3.7273857593536377, Class Loss=0.37373417615890503, Reg Loss=3.353651523590088
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=3.59073526263237
Loss made of: CE 0.30117589235305786, LKD 3.0231404304504395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.8559791892766953
Loss made of: CE 0.41452354192733765, LKD 3.7194631099700928, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.791893556714058
Loss made of: CE 0.3791043758392334, LKD 3.7389912605285645, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.779854881763458
Loss made of: CE 0.36950215697288513, LKD 4.030923366546631, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.775172746181488
Loss made of: CE 0.36251890659332275, LKD 3.005871295928955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.5809774547815323
Loss made of: CE 0.38001787662506104, LKD 3.7247564792633057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.5063645213842394
Loss made of: CE 0.31537944078445435, LKD 3.3172671794891357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.5034832805395126
Loss made of: CE 0.3980879485607147, LKD 3.398568630218506, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.6759927332401277
Loss made of: CE 0.3302975296974182, LKD 3.8927013874053955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3639757037162781, Reg Loss=3.3295230865478516
Clinet index 0, End of Epoch 4/6, Average Loss=3.6934988498687744, Class Loss=0.3639757037162781, Reg Loss=3.3295230865478516
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=3.725104144215584
Loss made of: CE 0.4616656005382538, LKD 4.252267837524414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.7488056808710097
Loss made of: CE 0.31946858763694763, LKD 2.7592313289642334, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.5578578889369963
Loss made of: CE 0.2630406320095062, LKD 2.668553113937378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.6609689980745315
Loss made of: CE 0.38133737444877625, LKD 3.291236162185669, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.6098349779844283
Loss made of: CE 0.3002742528915405, LKD 3.1463370323181152, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.735270670056343
Loss made of: CE 0.3647361993789673, LKD 3.1845130920410156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.7169720590114594
Loss made of: CE 0.3420819640159607, LKD 3.6274633407592773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.8021036714315413
Loss made of: CE 0.3366881310939789, LKD 3.136211633682251, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.803258490562439
Loss made of: CE 0.3741511106491089, LKD 2.9936132431030273, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.362425833940506, Reg Loss=3.3503575325012207
Clinet index 0, End of Epoch 5/6, Average Loss=3.7127833366394043, Class Loss=0.362425833940506, Reg Loss=3.3503575325012207
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=3.4705654621124267
Loss made of: CE 0.3312320411205292, LKD 3.807683229446411, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.626899802684784
Loss made of: CE 0.29719477891921997, LKD 2.793011426925659, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.576791077852249
Loss made of: CE 0.3946189284324646, LKD 3.4830780029296875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.5721177011728287
Loss made of: CE 0.33353084325790405, LKD 3.1614131927490234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.7896407574415205
Loss made of: CE 0.4058639407157898, LKD 2.829962968826294, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.7754269748926164
Loss made of: CE 0.30621492862701416, LKD 2.852175235748291, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.5841863244771957
Loss made of: CE 0.34803664684295654, LKD 2.932461738586426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.843922773003578
Loss made of: CE 0.323322594165802, LKD 3.042386054992676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.556640899181366
Loss made of: CE 0.3632882535457611, LKD 2.926424026489258, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3539845943450928, Reg Loss=3.3293590545654297
Clinet index 0, End of Epoch 6/6, Average Loss=3.6833436489105225, Class Loss=0.3539845943450928, Reg Loss=3.3293590545654297
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=4.248082557320595
Loss made of: CE 0.5421856045722961, LKD 3.712655544281006, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=3.8863738387823106
Loss made of: CE 0.5309363603591919, LKD 3.4528865814208984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=3.8319808781147002
Loss made of: CE 0.3538641333580017, LKD 3.8864896297454834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.873853099346161
Loss made of: CE 0.441490113735199, LKD 4.106732368469238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.968480756878853
Loss made of: CE 0.4825619161128998, LKD 3.217900276184082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=4.113311767578125
Loss made of: CE 0.3979174792766571, LKD 3.37362003326416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.788655585050583
Loss made of: CE 0.34546932578086853, LKD 3.218682050704956, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.8236204981803894
Loss made of: CE 0.4160519540309906, LKD 3.2800145149230957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.829057255387306
Loss made of: CE 0.3638629615306854, LKD 3.1964807510375977, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.455757200717926, Reg Loss=3.4506683349609375
Clinet index 25, End of Epoch 1/6, Average Loss=3.9064254760742188, Class Loss=0.455757200717926, Reg Loss=3.4506683349609375
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=3.8497740268707275
Loss made of: CE 0.45842617750167847, LKD 3.449923515319824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.899027332663536
Loss made of: CE 0.3943207263946533, LKD 3.88307785987854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=4.001084181666374
Loss made of: CE 0.42669981718063354, LKD 3.810868501663208, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.8403027236461638
Loss made of: CE 0.44796884059906006, LKD 3.8678903579711914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.679224443435669
Loss made of: CE 0.3836333751678467, LKD 3.100959539413452, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.909838891029358
Loss made of: CE 0.3977135121822357, LKD 3.8381409645080566, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.547233113646507
Loss made of: CE 0.4723294675350189, LKD 3.598883628845215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.954420807957649
Loss made of: CE 0.3638684153556824, LKD 3.3529486656188965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.813484662771225
Loss made of: CE 0.4345507323741913, LKD 2.995948076248169, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.398896187543869, Reg Loss=3.417102813720703
Clinet index 25, End of Epoch 2/6, Average Loss=3.8159990310668945, Class Loss=0.398896187543869, Reg Loss=3.417102813720703
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=3.5970695495605467
Loss made of: CE 0.33432191610336304, LKD 3.0325636863708496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.9180825382471083
Loss made of: CE 0.45521196722984314, LKD 3.6465063095092773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.7495664566755296
Loss made of: CE 0.4018028676509857, LKD 3.1394646167755127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.661456349492073
Loss made of: CE 0.3653193414211273, LKD 3.5516767501831055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.7336160123348234
Loss made of: CE 0.34813523292541504, LKD 3.786670684814453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.7388976395130156
Loss made of: CE 0.4172137677669525, LKD 3.0189080238342285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.7090041488409042
Loss made of: CE 0.3734099566936493, LKD 3.346100330352783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=4.018150243163109
Loss made of: CE 0.3532538115978241, LKD 3.034226179122925, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.7250371396541597
Loss made of: CE 0.34325075149536133, LKD 3.045196533203125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37875062227249146, Reg Loss=3.3865489959716797
Clinet index 25, End of Epoch 3/6, Average Loss=3.7652995586395264, Class Loss=0.37875062227249146, Reg Loss=3.3865489959716797
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=3.86045061647892
Loss made of: CE 0.3386315703392029, LKD 3.4025888442993164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.836052191257477
Loss made of: CE 0.39259204268455505, LKD 3.187653064727783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.8540965527296067
Loss made of: CE 0.3305049538612366, LKD 3.2942733764648438, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.5433405697345735
Loss made of: CE 0.3248257637023926, LKD 2.851135730743408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.9304256230592727
Loss made of: CE 0.3900533616542816, LKD 3.3240482807159424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.857298085093498
Loss made of: CE 0.34836769104003906, LKD 3.524216651916504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.927949494123459
Loss made of: CE 0.3790465295314789, LKD 4.408108234405518, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.584751707315445
Loss made of: CE 0.37526261806488037, LKD 3.481363534927368, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.650992754101753
Loss made of: CE 0.2783249020576477, LKD 2.8372957706451416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.37543076276779175, Reg Loss=3.4046084880828857
Clinet index 25, End of Epoch 4/6, Average Loss=3.7800393104553223, Class Loss=0.37543076276779175, Reg Loss=3.4046084880828857
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=3.941294312477112
Loss made of: CE 0.4138990342617035, LKD 3.1221673488616943, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.750423866510391
Loss made of: CE 0.39475536346435547, LKD 3.990095853805542, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.8031837910413744
Loss made of: CE 0.3747405707836151, LKD 3.3735926151275635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.5703447282314302
Loss made of: CE 0.29186493158340454, LKD 2.95327091217041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.5945105999708176
Loss made of: CE 0.36100563406944275, LKD 3.404074192047119, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.8268484979867936
Loss made of: CE 0.39307650923728943, LKD 3.6337740421295166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.6144223541021345
Loss made of: CE 0.4209761619567871, LKD 3.8691699504852295, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.6577280670404435
Loss made of: CE 0.3130027651786804, LKD 2.81801438331604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.7892815709114074
Loss made of: CE 0.4017915725708008, LKD 3.036161422729492, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3690677881240845, Reg Loss=3.385019063949585
Clinet index 25, End of Epoch 5/6, Average Loss=3.754086971282959, Class Loss=0.3690677881240845, Reg Loss=3.385019063949585
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=3.8462432116270064
Loss made of: CE 0.40381956100463867, LKD 3.758056402206421, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.784509837627411
Loss made of: CE 0.40999218821525574, LKD 3.5902462005615234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.6390206307172774
Loss made of: CE 0.30028337240219116, LKD 3.0067696571350098, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.5729152113199234
Loss made of: CE 0.3055649995803833, LKD 3.1028079986572266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.7318253755569457
Loss made of: CE 0.2833603620529175, LKD 2.8815507888793945, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.7919597178697586
Loss made of: CE 0.4078121781349182, LKD 3.796205759048462, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.629430851340294
Loss made of: CE 0.3784695565700531, LKD 2.9841160774230957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.744244506955147
Loss made of: CE 0.37172478437423706, LKD 4.412881851196289, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.769450527429581
Loss made of: CE 0.37983018159866333, LKD 3.2261464595794678, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3650050759315491, Reg Loss=3.3514456748962402
Clinet index 25, End of Epoch 6/6, Average Loss=3.7164506912231445, Class Loss=0.3650050759315491, Reg Loss=3.3514456748962402
Current Client Index:  23
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=4.243430277705192
Loss made of: CE 0.4175255298614502, LKD 3.514774799346924, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=3.906970775127411
Loss made of: CE 0.43800419569015503, LKD 3.185418128967285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=3.6025378078222277
Loss made of: CE 0.43767088651657104, LKD 3.3016912937164307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.819195991754532
Loss made of: CE 0.43109458684921265, LKD 3.608379602432251, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.666779363155365
Loss made of: CE 0.36658987402915955, LKD 2.9933481216430664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.8696510255336762
Loss made of: CE 0.3979222774505615, LKD 3.1479220390319824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.8961243718862533
Loss made of: CE 0.4200870990753174, LKD 3.422433853149414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.7604787349700928
Loss made of: CE 0.41283392906188965, LKD 3.3790483474731445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.8523896396160127
Loss made of: CE 0.40635618567466736, LKD 3.6788604259490967, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.44262757897377014, Reg Loss=3.3978865146636963
Clinet index 23, End of Epoch 1/6, Average Loss=3.8405141830444336, Class Loss=0.44262757897377014, Reg Loss=3.3978865146636963
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=3.72902275621891
Loss made of: CE 0.3395928740501404, LKD 4.667588710784912, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.7797262907028197
Loss made of: CE 0.3989691734313965, LKD 4.237494945526123, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.6408139884471895
Loss made of: CE 0.3510909676551819, LKD 3.040147542953491, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.748145207762718
Loss made of: CE 0.4185294806957245, LKD 3.7606329917907715, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.8297638833522796
Loss made of: CE 0.40456342697143555, LKD 3.9155285358428955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.717373824119568
Loss made of: CE 0.4243733882904053, LKD 3.6838769912719727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.784077486395836
Loss made of: CE 0.3557473123073578, LKD 3.1474239826202393, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.9480161339044573
Loss made of: CE 0.369165301322937, LKD 3.0780234336853027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.8372249215841294
Loss made of: CE 0.3892779052257538, LKD 2.9896578788757324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3858488202095032, Reg Loss=3.3530642986297607
Clinet index 23, End of Epoch 2/6, Average Loss=3.738913059234619, Class Loss=0.3858488202095032, Reg Loss=3.3530642986297607
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=3.5417788505554197
Loss made of: CE 0.356303870677948, LKD 3.406681776046753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.7388737589120864
Loss made of: CE 0.48248156905174255, LKD 3.4750924110412598, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.8000065952539446
Loss made of: CE 0.43696683645248413, LKD 2.9100513458251953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.642257437109947
Loss made of: CE 0.42247042059898376, LKD 3.0444984436035156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.5589122772216797
Loss made of: CE 0.3589387834072113, LKD 3.5772674083709717, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.8346662908792495
Loss made of: CE 0.38075828552246094, LKD 3.657075881958008, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.6698049664497376
Loss made of: CE 0.3952828645706177, LKD 3.6494505405426025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.7233325630426406
Loss made of: CE 0.4417099356651306, LKD 4.162497043609619, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.922243449091911
Loss made of: CE 0.32441699504852295, LKD 2.819629669189453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3729698359966278, Reg Loss=3.3439419269561768
Clinet index 23, End of Epoch 3/6, Average Loss=3.716911792755127, Class Loss=0.3729698359966278, Reg Loss=3.3439419269561768
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=3.6836737275123594
Loss made of: CE 0.3578971028327942, LKD 3.3944194316864014, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.6975181862711906
Loss made of: CE 0.36751794815063477, LKD 4.279407978057861, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.7765258878469465
Loss made of: CE 0.3952878415584564, LKD 2.954951524734497, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.818847671151161
Loss made of: CE 0.4119764268398285, LKD 2.952130079269409, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.829557698965073
Loss made of: CE 0.34866976737976074, LKD 3.2023065090179443, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.7072786718606947
Loss made of: CE 0.4165216088294983, LKD 3.325723886489868, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.526903119683266
Loss made of: CE 0.30139780044555664, LKD 2.772381544113159, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.8551940113306045
Loss made of: CE 0.3176674544811249, LKD 3.766181707382202, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.6461236625909805
Loss made of: CE 0.3514944911003113, LKD 3.0903141498565674, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3650246262550354, Reg Loss=3.365203380584717
Clinet index 23, End of Epoch 4/6, Average Loss=3.7302279472351074, Class Loss=0.3650246262550354, Reg Loss=3.365203380584717
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=3.6958622872829436
Loss made of: CE 0.34172457456588745, LKD 3.4988880157470703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.6586114943027495
Loss made of: CE 0.40035760402679443, LKD 3.7998616695404053, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.878004494309425
Loss made of: CE 0.41042447090148926, LKD 3.5095057487487793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.7146866083145142
Loss made of: CE 0.33150964975357056, LKD 2.9320483207702637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.4569636642932893
Loss made of: CE 0.33200711011886597, LKD 2.9232430458068848, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.6456559360027314
Loss made of: CE 0.34746867418289185, LKD 3.2380383014678955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.763572391867638
Loss made of: CE 0.36139559745788574, LKD 3.2270631790161133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.5371504694223406
Loss made of: CE 0.37442025542259216, LKD 3.1022157669067383, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.763988107442856
Loss made of: CE 0.3352733552455902, LKD 3.077941656112671, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3586842119693756, Reg Loss=3.33622145652771
Clinet index 23, End of Epoch 5/6, Average Loss=3.6949057579040527, Class Loss=0.3586842119693756, Reg Loss=3.33622145652771
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=3.852989748120308
Loss made of: CE 0.3558892607688904, LKD 3.04563307762146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.800017586350441
Loss made of: CE 0.3370905816555023, LKD 3.275137424468994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.7435342609882354
Loss made of: CE 0.3376089036464691, LKD 2.9264121055603027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.813810741901398
Loss made of: CE 0.3030734658241272, LKD 3.2448604106903076, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.8288592010736466
Loss made of: CE 0.3148597478866577, LKD 3.0196382999420166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.501655489206314
Loss made of: CE 0.36475643515586853, LKD 2.8743321895599365, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.941963252425194
Loss made of: CE 0.4416379928588867, LKD 3.9535775184631348, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.5197968095541
Loss made of: CE 0.270784854888916, LKD 2.5955584049224854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.6765093564987184
Loss made of: CE 0.3875455856323242, LKD 4.169955730438232, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35989800095558167, Reg Loss=3.370436191558838
Clinet index 23, End of Epoch 6/6, Average Loss=3.7303342819213867, Class Loss=0.35989800095558167, Reg Loss=3.370436191558838
federated aggregation...
Validation, Class Loss=0.8180921673774719, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.777452
Mean Acc: 0.240543
FreqW Acc: 0.681551
Mean IoU: 0.163809
Class IoU:
	class 0: 0.8747115
	class 1: 0.004680721
	class 2: 0.00027508364
	class 3: 0.0
	class 4: 0.24654864
	class 5: 0.046272587
	class 6: 0.016571026
	class 7: 0.5574337
	class 8: 0.0
	class 9: 0.0016464075
	class 10: 0.0
	class 11: 4.22967e-06
	class 12: 0.00015598617
	class 13: 0.110558644
	class 14: 0.23156045
	class 15: 0.69434047
	class 16: 0.0
Class Acc:
	class 0: 0.97011966
	class 1: 0.004680721
	class 2: 0.00027522244
	class 3: 0.0
	class 4: 0.2495713
	class 5: 0.04627859
	class 6: 0.016573902
	class 7: 0.5607222
	class 8: 0.0
	class 9: 0.0016474439
	class 10: 0.0
	class 11: 4.22967e-06
	class 12: 0.00016173325
	class 13: 0.9225151
	class 14: 0.42943794
	class 15: 0.8872515
	class 16: 0.0

federated global round: 23, step: 4
select part of clients to conduct local training
[17, 3, 5, 22]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=3.8266924053430555
Loss made of: CE 0.3717864453792572, LKD 2.709604501724243, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=3.657312461733818
Loss made of: CE 0.3814679980278015, LKD 3.6025609970092773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=3.8678644418716432
Loss made of: CE 0.3776955008506775, LKD 3.815199136734009, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.7576727628707887
Loss made of: CE 0.39896923303604126, LKD 3.2567195892333984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.664432570338249
Loss made of: CE 0.3058165907859802, LKD 3.1525120735168457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.716454643011093
Loss made of: CE 0.3614821135997772, LKD 3.610069990158081, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.590010127425194
Loss made of: CE 0.2751353085041046, LKD 3.0296730995178223, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.7639782071113586
Loss made of: CE 0.33377283811569214, LKD 3.3462445735931396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.6417385220527647
Loss made of: CE 0.3560168147087097, LKD 3.3824756145477295, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3591311275959015, Reg Loss=3.3521931171417236
Clinet index 17, End of Epoch 1/6, Average Loss=3.7113242149353027, Class Loss=0.3591311275959015, Reg Loss=3.3521931171417236
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=3.4538844347000124
Loss made of: CE 0.27120697498321533, LKD 3.6445510387420654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.8439282178878784
Loss made of: CE 0.33085548877716064, LKD 3.635254144668579, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.6640314370393754
Loss made of: CE 0.34124189615249634, LKD 4.490871906280518, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.6825025022029876
Loss made of: CE 0.33220019936561584, LKD 3.647793769836426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.5607009053230287
Loss made of: CE 0.39331716299057007, LKD 3.0920088291168213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.6373545080423355
Loss made of: CE 0.36480945348739624, LKD 3.209191083908081, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.934906741976738
Loss made of: CE 0.3980656564235687, LKD 4.088800430297852, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.7721876472234728
Loss made of: CE 0.3610517382621765, LKD 3.881190776824951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.5076799601316453
Loss made of: CE 0.29350799322128296, LKD 2.8457095623016357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3478007912635803, Reg Loss=3.32285475730896
Clinet index 17, End of Epoch 2/6, Average Loss=3.6706554889678955, Class Loss=0.3478007912635803, Reg Loss=3.32285475730896
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=3.629120147228241
Loss made of: CE 0.32261550426483154, LKD 3.3444018363952637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.7658180773258207
Loss made of: CE 0.37373611330986023, LKD 3.61297869682312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.8040334552526476
Loss made of: CE 0.33330237865448, LKD 3.3580236434936523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.8083621114492416
Loss made of: CE 0.4236268401145935, LKD 3.65445613861084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.6444118291139604
Loss made of: CE 0.3791641592979431, LKD 3.377678632736206, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.698789668083191
Loss made of: CE 0.3009300231933594, LKD 2.8528804779052734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.7638492405414583
Loss made of: CE 0.38696664571762085, LKD 3.3369712829589844, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.449802801012993
Loss made of: CE 0.35142478346824646, LKD 3.521078109741211, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.6781051248311996
Loss made of: CE 0.3628677725791931, LKD 3.4754574298858643, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3491431772708893, Reg Loss=3.3492462635040283
Clinet index 17, End of Epoch 3/6, Average Loss=3.6983895301818848, Class Loss=0.3491431772708893, Reg Loss=3.3492462635040283
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=3.5711863845586778
Loss made of: CE 0.39867520332336426, LKD 3.844614028930664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.681576833128929
Loss made of: CE 0.40776586532592773, LKD 3.148433208465576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.640004017949104
Loss made of: CE 0.40001410245895386, LKD 3.039069890975952, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.730005297064781
Loss made of: CE 0.4027290940284729, LKD 4.077916622161865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.705707108974457
Loss made of: CE 0.3189578354358673, LKD 2.4984474182128906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.876905146241188
Loss made of: CE 0.3330985903739929, LKD 3.9049088954925537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.799743691086769
Loss made of: CE 0.4128289222717285, LKD 4.196808338165283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.569723606109619
Loss made of: CE 0.3333228826522827, LKD 3.199126958847046, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.6885494917631148
Loss made of: CE 0.36124032735824585, LKD 3.567643165588379, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3454117774963379, Reg Loss=3.3405516147613525
Clinet index 17, End of Epoch 4/6, Average Loss=3.6859633922576904, Class Loss=0.3454117774963379, Reg Loss=3.3405516147613525
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=3.5846391558647155
Loss made of: CE 0.2901324927806854, LKD 2.769613742828369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.6959893733263014
Loss made of: CE 0.34589308500289917, LKD 3.664600372314453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.716228386759758
Loss made of: CE 0.36924514174461365, LKD 3.7468082904815674, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.5110488921403884
Loss made of: CE 0.33440253138542175, LKD 3.0897350311279297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.8769490242004396
Loss made of: CE 0.3500841557979584, LKD 3.646507501602173, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.6565610349178312
Loss made of: CE 0.3989278972148895, LKD 3.5127201080322266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.5781303524971007
Loss made of: CE 0.3380492925643921, LKD 2.700514793395996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.753980588912964
Loss made of: CE 0.32380563020706177, LKD 3.1057376861572266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.59337375164032
Loss made of: CE 0.3943648338317871, LKD 3.397146701812744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3437097668647766, Reg Loss=3.317283868789673
Clinet index 17, End of Epoch 5/6, Average Loss=3.6609935760498047, Class Loss=0.3437097668647766, Reg Loss=3.317283868789673
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=3.623858579993248
Loss made of: CE 0.31445321440696716, LKD 3.700697422027588, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.866346445679665
Loss made of: CE 0.35539716482162476, LKD 3.50449538230896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.6066366702318193
Loss made of: CE 0.32877105474472046, LKD 3.4414007663726807, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.7007883578538894
Loss made of: CE 0.38125595450401306, LKD 3.425051689147949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.344443625211716
Loss made of: CE 0.2918325364589691, LKD 2.9657905101776123, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.85264858007431
Loss made of: CE 0.2744769752025604, LKD 2.9089395999908447, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.6227090686559675
Loss made of: CE 0.3452855050563812, LKD 2.6348631381988525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.6791502982378006
Loss made of: CE 0.31835514307022095, LKD 3.5286173820495605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.582948824763298
Loss made of: CE 0.3240869641304016, LKD 3.3385210037231445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.33978408575057983, Reg Loss=3.3168764114379883
Clinet index 17, End of Epoch 6/6, Average Loss=3.656660556793213, Class Loss=0.33978408575057983, Reg Loss=3.3168764114379883
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.394458132982254
Loss made of: CE 0.6823708415031433, LKD 3.0464107990264893, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9055666923522949, Reg Loss=3.4728639125823975
Clinet index 3, End of Epoch 1/6, Average Loss=4.378430366516113, Class Loss=0.9055666923522949, Reg Loss=3.4728639125823975
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=4.18144371509552
Loss made of: CE 0.5263208150863647, LKD 3.5103538036346436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6609324216842651, Reg Loss=3.472909450531006
Clinet index 3, End of Epoch 2/6, Average Loss=4.1338419914245605, Class Loss=0.6609324216842651, Reg Loss=3.472909450531006
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=4.012338525056839
Loss made of: CE 0.35671040415763855, LKD 3.249918222427368, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5376332998275757, Reg Loss=3.4650275707244873
Clinet index 3, End of Epoch 3/6, Average Loss=4.002660751342773, Class Loss=0.5376332998275757, Reg Loss=3.4650275707244873
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=3.900409737229347
Loss made of: CE 0.4231536388397217, LKD 3.3403899669647217, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4744475781917572, Reg Loss=3.450679302215576
Clinet index 3, End of Epoch 4/6, Average Loss=3.925126791000366, Class Loss=0.4744475781917572, Reg Loss=3.450679302215576
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=3.8935272991657257
Loss made of: CE 0.46402889490127563, LKD 3.3370652198791504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4286838471889496, Reg Loss=3.378817558288574
Clinet index 3, End of Epoch 5/6, Average Loss=3.8075013160705566, Class Loss=0.4286838471889496, Reg Loss=3.378817558288574
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=4.010662105679512
Loss made of: CE 0.4866132140159607, LKD 3.3805272579193115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4218243956565857, Reg Loss=3.4980502128601074
Clinet index 3, End of Epoch 6/6, Average Loss=3.919874668121338, Class Loss=0.4218243956565857, Reg Loss=3.4980502128601074
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=3.8339288622140884
Loss made of: CE 0.3566187620162964, LKD 3.5616443157196045, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=4.014776796102524
Loss made of: CE 0.47835731506347656, LKD 4.124074935913086, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=3.73543818295002
Loss made of: CE 0.3012881875038147, LKD 3.231930732727051, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.738346928358078
Loss made of: CE 0.43643197417259216, LKD 4.549497127532959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.701774242520332
Loss made of: CE 0.3573046624660492, LKD 3.6807968616485596, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.6133432894945146
Loss made of: CE 0.3453002870082855, LKD 3.766158103942871, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.9874265998601914
Loss made of: CE 0.4168650507926941, LKD 3.251051902770996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.765174514055252
Loss made of: CE 0.45790359377861023, LKD 3.4258182048797607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.818233832716942
Loss made of: CE 0.37632569670677185, LKD 3.8766868114471436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3678058683872223, Reg Loss=3.437601089477539
Clinet index 5, End of Epoch 1/6, Average Loss=3.8054070472717285, Class Loss=0.3678058683872223, Reg Loss=3.437601089477539
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=3.378458669781685
Loss made of: CE 0.313260555267334, LKD 3.2692525386810303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.7352667927742003
Loss made of: CE 0.3234352767467499, LKD 3.2898008823394775, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.926886758208275
Loss made of: CE 0.3630160093307495, LKD 3.951183795928955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.818573680520058
Loss made of: CE 0.35976260900497437, LKD 3.4020676612854004, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.976739025115967
Loss made of: CE 0.3919469714164734, LKD 3.5940945148468018, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.994278359413147
Loss made of: CE 0.33564990758895874, LKD 2.921820878982544, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.7467499732971192
Loss made of: CE 0.31784310936927795, LKD 3.0552914142608643, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.708573207259178
Loss made of: CE 0.3377324044704437, LKD 3.1088082790374756, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.8834645241498946
Loss made of: CE 0.41022008657455444, LKD 3.372138261795044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36504441499710083, Reg Loss=3.438347578048706
Clinet index 5, End of Epoch 2/6, Average Loss=3.803391933441162, Class Loss=0.36504441499710083, Reg Loss=3.438347578048706
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=3.912340819835663
Loss made of: CE 0.34709590673446655, LKD 3.5692312717437744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.9367445021867753
Loss made of: CE 0.37497004866600037, LKD 3.0001332759857178, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.687180107831955
Loss made of: CE 0.3439781665802002, LKD 2.6131880283355713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.774223256111145
Loss made of: CE 0.32768747210502625, LKD 3.5878102779388428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=4.005443850159645
Loss made of: CE 0.2961885929107666, LKD 3.0576393604278564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.8592283964157104
Loss made of: CE 0.5280851721763611, LKD 3.9464704990386963, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.518021911382675
Loss made of: CE 0.2708483934402466, LKD 3.004333734512329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.752717670798302
Loss made of: CE 0.31515002250671387, LKD 2.841867208480835, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.7865288645029067
Loss made of: CE 0.2860342562198639, LKD 3.2117247581481934, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3617595434188843, Reg Loss=3.4326748847961426
Clinet index 5, End of Epoch 3/6, Average Loss=3.7944345474243164, Class Loss=0.3617595434188843, Reg Loss=3.4326748847961426
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=3.7711662739515304
Loss made of: CE 0.38249367475509644, LKD 3.249117851257324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.844285523891449
Loss made of: CE 0.3588756024837494, LKD 3.895312547683716, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.733424589037895
Loss made of: CE 0.37777894735336304, LKD 2.7421188354492188, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.7993014574050905
Loss made of: CE 0.41763025522232056, LKD 3.9948370456695557, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.79835384786129
Loss made of: CE 0.42788165807724, LKD 4.076202392578125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.716787976026535
Loss made of: CE 0.33485352993011475, LKD 3.132570505142212, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.8943160325288773
Loss made of: CE 0.34376582503318787, LKD 3.1871848106384277, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.704662746191025
Loss made of: CE 0.38206350803375244, LKD 3.2521822452545166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.8833267986774445
Loss made of: CE 0.3741741180419922, LKD 3.056103467941284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.35850831866264343, Reg Loss=3.425057888031006
Clinet index 5, End of Epoch 4/6, Average Loss=3.7835662364959717, Class Loss=0.35850831866264343, Reg Loss=3.425057888031006
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=3.7138981461524962
Loss made of: CE 0.3559221923351288, LKD 2.5221107006073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.8287130296230316
Loss made of: CE 0.3591485023498535, LKD 3.660322666168213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.754263111948967
Loss made of: CE 0.3124867081642151, LKD 3.0091028213500977, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.6120274275541306
Loss made of: CE 0.3662426471710205, LKD 3.242827892303467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.6943683475255966
Loss made of: CE 0.3469805121421814, LKD 2.8908870220184326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.9334033131599426
Loss made of: CE 0.305305153131485, LKD 3.4005203247070312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.9320770025253298
Loss made of: CE 0.33899641036987305, LKD 3.869227647781372, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.5071329176425934
Loss made of: CE 0.351672500371933, LKD 2.8015217781066895, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.9371838748455046
Loss made of: CE 0.3510252833366394, LKD 3.329756498336792, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.350509911775589, Reg Loss=3.41420841217041
Clinet index 5, End of Epoch 5/6, Average Loss=3.7647182941436768, Class Loss=0.350509911775589, Reg Loss=3.41420841217041
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=3.744558575749397
Loss made of: CE 0.3419443368911743, LKD 3.743690252304077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.839238801598549
Loss made of: CE 0.3193235993385315, LKD 3.1937613487243652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.4913421869277954
Loss made of: CE 0.3185163140296936, LKD 3.8384058475494385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.679821711778641
Loss made of: CE 0.37447959184646606, LKD 3.5049095153808594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.9506640493869782
Loss made of: CE 0.3166274428367615, LKD 2.992042064666748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.631712570786476
Loss made of: CE 0.27055472135543823, LKD 3.1764469146728516, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.8531568378210066
Loss made of: CE 0.2783246636390686, LKD 3.0718936920166016, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.8194102346897125
Loss made of: CE 0.3849836587905884, LKD 4.115760326385498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=4.054017320275307
Loss made of: CE 0.42510709166526794, LKD 3.377856969833374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3503331243991852, Reg Loss=3.417714834213257
Clinet index 5, End of Epoch 6/6, Average Loss=3.768048048019409, Class Loss=0.3503331243991852, Reg Loss=3.417714834213257
Current Client Index:  22
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.4957611680030825
Loss made of: CE 1.0667498111724854, LKD 4.34473991394043, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9529489874839783, Reg Loss=3.4984688758850098
Clinet index 22, End of Epoch 1/6, Average Loss=4.451417922973633, Class Loss=0.9529489874839783, Reg Loss=3.4984688758850098
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=4.102475047111511
Loss made of: CE 0.517444372177124, LKD 3.500945806503296, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6944758296012878, Reg Loss=3.4439897537231445
Clinet index 22, End of Epoch 2/6, Average Loss=4.138465404510498, Class Loss=0.6944758296012878, Reg Loss=3.4439897537231445
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=3.94887275993824
Loss made of: CE 0.6044637560844421, LKD 3.8202219009399414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5320736169815063, Reg Loss=3.3753552436828613
Clinet index 22, End of Epoch 3/6, Average Loss=3.907428741455078, Class Loss=0.5320736169815063, Reg Loss=3.3753552436828613
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=3.8818308502435683
Loss made of: CE 0.4819332957267761, LKD 3.1866822242736816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4770450294017792, Reg Loss=3.396902561187744
Clinet index 22, End of Epoch 4/6, Average Loss=3.8739476203918457, Class Loss=0.4770450294017792, Reg Loss=3.396902561187744
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=3.696679726243019
Loss made of: CE 0.35416024923324585, LKD 2.6592483520507812, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4436463713645935, Reg Loss=3.3602607250213623
Clinet index 22, End of Epoch 5/6, Average Loss=3.8039071559906006, Class Loss=0.4436463713645935, Reg Loss=3.3602607250213623
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=3.748349356651306
Loss made of: CE 0.533035159111023, LKD 3.381230592727661, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4323861002922058, Reg Loss=3.39985990524292
Clinet index 22, End of Epoch 6/6, Average Loss=3.8322460651397705, Class Loss=0.4323861002922058, Reg Loss=3.39985990524292
federated aggregation...
Validation, Class Loss=0.8001407980918884, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.778764
Mean Acc: 0.252896
FreqW Acc: 0.684470
Mean IoU: 0.178577
Class IoU:
	class 0: 0.8721835
	class 1: 0.033394095
	class 2: 0.00039903686
	class 3: 0.0
	class 4: 0.22840492
	class 5: 0.053124014
	class 6: 0.03888799
	class 7: 0.5672205
	class 8: 0.0
	class 9: 0.003167023
	class 10: 0.0
	class 11: 0.0
	class 12: 0.000101529906
	class 13: 0.108944796
	class 14: 0.20884109
	class 15: 0.7339619
	class 16: 0.1871767
Class Acc:
	class 0: 0.96978086
	class 1: 0.033395283
	class 2: 0.0003992159
	class 3: 0.0
	class 4: 0.23072146
	class 5: 0.05315586
	class 6: 0.03889798
	class 7: 0.57041776
	class 8: 0.0
	class 9: 0.0031695212
	class 10: 0.0
	class 11: 0.0
	class 12: 0.00010411918
	class 13: 0.9180027
	class 14: 0.3895102
	class 15: 0.88420147
	class 16: 0.20747069

federated global round: 24, step: 4
select part of clients to conduct local training
[16, 9, 12, 2]
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=3.7841196715831757
Loss made of: CE 0.394603967666626, LKD 3.9071435928344727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=3.6427479088306427
Loss made of: CE 0.3481041193008423, LKD 3.4095683097839355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=3.7063577324151993
Loss made of: CE 0.3751509189605713, LKD 3.476236343383789, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=3.6918808996677397
Loss made of: CE 0.38715264201164246, LKD 3.297891855239868, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=3.6369267463684083
Loss made of: CE 0.35678884387016296, LKD 3.1571011543273926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=3.9075714528560637
Loss made of: CE 0.39644187688827515, LKD 3.6316521167755127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=3.5170472651720046
Loss made of: CE 0.3495071828365326, LKD 3.125096082687378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=3.797619950771332
Loss made of: CE 0.3238868713378906, LKD 2.9813332557678223, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=3.727316805720329
Loss made of: CE 0.3699396848678589, LKD 3.4985337257385254, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3652832508087158, Reg Loss=3.3352153301239014
Clinet index 16, End of Epoch 1/6, Average Loss=3.700498580932617, Class Loss=0.3652832508087158, Reg Loss=3.3352153301239014
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/97, Loss=3.62317835688591
Loss made of: CE 0.3110096752643585, LKD 3.887998580932617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=3.737538230419159
Loss made of: CE 0.39437994360923767, LKD 4.080647945404053, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=3.523810628056526
Loss made of: CE 0.3617711663246155, LKD 3.22729754447937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=3.6564306646585463
Loss made of: CE 0.32344818115234375, LKD 3.0417003631591797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=3.698119196295738
Loss made of: CE 0.30314821004867554, LKD 3.1470906734466553, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=3.6606759428977966
Loss made of: CE 0.39096149802207947, LKD 3.987760066986084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=3.82229740023613
Loss made of: CE 0.36512070894241333, LKD 3.973480224609375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=3.4416951507329943
Loss made of: CE 0.3587460517883301, LKD 3.3234589099884033, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=3.786266915500164
Loss made of: CE 0.3473193645477295, LKD 3.346069812774658, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3500320017337799, Reg Loss=3.3071646690368652
Clinet index 16, End of Epoch 2/6, Average Loss=3.6571967601776123, Class Loss=0.3500320017337799, Reg Loss=3.3071646690368652
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/97, Loss=3.7552946150302886
Loss made of: CE 0.33826571702957153, LKD 2.8832149505615234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=3.5965290009975432
Loss made of: CE 0.378856360912323, LKD 3.0289080142974854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=3.7978217393159865
Loss made of: CE 0.3473394811153412, LKD 3.4181573390960693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=3.5185521304607392
Loss made of: CE 0.3502832055091858, LKD 3.5986146926879883, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=3.539088401198387
Loss made of: CE 0.2934119403362274, LKD 3.306006908416748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=3.6424964696168898
Loss made of: CE 0.36465904116630554, LKD 2.888805866241455, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=3.9092599868774416
Loss made of: CE 0.3658101260662079, LKD 3.9446473121643066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=3.737737262248993
Loss made of: CE 0.37407732009887695, LKD 3.0626816749572754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=3.5765144288539887
Loss made of: CE 0.3478674590587616, LKD 3.5289435386657715, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3491405248641968, Reg Loss=3.3185267448425293
Clinet index 16, End of Epoch 3/6, Average Loss=3.6676673889160156, Class Loss=0.3491405248641968, Reg Loss=3.3185267448425293
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/97, Loss=3.5796985149383547
Loss made of: CE 0.30606168508529663, LKD 3.137021064758301, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=3.9251802384853365
Loss made of: CE 0.322084903717041, LKD 3.376392364501953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=3.7261720150709152
Loss made of: CE 0.3796641230583191, LKD 3.6227221488952637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=3.5608968794345857
Loss made of: CE 0.33330237865448, LKD 3.1678617000579834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=3.564818200469017
Loss made of: CE 0.30078908801078796, LKD 3.4026153087615967, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=3.580898028612137
Loss made of: CE 0.36962890625, LKD 3.2692835330963135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=3.592919060587883
Loss made of: CE 0.34575995802879333, LKD 2.844001293182373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=3.660868692398071
Loss made of: CE 0.33952122926712036, LKD 3.143188714981079, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=3.604533162713051
Loss made of: CE 0.35495173931121826, LKD 3.2413179874420166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3461284041404724, Reg Loss=3.302983045578003
Clinet index 16, End of Epoch 4/6, Average Loss=3.64911150932312, Class Loss=0.3461284041404724, Reg Loss=3.302983045578003
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/97, Loss=3.847532621026039
Loss made of: CE 0.3890039622783661, LKD 3.1530613899230957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=3.621721702814102
Loss made of: CE 0.37980613112449646, LKD 3.2536654472351074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=3.9216947317123414
Loss made of: CE 0.39884480834007263, LKD 3.3149826526641846, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=3.632127606868744
Loss made of: CE 0.332139790058136, LKD 3.3609635829925537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=3.6146226674318314
Loss made of: CE 0.2898733615875244, LKD 3.0553250312805176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=3.445825406908989
Loss made of: CE 0.32878750562667847, LKD 3.4223928451538086, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=3.5386280953884124
Loss made of: CE 0.24651643633842468, LKD 3.19477915763855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=3.834855279326439
Loss made of: CE 0.4223063886165619, LKD 3.8071393966674805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=3.494743910431862
Loss made of: CE 0.3965272307395935, LKD 3.6697638034820557, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3469252288341522, Reg Loss=3.314486026763916
Clinet index 16, End of Epoch 5/6, Average Loss=3.6614112854003906, Class Loss=0.3469252288341522, Reg Loss=3.314486026763916
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/97, Loss=3.438669803738594
Loss made of: CE 0.33273130655288696, LKD 2.7103147506713867, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=3.711384493112564
Loss made of: CE 0.3412933051586151, LKD 2.544041633605957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=3.8344332337379456
Loss made of: CE 0.34298866987228394, LKD 3.858449935913086, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=3.552032133936882
Loss made of: CE 0.3500540256500244, LKD 3.6385269165039062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=3.494801640510559
Loss made of: CE 0.300703763961792, LKD 3.025123357772827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=3.7814789742231367
Loss made of: CE 0.3464880883693695, LKD 3.474137306213379, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=3.6862177580595015
Loss made of: CE 0.2901158034801483, LKD 2.992199420928955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=3.482587271928787
Loss made of: CE 0.28890636563301086, LKD 2.6175901889801025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=3.9199322164058685
Loss made of: CE 0.3713821768760681, LKD 3.245682954788208, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3432517647743225, Reg Loss=3.3098649978637695
Clinet index 16, End of Epoch 6/6, Average Loss=3.6531167030334473, Class Loss=0.3432517647743225, Reg Loss=3.3098649978637695
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.845259889960289
Loss made of: CE 0.5985409021377563, LKD 3.354422092437744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5564203262329102, Reg Loss=3.357260227203369
Clinet index 9, End of Epoch 1/6, Average Loss=3.9136805534362793, Class Loss=0.5564203262329102, Reg Loss=3.357260227203369
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=3.7940443754196167
Loss made of: CE 0.4723300635814667, LKD 3.308500289916992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.48854726552963257, Reg Loss=3.357921600341797
Clinet index 9, End of Epoch 2/6, Average Loss=3.846468925476074, Class Loss=0.48854726552963257, Reg Loss=3.357921600341797
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=3.817248412966728
Loss made of: CE 0.4275171160697937, LKD 2.9912381172180176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.44598931074142456, Reg Loss=3.3741536140441895
Clinet index 9, End of Epoch 3/6, Average Loss=3.820142984390259, Class Loss=0.44598931074142456, Reg Loss=3.3741536140441895
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=3.707771751284599
Loss made of: CE 0.43539485335350037, LKD 3.4516260623931885, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41550764441490173, Reg Loss=3.327810287475586
Clinet index 9, End of Epoch 4/6, Average Loss=3.7433178424835205, Class Loss=0.41550764441490173, Reg Loss=3.327810287475586
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=3.799742117524147
Loss made of: CE 0.4277454614639282, LKD 4.004156589508057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.41479068994522095, Reg Loss=3.397677183151245
Clinet index 9, End of Epoch 5/6, Average Loss=3.8124678134918213, Class Loss=0.41479068994522095, Reg Loss=3.397677183151245
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=3.733050873875618
Loss made of: CE 0.3847746253013611, LKD 3.1734564304351807, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.41709911823272705, Reg Loss=3.388594388961792
Clinet index 9, End of Epoch 6/6, Average Loss=3.8056936264038086, Class Loss=0.41709911823272705, Reg Loss=3.388594388961792
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.026225310564041
Loss made of: CE 0.4780527353286743, LKD 3.020735502243042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5658234357833862, Reg Loss=3.384899616241455
Clinet index 12, End of Epoch 1/6, Average Loss=3.950723171234131, Class Loss=0.5658234357833862, Reg Loss=3.384899616241455
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=3.6860741883516313
Loss made of: CE 0.48016220331192017, LKD 3.030341386795044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4684583842754364, Reg Loss=3.2621021270751953
Clinet index 12, End of Epoch 2/6, Average Loss=3.730560541152954, Class Loss=0.4684583842754364, Reg Loss=3.2621021270751953
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=3.6987895995378492
Loss made of: CE 0.5171703696250916, LKD 3.6386396884918213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.43121910095214844, Reg Loss=3.2612807750701904
Clinet index 12, End of Epoch 3/6, Average Loss=3.692499876022339, Class Loss=0.43121910095214844, Reg Loss=3.2612807750701904
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=3.6312743425369263
Loss made of: CE 0.4495203197002411, LKD 3.085207939147949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4128229022026062, Reg Loss=3.2584056854248047
Clinet index 12, End of Epoch 4/6, Average Loss=3.6712286472320557, Class Loss=0.4128229022026062, Reg Loss=3.2584056854248047
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=3.6616374433040617
Loss made of: CE 0.44044923782348633, LKD 3.4844114780426025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.40025752782821655, Reg Loss=3.288728713989258
Clinet index 12, End of Epoch 5/6, Average Loss=3.688986301422119, Class Loss=0.40025752782821655, Reg Loss=3.288728713989258
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=3.7629505783319472
Loss made of: CE 0.3494599759578705, LKD 3.069584608078003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.40547293424606323, Reg Loss=3.29837703704834
Clinet index 12, End of Epoch 6/6, Average Loss=3.703850030899048, Class Loss=0.40547293424606323, Reg Loss=3.29837703704834
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/12, Loss=4.046596121788025
Loss made of: CE 0.5735709071159363, LKD 3.9246222972869873, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5894888043403625, Reg Loss=3.468961238861084
Clinet index 2, End of Epoch 1/6, Average Loss=4.058450222015381, Class Loss=0.5894888043403625, Reg Loss=3.468961238861084
Pseudo labeling is: None
Epoch 2, lr = 0.000536
Epoch 2, Batch 10/12, Loss=4.018627953529358
Loss made of: CE 0.5580930709838867, LKD 3.102978229522705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5358421206474304, Reg Loss=3.4190855026245117
Clinet index 2, End of Epoch 2/6, Average Loss=3.954927682876587, Class Loss=0.5358421206474304, Reg Loss=3.4190855026245117
Pseudo labeling is: None
Epoch 3, lr = 0.000438
Epoch 3, Batch 10/12, Loss=3.942341557145119
Loss made of: CE 0.4987426996231079, LKD 3.136875867843628, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4763968586921692, Reg Loss=3.460608959197998
Clinet index 2, End of Epoch 3/6, Average Loss=3.9370057582855225, Class Loss=0.4763968586921692, Reg Loss=3.460608959197998
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/12, Loss=3.8614839375019074
Loss made of: CE 0.4576559066772461, LKD 3.7931361198425293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.45713043212890625, Reg Loss=3.481501340866089
Clinet index 2, End of Epoch 4/6, Average Loss=3.938631772994995, Class Loss=0.45713043212890625, Reg Loss=3.481501340866089
Pseudo labeling is: None
Epoch 5, lr = 0.000235
Epoch 5, Batch 10/12, Loss=3.8945069313049316
Loss made of: CE 0.5106369853019714, LKD 4.054463863372803, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4458546042442322, Reg Loss=3.380222797393799
Clinet index 2, End of Epoch 5/6, Average Loss=3.826077461242676, Class Loss=0.4458546042442322, Reg Loss=3.380222797393799
Pseudo labeling is: None
Epoch 6, lr = 0.000126
Epoch 6, Batch 10/12, Loss=3.8258558362722397
Loss made of: CE 0.38810980319976807, LKD 3.5213730335235596, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.45840582251548767, Reg Loss=3.4021012783050537
Clinet index 2, End of Epoch 6/6, Average Loss=3.860507011413574, Class Loss=0.45840582251548767, Reg Loss=3.4021012783050537
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=0.8042328953742981, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.777638
Mean Acc: 0.266758
FreqW Acc: 0.680989
Mean IoU: 0.181960
Class IoU:
	class 0: 0.8664459
	class 1: 0.050471637
	class 2: 0.0006590206
	class 3: 0.0
	class 4: 0.22429983
	class 5: 0.04422748
	class 6: 0.039728925
	class 7: 0.5439482
	class 8: 0.0
	class 9: 0.0032807062
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0002650638
	class 13: 0.11149759
	class 14: 0.21526706
	class 15: 0.7385306
	class 16: 0.2547059
Class Acc:
	class 0: 0.9663504
	class 1: 0.050474424
	class 2: 0.00065938715
	class 3: 0.0
	class 4: 0.22629131
	class 5: 0.044241346
	class 6: 0.03973776
	class 7: 0.5466503
	class 8: 0.0
	class 9: 0.0032833153
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0002697732
	class 13: 0.90483
	class 14: 0.3852575
	class 15: 0.88512206
	class 16: 0.48171318

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 25, step: 5
select part of clients to conduct local training
[24, 7, 4, 12]
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.365896272659302
Loss made of: CE 1.8370466232299805, LKD 3.6843671798706055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9530408382415771, Reg Loss=3.3555774688720703
Clinet index 24, End of Epoch 1/6, Average Loss=5.308618545532227, Class Loss=1.9530408382415771, Reg Loss=3.3555774688720703
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=4.973796463012695
Loss made of: CE 1.552573561668396, LKD 3.7172951698303223, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.4780457019805908, Reg Loss=3.354243755340576
Clinet index 24, End of Epoch 2/6, Average Loss=4.832289695739746, Class Loss=1.4780457019805908, Reg Loss=3.354243755340576
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.437740916013718
Loss made of: CE 0.9616973400115967, LKD 3.730323553085327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.0951318740844727, Reg Loss=3.282804012298584
Clinet index 24, End of Epoch 3/6, Average Loss=4.377935886383057, Class Loss=1.0951318740844727, Reg Loss=3.282804012298584
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.11876956820488
Loss made of: CE 0.8977551460266113, LKD 3.3397421836853027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.8025409579277039, Reg Loss=3.3435885906219482
Clinet index 24, End of Epoch 4/6, Average Loss=4.146129608154297, Class Loss=0.8025409579277039, Reg Loss=3.3435885906219482
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=3.948911762237549
Loss made of: CE 0.699885368347168, LKD 3.7182064056396484, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6876534223556519, Reg Loss=3.256951093673706
Clinet index 24, End of Epoch 5/6, Average Loss=3.9446043968200684, Class Loss=0.6876534223556519, Reg Loss=3.256951093673706
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=3.905249458551407
Loss made of: CE 0.5865684747695923, LKD 2.9513564109802246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6709884405136108, Reg Loss=3.296210289001465
Clinet index 24, End of Epoch 6/6, Average Loss=3.9671988487243652, Class Loss=0.6709884405136108, Reg Loss=3.296210289001465
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.4168217182159424, Reg Loss=3.8339884281158447
Clinet index 7, End of Epoch 1/6, Average Loss=5.250810146331787, Class Loss=1.4168217182159424, Reg Loss=3.8339884281158447
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.1574153900146484, Reg Loss=3.3512909412384033
Clinet index 7, End of Epoch 2/6, Average Loss=4.508706092834473, Class Loss=1.1574153900146484, Reg Loss=3.3512909412384033
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.9226589798927307, Reg Loss=3.4927985668182373
Clinet index 7, End of Epoch 3/6, Average Loss=4.415457725524902, Class Loss=0.9226589798927307, Reg Loss=3.4927985668182373
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.632264256477356, Reg Loss=3.4800941944122314
Clinet index 7, End of Epoch 4/6, Average Loss=4.112358570098877, Class Loss=0.632264256477356, Reg Loss=3.4800941944122314
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.4110771119594574, Reg Loss=3.427232503890991
Clinet index 7, End of Epoch 5/6, Average Loss=3.8383095264434814, Class Loss=0.4110771119594574, Reg Loss=3.427232503890991
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.3081636130809784, Reg Loss=3.440120220184326
Clinet index 7, End of Epoch 6/6, Average Loss=3.748283863067627, Class Loss=0.3081636130809784, Reg Loss=3.440120220184326
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.493391859531402
Loss made of: CE 1.7076468467712402, LKD 3.6431453227996826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9834656715393066, Reg Loss=3.4730563163757324
Clinet index 4, End of Epoch 1/6, Average Loss=5.456521987915039, Class Loss=1.9834656715393066, Reg Loss=3.4730563163757324
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=4.805563879013062
Loss made of: CE 1.4816198348999023, LKD 3.8923773765563965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.4762015342712402, Reg Loss=3.4373984336853027
Clinet index 4, End of Epoch 2/6, Average Loss=4.913599967956543, Class Loss=1.4762015342712402, Reg Loss=3.4373984336853027
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.4801127254962925
Loss made of: CE 0.7356668710708618, LKD 3.3802502155303955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.0838429927825928, Reg Loss=3.372093677520752
Clinet index 4, End of Epoch 3/6, Average Loss=4.455936431884766, Class Loss=1.0838429927825928, Reg Loss=3.372093677520752
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.256118625402451
Loss made of: CE 0.7175394892692566, LKD 3.2149276733398438, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.7505447864532471, Reg Loss=3.4574105739593506
Clinet index 4, End of Epoch 4/6, Average Loss=4.207955360412598, Class Loss=0.7505447864532471, Reg Loss=3.4574105739593506
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=4.158387356996537
Loss made of: CE 0.6481820344924927, LKD 3.467883825302124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6657618284225464, Reg Loss=3.3970112800598145
Clinet index 4, End of Epoch 5/6, Average Loss=4.06277322769165, Class Loss=0.6657618284225464, Reg Loss=3.3970112800598145
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=3.958267015218735
Loss made of: CE 0.582739531993866, LKD 3.489732265472412, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5979019403457642, Reg Loss=3.459481954574585
Clinet index 4, End of Epoch 6/6, Average Loss=4.057384014129639, Class Loss=0.5979019403457642, Reg Loss=3.459481954574585
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.205748081207275
Loss made of: CE 1.9061851501464844, LKD 3.416759490966797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.8540977239608765, Reg Loss=3.3920209407806396
Clinet index 12, End of Epoch 1/6, Average Loss=5.246118545532227, Class Loss=1.8540977239608765, Reg Loss=3.3920209407806396
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=4.848196673393249
Loss made of: CE 1.2903094291687012, LKD 3.1658239364624023, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.4801691770553589, Reg Loss=3.346104145050049
Clinet index 12, End of Epoch 2/6, Average Loss=4.826273441314697, Class Loss=1.4801691770553589, Reg Loss=3.346104145050049
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.363470149040222
Loss made of: CE 1.0167462825775146, LKD 3.283477544784546, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.0769150257110596, Reg Loss=3.298215866088867
Clinet index 12, End of Epoch 3/6, Average Loss=4.375130653381348, Class Loss=1.0769150257110596, Reg Loss=3.298215866088867
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.237538665533066
Loss made of: CE 0.6612721681594849, LKD 3.3289477825164795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.8322149515151978, Reg Loss=3.3472514152526855
Clinet index 12, End of Epoch 4/6, Average Loss=4.179466247558594, Class Loss=0.8322149515151978, Reg Loss=3.3472514152526855
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=3.987548691034317
Loss made of: CE 0.6320937871932983, LKD 2.8552820682525635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6936147212982178, Reg Loss=3.245877981185913
Clinet index 12, End of Epoch 5/6, Average Loss=3.939492702484131, Class Loss=0.6936147212982178, Reg Loss=3.245877981185913
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=3.9613967180252074
Loss made of: CE 0.557518482208252, LKD 2.9948782920837402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6426801681518555, Reg Loss=3.3073601722717285
Clinet index 12, End of Epoch 6/6, Average Loss=3.950040340423584, Class Loss=0.6426801681518555, Reg Loss=3.3073601722717285
federated aggregation...
Validation, Class Loss=0.8867850303649902, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.750064
Mean Acc: 0.181539
FreqW Acc: 0.638600
Mean IoU: 0.136201
Class IoU:
	class 0: 0.8317456
	class 1: 0.06792907
	class 2: 0.0024895002
	class 3: 0.0
	class 4: 0.20536746
	class 5: 0.012335634
	class 6: 0.07686654
	class 7: 0.40015677
	class 8: 0.0
	class 9: 2.5394735e-05
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.13046008
	class 14: 0.005264492
	class 15: 0.71831083
	class 16: 0.1018832
	class 17: 0.0
	class 18: 0.034987394
Class Acc:
	class 0: 0.97395915
	class 1: 0.06793001
	class 2: 0.0024942034
	class 3: 0.0
	class 4: 0.20839803
	class 5: 0.012336899
	class 6: 0.07689854
	class 7: 0.40120253
	class 8: 0.0
	class 9: 2.5394744e-05
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.6433345
	class 14: 0.0052678483
	class 15: 0.76306075
	class 16: 0.10595991
	class 17: 0.0
	class 18: 0.1883673

federated global round: 26, step: 5
select part of clients to conduct local training
[6, 28, 20, 4]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.165895879268646
Loss made of: CE 0.682127833366394, LKD 3.541576862335205, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.749194324016571, Reg Loss=3.4144535064697266
Clinet index 6, End of Epoch 1/6, Average Loss=4.163647651672363, Class Loss=0.749194324016571, Reg Loss=3.4144535064697266
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=4.155933648347855
Loss made of: CE 0.6267683506011963, LKD 2.7734079360961914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6778957843780518, Reg Loss=3.490851879119873
Clinet index 6, End of Epoch 2/6, Average Loss=4.168747901916504, Class Loss=0.6778957843780518, Reg Loss=3.490851879119873
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=3.986164790391922
Loss made of: CE 0.6174625754356384, LKD 4.006301403045654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5917164087295532, Reg Loss=3.404146194458008
Clinet index 6, End of Epoch 3/6, Average Loss=3.9958624839782715, Class Loss=0.5917164087295532, Reg Loss=3.404146194458008
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=3.9721898794174195
Loss made of: CE 0.6153314113616943, LKD 3.278522491455078, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5814312696456909, Reg Loss=3.435868978500366
Clinet index 6, End of Epoch 4/6, Average Loss=4.017300128936768, Class Loss=0.5814312696456909, Reg Loss=3.435868978500366
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=4.032992506027222
Loss made of: CE 0.6332384347915649, LKD 3.941920042037964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5565637350082397, Reg Loss=3.4163055419921875
Clinet index 6, End of Epoch 5/6, Average Loss=3.972869396209717, Class Loss=0.5565637350082397, Reg Loss=3.4163055419921875
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.8961820632219313
Loss made of: CE 0.43513792753219604, LKD 3.251586437225342, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5490012168884277, Reg Loss=3.3349881172180176
Clinet index 6, End of Epoch 6/6, Average Loss=3.8839893341064453, Class Loss=0.5490012168884277, Reg Loss=3.3349881172180176
Current Client Index:  28
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.1200037002563477, Reg Loss=3.704023838043213
Clinet index 28, End of Epoch 1/6, Average Loss=4.8240275382995605, Class Loss=1.1200037002563477, Reg Loss=3.704023838043213
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.8923402428627014, Reg Loss=3.5882179737091064
Clinet index 28, End of Epoch 2/6, Average Loss=4.480558395385742, Class Loss=0.8923402428627014, Reg Loss=3.5882179737091064
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6207247972488403, Reg Loss=3.686403512954712
Clinet index 28, End of Epoch 3/6, Average Loss=4.307128429412842, Class Loss=0.6207247972488403, Reg Loss=3.686403512954712
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.4387570321559906, Reg Loss=3.7089884281158447
Clinet index 28, End of Epoch 4/6, Average Loss=4.147745609283447, Class Loss=0.4387570321559906, Reg Loss=3.7089884281158447
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.3174377977848053, Reg Loss=3.5508129596710205
Clinet index 28, End of Epoch 5/6, Average Loss=3.868250846862793, Class Loss=0.3174377977848053, Reg Loss=3.5508129596710205
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.26522284746170044, Reg Loss=3.5458528995513916
Clinet index 28, End of Epoch 6/6, Average Loss=3.8110756874084473, Class Loss=0.26522284746170044, Reg Loss=3.5458528995513916
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.091649055480957, Reg Loss=3.5633296966552734
Clinet index 20, End of Epoch 1/6, Average Loss=4.6549787521362305, Class Loss=1.091649055480957, Reg Loss=3.5633296966552734
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.897423267364502, Reg Loss=3.493921995162964
Clinet index 20, End of Epoch 2/6, Average Loss=4.391345024108887, Class Loss=0.897423267364502, Reg Loss=3.493921995162964
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.5814478993415833, Reg Loss=3.343982219696045
Clinet index 20, End of Epoch 3/6, Average Loss=3.9254300594329834, Class Loss=0.5814478993415833, Reg Loss=3.343982219696045
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.41095441579818726, Reg Loss=3.488377571105957
Clinet index 20, End of Epoch 4/6, Average Loss=3.899332046508789, Class Loss=0.41095441579818726, Reg Loss=3.488377571105957
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.30143508315086365, Reg Loss=3.448519706726074
Clinet index 20, End of Epoch 5/6, Average Loss=3.7499547004699707, Class Loss=0.30143508315086365, Reg Loss=3.448519706726074
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.27327609062194824, Reg Loss=3.522956371307373
Clinet index 20, End of Epoch 6/6, Average Loss=3.7962324619293213, Class Loss=0.27327609062194824, Reg Loss=3.522956371307373
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=4.112357085943222
Loss made of: CE 0.7088466882705688, LKD 3.533571243286133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7535727024078369, Reg Loss=3.3591203689575195
Clinet index 4, End of Epoch 1/6, Average Loss=4.112692832946777, Class Loss=0.7535727024078369, Reg Loss=3.3591203689575195
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=3.9368595600128176
Loss made of: CE 0.7038941383361816, LKD 3.9895501136779785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6494613885879517, Reg Loss=3.414029836654663
Clinet index 4, End of Epoch 2/6, Average Loss=4.063491344451904, Class Loss=0.6494613885879517, Reg Loss=3.414029836654663
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=3.9514445424079896
Loss made of: CE 0.4623698592185974, LKD 3.3478147983551025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6189603805541992, Reg Loss=3.3461062908172607
Clinet index 4, End of Epoch 3/6, Average Loss=3.96506667137146, Class Loss=0.6189603805541992, Reg Loss=3.3461062908172607
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=3.9967205435037614
Loss made of: CE 0.5830608606338501, LKD 3.1466081142425537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5809193849563599, Reg Loss=3.384787082672119
Clinet index 4, End of Epoch 4/6, Average Loss=3.9657063484191895, Class Loss=0.5809193849563599, Reg Loss=3.384787082672119
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=4.036165869235992
Loss made of: CE 0.5746434926986694, LKD 3.3735790252685547, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5879464149475098, Reg Loss=3.384371519088745
Clinet index 4, End of Epoch 5/6, Average Loss=3.972317934036255, Class Loss=0.5879464149475098, Reg Loss=3.384371519088745
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=3.8957318484783174
Loss made of: CE 0.5617298483848572, LKD 3.436660051345825, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5574429035186768, Reg Loss=3.416980743408203
Clinet index 4, End of Epoch 6/6, Average Loss=3.97442364692688, Class Loss=0.5574429035186768, Reg Loss=3.416980743408203
federated aggregation...
Validation, Class Loss=0.8915402889251709, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.748308
Mean Acc: 0.186637
FreqW Acc: 0.642235
Mean IoU: 0.135459
Class IoU:
	class 0: 0.83713216
	class 1: 0.056704525
	class 2: 0.0012350482
	class 3: 0.0
	class 4: 0.1743042
	class 5: 0.016147047
	class 6: 0.12695949
	class 7: 0.31689894
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.13025616
	class 14: 0.0033249352
	class 15: 0.71636504
	class 16: 0.07153114
	class 17: 0.07034655
	class 18: 0.052512366
Class Acc:
	class 0: 0.9696375
	class 1: 0.056704912
	class 2: 0.0012356341
	class 3: 0.0
	class 4: 0.17597419
	class 5: 0.016150482
	class 6: 0.12702356
	class 7: 0.31750453
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.64026326
	class 14: 0.0033256498
	class 15: 0.75313145
	class 16: 0.072698645
	class 17: 0.10943293
	class 18: 0.30302486

federated global round: 27, step: 5
select part of clients to conduct local training
[24, 8, 26, 0]
Current Client Index:  24
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=4.018432146310806
Loss made of: CE 0.7388951182365417, LKD 3.51670503616333, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.704505443572998, Reg Loss=3.3074326515197754
Clinet index 24, End of Epoch 1/6, Average Loss=4.011938095092773, Class Loss=0.704505443572998, Reg Loss=3.3074326515197754
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/12, Loss=4.1313582301139835
Loss made of: CE 0.6604301929473877, LKD 3.7807047367095947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6673389673233032, Reg Loss=3.359694004058838
Clinet index 24, End of Epoch 2/6, Average Loss=4.027032852172852, Class Loss=0.6673389673233032, Reg Loss=3.359694004058838
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/12, Loss=3.9064638197422026
Loss made of: CE 0.6265002489089966, LKD 3.6000027656555176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6202781200408936, Reg Loss=3.2396247386932373
Clinet index 24, End of Epoch 3/6, Average Loss=3.859902858734131, Class Loss=0.6202781200408936, Reg Loss=3.2396247386932373
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/12, Loss=3.886440187692642
Loss made of: CE 0.5915650725364685, LKD 3.38202166557312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5953562259674072, Reg Loss=3.316817283630371
Clinet index 24, End of Epoch 4/6, Average Loss=3.9121735095977783, Class Loss=0.5953562259674072, Reg Loss=3.316817283630371
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/12, Loss=3.755416938662529
Loss made of: CE 0.6017909049987793, LKD 3.730180025100708, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5801572203636169, Reg Loss=3.18229079246521
Clinet index 24, End of Epoch 5/6, Average Loss=3.7624480724334717, Class Loss=0.5801572203636169, Reg Loss=3.18229079246521
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/12, Loss=3.8327207922935487
Loss made of: CE 0.5194901823997498, LKD 2.93300199508667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5968202352523804, Reg Loss=3.2663793563842773
Clinet index 24, End of Epoch 6/6, Average Loss=3.8631997108459473, Class Loss=0.5968202352523804, Reg Loss=3.2663793563842773
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5615209341049194, Reg Loss=3.302429676055908
Clinet index 8, End of Epoch 1/6, Average Loss=3.863950729370117, Class Loss=0.5615209341049194, Reg Loss=3.302429676055908
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.47191518545150757, Reg Loss=3.3625006675720215
Clinet index 8, End of Epoch 2/6, Average Loss=3.834415912628174, Class Loss=0.47191518545150757, Reg Loss=3.3625006675720215
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.3557657301425934, Reg Loss=3.3454158306121826
Clinet index 8, End of Epoch 3/6, Average Loss=3.701181650161743, Class Loss=0.3557657301425934, Reg Loss=3.3454158306121826
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.2960096597671509, Reg Loss=3.255774974822998
Clinet index 8, End of Epoch 4/6, Average Loss=3.5517845153808594, Class Loss=0.2960096597671509, Reg Loss=3.255774974822998
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.2675873935222626, Reg Loss=3.2834980487823486
Clinet index 8, End of Epoch 5/6, Average Loss=3.5510854721069336, Class Loss=0.2675873935222626, Reg Loss=3.2834980487823486
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.24950268864631653, Reg Loss=3.3564140796661377
Clinet index 8, End of Epoch 6/6, Average Loss=3.605916738510132, Class Loss=0.24950268864631653, Reg Loss=3.3564140796661377
Current Client Index:  26
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.867950028181076
Loss made of: CE 0.6774298548698425, LKD 3.3332831859588623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6763443946838379, Reg Loss=3.232025146484375
Clinet index 26, End of Epoch 1/6, Average Loss=3.908369541168213, Class Loss=0.6763443946838379, Reg Loss=3.232025146484375
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=3.9345037937164307
Loss made of: CE 0.571947455406189, LKD 3.39627742767334, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.625937283039093, Reg Loss=3.209550619125366
Clinet index 26, End of Epoch 2/6, Average Loss=3.8354878425598145, Class Loss=0.625937283039093, Reg Loss=3.209550619125366
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=3.899133491516113
Loss made of: CE 0.5867286324501038, LKD 2.613525629043579, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5780695676803589, Reg Loss=3.312204122543335
Clinet index 26, End of Epoch 3/6, Average Loss=3.8902735710144043, Class Loss=0.5780695676803589, Reg Loss=3.312204122543335
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=3.8809747815132143
Loss made of: CE 0.5362655520439148, LKD 3.1256978511810303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5665171146392822, Reg Loss=3.2767419815063477
Clinet index 26, End of Epoch 4/6, Average Loss=3.84325909614563, Class Loss=0.5665171146392822, Reg Loss=3.2767419815063477
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=3.786561277508736
Loss made of: CE 0.48907017707824707, LKD 3.016493082046509, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5419190526008606, Reg Loss=3.272961139678955
Clinet index 26, End of Epoch 5/6, Average Loss=3.814880132675171, Class Loss=0.5419190526008606, Reg Loss=3.272961139678955
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=3.822196567058563
Loss made of: CE 0.45248836278915405, LKD 2.8187108039855957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5588927268981934, Reg Loss=3.236910581588745
Clinet index 26, End of Epoch 6/6, Average Loss=3.7958033084869385, Class Loss=0.5588927268981934, Reg Loss=3.236910581588745
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.106189805269241
Loss made of: CE 0.6973905563354492, LKD 3.1783647537231445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.714256763458252, Reg Loss=3.387155055999756
Clinet index 0, End of Epoch 1/6, Average Loss=4.101411819458008, Class Loss=0.714256763458252, Reg Loss=3.387155055999756
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=4.029919850826263
Loss made of: CE 0.5523068308830261, LKD 3.424638509750366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6342648267745972, Reg Loss=3.4021811485290527
Clinet index 0, End of Epoch 2/6, Average Loss=4.0364460945129395, Class Loss=0.6342648267745972, Reg Loss=3.4021811485290527
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=3.9082482933998106
Loss made of: CE 0.48331189155578613, LKD 2.741114377975464, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5881537795066833, Reg Loss=3.346409320831299
Clinet index 0, End of Epoch 3/6, Average Loss=3.934563159942627, Class Loss=0.5881537795066833, Reg Loss=3.346409320831299
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=3.9213764488697054
Loss made of: CE 0.5979945659637451, LKD 3.250974416732788, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5732612609863281, Reg Loss=3.344294309616089
Clinet index 0, End of Epoch 4/6, Average Loss=3.917555570602417, Class Loss=0.5732612609863281, Reg Loss=3.344294309616089
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=3.8492744505405425
Loss made of: CE 0.521518349647522, LKD 3.2840218544006348, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.573401927947998, Reg Loss=3.3193359375
Clinet index 0, End of Epoch 5/6, Average Loss=3.892737865447998, Class Loss=0.573401927947998, Reg Loss=3.3193359375
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=3.8843145668506622
Loss made of: CE 0.47714686393737793, LKD 3.0943081378936768, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5445534586906433, Reg Loss=3.3704352378845215
Clinet index 0, End of Epoch 6/6, Average Loss=3.9149887561798096, Class Loss=0.5445534586906433, Reg Loss=3.3704352378845215
federated aggregation...
Validation, Class Loss=0.9603195190429688, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.730760
Mean Acc: 0.183526
FreqW Acc: 0.644165
Mean IoU: 0.122293
Class IoU:
	class 0: 0.84332204
	class 1: 0.011321249
	class 2: 0.0
	class 3: 0.0
	class 4: 0.124474496
	class 5: 0.00088490243
	class 6: 0.103606254
	class 7: 0.15749747
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.12815335
	class 14: 0.00057229283
	class 15: 0.7456033
	class 16: 0.045691524
	class 17: 0.09449644
	class 18: 0.06793529
Class Acc:
	class 0: 0.9421476
	class 1: 0.011321259
	class 2: 0.0
	class 3: 0.0
	class 4: 0.12533669
	class 5: 0.0008849215
	class 6: 0.103672855
	class 7: 0.15761685
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.5392287
	class 14: 0.0005723805
	class 15: 0.7855394
	class 16: 0.045788914
	class 17: 0.14070885
	class 18: 0.6341667

federated global round: 28, step: 5
select part of clients to conduct local training
[8, 9, 16, 3]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.6366814374923706, Reg Loss=3.368269443511963
Clinet index 8, End of Epoch 1/6, Average Loss=4.004951000213623, Class Loss=0.6366814374923706, Reg Loss=3.368269443511963
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.5390938520431519, Reg Loss=3.369504690170288
Clinet index 8, End of Epoch 2/6, Average Loss=3.9085984230041504, Class Loss=0.5390938520431519, Reg Loss=3.369504690170288
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.4384835660457611, Reg Loss=3.440852165222168
Clinet index 8, End of Epoch 3/6, Average Loss=3.879335641860962, Class Loss=0.4384835660457611, Reg Loss=3.440852165222168
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.3687833845615387, Reg Loss=3.4151809215545654
Clinet index 8, End of Epoch 4/6, Average Loss=3.7839643955230713, Class Loss=0.3687833845615387, Reg Loss=3.4151809215545654
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.3137877583503723, Reg Loss=3.289761543273926
Clinet index 8, End of Epoch 5/6, Average Loss=3.6035492420196533, Class Loss=0.3137877583503723, Reg Loss=3.289761543273926
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.3014410138130188, Reg Loss=3.3489670753479004
Clinet index 8, End of Epoch 6/6, Average Loss=3.6504080295562744, Class Loss=0.3014410138130188, Reg Loss=3.3489670753479004
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6463919878005981, Reg Loss=3.5258147716522217
Clinet index 9, End of Epoch 1/6, Average Loss=4.172206878662109, Class Loss=0.6463919878005981, Reg Loss=3.5258147716522217
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5022974014282227, Reg Loss=3.5456247329711914
Clinet index 9, End of Epoch 2/6, Average Loss=4.047922134399414, Class Loss=0.5022974014282227, Reg Loss=3.5456247329711914
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.3610180616378784, Reg Loss=3.5071442127227783
Clinet index 9, End of Epoch 3/6, Average Loss=3.868162155151367, Class Loss=0.3610180616378784, Reg Loss=3.5071442127227783
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.29585930705070496, Reg Loss=3.469672441482544
Clinet index 9, End of Epoch 4/6, Average Loss=3.7655317783355713, Class Loss=0.29585930705070496, Reg Loss=3.469672441482544
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.253133624792099, Reg Loss=3.4055416584014893
Clinet index 9, End of Epoch 5/6, Average Loss=3.658675193786621, Class Loss=0.253133624792099, Reg Loss=3.4055416584014893
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.2671090066432953, Reg Loss=3.451308012008667
Clinet index 9, End of Epoch 6/6, Average Loss=3.718416929244995, Class Loss=0.2671090066432953, Reg Loss=3.451308012008667
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.8526242077350616
Loss made of: CE 0.5937186479568481, LKD 2.796570301055908, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6149395108222961, Reg Loss=3.232346296310425
Clinet index 16, End of Epoch 1/6, Average Loss=3.847285747528076, Class Loss=0.6149395108222961, Reg Loss=3.232346296310425
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=3.7848989367485046
Loss made of: CE 0.5501575469970703, LKD 2.9527788162231445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5900264978408813, Reg Loss=3.184257984161377
Clinet index 16, End of Epoch 2/6, Average Loss=3.7742843627929688, Class Loss=0.5900264978408813, Reg Loss=3.184257984161377
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=3.762945705652237
Loss made of: CE 0.5585780143737793, LKD 3.086261749267578, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5385249853134155, Reg Loss=3.249293804168701
Clinet index 16, End of Epoch 3/6, Average Loss=3.7878189086914062, Class Loss=0.5385249853134155, Reg Loss=3.249293804168701
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=3.7529977679252626
Loss made of: CE 0.5483199954032898, LKD 3.0572586059570312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5737844705581665, Reg Loss=3.219696521759033
Clinet index 16, End of Epoch 4/6, Average Loss=3.79348087310791, Class Loss=0.5737844705581665, Reg Loss=3.219696521759033
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=3.747137960791588
Loss made of: CE 0.500529408454895, LKD 3.078524112701416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5391245484352112, Reg Loss=3.1815781593322754
Clinet index 16, End of Epoch 5/6, Average Loss=3.720702648162842, Class Loss=0.5391245484352112, Reg Loss=3.1815781593322754
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=3.7642573326826096
Loss made of: CE 0.527432918548584, LKD 3.4736781120300293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.533835768699646, Reg Loss=3.232372760772705
Clinet index 16, End of Epoch 6/6, Average Loss=3.7662086486816406, Class Loss=0.533835768699646, Reg Loss=3.232372760772705
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.8436311423778533
Loss made of: CE 0.5759103298187256, LKD 3.472121000289917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5809357762336731, Reg Loss=3.2496232986450195
Clinet index 3, End of Epoch 1/6, Average Loss=3.830559015274048, Class Loss=0.5809357762336731, Reg Loss=3.2496232986450195
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=3.748753494024277
Loss made of: CE 0.5159764885902405, LKD 3.4292142391204834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5480623245239258, Reg Loss=3.2161431312561035
Clinet index 3, End of Epoch 2/6, Average Loss=3.7642054557800293, Class Loss=0.5480623245239258, Reg Loss=3.2161431312561035
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=3.7844986021518707
Loss made of: CE 0.544710636138916, LKD 3.810534715652466, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.542576253414154, Reg Loss=3.2694201469421387
Clinet index 3, End of Epoch 3/6, Average Loss=3.8119964599609375, Class Loss=0.542576253414154, Reg Loss=3.2694201469421387
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=3.900632506608963
Loss made of: CE 0.5105612277984619, LKD 3.1982502937316895, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5239392518997192, Reg Loss=3.2915549278259277
Clinet index 3, End of Epoch 4/6, Average Loss=3.8154940605163574, Class Loss=0.5239392518997192, Reg Loss=3.2915549278259277
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=3.792914927005768
Loss made of: CE 0.4800252914428711, LKD 2.4872403144836426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.513858437538147, Reg Loss=3.266977071762085
Clinet index 3, End of Epoch 5/6, Average Loss=3.7808356285095215, Class Loss=0.513858437538147, Reg Loss=3.266977071762085
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=3.7985929578542708
Loss made of: CE 0.5477882623672485, LKD 3.1762607097625732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5247257947921753, Reg Loss=3.3097667694091797
Clinet index 3, End of Epoch 6/6, Average Loss=3.8344926834106445, Class Loss=0.5247257947921753, Reg Loss=3.3097667694091797
federated aggregation...
Validation, Class Loss=0.9508828520774841, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.740330
Mean Acc: 0.193399
FreqW Acc: 0.644228
Mean IoU: 0.120439
Class IoU:
	class 0: 0.84516937
	class 1: 0.020354046
	class 2: 0.0
	class 3: 0.0
	class 4: 0.112831466
	class 5: 0.0069433036
	class 6: 0.090942495
	class 7: 0.17794868
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.05113102
	class 14: 0.0052384734
	class 15: 0.73101526
	class 16: 0.046369415
	class 17: 0.09305645
	class 18: 0.1073459
Class Acc:
	class 0: 0.95843196
	class 1: 0.020354062
	class 2: 0.0
	class 3: 0.0
	class 4: 0.11333826
	class 5: 0.006944048
	class 6: 0.09099902
	class 7: 0.17806396
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.12631148
	class 14: 0.005239716
	class 15: 0.76681614
	class 16: 0.046667922
	class 17: 0.8288018
	class 18: 0.5326174

federated global round: 29, step: 5
select part of clients to conduct local training
[29, 27, 26, 18]
Current Client Index:  29
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.8499765753746034
Loss made of: CE 0.5337508916854858, LKD 2.9298975467681885, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6208062171936035, Reg Loss=3.200793743133545
Clinet index 29, End of Epoch 1/6, Average Loss=3.8215999603271484, Class Loss=0.6208062171936035, Reg Loss=3.200793743133545
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=3.794511166214943
Loss made of: CE 0.5221953392028809, LKD 3.191225290298462, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5502721071243286, Reg Loss=3.2212207317352295
Clinet index 29, End of Epoch 2/6, Average Loss=3.7714929580688477, Class Loss=0.5502721071243286, Reg Loss=3.2212207317352295
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=3.6672123849391935
Loss made of: CE 0.4580764174461365, LKD 3.0139784812927246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5457561016082764, Reg Loss=3.1935572624206543
Clinet index 29, End of Epoch 3/6, Average Loss=3.7393133640289307, Class Loss=0.5457561016082764, Reg Loss=3.1935572624206543
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=3.731920671463013
Loss made of: CE 0.5373824238777161, LKD 3.441312789916992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5251633524894714, Reg Loss=3.163768768310547
Clinet index 29, End of Epoch 4/6, Average Loss=3.688932180404663, Class Loss=0.5251633524894714, Reg Loss=3.163768768310547
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=3.770048904418945
Loss made of: CE 0.4815391004085541, LKD 3.360067367553711, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5137799978256226, Reg Loss=3.172635555267334
Clinet index 29, End of Epoch 5/6, Average Loss=3.686415672302246, Class Loss=0.5137799978256226, Reg Loss=3.172635555267334
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=3.838256275653839
Loss made of: CE 0.5409852862358093, LKD 3.4978785514831543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5169349908828735, Reg Loss=3.212036609649658
Clinet index 29, End of Epoch 6/6, Average Loss=3.728971481323242, Class Loss=0.5169349908828735, Reg Loss=3.212036609649658
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.47732433676719666, Reg Loss=3.6660327911376953
Clinet index 27, End of Epoch 1/6, Average Loss=4.143357276916504, Class Loss=0.47732433676719666, Reg Loss=3.6660327911376953
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.3887422978878021, Reg Loss=3.643059492111206
Clinet index 27, End of Epoch 2/6, Average Loss=4.031801700592041, Class Loss=0.3887422978878021, Reg Loss=3.643059492111206
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.31213364005088806, Reg Loss=3.480461597442627
Clinet index 27, End of Epoch 3/6, Average Loss=3.792595148086548, Class Loss=0.31213364005088806, Reg Loss=3.480461597442627
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.2889808118343353, Reg Loss=3.6157655715942383
Clinet index 27, End of Epoch 4/6, Average Loss=3.9047462940216064, Class Loss=0.2889808118343353, Reg Loss=3.6157655715942383
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.28529947996139526, Reg Loss=3.559622049331665
Clinet index 27, End of Epoch 5/6, Average Loss=3.844921588897705, Class Loss=0.28529947996139526, Reg Loss=3.559622049331665
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.2666126489639282, Reg Loss=3.5298798084259033
Clinet index 27, End of Epoch 6/6, Average Loss=3.796492576599121, Class Loss=0.2666126489639282, Reg Loss=3.5298798084259033
Current Client Index:  26
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/12, Loss=3.8465825498104094
Loss made of: CE 0.6095442771911621, LKD 3.2441489696502686, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6129604578018188, Reg Loss=3.277773857116699
Clinet index 26, End of Epoch 1/6, Average Loss=3.8907341957092285, Class Loss=0.6129604578018188, Reg Loss=3.277773857116699
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/12, Loss=3.9808044612407683
Loss made of: CE 0.5628198385238647, LKD 3.4128925800323486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6056784987449646, Reg Loss=3.2733941078186035
Clinet index 26, End of Epoch 2/6, Average Loss=3.879072666168213, Class Loss=0.6056784987449646, Reg Loss=3.2733941078186035
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/12, Loss=3.774673244357109
Loss made of: CE 0.5186668038368225, LKD 2.563945770263672, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5469058156013489, Reg Loss=3.233924388885498
Clinet index 26, End of Epoch 3/6, Average Loss=3.780830144882202, Class Loss=0.5469058156013489, Reg Loss=3.233924388885498
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/12, Loss=3.8622313290834427
Loss made of: CE 0.5396711826324463, LKD 3.120270013809204, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5400228500366211, Reg Loss=3.288416624069214
Clinet index 26, End of Epoch 4/6, Average Loss=3.828439474105835, Class Loss=0.5400228500366211, Reg Loss=3.288416624069214
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/12, Loss=3.7247538924217225
Loss made of: CE 0.5089609622955322, LKD 2.895200729370117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5411224365234375, Reg Loss=3.1944632530212402
Clinet index 26, End of Epoch 5/6, Average Loss=3.7355856895446777, Class Loss=0.5411224365234375, Reg Loss=3.1944632530212402
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/12, Loss=3.847840866446495
Loss made of: CE 0.40916070342063904, LKD 2.6938300132751465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5334176421165466, Reg Loss=3.2966535091400146
Clinet index 26, End of Epoch 6/6, Average Loss=3.830071210861206, Class Loss=0.5334176421165466, Reg Loss=3.2966535091400146
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=3.9562371879816056
Loss made of: CE 0.5618627667427063, LKD 3.1132688522338867, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.635291337966919, Reg Loss=3.3080947399139404
Clinet index 18, End of Epoch 1/6, Average Loss=3.9433860778808594, Class Loss=0.635291337966919, Reg Loss=3.3080947399139404
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=3.8303756713867188
Loss made of: CE 0.54227614402771, LKD 2.943450689315796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5808150172233582, Reg Loss=3.230410099029541
Clinet index 18, End of Epoch 2/6, Average Loss=3.811225175857544, Class Loss=0.5808150172233582, Reg Loss=3.230410099029541
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=3.818528491258621
Loss made of: CE 0.5428494215011597, LKD 2.8062891960144043, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5591140389442444, Reg Loss=3.2419018745422363
Clinet index 18, End of Epoch 3/6, Average Loss=3.801015853881836, Class Loss=0.5591140389442444, Reg Loss=3.2419018745422363
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=3.8471010327339172
Loss made of: CE 0.5469728708267212, LKD 3.4882359504699707, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5418185591697693, Reg Loss=3.259385585784912
Clinet index 18, End of Epoch 4/6, Average Loss=3.801204204559326, Class Loss=0.5418185591697693, Reg Loss=3.259385585784912
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=3.7858901262283324
Loss made of: CE 0.5234516263008118, LKD 3.1077733039855957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5205457806587219, Reg Loss=3.341836452484131
Clinet index 18, End of Epoch 5/6, Average Loss=3.862382173538208, Class Loss=0.5205457806587219, Reg Loss=3.341836452484131
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=3.7640276163816453
Loss made of: CE 0.5217609405517578, LKD 2.742044448852539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5361282229423523, Reg Loss=3.262455463409424
Clinet index 18, End of Epoch 6/6, Average Loss=3.798583745956421, Class Loss=0.5361282229423523, Reg Loss=3.262455463409424
federated aggregation...
Validation, Class Loss=0.9860680103302002, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.728316
Mean Acc: 0.196561
FreqW Acc: 0.641989
Mean IoU: 0.117566
Class IoU:
	class 0: 0.84277695
	class 1: 0.013211399
	class 2: 0.0
	class 3: 0.0
	class 4: 0.10289965
	class 5: 0.0011862362
	class 6: 0.07410925
	class 7: 0.12248826
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0780561
	class 14: 0.0020772428
	class 15: 0.742041
	class 16: 0.047624253
	class 17: 0.11594253
	class 18: 0.09133426
Class Acc:
	class 0: 0.93761015
	class 1: 0.013211413
	class 2: 0.0
	class 3: 0.0
	class 4: 0.103514746
	class 5: 0.0011862972
	class 6: 0.07415682
	class 7: 0.1225454
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.25078985
	class 14: 0.0020776654
	class 15: 0.7786514
	class 16: 0.04775622
	class 17: 0.6878118
	class 18: 0.7153464

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 30, step: 6
select part of clients to conduct local training
[10, 30, 4, 33]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.939872932434082
Loss made of: CE 2.2205541133880615, LKD 4.603268146514893, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9996240139007568, Reg Loss=4.018583297729492
Clinet index 10, End of Epoch 1/6, Average Loss=6.018207550048828, Class Loss=1.9996240139007568, Reg Loss=4.018583297729492
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=5.24409943819046
Loss made of: CE 1.608786940574646, LKD 4.407284736633301, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3394989967346191, Reg Loss=3.8730154037475586
Clinet index 10, End of Epoch 2/6, Average Loss=5.212514400482178, Class Loss=1.3394989967346191, Reg Loss=3.8730154037475586
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.559104704856873
Loss made of: CE 0.7444314360618591, LKD 4.290900230407715, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7391390204429626, Reg Loss=3.7694883346557617
Clinet index 10, End of Epoch 3/6, Average Loss=4.508627414703369, Class Loss=0.7391390204429626, Reg Loss=3.7694883346557617
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.168092262744904
Loss made of: CE 0.29306966066360474, LKD 3.5623133182525635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4293420910835266, Reg Loss=3.684159994125366
Clinet index 10, End of Epoch 4/6, Average Loss=4.113502025604248, Class Loss=0.4293420910835266, Reg Loss=3.684159994125366
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=3.967910294234753
Loss made of: CE 0.24590973556041718, LKD 3.7417807579040527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29411569237709045, Reg Loss=3.790668249130249
Clinet index 10, End of Epoch 5/6, Average Loss=4.084784030914307, Class Loss=0.29411569237709045, Reg Loss=3.790668249130249
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=4.002958914637565
Loss made of: CE 0.2652924954891205, LKD 3.04264760017395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26889681816101074, Reg Loss=3.7221479415893555
Clinet index 10, End of Epoch 6/6, Average Loss=3.991044759750366, Class Loss=0.26889681816101074, Reg Loss=3.7221479415893555
Current Client Index:  30
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=5.114959454536438
Loss made of: CE 1.2292693853378296, LKD 3.542268991470337, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.3426284790039062, Reg Loss=3.66473126411438
Clinet index 30, End of Epoch 1/6, Average Loss=5.007359504699707, Class Loss=1.3426284790039062, Reg Loss=3.66473126411438
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=4.682839494943619
Loss made of: CE 0.9902886152267456, LKD 3.162804126739502, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.110824704170227, Reg Loss=3.583265781402588
Clinet index 30, End of Epoch 2/6, Average Loss=4.694090366363525, Class Loss=1.110824704170227, Reg Loss=3.583265781402588
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=4.464299064874649
Loss made of: CE 0.7641704082489014, LKD 4.071027755737305, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.9167965054512024, Reg Loss=3.5381388664245605
Clinet index 30, End of Epoch 3/6, Average Loss=4.454935550689697, Class Loss=0.9167965054512024, Reg Loss=3.5381388664245605
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=4.235907047986984
Loss made of: CE 0.839791476726532, LKD 3.532072067260742, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.7564378380775452, Reg Loss=3.5041615962982178
Clinet index 30, End of Epoch 4/6, Average Loss=4.260599613189697, Class Loss=0.7564378380775452, Reg Loss=3.5041615962982178
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=4.146235445141793
Loss made of: CE 0.7170214653015137, LKD 3.2922520637512207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6355707049369812, Reg Loss=3.451944589614868
Clinet index 30, End of Epoch 5/6, Average Loss=4.087515354156494, Class Loss=0.6355707049369812, Reg Loss=3.451944589614868
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=4.1089609384536745
Loss made of: CE 0.6589252948760986, LKD 3.97080659866333, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5657278299331665, Reg Loss=3.519501209259033
Clinet index 30, End of Epoch 6/6, Average Loss=4.08522891998291, Class Loss=0.5657278299331665, Reg Loss=3.519501209259033
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.980883800983429
Loss made of: CE 2.181473731994629, LKD 3.833933115005493, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.952620506286621, Reg Loss=3.9523751735687256
Clinet index 4, End of Epoch 1/6, Average Loss=5.904995918273926, Class Loss=1.952620506286621, Reg Loss=3.9523751735687256
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=4.944432038068771
Loss made of: CE 1.1045483350753784, LKD 3.569761276245117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.286177396774292, Reg Loss=3.77132511138916
Clinet index 4, End of Epoch 2/6, Average Loss=5.057502746582031, Class Loss=1.286177396774292, Reg Loss=3.77132511138916
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.404301089048386
Loss made of: CE 0.8416355848312378, LKD 3.9752020835876465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7496213316917419, Reg Loss=3.6994521617889404
Clinet index 4, End of Epoch 3/6, Average Loss=4.449073314666748, Class Loss=0.7496213316917419, Reg Loss=3.6994521617889404
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.183209580183029
Loss made of: CE 0.34834927320480347, LKD 3.616401195526123, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.42987677454948425, Reg Loss=3.674654483795166
Clinet index 4, End of Epoch 4/6, Average Loss=4.104531288146973, Class Loss=0.42987677454948425, Reg Loss=3.674654483795166
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=3.7557589203119277
Loss made of: CE 0.2791668772697449, LKD 3.396426200866699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3014066815376282, Reg Loss=3.580509662628174
Clinet index 4, End of Epoch 5/6, Average Loss=3.8819162845611572, Class Loss=0.3014066815376282, Reg Loss=3.580509662628174
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=3.941337266564369
Loss made of: CE 0.25812074542045593, LKD 2.879167079925537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2744580805301666, Reg Loss=3.617804527282715
Clinet index 4, End of Epoch 6/6, Average Loss=3.8922626972198486, Class Loss=0.2744580805301666, Reg Loss=3.617804527282715
Current Client Index:  33
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=5.970186233520508
Loss made of: CE 1.6718711853027344, LKD 3.4778037071228027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9538238048553467, Reg Loss=3.9427332878112793
Clinet index 33, End of Epoch 1/6, Average Loss=5.896556854248047, Class Loss=1.9538238048553467, Reg Loss=3.9427332878112793
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=5.078946673870087
Loss made of: CE 1.1910966634750366, LKD 3.7434632778167725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2979246377944946, Reg Loss=3.7602975368499756
Clinet index 33, End of Epoch 2/6, Average Loss=5.05822229385376, Class Loss=1.2979246377944946, Reg Loss=3.7602975368499756
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=4.402350068092346
Loss made of: CE 0.5983321666717529, LKD 3.812610387802124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7257328033447266, Reg Loss=3.679744243621826
Clinet index 33, End of Epoch 3/6, Average Loss=4.405477046966553, Class Loss=0.7257328033447266, Reg Loss=3.679744243621826
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=4.006235873699188
Loss made of: CE 0.28610944747924805, LKD 3.843087673187256, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.416997492313385, Reg Loss=3.639875888824463
Clinet index 33, End of Epoch 4/6, Average Loss=4.056873321533203, Class Loss=0.416997492313385, Reg Loss=3.639875888824463
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=3.9435169488191604
Loss made of: CE 0.33130985498428345, LKD 3.8102872371673584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3014015555381775, Reg Loss=3.653280735015869
Clinet index 33, End of Epoch 5/6, Average Loss=3.9546823501586914, Class Loss=0.3014015555381775, Reg Loss=3.653280735015869
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=3.8586465924978257
Loss made of: CE 0.24442842602729797, LKD 3.8114466667175293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2491348683834076, Reg Loss=3.6177337169647217
Clinet index 33, End of Epoch 6/6, Average Loss=3.866868495941162, Class Loss=0.2491348683834076, Reg Loss=3.6177337169647217
federated aggregation...
Validation, Class Loss=1.1883423328399658, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.705004
Mean Acc: 0.108317
FreqW Acc: 0.613714
Mean IoU: 0.073965
Class IoU:
	class 0: 0.84441584
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.047962885
	class 5: 0.0
	class 6: 0.00015211331
	class 7: 0.034971904
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.50888276
	class 16: 0.006613621
	class 17: 8.24479e-05
	class 18: 0.051747154
	class 19: 0.058429778
	class 20: 0.0
Class Acc:
	class 0: 0.9598547
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.048097033
	class 5: 0.0
	class 6: 0.00015211331
	class 7: 0.034972195
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.5146828
	class 16: 0.006615851
	class 17: 8.248093e-05
	class 18: 0.061246753
	class 19: 0.64894307
	class 20: 0.0

federated global round: 31, step: 6
select part of clients to conduct local training
[9, 17, 14, 1]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.85575784444809
Loss made of: CE 1.3604238033294678, LKD 3.3759396076202393, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.1523312330245972, Reg Loss=3.5374927520751953
Clinet index 9, End of Epoch 1/6, Average Loss=4.689824104309082, Class Loss=1.1523312330245972, Reg Loss=3.5374927520751953
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=4.519546222686768
Loss made of: CE 0.7330626249313354, LKD 3.178617000579834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9848373532295227, Reg Loss=3.4691174030303955
Clinet index 9, End of Epoch 2/6, Average Loss=4.453954696655273, Class Loss=0.9848373532295227, Reg Loss=3.4691174030303955
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=4.312568968534469
Loss made of: CE 0.7165908813476562, LKD 3.3838601112365723, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7580995559692383, Reg Loss=3.448058605194092
Clinet index 9, End of Epoch 3/6, Average Loss=4.20615816116333, Class Loss=0.7580995559692383, Reg Loss=3.448058605194092
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=4.146982455253601
Loss made of: CE 0.6373910903930664, LKD 4.10628080368042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6245151162147522, Reg Loss=3.4908454418182373
Clinet index 9, End of Epoch 4/6, Average Loss=4.115360736846924, Class Loss=0.6245151162147522, Reg Loss=3.4908454418182373
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=4.036746156215668
Loss made of: CE 0.4870186746120453, LKD 3.260218620300293, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5592091679573059, Reg Loss=3.5132391452789307
Clinet index 9, End of Epoch 5/6, Average Loss=4.072448253631592, Class Loss=0.5592091679573059, Reg Loss=3.5132391452789307
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=4.160763311386108
Loss made of: CE 0.4836192727088928, LKD 3.3138554096221924, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5279873609542847, Reg Loss=3.5018601417541504
Clinet index 9, End of Epoch 6/6, Average Loss=4.029847621917725, Class Loss=0.5279873609542847, Reg Loss=3.5018601417541504
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.0671869844198225
Loss made of: CE 0.2925294041633606, LKD 3.1031763553619385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3944002389907837, Reg Loss=3.6894357204437256
Clinet index 17, End of Epoch 1/6, Average Loss=4.083836078643799, Class Loss=0.3944002389907837, Reg Loss=3.6894357204437256
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=3.858676891028881
Loss made of: CE 0.21864013373851776, LKD 3.645939350128174, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2993605136871338, Reg Loss=3.6507577896118164
Clinet index 17, End of Epoch 2/6, Average Loss=3.95011830329895, Class Loss=0.2993605136871338, Reg Loss=3.6507577896118164
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=3.90419180393219
Loss made of: CE 0.2866854667663574, LKD 4.297457218170166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26503464579582214, Reg Loss=3.6531589031219482
Clinet index 17, End of Epoch 3/6, Average Loss=3.9181935787200928, Class Loss=0.26503464579582214, Reg Loss=3.6531589031219482
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=3.9185981497168543
Loss made of: CE 0.236541748046875, LKD 3.5383529663085938, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24159568548202515, Reg Loss=3.69138240814209
Clinet index 17, End of Epoch 4/6, Average Loss=3.9329781532287598, Class Loss=0.24159568548202515, Reg Loss=3.69138240814209
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=3.8304485753178596
Loss made of: CE 0.2513379454612732, LKD 3.950652599334717, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23851244151592255, Reg Loss=3.6870670318603516
Clinet index 17, End of Epoch 5/6, Average Loss=3.92557954788208, Class Loss=0.23851244151592255, Reg Loss=3.6870670318603516
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.8650817200541496
Loss made of: CE 0.20339253544807434, LKD 4.109401226043701, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22937297821044922, Reg Loss=3.644211530685425
Clinet index 17, End of Epoch 6/6, Average Loss=3.873584508895874, Class Loss=0.22937297821044922, Reg Loss=3.644211530685425
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.6347911894321445
Loss made of: CE 1.2893460988998413, LKD 3.3946075439453125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.124312400817871, Reg Loss=3.453017234802246
Clinet index 14, End of Epoch 1/6, Average Loss=4.577329635620117, Class Loss=1.124312400817871, Reg Loss=3.453017234802246
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=4.423585206270218
Loss made of: CE 0.6951349973678589, LKD 3.1061336994171143, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9419429302215576, Reg Loss=3.4798004627227783
Clinet index 14, End of Epoch 2/6, Average Loss=4.421743392944336, Class Loss=0.9419429302215576, Reg Loss=3.4798004627227783
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=4.209561932086944
Loss made of: CE 0.5754576921463013, LKD 3.4717679023742676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7641475796699524, Reg Loss=3.4385764598846436
Clinet index 14, End of Epoch 3/6, Average Loss=4.202723979949951, Class Loss=0.7641475796699524, Reg Loss=3.4385764598846436
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=4.031958281993866
Loss made of: CE 0.5017197132110596, LKD 3.320124626159668, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6398641467094421, Reg Loss=3.387561559677124
Clinet index 14, End of Epoch 4/6, Average Loss=4.027425765991211, Class Loss=0.6398641467094421, Reg Loss=3.387561559677124
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=4.034705418348312
Loss made of: CE 0.4903373718261719, LKD 3.284507989883423, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5608835220336914, Reg Loss=3.4629104137420654
Clinet index 14, End of Epoch 5/6, Average Loss=4.023794174194336, Class Loss=0.5608835220336914, Reg Loss=3.4629104137420654
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=3.9251344203948975
Loss made of: CE 0.5720400214195251, LKD 3.4891855716705322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5330147743225098, Reg Loss=3.4252352714538574
Clinet index 14, End of Epoch 6/6, Average Loss=3.958250045776367, Class Loss=0.5330147743225098, Reg Loss=3.4252352714538574
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.0751639902591705
Loss made of: CE 0.32941409945487976, LKD 3.1816468238830566, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39701637625694275, Reg Loss=3.682342529296875
Clinet index 1, End of Epoch 1/6, Average Loss=4.07935905456543, Class Loss=0.39701637625694275, Reg Loss=3.682342529296875
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=4.030590215325356
Loss made of: CE 0.32501310110092163, LKD 3.7365670204162598, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2988467514514923, Reg Loss=3.7010085582733154
Clinet index 1, End of Epoch 2/6, Average Loss=3.9998552799224854, Class Loss=0.2988467514514923, Reg Loss=3.7010085582733154
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=3.9205978989601133
Loss made of: CE 0.25545403361320496, LKD 4.048159122467041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25101417303085327, Reg Loss=3.699084758758545
Clinet index 1, End of Epoch 3/6, Average Loss=3.950098991394043, Class Loss=0.25101417303085327, Reg Loss=3.699084758758545
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=3.819000005722046
Loss made of: CE 0.1925690621137619, LKD 3.764585494995117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22751031816005707, Reg Loss=3.6263813972473145
Clinet index 1, End of Epoch 4/6, Average Loss=3.853891611099243, Class Loss=0.22751031816005707, Reg Loss=3.6263813972473145
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=3.967602735757828
Loss made of: CE 0.2356056272983551, LKD 3.4240684509277344, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22926118969917297, Reg Loss=3.668149948120117
Clinet index 1, End of Epoch 5/6, Average Loss=3.8974111080169678, Class Loss=0.22926118969917297, Reg Loss=3.668149948120117
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=3.936006638407707
Loss made of: CE 0.23297938704490662, LKD 3.69144868850708, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22491979598999023, Reg Loss=3.705838680267334
Clinet index 1, End of Epoch 6/6, Average Loss=3.930758476257324, Class Loss=0.22491979598999023, Reg Loss=3.705838680267334
federated aggregation...
Validation, Class Loss=1.1503381729125977, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.711476
Mean Acc: 0.120375
FreqW Acc: 0.624480
Mean IoU: 0.082871
Class IoU:
	class 0: 0.8527071
	class 1: 2.1854652e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.064873874
	class 5: 0.0
	class 6: 0.0
	class 7: 0.04058572
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 6.4125134e-06
	class 14: 0.0
	class 15: 0.56339926
	class 16: 0.0055511044
	class 17: 0.0009890718
	class 18: 0.15238644
	class 19: 0.05967522
	class 20: 9.297347e-05
Class Acc:
	class 0: 0.96011347
	class 1: 2.1854657e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.06510028
	class 5: 0.0
	class 6: 0.0
	class 7: 0.040587775
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 6.4400224e-06
	class 14: 0.0
	class 15: 0.5718818
	class 16: 0.0055524805
	class 17: 0.0009951896
	class 18: 0.23543778
	class 19: 0.64808965
	class 20: 9.2975184e-05

federated global round: 32, step: 6
select part of clients to conduct local training
[3, 8, 27, 7]
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.185404926538467
Loss made of: CE 0.3284820318222046, LKD 3.9535694122314453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39986690878868103, Reg Loss=3.756453275680542
Clinet index 3, End of Epoch 1/6, Average Loss=4.156320095062256, Class Loss=0.39986690878868103, Reg Loss=3.756453275680542
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=4.063881644606591
Loss made of: CE 0.29981544613838196, LKD 3.964569330215454, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28731754422187805, Reg Loss=3.767526149749756
Clinet index 3, End of Epoch 2/6, Average Loss=4.054843902587891, Class Loss=0.28731754422187805, Reg Loss=3.767526149749756
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=4.048772424459457
Loss made of: CE 0.2162645310163498, LKD 3.7356607913970947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25434669852256775, Reg Loss=3.7572240829467773
Clinet index 3, End of Epoch 3/6, Average Loss=4.011570930480957, Class Loss=0.25434669852256775, Reg Loss=3.7572240829467773
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=3.926460887491703
Loss made of: CE 0.23144742846488953, LKD 3.3441357612609863, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24228665232658386, Reg Loss=3.687164306640625
Clinet index 3, End of Epoch 4/6, Average Loss=3.9294509887695312, Class Loss=0.24228665232658386, Reg Loss=3.687164306640625
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=3.9157835453748704
Loss made of: CE 0.19709661602973938, LKD 3.0319974422454834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23204998672008514, Reg Loss=3.751249074935913
Clinet index 3, End of Epoch 5/6, Average Loss=3.9832990169525146, Class Loss=0.23204998672008514, Reg Loss=3.751249074935913
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=3.8999751687049864
Loss made of: CE 0.23795662820339203, LKD 3.50309681892395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21466132998466492, Reg Loss=3.696549892425537
Clinet index 3, End of Epoch 6/6, Average Loss=3.9112112522125244, Class Loss=0.21466132998466492, Reg Loss=3.696549892425537
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.1869853079319
Loss made of: CE 0.6190671324729919, LKD 3.3640270233154297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7812662124633789, Reg Loss=3.328789472579956
Clinet index 8, End of Epoch 1/6, Average Loss=4.110055923461914, Class Loss=0.7812662124633789, Reg Loss=3.328789472579956
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=4.060659170150757
Loss made of: CE 0.6027050018310547, LKD 3.3413329124450684, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6464347839355469, Reg Loss=3.3876237869262695
Clinet index 8, End of Epoch 2/6, Average Loss=4.034058570861816, Class Loss=0.6464347839355469, Reg Loss=3.3876237869262695
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=4.0112702518701555
Loss made of: CE 0.5570388436317444, LKD 2.8756699562072754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.541010856628418, Reg Loss=3.4166877269744873
Clinet index 8, End of Epoch 3/6, Average Loss=3.9576985836029053, Class Loss=0.541010856628418, Reg Loss=3.4166877269744873
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=3.832557311654091
Loss made of: CE 0.5678133368492126, LKD 3.2930498123168945, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4891494810581207, Reg Loss=3.3110344409942627
Clinet index 8, End of Epoch 4/6, Average Loss=3.8001840114593506, Class Loss=0.4891494810581207, Reg Loss=3.3110344409942627
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=3.8955606818199158
Loss made of: CE 0.5446030497550964, LKD 3.1929306983947754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.47441184520721436, Reg Loss=3.345048666000366
Clinet index 8, End of Epoch 5/6, Average Loss=3.819460391998291, Class Loss=0.47441184520721436, Reg Loss=3.345048666000366
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=3.793130138516426
Loss made of: CE 0.3930790424346924, LKD 3.9568588733673096, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.44141969084739685, Reg Loss=3.3204643726348877
Clinet index 8, End of Epoch 6/6, Average Loss=3.7618839740753174, Class Loss=0.44141969084739685, Reg Loss=3.3204643726348877
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.36789253950119
Loss made of: CE 0.7174379229545593, LKD 3.541779041290283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8230807781219482, Reg Loss=3.566598653793335
Clinet index 27, End of Epoch 1/6, Average Loss=4.389679431915283, Class Loss=0.8230807781219482, Reg Loss=3.566598653793335
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=4.172651329636574
Loss made of: CE 0.7828113436698914, LKD 3.374077320098877, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6803267598152161, Reg Loss=3.560309410095215
Clinet index 27, End of Epoch 2/6, Average Loss=4.240636348724365, Class Loss=0.6803267598152161, Reg Loss=3.560309410095215
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=4.031284502148628
Loss made of: CE 0.5773283243179321, LKD 3.4891955852508545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5579113364219666, Reg Loss=3.513735055923462
Clinet index 27, End of Epoch 3/6, Average Loss=4.071646213531494, Class Loss=0.5579113364219666, Reg Loss=3.513735055923462
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=4.004391777515411
Loss made of: CE 0.47797247767448425, LKD 3.3667843341827393, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5191798210144043, Reg Loss=3.428591251373291
Clinet index 27, End of Epoch 4/6, Average Loss=3.9477710723876953, Class Loss=0.5191798210144043, Reg Loss=3.428591251373291
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=4.055124074220657
Loss made of: CE 0.5082809925079346, LKD 3.379915952682495, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5016909241676331, Reg Loss=3.509253740310669
Clinet index 27, End of Epoch 5/6, Average Loss=4.010944843292236, Class Loss=0.5016909241676331, Reg Loss=3.509253740310669
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=3.9371403723955156
Loss made of: CE 0.5201390981674194, LKD 3.5536270141601562, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4792717695236206, Reg Loss=3.5044665336608887
Clinet index 27, End of Epoch 6/6, Average Loss=3.983738422393799, Class Loss=0.4792717695236206, Reg Loss=3.5044665336608887
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.364348244667053
Loss made of: CE 0.8276432752609253, LKD 3.1524882316589355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8239569664001465, Reg Loss=3.5340676307678223
Clinet index 7, End of Epoch 1/6, Average Loss=4.358024597167969, Class Loss=0.8239569664001465, Reg Loss=3.5340676307678223
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=4.311434626579285
Loss made of: CE 0.6088782548904419, LKD 3.552191734313965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6831031441688538, Reg Loss=3.582098960876465
Clinet index 7, End of Epoch 2/6, Average Loss=4.265202045440674, Class Loss=0.6831031441688538, Reg Loss=3.582098960876465
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=4.116459101438522
Loss made of: CE 0.4919699430465698, LKD 3.6588594913482666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5613317489624023, Reg Loss=3.555191993713379
Clinet index 7, End of Epoch 3/6, Average Loss=4.116523742675781, Class Loss=0.5613317489624023, Reg Loss=3.555191993713379
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=4.029454711079597
Loss made of: CE 0.44803911447525024, LKD 3.1714844703674316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.526014506816864, Reg Loss=3.474863290786743
Clinet index 7, End of Epoch 4/6, Average Loss=4.000877857208252, Class Loss=0.526014506816864, Reg Loss=3.474863290786743
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=3.97251643538475
Loss made of: CE 0.49318358302116394, LKD 3.651869773864746, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.48171573877334595, Reg Loss=3.5240790843963623
Clinet index 7, End of Epoch 5/6, Average Loss=4.005795001983643, Class Loss=0.48171573877334595, Reg Loss=3.5240790843963623
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=3.948073756694794
Loss made of: CE 0.4607057273387909, LKD 3.577934980392456, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.46581724286079407, Reg Loss=3.5040721893310547
Clinet index 7, End of Epoch 6/6, Average Loss=3.9698894023895264, Class Loss=0.46581724286079407, Reg Loss=3.5040721893310547
federated aggregation...
Validation, Class Loss=1.1219590902328491, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.720982
Mean Acc: 0.141984
FreqW Acc: 0.616010
Mean IoU: 0.092802
Class IoU:
	class 0: 0.8322237
	class 1: 0.0036073823
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0730668
	class 5: 0.00015984726
	class 6: 1.0790044e-05
	class 7: 0.09806302
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.004970051
	class 14: 0.0
	class 15: 0.6191795
	class 16: 0.0031177904
	class 17: 0.03549113
	class 18: 0.1815303
	class 19: 0.056621447
	class 20: 0.040792778
Class Acc:
	class 0: 0.9682633
	class 1: 0.0036073844
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0733244
	class 5: 0.00015984726
	class 6: 1.0790044e-05
	class 7: 0.098078586
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0057449155
	class 14: 0.0
	class 15: 0.63335687
	class 16: 0.0031181555
	class 17: 0.04757855
	class 18: 0.46540278
	class 19: 0.20073709
	class 20: 0.482271

federated global round: 33, step: 6
select part of clients to conduct local training
[6, 20, 13, 10]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.044896066188812
Loss made of: CE 0.5099146366119385, LKD 3.8494772911071777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5168951153755188, Reg Loss=3.437434673309326
Clinet index 6, End of Epoch 1/6, Average Loss=3.9543297290802, Class Loss=0.5168951153755188, Reg Loss=3.437434673309326
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=3.9821875154972077
Loss made of: CE 0.5197954177856445, LKD 3.3968851566314697, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4917283356189728, Reg Loss=3.428795576095581
Clinet index 6, End of Epoch 2/6, Average Loss=3.9205238819122314, Class Loss=0.4917283356189728, Reg Loss=3.428795576095581
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=3.9635927349328997
Loss made of: CE 0.4289633631706238, LKD 3.187727212905884, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4747256636619568, Reg Loss=3.4998342990875244
Clinet index 6, End of Epoch 3/6, Average Loss=3.974560022354126, Class Loss=0.4747256636619568, Reg Loss=3.4998342990875244
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=3.960176023840904
Loss made of: CE 0.378593385219574, LKD 3.128857135772705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.454556405544281, Reg Loss=3.4558024406433105
Clinet index 6, End of Epoch 4/6, Average Loss=3.9103589057922363, Class Loss=0.454556405544281, Reg Loss=3.4558024406433105
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=3.943526929616928
Loss made of: CE 0.447923868894577, LKD 3.593580484390259, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4560970366001129, Reg Loss=3.4961042404174805
Clinet index 6, End of Epoch 5/6, Average Loss=3.9522013664245605, Class Loss=0.4560970366001129, Reg Loss=3.4961042404174805
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=3.9860315054655073
Loss made of: CE 0.4141274094581604, LKD 3.049915075302124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.44133260846138, Reg Loss=3.4400429725646973
Clinet index 6, End of Epoch 6/6, Average Loss=3.881375551223755, Class Loss=0.44133260846138, Reg Loss=3.4400429725646973
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.002396914362907
Loss made of: CE 0.49292677640914917, LKD 3.590127944946289, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.526872456073761, Reg Loss=3.526221990585327
Clinet index 20, End of Epoch 1/6, Average Loss=4.053094387054443, Class Loss=0.526872456073761, Reg Loss=3.526221990585327
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=3.9967177242040632
Loss made of: CE 0.573277473449707, LKD 3.432715654373169, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5080143809318542, Reg Loss=3.4640705585479736
Clinet index 20, End of Epoch 2/6, Average Loss=3.9720849990844727, Class Loss=0.5080143809318542, Reg Loss=3.4640705585479736
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=3.940621092915535
Loss made of: CE 0.4030676782131195, LKD 3.31453013420105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4720951318740845, Reg Loss=3.4943058490753174
Clinet index 20, End of Epoch 3/6, Average Loss=3.9664011001586914, Class Loss=0.4720951318740845, Reg Loss=3.4943058490753174
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=3.9168700009584425
Loss made of: CE 0.5810102224349976, LKD 3.857398748397827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.47120803594589233, Reg Loss=3.437356948852539
Clinet index 20, End of Epoch 4/6, Average Loss=3.908565044403076, Class Loss=0.47120803594589233, Reg Loss=3.437356948852539
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=3.9084274500608442
Loss made of: CE 0.4692387282848358, LKD 3.013144016265869, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4578413665294647, Reg Loss=3.4967238903045654
Clinet index 20, End of Epoch 5/6, Average Loss=3.9545652866363525, Class Loss=0.4578413665294647, Reg Loss=3.4967238903045654
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=3.9313822954893114
Loss made of: CE 0.4060084819793701, LKD 3.9001128673553467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.43468329310417175, Reg Loss=3.4640679359436035
Clinet index 20, End of Epoch 6/6, Average Loss=3.8987512588500977, Class Loss=0.43468329310417175, Reg Loss=3.4640679359436035
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=4.2809756875038145
Loss made of: CE 0.4903640151023865, LKD 3.970127820968628, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5629629492759705, Reg Loss=3.6917190551757812
Clinet index 13, End of Epoch 1/6, Average Loss=4.2546820640563965, Class Loss=0.5629629492759705, Reg Loss=3.6917190551757812
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=4.10701365172863
Loss made of: CE 0.33608192205429077, LKD 3.9098072052001953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3292856812477112, Reg Loss=3.6929738521575928
Clinet index 13, End of Epoch 2/6, Average Loss=4.022259712219238, Class Loss=0.3292856812477112, Reg Loss=3.6929738521575928
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=3.7755632981657983
Loss made of: CE 0.3292195200920105, LKD 3.7694461345672607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25489503145217896, Reg Loss=3.6508939266204834
Clinet index 13, End of Epoch 3/6, Average Loss=3.9057888984680176, Class Loss=0.25489503145217896, Reg Loss=3.6508939266204834
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=3.910429435968399
Loss made of: CE 0.18090558052062988, LKD 4.2108564376831055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23313471674919128, Reg Loss=3.660541296005249
Clinet index 13, End of Epoch 4/6, Average Loss=3.8936760425567627, Class Loss=0.23313471674919128, Reg Loss=3.660541296005249
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=3.9194123834371566
Loss made of: CE 0.24398617446422577, LKD 3.1159465312957764, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22391065955162048, Reg Loss=3.70188307762146
Clinet index 13, End of Epoch 5/6, Average Loss=3.9257936477661133, Class Loss=0.22391065955162048, Reg Loss=3.70188307762146
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=3.9362480834126474
Loss made of: CE 0.2054119110107422, LKD 3.5797502994537354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22587256133556366, Reg Loss=3.68686580657959
Clinet index 13, End of Epoch 6/6, Average Loss=3.91273832321167, Class Loss=0.22587256133556366, Reg Loss=3.68686580657959
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=4.226089334487915
Loss made of: CE 0.6634036302566528, LKD 4.389185905456543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5831238031387329, Reg Loss=3.690969467163086
Clinet index 10, End of Epoch 1/6, Average Loss=4.274093151092529, Class Loss=0.5831238031387329, Reg Loss=3.690969467163086
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/12, Loss=4.070141363143921
Loss made of: CE 0.5016336441040039, LKD 4.438089370727539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3727613389492035, Reg Loss=3.699666976928711
Clinet index 10, End of Epoch 2/6, Average Loss=4.072428226470947, Class Loss=0.3727613389492035, Reg Loss=3.699666976928711
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=3.9707400798797607
Loss made of: CE 0.31344085931777954, LKD 4.177463054656982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2855414152145386, Reg Loss=3.642828941345215
Clinet index 10, End of Epoch 3/6, Average Loss=3.928370475769043, Class Loss=0.2855414152145386, Reg Loss=3.642828941345215
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/12, Loss=3.9529404550790788
Loss made of: CE 0.19880306720733643, LKD 3.5433263778686523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25786417722702026, Reg Loss=3.656010150909424
Clinet index 10, End of Epoch 4/6, Average Loss=3.913874387741089, Class Loss=0.25786417722702026, Reg Loss=3.656010150909424
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/12, Loss=3.8080564066767693
Loss made of: CE 0.21566365659236908, LKD 3.632159471511841, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23688796162605286, Reg Loss=3.656477689743042
Clinet index 10, End of Epoch 5/6, Average Loss=3.8933656215667725, Class Loss=0.23688796162605286, Reg Loss=3.656477689743042
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/12, Loss=3.965221105515957
Loss made of: CE 0.234767884016037, LKD 2.935119390487671, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23829428851604462, Reg Loss=3.693355083465576
Clinet index 10, End of Epoch 6/6, Average Loss=3.9316494464874268, Class Loss=0.23829428851604462, Reg Loss=3.693355083465576
federated aggregation...
Validation, Class Loss=1.165383219718933, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.719501
Mean Acc: 0.150462
FreqW Acc: 0.628710
Mean IoU: 0.094351
Class IoU:
	class 0: 0.8539473
	class 1: 2.1854657e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.06383688
	class 5: 0.0
	class 6: 0.0
	class 7: 0.033885077
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00047738958
	class 14: 0.0
	class 15: 0.58425033
	class 16: 0.0027929165
	class 17: 0.015546493
	class 18: 0.18492973
	class 19: 0.072832026
	class 20: 0.16885132
Class Acc:
	class 0: 0.9608655
	class 1: 2.1854657e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.06404837
	class 5: 0.0
	class 6: 0.0
	class 7: 0.033885125
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00052621216
	class 14: 0.0
	class 15: 0.5953573
	class 16: 0.0027931712
	class 17: 0.01739896
	class 18: 0.35350025
	class 19: 0.6835203
	class 20: 0.4477901

federated global round: 34, step: 6
select part of clients to conduct local training
[19, 18, 27, 14]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.053800955414772
Loss made of: CE 0.4671977758407593, LKD 3.7427637577056885, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5676385760307312, Reg Loss=3.5132100582122803
Clinet index 19, End of Epoch 1/6, Average Loss=4.080848693847656, Class Loss=0.5676385760307312, Reg Loss=3.5132100582122803
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=4.123671811819077
Loss made of: CE 0.49805593490600586, LKD 3.84017276763916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5218419432640076, Reg Loss=3.5453481674194336
Clinet index 19, End of Epoch 2/6, Average Loss=4.067190170288086, Class Loss=0.5218419432640076, Reg Loss=3.5453481674194336
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=4.0574132114648815
Loss made of: CE 0.45072826743125916, LKD 3.2277016639709473, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4796961843967438, Reg Loss=3.5366640090942383
Clinet index 19, End of Epoch 3/6, Average Loss=4.016360282897949, Class Loss=0.4796961843967438, Reg Loss=3.5366640090942383
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=4.045885279774666
Loss made of: CE 0.4638231694698334, LKD 3.806018114089966, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4640492796897888, Reg Loss=3.5400075912475586
Clinet index 19, End of Epoch 4/6, Average Loss=4.004056930541992, Class Loss=0.4640492796897888, Reg Loss=3.5400075912475586
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=3.9020596861839296
Loss made of: CE 0.4426165521144867, LKD 3.712050199508667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4457782506942749, Reg Loss=3.5040009021759033
Clinet index 19, End of Epoch 5/6, Average Loss=3.9497790336608887, Class Loss=0.4457782506942749, Reg Loss=3.5040009021759033
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=3.874012327194214
Loss made of: CE 0.5142220854759216, LKD 3.139281749725342, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.45608794689178467, Reg Loss=3.494058847427368
Clinet index 19, End of Epoch 6/6, Average Loss=3.9501466751098633, Class Loss=0.45608794689178467, Reg Loss=3.494058847427368
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=4.141961860656738
Loss made of: CE 0.5644814968109131, LKD 3.6934592723846436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5581669211387634, Reg Loss=3.5534145832061768
Clinet index 18, End of Epoch 1/6, Average Loss=4.111581325531006, Class Loss=0.5581669211387634, Reg Loss=3.5534145832061768
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=4.026007121801376
Loss made of: CE 0.5278924703598022, LKD 3.3663556575775146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5146546363830566, Reg Loss=3.493156909942627
Clinet index 18, End of Epoch 2/6, Average Loss=4.007811546325684, Class Loss=0.5146546363830566, Reg Loss=3.493156909942627
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=4.047051292657852
Loss made of: CE 0.45180583000183105, LKD 3.6298446655273438, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.487883985042572, Reg Loss=3.499314069747925
Clinet index 18, End of Epoch 3/6, Average Loss=3.9871981143951416, Class Loss=0.487883985042572, Reg Loss=3.499314069747925
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=3.951612240076065
Loss made of: CE 0.4211423099040985, LKD 3.2420151233673096, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.47047388553619385, Reg Loss=3.535205125808716
Clinet index 18, End of Epoch 4/6, Average Loss=4.005679130554199, Class Loss=0.47047388553619385, Reg Loss=3.535205125808716
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=4.080008918046952
Loss made of: CE 0.514863908290863, LKD 3.779871702194214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.45948973298072815, Reg Loss=3.511615037918091
Clinet index 18, End of Epoch 5/6, Average Loss=3.971104860305786, Class Loss=0.45948973298072815, Reg Loss=3.511615037918091
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=3.9395682066679
Loss made of: CE 0.4292822778224945, LKD 3.1871821880340576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4612269997596741, Reg Loss=3.5566349029541016
Clinet index 18, End of Epoch 6/6, Average Loss=4.017861843109131, Class Loss=0.4612269997596741, Reg Loss=3.5566349029541016
Current Client Index:  27
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/13, Loss=4.066698575019837
Loss made of: CE 0.5096391439437866, LKD 3.581702709197998, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.562617301940918, Reg Loss=3.5711076259613037
Clinet index 27, End of Epoch 1/6, Average Loss=4.133725166320801, Class Loss=0.562617301940918, Reg Loss=3.5711076259613037
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/13, Loss=4.010415530204773
Loss made of: CE 0.5464264750480652, LKD 2.9478158950805664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5494933128356934, Reg Loss=3.518690586090088
Clinet index 27, End of Epoch 2/6, Average Loss=4.068183898925781, Class Loss=0.5494933128356934, Reg Loss=3.518690586090088
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/13, Loss=3.9556443065404894
Loss made of: CE 0.497640460729599, LKD 3.6600306034088135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4932110905647278, Reg Loss=3.4649882316589355
Clinet index 27, End of Epoch 3/6, Average Loss=3.9581992626190186, Class Loss=0.4932110905647278, Reg Loss=3.4649882316589355
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/13, Loss=3.9527353167533876
Loss made of: CE 0.4507318437099457, LKD 3.4623796939849854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4657846689224243, Reg Loss=3.42116117477417
Clinet index 27, End of Epoch 4/6, Average Loss=3.8869457244873047, Class Loss=0.4657846689224243, Reg Loss=3.42116117477417
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/13, Loss=4.083148348331451
Loss made of: CE 0.4938277006149292, LKD 3.508763074874878, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.49437594413757324, Reg Loss=3.54701828956604
Clinet index 27, End of Epoch 5/6, Average Loss=4.041394233703613, Class Loss=0.49437594413757324, Reg Loss=3.54701828956604
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/13, Loss=3.930480796098709
Loss made of: CE 0.48660847544670105, LKD 3.360771417617798, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4761498272418976, Reg Loss=3.4963839054107666
Clinet index 27, End of Epoch 6/6, Average Loss=3.972533702850342, Class Loss=0.4761498272418976, Reg Loss=3.4963839054107666
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/13, Loss=4.006391811370849
Loss made of: CE 0.5738352537155151, LKD 3.625986099243164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5577805638313293, Reg Loss=3.4291508197784424
Clinet index 14, End of Epoch 1/6, Average Loss=3.986931324005127, Class Loss=0.5577805638313293, Reg Loss=3.4291508197784424
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/13, Loss=3.9250388503074647
Loss made of: CE 0.46136826276779175, LKD 3.061854839324951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5163675546646118, Reg Loss=3.407331943511963
Clinet index 14, End of Epoch 2/6, Average Loss=3.923699378967285, Class Loss=0.5163675546646118, Reg Loss=3.407331943511963
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/13, Loss=3.9383425176143647
Loss made of: CE 0.45174479484558105, LKD 3.678016424179077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.49798810482025146, Reg Loss=3.3943307399749756
Clinet index 14, End of Epoch 3/6, Average Loss=3.8923187255859375, Class Loss=0.49798810482025146, Reg Loss=3.3943307399749756
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/13, Loss=3.7937829047441483
Loss made of: CE 0.44330283999443054, LKD 3.176854133605957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.47340700030326843, Reg Loss=3.3363804817199707
Clinet index 14, End of Epoch 4/6, Average Loss=3.8097875118255615, Class Loss=0.47340700030326843, Reg Loss=3.3363804817199707
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/13, Loss=3.8466435849666594
Loss made of: CE 0.4171789586544037, LKD 3.29957914352417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4555140435695648, Reg Loss=3.37825870513916
Clinet index 14, End of Epoch 5/6, Average Loss=3.833772659301758, Class Loss=0.4555140435695648, Reg Loss=3.37825870513916
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/13, Loss=3.8343660086393356
Loss made of: CE 0.4535740613937378, LKD 3.4583096504211426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.464574933052063, Reg Loss=3.3921968936920166
Clinet index 14, End of Epoch 6/6, Average Loss=3.856771945953369, Class Loss=0.464574933052063, Reg Loss=3.3921968936920166
federated aggregation...
Validation, Class Loss=1.1741915941238403, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.714709
Mean Acc: 0.148660
FreqW Acc: 0.615947
Mean IoU: 0.091572
Class IoU:
	class 0: 0.831069
	class 1: 0.0021759043
	class 2: 0.0
	class 3: 0.0
	class 4: 0.050131857
	class 5: 1.0932252e-05
	class 6: 0.0
	class 7: 0.06812047
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.010583755
	class 14: 0.0
	class 15: 0.64468646
	class 16: 0.003164246
	class 17: 0.045347407
	class 18: 0.19746792
	class 19: 0.028160518
	class 20: 0.042101044
Class Acc:
	class 0: 0.9574259
	class 1: 0.0021759043
	class 2: 0.0
	class 3: 0.0
	class 4: 0.050273202
	class 5: 1.0932252e-05
	class 6: 0.0
	class 7: 0.06812047
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.014134603
	class 14: 0.0
	class 15: 0.66142535
	class 16: 0.003164246
	class 17: 0.063625306
	class 18: 0.5211483
	class 19: 0.049988892
	class 20: 0.73036325

voc_8-2_LWF On GPUs 2
Run in 43929s
