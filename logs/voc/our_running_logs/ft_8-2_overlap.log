nohup: ignoring input
35
kvoc_8-2_FT On GPUs 2\Writing in results/seed_2023-ov/2023-03-12_voc_8-2_FT.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[4, 3, 1, 2]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[0, 4, 7, 2]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  4
Current Client Index:  7
Current Client Index:  2
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[1, 9, 3, 8]
Current Client Index:  1
Current Client Index:  9
Current Client Index:  3
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[5, 9, 0, 4]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Current Client Index:  0
Current Client Index:  4
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.11884414404630661, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.959771
Mean Acc: 0.898867
FreqW Acc: 0.927997
Mean IoU: 0.803600
Class IoU:
	class 0: 0.9505860659032771
	class 1: 0.9002121543757099
	class 2: 0.3911996045853578
	class 3: 0.7886755539422873
	class 4: 0.7227948650191602
	class 5: 0.777020491034379
	class 6: 0.9452273228283382
	class 7: 0.8680230685934628
	class 8: 0.8886579855388657
Class Acc:
	class 0: 0.9742031520387592
	class 1: 0.9505188705401268
	class 2: 0.8333169681087177
	class 3: 0.7954920085182839
	class 4: 0.8649138231019398
	class 5: 0.839701567241524
	class 6: 0.9766569231687022
	class 7: 0.9440467027150332
	class 8: 0.910953836504121

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[5, 11, 7, 1]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: None
Epoch 1, lr = 0.001000
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Epoch 1, Batch 10/27, Loss=1.1208950519561767
Loss made of: CE 0.8721970319747925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.8227998197078705
Loss made of: CE 0.626151442527771, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8893846869468689, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.8893846869468689, Class Loss=0.8893846869468689, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=0.510742437839508
Loss made of: CE 0.37590235471725464, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.4165817230939865
Loss made of: CE 0.34207746386528015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.45106834173202515, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.45106834173202515, Class Loss=0.45106834173202515, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=0.34347037971019745
Loss made of: CE 0.38486379384994507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.2814064145088196
Loss made of: CE 0.25156497955322266, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.30752840638160706, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.30752840638160706, Class Loss=0.30752840638160706, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=0.27502588331699374
Loss made of: CE 0.30083030462265015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.2510244816541672
Loss made of: CE 0.22081145644187927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25977012515068054, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.25977012515068054, Class Loss=0.25977012515068054, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.2474514812231064
Loss made of: CE 0.2035626471042633, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.20587729066610336
Loss made of: CE 0.18237881362438202, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23090684413909912, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.23090684413909912, Class Loss=0.23090684413909912, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.22718268930912017
Loss made of: CE 0.25509417057037354, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.21441118121147157
Loss made of: CE 0.2033093273639679, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21781779825687408, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.21781779825687408, Class Loss=0.21781779825687408, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.186119556427002, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=1.186119556427002, Class Loss=1.186119556427002, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.9347442984580994, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.9347442984580994, Class Loss=0.9347442984580994, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.6683266162872314, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.6683266162872314, Class Loss=0.6683266162872314, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.43139714002609253, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.43139714002609253, Class Loss=0.43139714002609253, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.28276145458221436, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.28276145458221436, Class Loss=0.28276145458221436, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.20850905776023865, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.20850905776023865, Class Loss=0.20850905776023865, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=1.063271802663803
Loss made of: CE 0.7533926963806152, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.9051848411560058
Loss made of: CE 0.7799078822135925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8798617124557495, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.8798617124557495, Class Loss=0.8798617124557495, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=0.5682062327861785
Loss made of: CE 0.8089370727539062, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.41840252578258513
Loss made of: CE 0.3622545897960663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.46415993571281433, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.46415993571281433, Class Loss=0.46415993571281433, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=0.31937137246131897
Loss made of: CE 0.32853394746780396, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.31977892220020293
Loss made of: CE 0.3447003960609436, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3272743225097656, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.3272743225097656, Class Loss=0.3272743225097656, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=0.2717999145388603
Loss made of: CE 0.24719063937664032, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.28070894479751585
Loss made of: CE 0.2886222004890442, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27368399500846863, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.27368399500846863, Class Loss=0.27368399500846863, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.2465004339814186
Loss made of: CE 0.20224052667617798, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.23998287171125413
Loss made of: CE 0.21076005697250366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24059557914733887, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.24059557914733887, Class Loss=0.24059557914733887, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.23105229437351227
Loss made of: CE 0.24815420806407928, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.22366154491901397
Loss made of: CE 0.15618376433849335, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22648398578166962, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.22648398578166962, Class Loss=0.22648398578166962, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=1.108972442150116
Loss made of: CE 0.804594874382019, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.7501754760742188
Loss made of: CE 0.6317187547683716, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8658276200294495, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.8658276200294495, Class Loss=0.8658276200294495, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=0.522730416059494
Loss made of: CE 0.4001224935054779, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.4438201755285263
Loss made of: CE 0.34050554037094116, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.45520609617233276, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.45520609617233276, Class Loss=0.45520609617233276, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=0.342503148317337
Loss made of: CE 0.3271629214286804, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.31952396035194397
Loss made of: CE 0.2776342034339905, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31604617834091187, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.31604617834091187, Class Loss=0.31604617834091187, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=0.2804095983505249
Loss made of: CE 0.22248801589012146, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.2640031412243843
Loss made of: CE 0.26461929082870483, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2629064619541168, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.2629064619541168, Class Loss=0.2629064619541168, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.23136957734823227
Loss made of: CE 0.23520022630691528, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.22713993340730668
Loss made of: CE 0.2061997354030609, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22909727692604065, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.22909727692604065, Class Loss=0.22909727692604065, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.2111162483692169
Loss made of: CE 0.23774753510951996, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.21333222687244416
Loss made of: CE 0.2466324269771576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2216361165046692, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.2216361165046692, Class Loss=0.2216361165046692, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.5360282063484192, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.842476
Mean Acc: 0.379437
FreqW Acc: 0.724589
Mean IoU: 0.352417
Class IoU:
	class 0: 0.8431072
	class 1: 0.69850665
	class 2: 0.08406572
	class 3: 0.3038552
	class 4: 0.4599134
	class 5: 0.44307128
	class 6: 0.63917524
	class 7: 0.21589455
	class 8: 0.10600292
	class 9: 0.08299513
	class 10: 0.0
Class Acc:
	class 0: 0.9909124
	class 1: 0.7031982
	class 2: 0.09273635
	class 3: 0.30430022
	class 4: 0.47233757
	class 5: 0.4514104
	class 6: 0.64821047
	class 7: 0.21794713
	class 8: 0.106168605
	class 9: 0.18658997
	class 10: 0.0

federated global round: 6, step: 1
select part of clients to conduct local training
[1, 6, 7, 3]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.3110335409641266
Loss made of: CE 0.24356848001480103, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.2470991387963295
Loss made of: CE 0.28850656747817993, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2771187126636505, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.2771187126636505, Class Loss=0.2771187126636505, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=0.24726468622684478
Loss made of: CE 0.23215702176094055, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.23565575182437898
Loss made of: CE 0.18875323235988617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23879413306713104, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.23879413306713104, Class Loss=0.23879413306713104, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=0.22545054107904433
Loss made of: CE 0.2133999764919281, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.22730154991149903
Loss made of: CE 0.21051762998104095, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2222617268562317, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.2222617268562317, Class Loss=0.2222617268562317, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=0.22237155586481094
Loss made of: CE 0.16385382413864136, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.21067941337823867
Loss made of: CE 0.20594105124473572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2126447856426239, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.2126447856426239, Class Loss=0.2126447856426239, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.2033461555838585
Loss made of: CE 0.190504252910614, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.20418593436479568
Loss made of: CE 0.166323721408844, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20448312163352966, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.20448312163352966, Class Loss=0.20448312163352966, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=0.18650380074977874
Loss made of: CE 0.20500513911247253, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.19009293913841246
Loss made of: CE 0.2257162630558014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1943155825138092, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.1943155825138092, Class Loss=0.1943155825138092, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.33331257551908494
Loss made of: CE 0.24918656051158905, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.2941417470574379
Loss made of: CE 0.2899101972579956, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3046257495880127, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.3046257495880127, Class Loss=0.3046257495880127, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/27, Loss=0.2510028377175331
Loss made of: CE 0.240727037191391, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.2636409759521484
Loss made of: CE 0.3085712492465973, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.25436538457870483, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.25436538457870483, Class Loss=0.25436538457870483, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/27, Loss=0.23104171454906464
Loss made of: CE 0.22942852973937988, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.2189208000898361
Loss made of: CE 0.21230632066726685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22600550949573517, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.22600550949573517, Class Loss=0.22600550949573517, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/27, Loss=0.2130485475063324
Loss made of: CE 0.25228947401046753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.21172631531953812
Loss made of: CE 0.17924094200134277, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21707889437675476, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.21707889437675476, Class Loss=0.21707889437675476, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/27, Loss=0.20312101691961287
Loss made of: CE 0.1479320377111435, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.1999759554862976
Loss made of: CE 0.17215105891227722, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20372667908668518, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.20372667908668518, Class Loss=0.20372667908668518, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/27, Loss=0.19552118182182313
Loss made of: CE 0.1895885318517685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.19591027349233628
Loss made of: CE 0.18861816823482513, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19914591312408447, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.19914591312408447, Class Loss=0.19914591312408447, Reg Loss=0.0
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.30188154727220534
Loss made of: CE 0.2371877282857895, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.30531228631734847
Loss made of: CE 0.2742335796356201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.28940948843955994, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.28940948843955994, Class Loss=0.28940948843955994, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=0.26269295811653137
Loss made of: CE 0.3831244111061096, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.23775485157966614
Loss made of: CE 0.22733628749847412, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24904781579971313, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.24904781579971313, Class Loss=0.24904781579971313, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=0.23111525774002076
Loss made of: CE 0.2553434371948242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.23401616960763932
Loss made of: CE 0.23891668021678925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2389920949935913, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.2389920949935913, Class Loss=0.2389920949935913, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=0.2181879088282585
Loss made of: CE 0.204832524061203, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.2202454313635826
Loss made of: CE 0.2612534761428833, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2164645940065384, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.2164645940065384, Class Loss=0.2164645940065384, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.21525706946849824
Loss made of: CE 0.17383387684822083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.2097212165594101
Loss made of: CE 0.17443501949310303, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20991840958595276, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.20991840958595276, Class Loss=0.20991840958595276, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=0.20357141494750977
Loss made of: CE 0.220570906996727, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.19210348427295684
Loss made of: CE 0.14593854546546936, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19653809070587158, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.19653809070587158, Class Loss=0.19653809070587158, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9942740797996521, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.9942740797996521, Class Loss=0.9942740797996521, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7827126383781433, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.7827126383781433, Class Loss=0.7827126383781433, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.5500476360321045, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.5500476360321045, Class Loss=0.5500476360321045, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.3927377164363861, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.3927377164363861, Class Loss=0.3927377164363861, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.27982470393180847, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.27982470393180847, Class Loss=0.27982470393180847, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.19691412150859833, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.19691412150859833, Class Loss=0.19691412150859833, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.6698623895645142, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.809376
Mean Acc: 0.261541
FreqW Acc: 0.674359
Mean IoU: 0.221145
Class IoU:
	class 0: 0.818229
	class 1: 0.44237936
	class 2: 0.0068328185
	class 3: 0.08250337
	class 4: 0.2867582
	class 5: 0.16529444
	class 6: 0.44014823
	class 7: 0.042865135
	class 8: 0.017501187
	class 9: 0.13008592
	class 10: 0.0
Class Acc:
	class 0: 0.9856893
	class 1: 0.4435643
	class 2: 0.0068848617
	class 3: 0.08251309
	class 4: 0.29134977
	class 5: 0.16629906
	class 6: 0.44265842
	class 7: 0.042960115
	class 8: 0.017507384
	class 9: 0.39752546
	class 10: 0.0

federated global round: 7, step: 1
select part of clients to conduct local training
[13, 8, 0, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.8806672096252441, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.8806672096252441, Class Loss=0.8806672096252441, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.7026515007019043, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.7026515007019043, Class Loss=0.7026515007019043, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.47841140627861023, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.47841140627861023, Class Loss=0.47841140627861023, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.310342937707901, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.310342937707901, Class Loss=0.310342937707901, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.23253272473812103, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.23253272473812103, Class Loss=0.23253272473812103, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.20672178268432617, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.20672178268432617, Class Loss=0.20672178268432617, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9928914904594421, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.9928914904594421, Class Loss=0.9928914904594421, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.7494274377822876, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.7494274377822876, Class Loss=0.7494274377822876, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.5172186493873596, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.5172186493873596, Class Loss=0.5172186493873596, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.34204572439193726, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.34204572439193726, Class Loss=0.34204572439193726, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.23366865515708923, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.23366865515708923, Class Loss=0.23366865515708923, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.1980774849653244, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.1980774849653244, Class Loss=0.1980774849653244, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9585628509521484, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.9585628509521484, Class Loss=0.9585628509521484, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.746302604675293, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.746302604675293, Class Loss=0.746302604675293, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.4896332025527954, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.4896332025527954, Class Loss=0.4896332025527954, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.31980815529823303, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.31980815529823303, Class Loss=0.31980815529823303, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.22133533656597137, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.22133533656597137, Class Loss=0.22133533656597137, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.19441810250282288, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.19441810250282288, Class Loss=0.19441810250282288, Reg Loss=0.0
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.22575590908527374
Loss made of: CE 0.15894120931625366, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.2357175573706627
Loss made of: CE 0.23422805964946747, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2240268886089325, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.2240268886089325, Class Loss=0.2240268886089325, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/27, Loss=0.2141118273139
Loss made of: CE 0.21403160691261292, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.2030750945210457
Loss made of: CE 0.19541174173355103, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21029417216777802, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.21029417216777802, Class Loss=0.21029417216777802, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/27, Loss=0.1944529354572296
Loss made of: CE 0.2277078628540039, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.1782909169793129
Loss made of: CE 0.1701980084180832, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1903804987668991, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.1903804987668991, Class Loss=0.1903804987668991, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/27, Loss=0.1908618688583374
Loss made of: CE 0.21061226725578308, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.17613574862480164
Loss made of: CE 0.1669723242521286, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18294750154018402, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.18294750154018402, Class Loss=0.18294750154018402, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/27, Loss=0.19015729427337646
Loss made of: CE 0.18339404463768005, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.1578034669160843
Loss made of: CE 0.16446509957313538, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1743454486131668, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.1743454486131668, Class Loss=0.1743454486131668, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/27, Loss=0.18293048292398453
Loss made of: CE 0.2104993760585785, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.16618762612342836
Loss made of: CE 0.1745615303516388, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17196795344352722, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.17196795344352722, Class Loss=0.17196795344352722, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4749126136302948, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.830328
Mean Acc: 0.331452
FreqW Acc: 0.722132
Mean IoU: 0.274153
Class IoU:
	class 0: 0.8619904
	class 1: 0.3827947
	class 2: 0.054893702
	class 3: 0.21785633
	class 4: 0.32207587
	class 5: 0.25009584
	class 6: 0.46993884
	class 7: 0.0768726
	class 8: 0.10066665
	class 9: 0.06088948
	class 10: 0.21760854
Class Acc:
	class 0: 0.9853668
	class 1: 0.3832971
	class 2: 0.0586059
	class 3: 0.21792096
	class 4: 0.33252138
	class 5: 0.2532728
	class 6: 0.47587898
	class 7: 0.077441454
	class 8: 0.10108689
	class 9: 0.084382236
	class 10: 0.6761964

federated global round: 8, step: 1
select part of clients to conduct local training
[12, 9, 4, 13]
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.352017742395401
Loss made of: CE 0.3454243540763855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.2654348358511925
Loss made of: CE 0.2598976492881775, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.29203590750694275, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.29203590750694275, Class Loss=0.29203590750694275, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=0.21293678283691406
Loss made of: CE 0.2129877805709839, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.23119120448827743
Loss made of: CE 0.2559482455253601, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21414107084274292, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.21414107084274292, Class Loss=0.21414107084274292, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=0.18542756289243698
Loss made of: CE 0.20729190111160278, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.18909843564033507
Loss made of: CE 0.17277878522872925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.190142422914505, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.190142422914505, Class Loss=0.190142422914505, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=0.17373388558626174
Loss made of: CE 0.15391197800636292, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.18046105653047562
Loss made of: CE 0.13887545466423035, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17724864184856415, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.17724864184856415, Class Loss=0.17724864184856415, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.17177562564611434
Loss made of: CE 0.17883962392807007, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.17846714556217194
Loss made of: CE 0.1841590404510498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1756158024072647, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.1756158024072647, Class Loss=0.1756158024072647, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=0.18113656640052794
Loss made of: CE 0.2126532793045044, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.16969353556632996
Loss made of: CE 0.1892184019088745, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17238612473011017, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.17238612473011017, Class Loss=0.17238612473011017, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.2787438929080963, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.2787438929080963, Class Loss=0.2787438929080963, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.22806845605373383, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.22806845605373383, Class Loss=0.22806845605373383, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.18863265216350555, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.18863265216350555, Class Loss=0.18863265216350555, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.16788417100906372, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.16788417100906372, Class Loss=0.16788417100906372, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.16041909158229828, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.16041909158229828, Class Loss=0.16041909158229828, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.1395176202058792, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.1395176202058792, Class Loss=0.1395176202058792, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.32427419871091845
Loss made of: CE 0.3338002562522888, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.3121727228164673
Loss made of: CE 0.25017592310905457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.29888540506362915, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.29888540506362915, Class Loss=0.29888540506362915, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=0.21772134602069854
Loss made of: CE 0.20575284957885742, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.22941922694444655
Loss made of: CE 0.23170122504234314, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2207545042037964, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.2207545042037964, Class Loss=0.2207545042037964, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=0.19604080617427827
Loss made of: CE 0.1691596508026123, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.2040910929441452
Loss made of: CE 0.2077142894268036, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1971246600151062, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.1971246600151062, Class Loss=0.1971246600151062, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=0.187323759496212
Loss made of: CE 0.2663300037384033, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.18527161702513695
Loss made of: CE 0.1739809513092041, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18586255609989166, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.18586255609989166, Class Loss=0.18586255609989166, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.1967481404542923
Loss made of: CE 0.18925690650939941, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.1702900104224682
Loss made of: CE 0.18991951644420624, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18521791696548462, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.18521791696548462, Class Loss=0.18521791696548462, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=0.16823841035366058
Loss made of: CE 0.1839236468076706, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.18280744552612305
Loss made of: CE 0.17062771320343018, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1741636097431183, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.1741636097431183, Class Loss=0.1741636097431183, Reg Loss=0.0
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.25645917654037476, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.25645917654037476, Class Loss=0.25645917654037476, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.2413610816001892, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.2413610816001892, Class Loss=0.2413610816001892, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.2169666588306427, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.2169666588306427, Class Loss=0.2169666588306427, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.20078155398368835, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.20078155398368835, Class Loss=0.20078155398368835, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.17632156610488892, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.17632156610488892, Class Loss=0.17632156610488892, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.17495006322860718, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.17495006322860718, Class Loss=0.17495006322860718, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.5820754170417786, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.805043
Mean Acc: 0.228708
FreqW Acc: 0.668453
Mean IoU: 0.195348
Class IoU:
	class 0: 0.8173056
	class 1: 0.2757183
	class 2: 0.0057404297
	class 3: 0.1544969
	class 4: 0.20421737
	class 5: 0.1367656
	class 6: 0.3578644
	class 7: 0.026599439
	class 8: 0.031978887
	class 9: 0.09914739
	class 10: 0.03898922
Class Acc:
	class 0: 0.98822314
	class 1: 0.27596202
	class 2: 0.005822675
	class 3: 0.1545156
	class 4: 0.20692953
	class 5: 0.13750468
	class 6: 0.35976535
	class 7: 0.026680393
	class 8: 0.03201845
	class 9: 0.28330666
	class 10: 0.045057878

federated global round: 9, step: 1
select part of clients to conduct local training
[4, 6, 13, 12]
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=0.22413701117038726
Loss made of: CE 0.22413122653961182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.2599232062697411
Loss made of: CE 0.22043833136558533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.23613783717155457, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.23613783717155457, Class Loss=0.23613783717155457, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=0.21576396226882935
Loss made of: CE 0.19481752812862396, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.23781778514385224
Loss made of: CE 0.22017452120780945, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21995431184768677, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.21995431184768677, Class Loss=0.21995431184768677, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=0.19990892708301544
Loss made of: CE 0.1978822946548462, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.20460622012615204
Loss made of: CE 0.22309327125549316, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19930186867713928, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.19930186867713928, Class Loss=0.19930186867713928, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=0.19791167676448823
Loss made of: CE 0.317629873752594, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.19407496154308318
Loss made of: CE 0.1725856512784958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1944669932126999, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.1944669932126999, Class Loss=0.1944669932126999, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=0.20391299128532409
Loss made of: CE 0.20958685874938965, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.17786774933338165
Loss made of: CE 0.19348280131816864, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19585326313972473, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.19585326313972473, Class Loss=0.19585326313972473, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=0.187001271545887
Loss made of: CE 0.23148295283317566, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.19264951050281526
Loss made of: CE 0.1899532973766327, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18845678865909576, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.18845678865909576, Class Loss=0.18845678865909576, Reg Loss=0.0
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/27, Loss=0.2689755395054817
Loss made of: CE 0.2280747890472412, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.23647153675556182
Loss made of: CE 0.24194112420082092, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.24897924065589905, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.24897924065589905, Class Loss=0.24897924065589905, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/27, Loss=0.21087196171283723
Loss made of: CE 0.19296550750732422, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.2235819160938263
Loss made of: CE 0.27999943494796753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21413633227348328, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.21413633227348328, Class Loss=0.21413633227348328, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/27, Loss=0.1970207467675209
Loss made of: CE 0.20232783257961273, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.19074652791023256
Loss made of: CE 0.19176289439201355, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19560706615447998, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.19560706615447998, Class Loss=0.19560706615447998, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/27, Loss=0.1873556852340698
Loss made of: CE 0.20238876342773438, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.18282644748687743
Loss made of: CE 0.17643988132476807, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.19325271248817444, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.19325271248817444, Class Loss=0.19325271248817444, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/27, Loss=0.1890615552663803
Loss made of: CE 0.1575336754322052, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.1857696756720543
Loss made of: CE 0.16442982852458954, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19196507334709167, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.19196507334709167, Class Loss=0.19196507334709167, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/27, Loss=0.18094898015260696
Loss made of: CE 0.16236452758312225, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.18713733404874802
Loss made of: CE 0.1938595026731491, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18884117901325226, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.18884117901325226, Class Loss=0.18884117901325226, Reg Loss=0.0
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000372
Epoch 1, Class Loss=0.36264848709106445, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.36264848709106445, Class Loss=0.36264848709106445, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000316
Epoch 2, Class Loss=0.3300389349460602, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.3300389349460602, Class Loss=0.3300389349460602, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000258
Epoch 3, Class Loss=0.3085520267486572, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.3085520267486572, Class Loss=0.3085520267486572, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000199
Epoch 4, Class Loss=0.2785627841949463, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.2785627841949463, Class Loss=0.2785627841949463, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000138
Epoch 5, Class Loss=0.27604925632476807, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.27604925632476807, Class Loss=0.27604925632476807, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000074
Epoch 6, Class Loss=0.28674939274787903, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.28674939274787903, Class Loss=0.28674939274787903, Reg Loss=0.0
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=0.2538213476538658
Loss made of: CE 0.28755050897598267, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.230485138297081
Loss made of: CE 0.2179122418165207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.23972293734550476, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.23972293734550476, Class Loss=0.23972293734550476, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=0.20343077480792998
Loss made of: CE 0.20516619086265564, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.21486939191818238
Loss made of: CE 0.23558670282363892, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20597200095653534, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.20597200095653534, Class Loss=0.20597200095653534, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=0.19728480875492097
Loss made of: CE 0.1970033496618271, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.18807804435491562
Loss made of: CE 0.1695622056722641, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19564901292324066, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.19564901292324066, Class Loss=0.19564901292324066, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=0.18240335136651992
Loss made of: CE 0.15543046593666077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.18575900942087173
Loss made of: CE 0.1520475149154663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1826355755329132, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.1826355755329132, Class Loss=0.1826355755329132, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=0.18312491476535797
Loss made of: CE 0.19635096192359924, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.18705036640167236
Loss made of: CE 0.1844838559627533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1875053346157074, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.1875053346157074, Class Loss=0.1875053346157074, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=0.18710582256317138
Loss made of: CE 0.21957731246948242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.1834568962454796
Loss made of: CE 0.1893804520368576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1837037354707718, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.1837037354707718, Class Loss=0.1837037354707718, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.7547935843467712, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.792519
Mean Acc: 0.195324
FreqW Acc: 0.644220
Mean IoU: 0.150956
Class IoU:
	class 0: 0.80015016
	class 1: 0.20219988
	class 2: 0.0009331745
	class 3: 0.025559321
	class 4: 0.1410827
	class 5: 0.051673237
	class 6: 0.2640775
	class 7: 0.010054699
	class 8: 0.004426103
	class 9: 0.16035458
	class 10: 0.0
Class Acc:
	class 0: 0.98413384
	class 1: 0.20233697
	class 2: 0.00093389285
	class 3: 0.025559321
	class 4: 0.14249636
	class 5: 0.051696554
	class 6: 0.2647181
	class 7: 0.01005574
	class 8: 0.004426401
	class 9: 0.4622049
	class 10: 0.0

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[10, 14, 16, 7]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.5181677997112275
Loss made of: CE 0.9709886908531189, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.9448540925979614
Loss made of: CE 0.7633342742919922, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.0241336822509766, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=1.0241336822509766, Class Loss=1.0241336822509766, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=0.30328608602285384
Loss made of: CE 0.26949045062065125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.23594053834676743
Loss made of: CE 0.2235952615737915, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24816910922527313, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.24816910922527313, Class Loss=0.24816910922527313, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=0.19388359189033508
Loss made of: CE 0.2271699160337448, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.16928574144840242
Loss made of: CE 0.1184718906879425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1840762495994568, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.1840762495994568, Class Loss=0.1840762495994568, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=0.1508064515888691
Loss made of: CE 0.18563884496688843, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.1517765387892723
Loss made of: CE 0.16149726510047913, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15881508588790894, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.15881508588790894, Class Loss=0.15881508588790894, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=0.15366448163986207
Loss made of: CE 0.14189766347408295, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.1304949440062046
Loss made of: CE 0.10829278081655502, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14445127546787262, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.14445127546787262, Class Loss=0.14445127546787262, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=0.11545969024300576
Loss made of: CE 0.10013449192047119, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.1395803399384022
Loss made of: CE 0.11597074568271637, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13338901102542877, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.13338901102542877, Class Loss=0.13338901102542877, Reg Loss=0.0
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.6219699382781982
Loss made of: CE 1.4095786809921265, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.544626235961914, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=1.544626235961914, Class Loss=1.544626235961914, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=0.9333421349525451
Loss made of: CE 0.779308021068573, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9029933214187622, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.9029933214187622, Class Loss=0.9029933214187622, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=0.5311736792325974
Loss made of: CE 0.42278480529785156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5177789926528931, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.5177789926528931, Class Loss=0.5177789926528931, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=0.37585166096687317
Loss made of: CE 0.3251475393772125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3602534234523773, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.3602534234523773, Class Loss=0.3602534234523773, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=0.31427609026432035
Loss made of: CE 0.3206208348274231, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3112452030181885, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.3112452030181885, Class Loss=0.3112452030181885, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=0.28385634124279024
Loss made of: CE 0.2349339723587036, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2753105163574219, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.2753105163574219, Class Loss=0.2753105163574219, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.5897570610046388
Loss made of: CE 1.2959489822387695, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.9340337455272675
Loss made of: CE 0.7244099974632263, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.0352094173431396, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=1.0352094173431396, Class Loss=1.0352094173431396, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=0.29856424033641815
Loss made of: CE 0.2404358834028244, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.22417744845151902
Loss made of: CE 0.16254837810993195, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24781329929828644, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.24781329929828644, Class Loss=0.24781329929828644, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=0.18004605770111085
Loss made of: CE 0.1779220998287201, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.16341002583503722
Loss made of: CE 0.14942637085914612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1724730283021927, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.1724730283021927, Class Loss=0.1724730283021927, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=0.1592148870229721
Loss made of: CE 0.18337610363960266, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.14209260791540146
Loss made of: CE 0.14937134087085724, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14743439853191376, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.14743439853191376, Class Loss=0.14743439853191376, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=0.15710828974843025
Loss made of: CE 0.15768104791641235, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.14357761442661285
Loss made of: CE 0.092280313372612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14862528443336487, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.14862528443336487, Class Loss=0.14862528443336487, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=0.14289017096161843
Loss made of: CE 0.11898805946111679, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.1281500294804573
Loss made of: CE 0.11048426479101181, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13478153944015503, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.13478153944015503, Class Loss=0.13478153944015503, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.5864254832267761
Loss made of: CE 1.2360303401947021, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.5235669612884521, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=1.5235669612884521, Class Loss=1.5235669612884521, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=0.898406982421875
Loss made of: CE 0.8874983787536621, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9074164628982544, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.9074164628982544, Class Loss=0.9074164628982544, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=0.5819129794836044
Loss made of: CE 0.4413139820098877, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5504989624023438, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.5504989624023438, Class Loss=0.5504989624023438, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=0.4064469665288925
Loss made of: CE 0.36367523670196533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3940969705581665, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.3940969705581665, Class Loss=0.3940969705581665, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=0.3251381069421768
Loss made of: CE 0.26090991497039795, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3198789954185486, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.3198789954185486, Class Loss=0.3198789954185486, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=0.3133120954036713
Loss made of: CE 0.29692572355270386, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29556241631507874, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.29556241631507874, Class Loss=0.29556241631507874, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.7353748083114624, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.776822
Mean Acc: 0.149748
FreqW Acc: 0.616333
Mean IoU: 0.126755
Class IoU:
	class 0: 0.7886131
	class 1: 0.108617626
	class 2: 0.00013474248
	class 3: 0.17914052
	class 4: 0.15428044
	class 5: 0.04067739
	class 6: 0.18982816
	class 7: 0.0053288997
	class 8: 0.040126193
	class 9: 0.0
	class 10: 0.0
	class 11: 5.829744e-05
	class 12: 0.14101493
Class Acc:
	class 0: 0.99617195
	class 1: 0.10865125
	class 2: 0.00013474433
	class 3: 0.17921449
	class 4: 0.15577215
	class 5: 0.04070757
	class 6: 0.18994583
	class 7: 0.0053291833
	class 8: 0.040184293
	class 9: 0.0
	class 10: 0.0
	class 11: 5.874542e-05
	class 12: 0.23055188

federated global round: 11, step: 2
select part of clients to conduct local training
[10, 13, 6, 1]
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/29, Loss=0.4437640130519867
Loss made of: CE 0.3091921806335449, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.30139314085245134
Loss made of: CE 0.24208542704582214, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33402886986732483, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.33402886986732483, Class Loss=0.33402886986732483, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/29, Loss=0.19126320630311966
Loss made of: CE 0.18914608657360077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.17738412469625472
Loss made of: CE 0.17577719688415527, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.17834773659706116, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.17834773659706116, Class Loss=0.17834773659706116, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/29, Loss=0.15632539764046668
Loss made of: CE 0.174900084733963, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.1485438272356987
Loss made of: CE 0.10600617527961731, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15777231752872467, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.15777231752872467, Class Loss=0.15777231752872467, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/29, Loss=0.13824881464242936
Loss made of: CE 0.15140476822853088, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.13679368197917938
Loss made of: CE 0.1408630907535553, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1439395546913147, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.1439395546913147, Class Loss=0.1439395546913147, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=0.1412414737045765
Loss made of: CE 0.12564967572689056, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.11472898200154305
Loss made of: CE 0.1103423684835434, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1336091309785843, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.1336091309785843, Class Loss=0.1336091309785843, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/29, Loss=0.11618921235203743
Loss made of: CE 0.09844555705785751, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.14104197844862937
Loss made of: CE 0.12802627682685852, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1324434131383896, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.1324434131383896, Class Loss=0.1324434131383896, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.4965727210044861
Loss made of: CE 0.2492201328277588, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.2912085339426994
Loss made of: CE 0.18962624669075012, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33942919969558716, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.33942919969558716, Class Loss=0.33942919969558716, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/29, Loss=0.17904178202152252
Loss made of: CE 0.2175927609205246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.177334026992321
Loss made of: CE 0.13761553168296814, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.17125016450881958, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.17125016450881958, Class Loss=0.17125016450881958, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/29, Loss=0.15377151370048522
Loss made of: CE 0.1260450780391693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.16441752016544342
Loss made of: CE 0.13732166588306427, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15193922817707062, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.15193922817707062, Class Loss=0.15193922817707062, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/29, Loss=0.13294217735528946
Loss made of: CE 0.1200752705335617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.13690340295433998
Loss made of: CE 0.11984898149967194, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13581909239292145, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.13581909239292145, Class Loss=0.13581909239292145, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/29, Loss=0.14119342416524888
Loss made of: CE 0.09817397594451904, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.11939026117324829
Loss made of: CE 0.11317157000303268, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1294531524181366, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.1294531524181366, Class Loss=0.1294531524181366, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/29, Loss=0.10676688626408577
Loss made of: CE 0.10708542913198471, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.13513358756899835
Loss made of: CE 0.14320605993270874, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.12159755080938339, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.12159755080938339, Class Loss=0.12159755080938339, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.6516813486814499
Loss made of: CE 0.7496002912521362, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6369011402130127, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.6369011402130127, Class Loss=0.6369011402130127, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.4535783290863037
Loss made of: CE 0.3758172392845154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.43041661381721497, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.43041661381721497, Class Loss=0.43041661381721497, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.3009881407022476
Loss made of: CE 0.24569055438041687, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3055972456932068, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.3055972456932068, Class Loss=0.3055972456932068, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.26905601769685744
Loss made of: CE 0.22014246881008148, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26925501227378845, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.26925501227378845, Class Loss=0.26925501227378845, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.24862508177757264
Loss made of: CE 0.3298000693321228, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2491980493068695, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.2491980493068695, Class Loss=0.2491980493068695, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.20953069180250167
Loss made of: CE 0.21677133440971375, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2192365974187851, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.2192365974187851, Class Loss=0.2192365974187851, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.6338827222585678
Loss made of: CE 0.6249353289604187, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6018730401992798, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.6018730401992798, Class Loss=0.6018730401992798, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.41152144968509674
Loss made of: CE 0.3337230384349823, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.39733052253723145, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.39733052253723145, Class Loss=0.39733052253723145, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.30551257729530334
Loss made of: CE 0.29585903882980347, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29134511947631836, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.29134511947631836, Class Loss=0.29134511947631836, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.2707374170422554
Loss made of: CE 0.26638954877853394, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26597967743873596, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.26597967743873596, Class Loss=0.26597967743873596, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.2239563673734665
Loss made of: CE 0.17647656798362732, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22550693154335022, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.22550693154335022, Class Loss=0.22550693154335022, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.2176170453429222
Loss made of: CE 0.23932969570159912, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21800300478935242, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.21800300478935242, Class Loss=0.21800300478935242, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.7999023199081421, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.780920
Mean Acc: 0.153429
FreqW Acc: 0.630239
Mean IoU: 0.115604
Class IoU:
	class 0: 0.8093548
	class 1: 0.0847136
	class 2: 0.0
	class 3: 0.066266894
	class 4: 0.12265586
	class 5: 0.012338967
	class 6: 0.1409091
	class 7: 0.0009871649
	class 8: 0.00033792693
	class 9: 0.0
	class 10: 0.0
	class 11: 0.019672362
	class 12: 0.24561332
Class Acc:
	class 0: 0.99332964
	class 1: 0.08472996
	class 2: 0.0
	class 3: 0.06627227
	class 4: 0.12352356
	class 5: 0.012338967
	class 6: 0.14095627
	class 7: 0.0009871649
	class 8: 0.0003379328
	class 9: 0.0
	class 10: 0.0
	class 11: 0.020343538
	class 12: 0.5517639

federated global round: 12, step: 2
select part of clients to conduct local training
[11, 0, 8, 14]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.527997761964798
Loss made of: CE 0.4964849352836609, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5071567893028259, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.5071567893028259, Class Loss=0.5071567893028259, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.37228581607341765
Loss made of: CE 0.29195886850357056, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35043779015541077, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.35043779015541077, Class Loss=0.35043779015541077, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.26420806646347045
Loss made of: CE 0.28990551829338074, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2694495618343353, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.2694495618343353, Class Loss=0.2694495618343353, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.24610059410333635
Loss made of: CE 0.22538337111473083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2401358187198639, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.2401358187198639, Class Loss=0.2401358187198639, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.23336175680160523
Loss made of: CE 0.18877069652080536, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23134656250476837, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.23134656250476837, Class Loss=0.23134656250476837, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.22021164745092392
Loss made of: CE 0.19195076823234558, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21882309019565582, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.21882309019565582, Class Loss=0.21882309019565582, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.31519344449043274
Loss made of: CE 0.328411340713501, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.21895767897367477
Loss made of: CE 0.16238459944725037, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2405330389738083, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.2405330389738083, Class Loss=0.2405330389738083, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=0.15726576671004294
Loss made of: CE 0.10786962509155273, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.15285638868808746
Loss made of: CE 0.15116487443447113, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.15321935713291168, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.15321935713291168, Class Loss=0.15321935713291168, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=0.15832061395049096
Loss made of: CE 0.10132895410060883, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.12384133785963058
Loss made of: CE 0.16541260480880737, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.13847579061985016, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.13847579061985016, Class Loss=0.13847579061985016, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=0.1406179279088974
Loss made of: CE 0.20652183890342712, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.1411132998764515
Loss made of: CE 0.1251823902130127, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13332344591617584, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.13332344591617584, Class Loss=0.13332344591617584, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=0.11975115239620208
Loss made of: CE 0.08561094850301743, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.11427135914564132
Loss made of: CE 0.13329926133155823, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11842182278633118, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.11842182278633118, Class Loss=0.11842182278633118, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=0.11141490638256073
Loss made of: CE 0.12721319496631622, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.12083930894732475
Loss made of: CE 0.12765879929065704, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.11370822787284851, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.11370822787284851, Class Loss=0.11370822787284851, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.33552436381578443
Loss made of: CE 0.31905168294906616, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.21164489388465882
Loss made of: CE 0.17897365987300873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2470993548631668, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.2470993548631668, Class Loss=0.2470993548631668, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=0.1522603653371334
Loss made of: CE 0.15890246629714966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.1564505696296692
Loss made of: CE 0.15198393166065216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.14816203713417053, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.14816203713417053, Class Loss=0.14816203713417053, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=0.15767463967204093
Loss made of: CE 0.13183946907520294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.14205677509307862
Loss made of: CE 0.16213975846767426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14561323821544647, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.14561323821544647, Class Loss=0.14561323821544647, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=0.137015014141798
Loss made of: CE 0.1252608299255371, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.13806418403983117
Loss made of: CE 0.12826815247535706, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13044096529483795, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.13044096529483795, Class Loss=0.13044096529483795, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=0.11923682540655137
Loss made of: CE 0.13349255919456482, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.11875502318143845
Loss made of: CE 0.13294818997383118, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11905574053525925, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.11905574053525925, Class Loss=0.11905574053525925, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=0.1193530522286892
Loss made of: CE 0.15085050463676453, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.10465751886367798
Loss made of: CE 0.10953431576490402, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.10898186266422272, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.10898186266422272, Class Loss=0.10898186266422272, Reg Loss=0.0
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=0.5185543447732925
Loss made of: CE 0.4985562264919281, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.49716585874557495, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.49716585874557495, Class Loss=0.49716585874557495, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/13, Loss=0.3552638828754425
Loss made of: CE 0.29770350456237793, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35244622826576233, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.35244622826576233, Class Loss=0.35244622826576233, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/13, Loss=0.2625804290175438
Loss made of: CE 0.23383145034313202, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26237574219703674, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.26237574219703674, Class Loss=0.26237574219703674, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/13, Loss=0.234384223818779
Loss made of: CE 0.20846903324127197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22934575378894806, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.22934575378894806, Class Loss=0.22934575378894806, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/13, Loss=0.22395084500312806
Loss made of: CE 0.23459398746490479, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22482791543006897, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.22482791543006897, Class Loss=0.22482791543006897, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/13, Loss=0.2183539241552353
Loss made of: CE 0.16867832839488983, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21352940797805786, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.21352940797805786, Class Loss=0.21352940797805786, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.8525534272193909, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.784506
Mean Acc: 0.157501
FreqW Acc: 0.636608
Mean IoU: 0.112152
Class IoU:
	class 0: 0.81760395
	class 1: 0.060183633
	class 2: 0.0
	class 3: 0.017335443
	class 4: 0.08344725
	class 5: 0.0040753665
	class 6: 0.11642193
	class 7: 0.0003308189
	class 8: 1.2210761e-06
	class 9: 0.0
	class 10: 0.0
	class 11: 0.06644417
	class 12: 0.29212856
Class Acc:
	class 0: 0.99275416
	class 1: 0.060194008
	class 2: 0.0
	class 3: 0.017335443
	class 4: 0.083900765
	class 5: 0.0040753665
	class 6: 0.11644787
	class 7: 0.0003308189
	class 8: 1.2210761e-06
	class 9: 0.0
	class 10: 0.0
	class 11: 0.070991255
	class 12: 0.70148695

federated global round: 13, step: 2
select part of clients to conduct local training
[13, 5, 15, 7]
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/29, Loss=0.30817187428474424
Loss made of: CE 0.1558857560157776, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.20125397443771362
Loss made of: CE 0.1578899323940277, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.23015087842941284, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.23015087842941284, Class Loss=0.23015087842941284, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/29, Loss=0.14905756190419198
Loss made of: CE 0.15915802121162415, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.15672186240553856
Loss made of: CE 0.11274044215679169, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1481970250606537, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.1481970250606537, Class Loss=0.1481970250606537, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/29, Loss=0.14178832471370698
Loss made of: CE 0.1130935549736023, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.14412580505013467
Loss made of: CE 0.11049072444438934, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.13747911155223846, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.13747911155223846, Class Loss=0.13747911155223846, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/29, Loss=0.125103846937418
Loss made of: CE 0.1236778125166893, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.12016634419560432
Loss made of: CE 0.10524281114339828, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.12386377900838852, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.12386377900838852, Class Loss=0.12386377900838852, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/29, Loss=0.12926211804151536
Loss made of: CE 0.09600687026977539, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.10876932889223098
Loss made of: CE 0.11837862432003021, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11773540079593658, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.11773540079593658, Class Loss=0.11773540079593658, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/29, Loss=0.10584783032536507
Loss made of: CE 0.09704011678695679, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.12395339533686638
Loss made of: CE 0.13267602026462555, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.11443004757165909, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.11443004757165909, Class Loss=0.11443004757165909, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.23039249926805497
Loss made of: CE 0.16760055720806122, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.19745789766311644
Loss made of: CE 0.19345375895500183, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.20235136151313782, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.20235136151313782, Class Loss=0.20235136151313782, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/29, Loss=0.14620073810219764
Loss made of: CE 0.12076863646507263, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.1331237107515335
Loss made of: CE 0.10542648285627365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1379062384366989, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.1379062384366989, Class Loss=0.1379062384366989, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/29, Loss=0.1349072128534317
Loss made of: CE 0.10955582559108734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.11945286318659783
Loss made of: CE 0.0983450636267662, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.12417924404144287, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.12417924404144287, Class Loss=0.12417924404144287, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/29, Loss=0.10865668952465057
Loss made of: CE 0.10021603107452393, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.11965009421110154
Loss made of: CE 0.19045042991638184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.11510211229324341, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.11510211229324341, Class Loss=0.11510211229324341, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=0.10776987597346306
Loss made of: CE 0.13247893750667572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.11376250684261321
Loss made of: CE 0.10560236871242523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11394607275724411, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.11394607275724411, Class Loss=0.11394607275724411, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/29, Loss=0.107916921377182
Loss made of: CE 0.1035049557685852, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.09371547102928161
Loss made of: CE 0.08068716526031494, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.10362736880779266, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.10362736880779266, Class Loss=0.10362736880779266, Reg Loss=0.0
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.4126642346382141
Loss made of: CE 0.3853105902671814, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39699721336364746, Reg Loss=0.0
Clinet index 15, End of Epoch 1/6, Average Loss=0.39699721336364746, Class Loss=0.39699721336364746, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=0.2947568342089653
Loss made of: CE 0.22609184682369232, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2815375328063965, Reg Loss=0.0
Clinet index 15, End of Epoch 2/6, Average Loss=0.2815375328063965, Class Loss=0.2815375328063965, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=0.23092892169952392
Loss made of: CE 0.2013261765241623, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23260144889354706, Reg Loss=0.0
Clinet index 15, End of Epoch 3/6, Average Loss=0.23260144889354706, Class Loss=0.23260144889354706, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=0.2067589655518532
Loss made of: CE 0.21092896163463593, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2057829201221466, Reg Loss=0.0
Clinet index 15, End of Epoch 4/6, Average Loss=0.2057829201221466, Class Loss=0.2057829201221466, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=0.2046550288796425
Loss made of: CE 0.15713827311992645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19811099767684937, Reg Loss=0.0
Clinet index 15, End of Epoch 5/6, Average Loss=0.19811099767684937, Class Loss=0.19811099767684937, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=0.20027128010988235
Loss made of: CE 0.17022103071212769, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1955515295267105, Reg Loss=0.0
Clinet index 15, End of Epoch 6/6, Average Loss=0.1955515295267105, Class Loss=0.1955515295267105, Reg Loss=0.0
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=0.4601610451936722
Loss made of: CE 0.36153602600097656, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.44422370195388794, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.44422370195388794, Class Loss=0.44422370195388794, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/13, Loss=0.3024683102965355
Loss made of: CE 0.28036996722221375, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31908664107322693, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.31908664107322693, Class Loss=0.31908664107322693, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.26689276546239854
Loss made of: CE 0.23006145656108856, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2628052234649658, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.2628052234649658, Class Loss=0.2628052234649658, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/13, Loss=0.24149110019207
Loss made of: CE 0.2589585483074188, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23937244713306427, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.23937244713306427, Class Loss=0.23937244713306427, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/13, Loss=0.21195044815540315
Loss made of: CE 0.1917037069797516, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21768338978290558, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.21768338978290558, Class Loss=0.21768338978290558, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/13, Loss=0.2243093490600586
Loss made of: CE 0.22437560558319092, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2142668068408966, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.2142668068408966, Class Loss=0.2142668068408966, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.8924939632415771, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.787147
Mean Acc: 0.168400
FreqW Acc: 0.643741
Mean IoU: 0.116176
Class IoU:
	class 0: 0.82589173
	class 1: 0.05912875
	class 2: 0.0
	class 3: 0.005367501
	class 4: 0.08036272
	class 5: 0.0020203984
	class 6: 0.09420615
	class 7: 9.7978846e-05
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.13345975
	class 12: 0.30974683
Class Acc:
	class 0: 0.9906009
	class 1: 0.059142526
	class 2: 0.0
	class 3: 0.005367501
	class 4: 0.08084542
	class 5: 0.0020203984
	class 6: 0.09422525
	class 7: 9.7978846e-05
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.15278603
	class 12: 0.8041168

federated global round: 14, step: 2
select part of clients to conduct local training
[17, 3, 12, 16]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.26467725932598113
Loss made of: CE 0.1306498944759369, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.2238416165113449
Loss made of: CE 0.17445698380470276, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.21303381025791168, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.21303381025791168, Class Loss=0.21303381025791168, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=0.12684320509433747
Loss made of: CE 0.09967182576656342, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.13628291860222816
Loss made of: CE 0.13951171934604645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.12959784269332886, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.12959784269332886, Class Loss=0.12959784269332886, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=0.1243370570242405
Loss made of: CE 0.12652899324893951, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.13680558800697326
Loss made of: CE 0.11895069479942322, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.12731920182704926, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.12731920182704926, Class Loss=0.12731920182704926, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=0.1138407602906227
Loss made of: CE 0.15002599358558655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.11774660423398017
Loss made of: CE 0.10387818515300751, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.11776985228061676, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.11776985228061676, Class Loss=0.11776985228061676, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=0.11484218910336494
Loss made of: CE 0.10047232359647751, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.1040125384926796
Loss made of: CE 0.10345395654439926, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11349331587553024, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.11349331587553024, Class Loss=0.11349331587553024, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=0.10860307216644287
Loss made of: CE 0.1194809302687645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.1221065990626812
Loss made of: CE 0.09662150591611862, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.11914434283971786, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.11914434283971786, Class Loss=0.11914434283971786, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.23523157685995102
Loss made of: CE 0.19588398933410645, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.17481206953525544
Loss made of: CE 0.1352541744709015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1904553771018982, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.1904553771018982, Class Loss=0.1904553771018982, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=0.13853599801659583
Loss made of: CE 0.10094213485717773, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.11945155486464501
Loss made of: CE 0.2021920382976532, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.12892496585845947, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.12892496585845947, Class Loss=0.12892496585845947, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=0.14312465861439705
Loss made of: CE 0.09820383787155151, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.1192576602101326
Loss made of: CE 0.10833203792572021, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.12910665571689606, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.12910665571689606, Class Loss=0.12910665571689606, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=0.1256608709692955
Loss made of: CE 0.11596488952636719, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.123320934176445
Loss made of: CE 0.09994232654571533, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.12363747507333755, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.12363747507333755, Class Loss=0.12363747507333755, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=0.11535615101456642
Loss made of: CE 0.09661885350942612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.10647306814789773
Loss made of: CE 0.0937461256980896, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11474388092756271, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.11474388092756271, Class Loss=0.11474388092756271, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=0.11199669092893601
Loss made of: CE 0.10308142751455307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.11239981651306152
Loss made of: CE 0.130225270986557, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.11268150806427002, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.11268150806427002, Class Loss=0.11268150806427002, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.4374015212059021
Loss made of: CE 0.28680893778800964, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4100274443626404, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.4100274443626404, Class Loss=0.4100274443626404, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=0.27563446611166
Loss made of: CE 0.2419125735759735, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2708171010017395, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.2708171010017395, Class Loss=0.2708171010017395, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.2439186006784439
Loss made of: CE 0.20577184855937958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2434338480234146, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.2434338480234146, Class Loss=0.2434338480234146, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=0.21489557176828383
Loss made of: CE 0.1920991986989975, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22587822377681732, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.22587822377681732, Class Loss=0.22587822377681732, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=0.22681084871292115
Loss made of: CE 0.23492757976055145, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21827057003974915, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.21827057003974915, Class Loss=0.21827057003974915, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=0.2007368579506874
Loss made of: CE 0.178045392036438, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20504418015480042, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.20504418015480042, Class Loss=0.20504418015480042, Reg Loss=0.0
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/29, Loss=0.2621056616306305
Loss made of: CE 0.18011248111724854, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.18266814053058625
Loss made of: CE 0.17859569191932678, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.20772331953048706, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.20772331953048706, Class Loss=0.20772331953048706, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/29, Loss=0.15006135776638985
Loss made of: CE 0.13412973284721375, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.13828031793236734
Loss made of: CE 0.1119045838713646, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1418035477399826, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.1418035477399826, Class Loss=0.1418035477399826, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/29, Loss=0.12433695197105407
Loss made of: CE 0.11801330745220184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.115691077709198
Loss made of: CE 0.09998530149459839, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1237901821732521, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.1237901821732521, Class Loss=0.1237901821732521, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/29, Loss=0.12277324944734573
Loss made of: CE 0.12714560329914093, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.11740182042121887
Loss made of: CE 0.12360236048698425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.11713647097349167, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.11713647097349167, Class Loss=0.11713647097349167, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/29, Loss=0.12180239483714103
Loss made of: CE 0.13304153084754944, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.11392868235707283
Loss made of: CE 0.07736972719430923, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.11760447174310684, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.11760447174310684, Class Loss=0.11760447174310684, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/29, Loss=0.11970836147665978
Loss made of: CE 0.09823062270879745, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.11142614781856537
Loss made of: CE 0.09309230744838715, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.11624441295862198, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.11624441295862198, Class Loss=0.11624441295862198, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.9731962084770203, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.788200
Mean Acc: 0.158742
FreqW Acc: 0.649842
Mean IoU: 0.098589
Class IoU:
	class 0: 0.83997214
	class 1: 0.025286917
	class 2: 0.0
	class 3: 0.00014884732
	class 4: 0.053422254
	class 5: 0.0
	class 6: 0.04005337
	class 7: 4.1693124e-06
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.01024892
	class 12: 0.31251422
Class Acc:
	class 0: 0.9918024
	class 1: 0.025286932
	class 2: 0.0
	class 3: 0.00014884732
	class 4: 0.053596225
	class 5: 0.0
	class 6: 0.04005449
	class 7: 4.1693124e-06
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.01025883
	class 12: 0.94249105

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[13, 9, 6, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=1.574663519859314
Loss made of: CE 1.16905677318573, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.5211894512176514, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=1.5211894512176514, Class Loss=1.5211894512176514, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=0.8057173907756805
Loss made of: CE 0.472320556640625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7672380208969116, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.7672380208969116, Class Loss=0.7672380208969116, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=0.32114005982875826
Loss made of: CE 0.2579691410064697, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3115687966346741, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.3115687966346741, Class Loss=0.3115687966346741, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=0.19362907260656356
Loss made of: CE 0.159674733877182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18747299909591675, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.18747299909591675, Class Loss=0.18747299909591675, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=0.15899267941713333
Loss made of: CE 0.18549184501171112, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1579643040895462, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.1579643040895462, Class Loss=0.1579643040895462, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=0.1460670217871666
Loss made of: CE 0.13584712147712708, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1453048437833786, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.1453048437833786, Class Loss=0.1453048437833786, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.9145851612091065
Loss made of: CE 1.7403504848480225, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.784496545791626, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=1.784496545791626, Class Loss=1.784496545791626, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=0.9606434822082519
Loss made of: CE 0.6277641654014587, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.915655791759491, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.915655791759491, Class Loss=0.915655791759491, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.4335055470466614
Loss made of: CE 0.37590885162353516, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.40783756971359253, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.40783756971359253, Class Loss=0.40783756971359253, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.26394656151533125
Loss made of: CE 0.23642683029174805, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25748753547668457, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.25748753547668457, Class Loss=0.25748753547668457, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.2069161653518677
Loss made of: CE 0.1837633103132248, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2056264579296112, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.2056264579296112, Class Loss=0.2056264579296112, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.18669066280126573
Loss made of: CE 0.1444578915834427, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18776266276836395, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.18776266276836395, Class Loss=0.18776266276836395, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=1.531630003452301
Loss made of: CE 1.341912031173706, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.5015865564346313, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=1.5015865564346313, Class Loss=1.5015865564346313, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=0.78394535779953
Loss made of: CE 0.7315323352813721, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7690110802650452, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.7690110802650452, Class Loss=0.7690110802650452, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=0.3272954747080803
Loss made of: CE 0.2590565085411072, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3147103786468506, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.3147103786468506, Class Loss=0.3147103786468506, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=0.19059866964817046
Loss made of: CE 0.1792108416557312, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18981236219406128, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.18981236219406128, Class Loss=0.18981236219406128, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=0.16935622841119766
Loss made of: CE 0.1879945993423462, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16923771798610687, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.16923771798610687, Class Loss=0.16923771798610687, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=0.14412497878074645
Loss made of: CE 0.1176941841840744, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14499393105506897, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.14499393105506897, Class Loss=0.14499393105506897, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.7670890808105468
Loss made of: CE 1.6358463764190674, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.751843810081482, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=1.751843810081482, Class Loss=1.751843810081482, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=0.9847610592842102
Loss made of: CE 0.7605261206626892, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9361628890037537, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.9361628890037537, Class Loss=0.9361628890037537, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.4197968691587448
Loss made of: CE 0.353924036026001, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.40726834535598755, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.40726834535598755, Class Loss=0.40726834535598755, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.26517138779163363
Loss made of: CE 0.30463555455207825, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26619482040405273, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.26619482040405273, Class Loss=0.26619482040405273, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.2222343787550926
Loss made of: CE 0.27089089155197144, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21954557299613953, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.21954557299613953, Class Loss=0.21954557299613953, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.20208678990602494
Loss made of: CE 0.18721416592597961, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19942396879196167, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.19942396879196167, Class Loss=0.19942396879196167, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.8259665966033936, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.769503
Mean Acc: 0.147088
FreqW Acc: 0.611967
Mean IoU: 0.117066
Class IoU:
	class 0: 0.7943271
	class 1: 0.2200801
	class 2: 0.060724974
	class 3: 0.1609817
	class 4: 0.15748368
	class 5: 0.02139638
	class 6: 0.104813494
	class 7: 0.004559843
	class 8: 0.010147561
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0009596914
	class 12: 0.02432684
	class 13: 0.1361729
	class 14: 0.060018454
Class Acc:
	class 0: 0.99818015
	class 1: 0.22022392
	class 2: 0.06244396
	class 3: 0.16101758
	class 4: 0.15993042
	class 5: 0.021400623
	class 6: 0.10483752
	class 7: 0.004570048
	class 8: 0.010148262
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0010078364
	class 12: 0.025712535
	class 13: 0.3490272
	class 14: 0.087815285

federated global round: 16, step: 3
select part of clients to conduct local training
[18, 5, 20, 0]
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.519048061966896
Loss made of: CE 0.3806086480617523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.522872805595398, Reg Loss=0.0
Clinet index 18, End of Epoch 1/6, Average Loss=0.522872805595398, Class Loss=0.522872805595398, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.3337627649307251
Loss made of: CE 0.25901302695274353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3136635422706604, Reg Loss=0.0
Clinet index 18, End of Epoch 2/6, Average Loss=0.3136635422706604, Class Loss=0.3136635422706604, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.2229769319295883
Loss made of: CE 0.2108379304409027, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2217411994934082, Reg Loss=0.0
Clinet index 18, End of Epoch 3/6, Average Loss=0.2217411994934082, Class Loss=0.2217411994934082, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.192140594124794
Loss made of: CE 0.17077873647212982, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1913282573223114, Reg Loss=0.0
Clinet index 18, End of Epoch 4/6, Average Loss=0.1913282573223114, Class Loss=0.1913282573223114, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.17287577390670777
Loss made of: CE 0.1652192622423172, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18176637589931488, Reg Loss=0.0
Clinet index 18, End of Epoch 5/6, Average Loss=0.18176637589931488, Class Loss=0.18176637589931488, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.17236578315496445
Loss made of: CE 0.16593503952026367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1695934236049652, Reg Loss=0.0
Clinet index 18, End of Epoch 6/6, Average Loss=0.1695934236049652, Class Loss=0.1695934236049652, Reg Loss=0.0
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.5136689156293869
Loss made of: CE 0.492969810962677, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.51466965675354, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.51466965675354, Class Loss=0.51466965675354, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=0.3359226584434509
Loss made of: CE 0.3176271915435791, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32521146535873413, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.32521146535873413, Class Loss=0.32521146535873413, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=0.24045149087905884
Loss made of: CE 0.23070089519023895, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24364635348320007, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.24364635348320007, Class Loss=0.24364635348320007, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=0.21022421717643738
Loss made of: CE 0.2814827561378479, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.215127632021904, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.215127632021904, Class Loss=0.215127632021904, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.1995985686779022
Loss made of: CE 0.26819556951522827, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1950206160545349, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.1950206160545349, Class Loss=0.1950206160545349, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=0.18724117875099183
Loss made of: CE 0.1854228973388672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18962857127189636, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.18962857127189636, Class Loss=0.18962857127189636, Reg Loss=0.0
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.5263182818889618
Loss made of: CE 0.6136549711227417, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5081961154937744, Reg Loss=0.0
Clinet index 20, End of Epoch 1/6, Average Loss=0.5081961154937744, Class Loss=0.5081961154937744, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.30843349993228913
Loss made of: CE 0.2599642872810364, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.288830041885376, Reg Loss=0.0
Clinet index 20, End of Epoch 2/6, Average Loss=0.288830041885376, Class Loss=0.288830041885376, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.22327875941991807
Loss made of: CE 0.23730282485485077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21790632605552673, Reg Loss=0.0
Clinet index 20, End of Epoch 3/6, Average Loss=0.21790632605552673, Class Loss=0.21790632605552673, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.19306480884552002
Loss made of: CE 0.13511401414871216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1901376098394394, Reg Loss=0.0
Clinet index 20, End of Epoch 4/6, Average Loss=0.1901376098394394, Class Loss=0.1901376098394394, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.17118455320596696
Loss made of: CE 0.15381139516830444, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17069140076637268, Reg Loss=0.0
Clinet index 20, End of Epoch 5/6, Average Loss=0.17069140076637268, Class Loss=0.17069140076637268, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.15390690341591834
Loss made of: CE 0.197027787566185, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15693289041519165, Reg Loss=0.0
Clinet index 20, End of Epoch 6/6, Average Loss=0.15693289041519165, Class Loss=0.15693289041519165, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.3807465761899948
Loss made of: CE 0.32842493057250977, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.37137898802757263, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.37137898802757263, Class Loss=0.37137898802757263, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/11, Loss=0.25495985299348833
Loss made of: CE 0.16700801253318787, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24688391387462616, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.24688391387462616, Class Loss=0.24688391387462616, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/11, Loss=0.18965642005205155
Loss made of: CE 0.1773751676082611, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1879955679178238, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.1879955679178238, Class Loss=0.1879955679178238, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/11, Loss=0.1698564313352108
Loss made of: CE 0.17524729669094086, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1682531088590622, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.1682531088590622, Class Loss=0.1682531088590622, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/11, Loss=0.15908170640468597
Loss made of: CE 0.16496509313583374, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1603914052248001, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.1603914052248001, Class Loss=0.1603914052248001, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/11, Loss=0.14588535502552985
Loss made of: CE 0.11298114061355591, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14473310112953186, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.14473310112953186, Class Loss=0.14473310112953186, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.9776259660720825, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.762294
Mean Acc: 0.143252
FreqW Acc: 0.620699
Mean IoU: 0.084693
Class IoU:
	class 0: 0.8164797
	class 1: 0.118510924
	class 2: 0.0007020208
	class 3: 0.023812076
	class 4: 0.1191021
	class 5: 0.00048751937
	class 6: 0.04210106
	class 7: 0.00016276349
	class 8: 0.00064482994
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00029710843
	class 14: 0.1481002
Class Acc:
	class 0: 0.9892619
	class 1: 0.11856425
	class 2: 0.0007023906
	class 3: 0.023812743
	class 4: 0.120118566
	class 5: 0.00048751937
	class 6: 0.042105384
	class 7: 0.00016276355
	class 8: 0.00064482994
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.00029748748
	class 14: 0.8526266

federated global round: 17, step: 3
select part of clients to conduct local training
[1, 16, 6, 21]
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.5858739048242569
Loss made of: CE 0.4063844084739685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5806598663330078, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.5806598663330078, Class Loss=0.5806598663330078, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=0.2626574143767357
Loss made of: CE 0.1747661679983139, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.25715890526771545, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.25715890526771545, Class Loss=0.25715890526771545, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=0.17629775851964952
Loss made of: CE 0.1333717703819275, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.17377687990665436, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.17377687990665436, Class Loss=0.17377687990665436, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=0.15115357786417008
Loss made of: CE 0.14440850913524628, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15295934677124023, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.15295934677124023, Class Loss=0.15295934677124023, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=0.14092910885810853
Loss made of: CE 0.14000844955444336, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14129796624183655, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.14129796624183655, Class Loss=0.14129796624183655, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=0.13831643462181092
Loss made of: CE 0.14294913411140442, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14033475518226624, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.14033475518226624, Class Loss=0.14033475518226624, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.5967218935489654
Loss made of: CE 0.41782093048095703, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5789664387702942, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.5789664387702942, Class Loss=0.5789664387702942, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=0.2676676481962204
Loss made of: CE 0.22469207644462585, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.25740084052085876, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.25740084052085876, Class Loss=0.25740084052085876, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=0.17050403505563735
Loss made of: CE 0.16248026490211487, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16806377470493317, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.16806377470493317, Class Loss=0.16806377470493317, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=0.15982147604227065
Loss made of: CE 0.15467338263988495, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15554414689540863, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.15554414689540863, Class Loss=0.15554414689540863, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=0.14258925393223762
Loss made of: CE 0.14594677090644836, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14325645565986633, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.14325645565986633, Class Loss=0.14325645565986633, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=0.12833708971738816
Loss made of: CE 0.10710702836513519, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13092194497585297, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.13092194497585297, Class Loss=0.13092194497585297, Reg Loss=0.0
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/11, Loss=0.6370263636112213
Loss made of: CE 0.519976019859314, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6191830635070801, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.6191830635070801, Class Loss=0.6191830635070801, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/11, Loss=0.3046773999929428
Loss made of: CE 0.3385860323905945, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3003470003604889, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.3003470003604889, Class Loss=0.3003470003604889, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/11, Loss=0.1925068274140358
Loss made of: CE 0.20830845832824707, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19064825773239136, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.19064825773239136, Class Loss=0.19064825773239136, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/11, Loss=0.15511834025382995
Loss made of: CE 0.17732927203178406, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15542009472846985, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.15542009472846985, Class Loss=0.15542009472846985, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/11, Loss=0.14662172198295592
Loss made of: CE 0.15612129867076874, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14764173328876495, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.14764173328876495, Class Loss=0.14764173328876495, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/11, Loss=0.13775926008820533
Loss made of: CE 0.11871715635061264, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1377890259027481, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.1377890259027481, Class Loss=0.1377890259027481, Reg Loss=0.0
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.22285026162862778
Loss made of: CE 0.17917248606681824, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.22639726102352142, Reg Loss=0.0
Clinet index 21, End of Epoch 1/6, Average Loss=0.22639726102352142, Class Loss=0.22639726102352142, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=0.19450607597827912
Loss made of: CE 0.19071528315544128, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.19393369555473328, Reg Loss=0.0
Clinet index 21, End of Epoch 2/6, Average Loss=0.19393369555473328, Class Loss=0.19393369555473328, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=0.1879693627357483
Loss made of: CE 0.1753040999174118, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18563906848430634, Reg Loss=0.0
Clinet index 21, End of Epoch 3/6, Average Loss=0.18563906848430634, Class Loss=0.18563906848430634, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.17870321571826936
Loss made of: CE 0.15609022974967957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17201629281044006, Reg Loss=0.0
Clinet index 21, End of Epoch 4/6, Average Loss=0.17201629281044006, Class Loss=0.17201629281044006, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.15066102743148804
Loss made of: CE 0.16009621322155, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16137617826461792, Reg Loss=0.0
Clinet index 21, End of Epoch 5/6, Average Loss=0.16137617826461792, Class Loss=0.16137617826461792, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.15605394542217255
Loss made of: CE 0.13128945231437683, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1551055908203125, Reg Loss=0.0
Clinet index 21, End of Epoch 6/6, Average Loss=0.1551055908203125, Class Loss=0.1551055908203125, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.0751538276672363, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.763474
Mean Acc: 0.139374
FreqW Acc: 0.635054
Mean IoU: 0.077270
Class IoU:
	class 0: 0.83799833
	class 1: 0.02472258
	class 2: 0.0050548506
	class 3: 0.00015038978
	class 4: 0.0846286
	class 5: 0.0006591853
	class 6: 0.011149688
	class 7: 3.2060046e-07
	class 8: 4.7825483e-06
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.13523354
	class 14: 0.05944094
Class Acc:
	class 0: 0.9909551
	class 1: 0.024726633
	class 2: 0.0050736973
	class 3: 0.00015038978
	class 4: 0.08528644
	class 5: 0.0006591853
	class 6: 0.011150063
	class 7: 3.2071634e-07
	class 8: 4.7825483e-06
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.9108028
	class 14: 0.061803028

federated global round: 18, step: 3
select part of clients to conduct local training
[8, 2, 17, 14]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.18219765573740004
Loss made of: CE 0.16157318651676178, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.18066631257534027, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.18066631257534027, Class Loss=0.18066631257534027, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=0.15614559277892112
Loss made of: CE 0.14910992980003357, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1542004644870758, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.1542004644870758, Class Loss=0.1542004644870758, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=0.14162855669856073
Loss made of: CE 0.1343879997730255, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1459377557039261, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.1459377557039261, Class Loss=0.1459377557039261, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=0.13374853059649466
Loss made of: CE 0.10680016130208969, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13250097632408142, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.13250097632408142, Class Loss=0.13250097632408142, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=0.12781952321529388
Loss made of: CE 0.14307235181331635, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.12819595634937286, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.12819595634937286, Class Loss=0.12819595634937286, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=0.1228118970990181
Loss made of: CE 0.1284894347190857, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.12247103452682495, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.12247103452682495, Class Loss=0.12247103452682495, Reg Loss=0.0
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.1708146832883358
Loss made of: CE 0.15405330061912537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.17358815670013428, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.17358815670013428, Class Loss=0.17358815670013428, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=0.16555757373571395
Loss made of: CE 0.12161785364151001, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16144852340221405, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.16144852340221405, Class Loss=0.16144852340221405, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=0.14697541296482086
Loss made of: CE 0.12025806307792664, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14482033252716064, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.14482033252716064, Class Loss=0.14482033252716064, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=0.13328018710017203
Loss made of: CE 0.11897285282611847, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13421545922756195, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.13421545922756195, Class Loss=0.13421545922756195, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=0.12826588675379752
Loss made of: CE 0.11763007938861847, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.12665030360221863, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.12665030360221863, Class Loss=0.12665030360221863, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=0.12672176212072372
Loss made of: CE 0.14364948868751526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.12670809030532837, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.12670809030532837, Class Loss=0.12670809030532837, Reg Loss=0.0
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.5543522268533707
Loss made of: CE 0.43722400069236755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.518159806728363, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.518159806728363, Class Loss=0.518159806728363, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.25922001153230667
Loss made of: CE 0.17144310474395752, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24908855557441711, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.24908855557441711, Class Loss=0.24908855557441711, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.18866952657699584
Loss made of: CE 0.16828660666942596, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18573085963726044, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.18573085963726044, Class Loss=0.18573085963726044, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.18261462748050689
Loss made of: CE 0.14205387234687805, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17752796411514282, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.17752796411514282, Class Loss=0.17752796411514282, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.170895953476429
Loss made of: CE 0.1671406477689743, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1901862621307373, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.1901862621307373, Class Loss=0.1901862621307373, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.1802309826016426
Loss made of: CE 0.1482008993625641, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17321649193763733, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.17321649193763733, Class Loss=0.17321649193763733, Reg Loss=0.0
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.1822674334049225
Loss made of: CE 0.17098943889141083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1818484514951706, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.1818484514951706, Class Loss=0.1818484514951706, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=0.15971539169549942
Loss made of: CE 0.13896839320659637, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1614566147327423, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.1614566147327423, Class Loss=0.1614566147327423, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=0.1444347009062767
Loss made of: CE 0.15222090482711792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14515230059623718, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.14515230059623718, Class Loss=0.14515230059623718, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=0.15038879960775375
Loss made of: CE 0.1254068911075592, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14987090229988098, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.14987090229988098, Class Loss=0.14987090229988098, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=0.1324356123805046
Loss made of: CE 0.12825864553451538, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13141188025474548, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.13141188025474548, Class Loss=0.13141188025474548, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=0.12267632782459259
Loss made of: CE 0.12218821048736572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1232791393995285, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.1232791393995285, Class Loss=0.1232791393995285, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.1276980638504028, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.763445
Mean Acc: 0.139694
FreqW Acc: 0.635392
Mean IoU: 0.076455
Class IoU:
	class 0: 0.8384946
	class 1: 0.013601345
	class 2: 0.0011514897
	class 3: 1.2853827e-06
	class 4: 0.066502355
	class 5: 0.00011523185
	class 6: 0.0058768233
	class 7: 0.0
	class 8: 5.0878174e-07
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.13704428
	class 14: 0.084031664
Class Acc:
	class 0: 0.99055237
	class 1: 0.013602612
	class 2: 0.001152494
	class 3: 1.2853827e-06
	class 4: 0.06689877
	class 5: 0.00011523185
	class 6: 0.0058770212
	class 7: 0.0
	class 8: 5.0878174e-07
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.9284873
	class 14: 0.0887166

federated global round: 19, step: 3
select part of clients to conduct local training
[1, 9, 8, 0]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/11, Loss=0.15703748241066934
Loss made of: CE 0.13997554779052734, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.16236698627471924, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.16236698627471924, Class Loss=0.16236698627471924, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/11, Loss=0.15010125637054444
Loss made of: CE 0.13465791940689087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.14993873238563538, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.14993873238563538, Class Loss=0.14993873238563538, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/11, Loss=0.14952457547187806
Loss made of: CE 0.12117783725261688, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14701472222805023, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.14701472222805023, Class Loss=0.14701472222805023, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/11, Loss=0.136022686958313
Loss made of: CE 0.13120204210281372, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.13981986045837402, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.13981986045837402, Class Loss=0.13981986045837402, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/11, Loss=0.1329742632806301
Loss made of: CE 0.1440770924091339, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13292767107486725, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.13292767107486725, Class Loss=0.13292767107486725, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/11, Loss=0.1381256453692913
Loss made of: CE 0.15003275871276855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14004649221897125, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.14004649221897125, Class Loss=0.14004649221897125, Reg Loss=0.0
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.5564307391643524
Loss made of: CE 0.45550090074539185, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5170618295669556, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.5170618295669556, Class Loss=0.5170618295669556, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/12, Loss=0.27803590446710585
Loss made of: CE 0.21903102099895477, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2709576487541199, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.2709576487541199, Class Loss=0.2709576487541199, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/12, Loss=0.20872089862823487
Loss made of: CE 0.21155989170074463, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2022223323583603, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.2022223323583603, Class Loss=0.2022223323583603, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/12, Loss=0.18573762476444244
Loss made of: CE 0.1864117980003357, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18346470594406128, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.18346470594406128, Class Loss=0.18346470594406128, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/12, Loss=0.17536625117063523
Loss made of: CE 0.16461634635925293, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1736404299736023, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.1736404299736023, Class Loss=0.1736404299736023, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/12, Loss=0.17737363874912263
Loss made of: CE 0.15643945336341858, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17789076268672943, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.17789076268672943, Class Loss=0.17789076268672943, Reg Loss=0.0
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/11, Loss=0.16311538890004157
Loss made of: CE 0.14138470590114594, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.16290199756622314, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.16290199756622314, Class Loss=0.16290199756622314, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/11, Loss=0.14830576926469802
Loss made of: CE 0.1406712383031845, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.147139772772789, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.147139772772789, Class Loss=0.147139772772789, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/11, Loss=0.14538683742284775
Loss made of: CE 0.1356353908777237, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14736847579479218, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.14736847579479218, Class Loss=0.14736847579479218, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/11, Loss=0.14106498509645463
Loss made of: CE 0.11113227903842926, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14030320942401886, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.14030320942401886, Class Loss=0.14030320942401886, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/11, Loss=0.13608909994363785
Loss made of: CE 0.14455367624759674, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1376306414604187, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.1376306414604187, Class Loss=0.1376306414604187, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/11, Loss=0.13580209165811538
Loss made of: CE 0.13485153019428253, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1345423012971878, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.1345423012971878, Class Loss=0.1345423012971878, Reg Loss=0.0
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/11, Loss=0.16988705545663835
Loss made of: CE 0.1633126139640808, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.16994456946849823, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.16994456946849823, Class Loss=0.16994456946849823, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/11, Loss=0.16491539180278778
Loss made of: CE 0.1205577701330185, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16088734567165375, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.16088734567165375, Class Loss=0.16088734567165375, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/11, Loss=0.1503182291984558
Loss made of: CE 0.15739518404006958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14904525876045227, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.14904525876045227, Class Loss=0.14904525876045227, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/11, Loss=0.1432775564491749
Loss made of: CE 0.14860233664512634, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14484810829162598, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.14484810829162598, Class Loss=0.14484810829162598, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/11, Loss=0.13641149699687957
Loss made of: CE 0.12784621119499207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1382886916399002, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.1382886916399002, Class Loss=0.1382886916399002, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/11, Loss=0.14051651880145072
Loss made of: CE 0.11176691949367523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1388043761253357, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.1388043761253357, Class Loss=0.1388043761253357, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.1421619653701782, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.764696
Mean Acc: 0.147074
FreqW Acc: 0.637642
Mean IoU: 0.082117
Class IoU:
	class 0: 0.83964187
	class 1: 0.013779668
	class 2: 0.0008075414
	class 3: 5.141531e-07
	class 4: 0.065208994
	class 5: 2.0091707e-05
	class 6: 0.004932598
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.13941604
	class 14: 0.16795236
Class Acc:
	class 0: 0.9897605
	class 1: 0.013781001
	class 2: 0.0008077492
	class 3: 5.141531e-07
	class 4: 0.06560929
	class 5: 2.0091707e-05
	class 6: 0.0049327607
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.9350264
	class 14: 0.19616616

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[11, 2, 15, 6]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.6539433121681213
Loss made of: CE 1.8019893169403076, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.5805513858795166, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=1.5805513858795166, Class Loss=1.5805513858795166, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.0654404997825622
Loss made of: CE 0.9530520439147949, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.0897332429885864, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=1.0897332429885864, Class Loss=1.0897332429885864, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.7196252703666687
Loss made of: CE 0.7132242918014526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7285559177398682, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.7285559177398682, Class Loss=0.7285559177398682, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.5732587218284607
Loss made of: CE 0.5137907266616821, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5544278025627136, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.5544278025627136, Class Loss=0.5544278025627136, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.4674661487340927
Loss made of: CE 0.32598060369491577, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.45054373145103455, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.45054373145103455, Class Loss=0.45054373145103455, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.4050617128610611
Loss made of: CE 0.5081560611724854, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4171578288078308, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.4171578288078308, Class Loss=0.4171578288078308, Reg Loss=0.0
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.5793605327606202
Loss made of: CE 1.7637789249420166, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.5628513097763062, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=1.5628513097763062, Class Loss=1.5628513097763062, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.1253565728664399
Loss made of: CE 0.8951045870780945, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.0663648843765259, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=1.0663648843765259, Class Loss=1.0663648843765259, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.729520320892334
Loss made of: CE 0.5471314191818237, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7180200815200806, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.7180200815200806, Class Loss=0.7180200815200806, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.5532337814569473
Loss made of: CE 0.48581239581108093, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5456370115280151, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.5456370115280151, Class Loss=0.5456370115280151, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.464926877617836
Loss made of: CE 0.4128997325897217, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.446708083152771, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.446708083152771, Class Loss=0.446708083152771, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.43134562075138094
Loss made of: CE 0.46849867701530457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4276604652404785, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.4276604652404785, Class Loss=0.4276604652404785, Reg Loss=0.0
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.618116521835327
Loss made of: CE 1.8391849994659424, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.5668988227844238, Reg Loss=0.0
Clinet index 15, End of Epoch 1/6, Average Loss=1.5668988227844238, Class Loss=1.5668988227844238, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.1176268577575683
Loss made of: CE 1.000605821609497, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.0647060871124268, Reg Loss=0.0
Clinet index 15, End of Epoch 2/6, Average Loss=1.0647060871124268, Class Loss=1.0647060871124268, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.7337070584297181
Loss made of: CE 0.7697133421897888, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.734947144985199, Reg Loss=0.0
Clinet index 15, End of Epoch 3/6, Average Loss=0.734947144985199, Class Loss=0.734947144985199, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.5715994864702225
Loss made of: CE 0.43889492750167847, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5601220726966858, Reg Loss=0.0
Clinet index 15, End of Epoch 4/6, Average Loss=0.5601220726966858, Class Loss=0.5601220726966858, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.47818818092346194
Loss made of: CE 0.4928319454193115, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.48151344060897827, Reg Loss=0.0
Clinet index 15, End of Epoch 5/6, Average Loss=0.48151344060897827, Class Loss=0.48151344060897827, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.3925661206245422
Loss made of: CE 0.4140129089355469, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.39546388387680054, Reg Loss=0.0
Clinet index 15, End of Epoch 6/6, Average Loss=0.39546388387680054, Class Loss=0.39546388387680054, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=1.6280405640602111
Loss made of: CE 1.2712841033935547, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=1.2231493711471557
Loss made of: CE 1.0474522113800049, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.6949851155281067
Loss made of: CE 0.5723369717597961, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.4144641488790512
Loss made of: CE 0.2935551106929779, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.26060552299022677
Loss made of: CE 0.2352307289838791, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.27454533725976943
Loss made of: CE 0.3154783248901367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.26028347462415696
Loss made of: CE 0.3231964111328125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.22780976444482803
Loss made of: CE 0.20238664746284485, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.24177332669496537
Loss made of: CE 0.22064527869224548, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5544739365577698, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.5544739365577698, Class Loss=0.5544739365577698, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/97, Loss=0.20377150028944016
Loss made of: CE 0.1593746542930603, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.17399151921272277
Loss made of: CE 0.2440861463546753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.18493718951940535
Loss made of: CE 0.12668977677822113, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.18103967756032943
Loss made of: CE 0.16877451539039612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.1883878529071808
Loss made of: CE 0.17142999172210693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.19540319144725798
Loss made of: CE 0.24133890867233276, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.18358421921730042
Loss made of: CE 0.133992999792099, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.19436887353658677
Loss made of: CE 0.1685376614332199, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.1955335631966591
Loss made of: CE 0.18661722540855408, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.18855442106723785, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.18855442106723785, Class Loss=0.18855442106723785, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/97, Loss=0.18614899069070817
Loss made of: CE 0.17097805440425873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.16574536710977555
Loss made of: CE 0.16990017890930176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.1539985828101635
Loss made of: CE 0.09687598794698715, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.16157908737659454
Loss made of: CE 0.19054067134857178, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.16711625456809998
Loss made of: CE 0.13362303376197815, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.16833426803350449
Loss made of: CE 0.23745720088481903, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.1739116095006466
Loss made of: CE 0.14332449436187744, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.1867808759212494
Loss made of: CE 0.16239994764328003, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.1784830778837204
Loss made of: CE 0.15042583644390106, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.17194853723049164, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.17194853723049164, Class Loss=0.17194853723049164, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/97, Loss=0.16341482400894164
Loss made of: CE 0.15208296477794647, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.1784566156566143
Loss made of: CE 0.13291218876838684, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.1540438190102577
Loss made of: CE 0.13732200860977173, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.14155814424157143
Loss made of: CE 0.16987848281860352, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.16924043893814086
Loss made of: CE 0.16711203753948212, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.15870100110769272
Loss made of: CE 0.16177791357040405, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.15677024126052858
Loss made of: CE 0.15283653140068054, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.18049467280507087
Loss made of: CE 0.12162008881568909, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.17927092015743257
Loss made of: CE 0.21928933262825012, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.16232071816921234, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.16232071816921234, Class Loss=0.16232071816921234, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/97, Loss=0.13880790770053864
Loss made of: CE 0.12337185442447662, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.1547406494617462
Loss made of: CE 0.12813310325145721, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.14143222719430923
Loss made of: CE 0.13424354791641235, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.1631619155406952
Loss made of: CE 0.15687912702560425, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.15144152268767358
Loss made of: CE 0.13801485300064087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.14924924150109292
Loss made of: CE 0.0935281366109848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.16783634275197984
Loss made of: CE 0.1264980435371399, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.1398279406130314
Loss made of: CE 0.11168637126684189, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.16140974313020706
Loss made of: CE 0.11611650884151459, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1521347314119339, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.1521347314119339, Class Loss=0.1521347314119339, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/97, Loss=0.1338627628982067
Loss made of: CE 0.11582976579666138, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.14942859560251237
Loss made of: CE 0.10346752405166626, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.13211998865008354
Loss made of: CE 0.12335413694381714, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.14501837491989136
Loss made of: CE 0.15123896300792694, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.1385897882282734
Loss made of: CE 0.10817819833755493, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.16273397579789162
Loss made of: CE 0.1733752340078354, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.13589336574077607
Loss made of: CE 0.1643991470336914, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.13831717297434806
Loss made of: CE 0.15068598091602325, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.15635619536042214
Loss made of: CE 0.1418081820011139, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14453303813934326, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.14453303813934326, Class Loss=0.14453303813934326, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.3575303554534912, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.729319
Mean Acc: 0.100376
FreqW Acc: 0.536362
Mean IoU: 0.078420
Class IoU:
	class 0: 0.72306764
	class 1: 0.0063902074
	class 2: 0.0
	class 3: 0.0014211192
	class 4: 0.04249091
	class 5: 0.0005764547
	class 6: 0.0028573729
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 2.0771482e-07
	class 14: 0.0
	class 15: 0.38885885
	class 16: 0.16748327
Class Acc:
	class 0: 0.995872
	class 1: 0.006390302
	class 2: 0.0
	class 3: 0.0014211192
	class 4: 0.04289396
	class 5: 0.0005764547
	class 6: 0.002858309
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 2.0774266e-07
	class 14: 0.0
	class 15: 0.40096533
	class 16: 0.2554089

federated global round: 21, step: 4
select part of clients to conduct local training
[20, 2, 24, 4]
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.519130477309227
Loss made of: CE 0.35714611411094666, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.335254094004631
Loss made of: CE 0.3345871567726135, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.3082559436559677
Loss made of: CE 0.21487721800804138, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.25967226177453995
Loss made of: CE 0.21059152483940125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.206212642788887
Loss made of: CE 0.23799309134483337, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.21875858306884766
Loss made of: CE 0.17745187878608704, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.21708139181137084
Loss made of: CE 0.2255086600780487, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.194699065387249
Loss made of: CE 0.18772689998149872, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.18326405808329582
Loss made of: CE 0.21041807532310486, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2666756212711334, Reg Loss=0.0
Clinet index 20, End of Epoch 1/6, Average Loss=0.2666756212711334, Class Loss=0.2666756212711334, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/97, Loss=0.18021153658628464
Loss made of: CE 0.21056735515594482, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.17960541546344758
Loss made of: CE 0.2319052517414093, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.17441072911024094
Loss made of: CE 0.16581487655639648, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.17767225354909896
Loss made of: CE 0.2027265727519989, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.17085983380675315
Loss made of: CE 0.18108996748924255, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.17564230114221574
Loss made of: CE 0.19279174506664276, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.19068876206874846
Loss made of: CE 0.21238753199577332, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.18984191864728928
Loss made of: CE 0.15289835631847382, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.15718940868973733
Loss made of: CE 0.17665623128414154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1760491132736206, Reg Loss=0.0
Clinet index 20, End of Epoch 2/6, Average Loss=0.1760491132736206, Class Loss=0.1760491132736206, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/97, Loss=0.16005307212471961
Loss made of: CE 0.1943490207195282, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.15129073783755304
Loss made of: CE 0.14790061116218567, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.1608426406979561
Loss made of: CE 0.12753556668758392, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.15269304066896439
Loss made of: CE 0.18554803729057312, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.16565881595015525
Loss made of: CE 0.12296267598867416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.16696856170892715
Loss made of: CE 0.1380918025970459, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.1503804951906204
Loss made of: CE 0.1298123002052307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.16797903925180435
Loss made of: CE 0.11663037538528442, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.17369853854179382
Loss made of: CE 0.1525927484035492, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16089722514152527, Reg Loss=0.0
Clinet index 20, End of Epoch 3/6, Average Loss=0.16089722514152527, Class Loss=0.16089722514152527, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/97, Loss=0.14352325201034546
Loss made of: CE 0.12932512164115906, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.15446278899908067
Loss made of: CE 0.1294625699520111, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.14527140110731124
Loss made of: CE 0.1009921059012413, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.14995506778359413
Loss made of: CE 0.15247663855552673, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.14754468351602554
Loss made of: CE 0.11277901381254196, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.15223413854837417
Loss made of: CE 0.17297586798667908, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.1380448892712593
Loss made of: CE 0.15992599725723267, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.165081125497818
Loss made of: CE 0.13481490314006805, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.15594042241573333
Loss made of: CE 0.176541268825531, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1488778442144394, Reg Loss=0.0
Clinet index 20, End of Epoch 4/6, Average Loss=0.1488778442144394, Class Loss=0.1488778442144394, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/97, Loss=0.15877940207719804
Loss made of: CE 0.16595028340816498, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.15057879239320754
Loss made of: CE 0.14415037631988525, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.14709731563925743
Loss made of: CE 0.15173089504241943, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.1371672421693802
Loss made of: CE 0.1186991035938263, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.15087577775120736
Loss made of: CE 0.16197410225868225, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.13983757570385932
Loss made of: CE 0.159197136759758, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.1465621657669544
Loss made of: CE 0.10657616704702377, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.137678761780262
Loss made of: CE 0.1269764006137848, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.14598272144794464
Loss made of: CE 0.12847968935966492, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14594505727291107, Reg Loss=0.0
Clinet index 20, End of Epoch 5/6, Average Loss=0.14594505727291107, Class Loss=0.14594505727291107, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/97, Loss=0.13363366648554803
Loss made of: CE 0.13828125596046448, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.1427968867123127
Loss made of: CE 0.1864841878414154, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.13236174285411834
Loss made of: CE 0.12325018644332886, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.14698070660233498
Loss made of: CE 0.14343908429145813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.1289819970726967
Loss made of: CE 0.10326962172985077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.1489115424454212
Loss made of: CE 0.12482458353042603, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.14214510470628738
Loss made of: CE 0.20054221153259277, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.1398658499121666
Loss made of: CE 0.16445887088775635, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.1326113797724247
Loss made of: CE 0.1346721053123474, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13779370486736298, Reg Loss=0.0
Clinet index 20, End of Epoch 6/6, Average Loss=0.13779370486736298, Class Loss=0.13779370486736298, Reg Loss=0.0
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.4078638732433319
Loss made of: CE 0.5342957973480225, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4002072215080261, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.4002072215080261, Class Loss=0.4002072215080261, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=0.3625691384077072
Loss made of: CE 0.3941953182220459, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3524346947669983, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.3524346947669983, Class Loss=0.3524346947669983, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=0.3127036541700363
Loss made of: CE 0.265271931886673, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.30935215950012207, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.30935215950012207, Class Loss=0.30935215950012207, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=0.2842810332775116
Loss made of: CE 0.24397101998329163, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28412118554115295, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.28412118554115295, Class Loss=0.28412118554115295, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.28257495164871216
Loss made of: CE 0.2807410955429077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27335983514785767, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.27335983514785767, Class Loss=0.27335983514785767, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=0.2712388411164284
Loss made of: CE 0.2555159032344818, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.27126848697662354, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.27126848697662354, Class Loss=0.27126848697662354, Reg Loss=0.0
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.38335944414138795
Loss made of: CE 0.31892645359039307, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.38610363006591797, Reg Loss=0.0
Clinet index 24, End of Epoch 1/6, Average Loss=0.38610363006591797, Class Loss=0.38610363006591797, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.3219707429409027
Loss made of: CE 0.33438703417778015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3220289945602417, Reg Loss=0.0
Clinet index 24, End of Epoch 2/6, Average Loss=0.3220289945602417, Class Loss=0.3220289945602417, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.2806336387991905
Loss made of: CE 0.23723241686820984, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28075864911079407, Reg Loss=0.0
Clinet index 24, End of Epoch 3/6, Average Loss=0.28075864911079407, Class Loss=0.28075864911079407, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.27636864632368086
Loss made of: CE 0.16583675146102905, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27747392654418945, Reg Loss=0.0
Clinet index 24, End of Epoch 4/6, Average Loss=0.27747392654418945, Class Loss=0.27747392654418945, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.24924541264772415
Loss made of: CE 0.2388513684272766, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2500609755516052, Reg Loss=0.0
Clinet index 24, End of Epoch 5/6, Average Loss=0.2500609755516052, Class Loss=0.2500609755516052, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.25380067974328996
Loss made of: CE 0.2622559070587158, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24884650111198425, Reg Loss=0.0
Clinet index 24, End of Epoch 6/6, Average Loss=0.24884650111198425, Class Loss=0.24884650111198425, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.39003248512744904
Loss made of: CE 0.28395217657089233, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39206719398498535, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.39206719398498535, Class Loss=0.39206719398498535, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.35059358179569244
Loss made of: CE 0.3483549952507019, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.34047481417655945, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.34047481417655945, Class Loss=0.34047481417655945, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.31279953718185427
Loss made of: CE 0.33797115087509155, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3053467273712158, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.3053467273712158, Class Loss=0.3053467273712158, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.2715422585606575
Loss made of: CE 0.3404802978038788, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2799716293811798, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.2799716293811798, Class Loss=0.2799716293811798, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.2585080549120903
Loss made of: CE 0.2656092047691345, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26120463013648987, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.26120463013648987, Class Loss=0.26120463013648987, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.24398212879896164
Loss made of: CE 0.2338692843914032, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24013584852218628, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.24013584852218628, Class Loss=0.24013584852218628, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.5051103830337524, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.751127
Mean Acc: 0.130592
FreqW Acc: 0.570495
Mean IoU: 0.098940
Class IoU:
	class 0: 0.7404453
	class 1: 0.0005291559
	class 2: 0.0
	class 3: 0.0
	class 4: 0.015892766
	class 5: 0.0
	class 6: 0.0008088475
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.702937
	class 16: 0.22136025
Class Acc:
	class 0: 0.98739225
	class 1: 0.0005291559
	class 2: 0.0
	class 3: 0.0
	class 4: 0.016015334
	class 5: 0.0
	class 6: 0.00080885855
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.7870375
	class 16: 0.428285

federated global round: 22, step: 4
select part of clients to conduct local training
[21, 0, 25, 23]
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.32802617102861403
Loss made of: CE 0.30876362323760986, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.269066596031189
Loss made of: CE 0.3294708728790283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.2282923087477684
Loss made of: CE 0.17492422461509705, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.19834635108709336
Loss made of: CE 0.16312287747859955, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.1828335255384445
Loss made of: CE 0.16052483022212982, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.18617482781410216
Loss made of: CE 0.19146010279655457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.20354512259364127
Loss made of: CE 0.18661098182201385, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.18635040372610093
Loss made of: CE 0.154868945479393, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.1659792736172676
Loss made of: CE 0.1941625326871872, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.21429428458213806, Reg Loss=0.0
Clinet index 21, End of Epoch 1/6, Average Loss=0.21429428458213806, Class Loss=0.21429428458213806, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.16694443672895432
Loss made of: CE 0.15831419825553894, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.1699395678937435
Loss made of: CE 0.15353497862815857, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.15817867070436478
Loss made of: CE 0.17480453848838806, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.17805129438638687
Loss made of: CE 0.1564057171344757, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.15072973519563676
Loss made of: CE 0.17888757586479187, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.1565310314297676
Loss made of: CE 0.14894279837608337, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.17197083532810212
Loss made of: CE 0.13950681686401367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.146941177546978
Loss made of: CE 0.18413709104061127, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.15724943652749063
Loss made of: CE 0.17264406383037567, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16160155832767487, Reg Loss=0.0
Clinet index 21, End of Epoch 2/6, Average Loss=0.16160155832767487, Class Loss=0.16160155832767487, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.15711150616407393
Loss made of: CE 0.22025136649608612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.14027788862586021
Loss made of: CE 0.14808791875839233, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.15830097123980522
Loss made of: CE 0.17441067099571228, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.14557164981961251
Loss made of: CE 0.12294801324605942, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.1474072277545929
Loss made of: CE 0.1686905324459076, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.14180969074368477
Loss made of: CE 0.150608628988266, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.16674659997224808
Loss made of: CE 0.1976938247680664, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.15711090117692947
Loss made of: CE 0.1742401123046875, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.13058051243424415
Loss made of: CE 0.10649465024471283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.14811605215072632, Reg Loss=0.0
Clinet index 21, End of Epoch 3/6, Average Loss=0.14811605215072632, Class Loss=0.14811605215072632, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.15467703193426133
Loss made of: CE 0.1710415780544281, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.13569570034742356
Loss made of: CE 0.1265142560005188, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.14457905441522598
Loss made of: CE 0.14232583343982697, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.14810398817062378
Loss made of: CE 0.1637101173400879, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.13845792636275292
Loss made of: CE 0.11544805765151978, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.1441177323460579
Loss made of: CE 0.19204770028591156, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.14967228546738626
Loss made of: CE 0.14034496247768402, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.15663042813539504
Loss made of: CE 0.10667552798986435, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.14666005074977875
Loss made of: CE 0.13527046144008636, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1455707848072052, Reg Loss=0.0
Clinet index 21, End of Epoch 4/6, Average Loss=0.1455707848072052, Class Loss=0.1455707848072052, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.13698189854621887
Loss made of: CE 0.1425144076347351, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.1273556999862194
Loss made of: CE 0.17375439405441284, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.12247867807745934
Loss made of: CE 0.12384647130966187, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.13349929004907607
Loss made of: CE 0.149146169424057, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.12898848354816436
Loss made of: CE 0.11312520503997803, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.14075882434844972
Loss made of: CE 0.12840883433818817, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.13470253571867943
Loss made of: CE 0.12477435916662216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.14745567813515664
Loss made of: CE 0.14470359683036804, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.14599649980664253
Loss made of: CE 0.18655475974082947, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13628624379634857, Reg Loss=0.0
Clinet index 21, End of Epoch 5/6, Average Loss=0.13628624379634857, Class Loss=0.13628624379634857, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.13388434275984765
Loss made of: CE 0.09755798429250717, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.12199600785970688
Loss made of: CE 0.12142638862133026, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.13581708446145058
Loss made of: CE 0.10614195466041565, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.12245445773005485
Loss made of: CE 0.11097288131713867, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.12778654545545579
Loss made of: CE 0.14237229526042938, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.13058003038167953
Loss made of: CE 0.1402849406003952, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.13285666033625604
Loss made of: CE 0.14054590463638306, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.13091606497764588
Loss made of: CE 0.16937941312789917, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.12816301509737968
Loss made of: CE 0.12972766160964966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.12990285456180573, Reg Loss=0.0
Clinet index 21, End of Epoch 6/6, Average Loss=0.12990285456180573, Class Loss=0.12990285456180573, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.29490411281585693
Loss made of: CE 0.3990432620048523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.2546690106391907
Loss made of: CE 0.18843095004558563, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.22901261150836943
Loss made of: CE 0.16944143176078796, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.21597457975149154
Loss made of: CE 0.2530982494354248, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.17608582228422165
Loss made of: CE 0.24399392306804657, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.18511053174734116
Loss made of: CE 0.1414717435836792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.18521789014339446
Loss made of: CE 0.2966718077659607, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.18201171606779099
Loss made of: CE 0.1547393649816513, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.19562601000070573
Loss made of: CE 0.12347269058227539, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.20950797200202942, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.20950797200202942, Class Loss=0.20950797200202942, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.17095615118741989
Loss made of: CE 0.15823213756084442, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.16301833242177963
Loss made of: CE 0.18285773694515228, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.17333895564079285
Loss made of: CE 0.1691727489233017, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.1431201606988907
Loss made of: CE 0.12828418612480164, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.17948117926716806
Loss made of: CE 0.11107160896062851, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.16765379756689072
Loss made of: CE 0.16131199896335602, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.16065944507718086
Loss made of: CE 0.16475504636764526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.1586969390511513
Loss made of: CE 0.12055365741252899, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.17900317758321763
Loss made of: CE 0.1320165991783142, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1646803319454193, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.1646803319454193, Class Loss=0.1646803319454193, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.1562734514474869
Loss made of: CE 0.14562922716140747, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.14873572140932084
Loss made of: CE 0.12561896443367004, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.15662625879049302
Loss made of: CE 0.2138923853635788, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.15108093172311782
Loss made of: CE 0.1631508618593216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.14143044352531434
Loss made of: CE 0.16337959468364716, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.15935747921466828
Loss made of: CE 0.1275084912776947, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.1449680097401142
Loss made of: CE 0.14946617186069489, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.1448994442820549
Loss made of: CE 0.12564592063426971, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.15180033594369888
Loss made of: CE 0.15447156131267548, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15290120244026184, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.15290120244026184, Class Loss=0.15290120244026184, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.13816620856523515
Loss made of: CE 0.09337105602025986, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.14469564706087112
Loss made of: CE 0.15521162748336792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.1519930765032768
Loss made of: CE 0.15142947435379028, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.15121642053127288
Loss made of: CE 0.11718630790710449, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.1453874260187149
Loss made of: CE 0.1429581642150879, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.14657260105013847
Loss made of: CE 0.11812213063240051, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.13468529060482978
Loss made of: CE 0.1282489150762558, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.15310534909367562
Loss made of: CE 0.17314216494560242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.12975891977548598
Loss made of: CE 0.12016180157661438, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1437961757183075, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.1437961757183075, Class Loss=0.1437961757183075, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.1492386594414711
Loss made of: CE 0.20438262820243835, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.1410147711634636
Loss made of: CE 0.12187902629375458, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.14925577715039254
Loss made of: CE 0.12239569425582886, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.14287953674793244
Loss made of: CE 0.13816934823989868, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.12834038138389586
Loss made of: CE 0.1330471783876419, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.1389157585799694
Loss made of: CE 0.15861475467681885, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.1333355948328972
Loss made of: CE 0.12956397235393524, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.13813498616218567
Loss made of: CE 0.12279200553894043, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.12825791910290718
Loss made of: CE 0.13753294944763184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.13990795612335205, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.13990795612335205, Class Loss=0.13990795612335205, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.12551991939544677
Loss made of: CE 0.10002665221691132, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.12380281761288643
Loss made of: CE 0.09716647118330002, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.12952031791210175
Loss made of: CE 0.11819394677877426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.17074671462178231
Loss made of: CE 0.1402190625667572, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.1352626219391823
Loss made of: CE 0.11521682143211365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.13669800534844398
Loss made of: CE 0.10492806136608124, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.12584923207759857
Loss made of: CE 0.140491783618927, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.13419504463672638
Loss made of: CE 0.1091918796300888, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.12481427863240242
Loss made of: CE 0.14128190279006958, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1348954439163208, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.1348954439163208, Class Loss=0.1348954439163208, Reg Loss=0.0
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.3407903745770454
Loss made of: CE 0.272749125957489, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.2574525475502014
Loss made of: CE 0.26529812812805176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.20754227936267852
Loss made of: CE 0.1675964891910553, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.20003214478492737
Loss made of: CE 0.22006821632385254, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.1990616127848625
Loss made of: CE 0.21399597823619843, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.19564392417669296
Loss made of: CE 0.1305641084909439, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.17235731184482575
Loss made of: CE 0.14120392501354218, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.20472332686185837
Loss made of: CE 0.21884527802467346, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.1638617232441902
Loss made of: CE 0.12636493146419525, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.21466375887393951, Reg Loss=0.0
Clinet index 25, End of Epoch 1/6, Average Loss=0.21466375887393951, Class Loss=0.21466375887393951, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.17614182084798813
Loss made of: CE 0.17682719230651855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.16095834821462632
Loss made of: CE 0.14420217275619507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.17574407309293746
Loss made of: CE 0.17107944190502167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.17089639008045196
Loss made of: CE 0.13984230160713196, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.15188710913062095
Loss made of: CE 0.17636661231517792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.15315069109201432
Loss made of: CE 0.11464174091815948, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.16718417629599572
Loss made of: CE 0.19810721278190613, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.17191615849733352
Loss made of: CE 0.1392945498228073, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.17642533257603646
Loss made of: CE 0.21647581458091736, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16602833569049835, Reg Loss=0.0
Clinet index 25, End of Epoch 2/6, Average Loss=0.16602833569049835, Class Loss=0.16602833569049835, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.162481327354908
Loss made of: CE 0.16093014180660248, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.15113634318113328
Loss made of: CE 0.1750791072845459, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.1544295072555542
Loss made of: CE 0.1390628218650818, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.15180789679288864
Loss made of: CE 0.1875997632741928, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.14517960771918298
Loss made of: CE 0.15581312775611877, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.14834240227937698
Loss made of: CE 0.2325226068496704, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.16279537975788116
Loss made of: CE 0.15230949223041534, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.14788716584444045
Loss made of: CE 0.1292923390865326, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.16071089804172517
Loss made of: CE 0.1548207849264145, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1532781422138214, Reg Loss=0.0
Clinet index 25, End of Epoch 3/6, Average Loss=0.1532781422138214, Class Loss=0.1532781422138214, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.14733738973736762
Loss made of: CE 0.1363067477941513, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.1366987258195877
Loss made of: CE 0.1649428904056549, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.14209819063544274
Loss made of: CE 0.11667104810476303, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.15361164957284928
Loss made of: CE 0.15819399058818817, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.1565252088010311
Loss made of: CE 0.21326403319835663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.18941516876220704
Loss made of: CE 0.13701239228248596, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.14839266389608383
Loss made of: CE 0.13335803151130676, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.1483790658414364
Loss made of: CE 0.17039525508880615, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.12484957575798035
Loss made of: CE 0.1142326220870018, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.14905984699726105, Reg Loss=0.0
Clinet index 25, End of Epoch 4/6, Average Loss=0.14905984699726105, Class Loss=0.14905984699726105, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.13915595933794975
Loss made of: CE 0.14022208750247955, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.14205446541309358
Loss made of: CE 0.15807507932186127, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.13200134709477424
Loss made of: CE 0.11689477413892746, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.1355445973575115
Loss made of: CE 0.14548496901988983, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.1436918057501316
Loss made of: CE 0.1310628354549408, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.1373601548373699
Loss made of: CE 0.14663368463516235, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.1483960695564747
Loss made of: CE 0.16825155913829803, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.14013745188713073
Loss made of: CE 0.09327312558889389, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.14806235432624817
Loss made of: CE 0.1436099410057068, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14239689707756042, Reg Loss=0.0
Clinet index 25, End of Epoch 5/6, Average Loss=0.14239689707756042, Class Loss=0.14239689707756042, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.12673504576086997
Loss made of: CE 0.11989785730838776, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.1494143411517143
Loss made of: CE 0.15272676944732666, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.14605597257614136
Loss made of: CE 0.1070709079504013, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.13038670793175697
Loss made of: CE 0.08872728049755096, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.1508052356541157
Loss made of: CE 0.16009604930877686, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.1335320718586445
Loss made of: CE 0.1551087498664856, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.1306220233440399
Loss made of: CE 0.15021827816963196, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.12736227884888648
Loss made of: CE 0.11552666872739792, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.13804667294025422
Loss made of: CE 0.1132412701845169, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13688461482524872, Reg Loss=0.0
Clinet index 25, End of Epoch 6/6, Average Loss=0.13688461482524872, Class Loss=0.13688461482524872, Reg Loss=0.0
Current Client Index:  23
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.34994533509016035
Loss made of: CE 0.20599991083145142, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.24351392388343812
Loss made of: CE 0.2094317376613617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.19178044348955153
Loss made of: CE 0.1978253573179245, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.19499253630638122
Loss made of: CE 0.14878736436367035, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.20408140271902084
Loss made of: CE 0.1899351328611374, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.19220378547906875
Loss made of: CE 0.18785634636878967, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.1812389761209488
Loss made of: CE 0.19459974765777588, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.17165714651346206
Loss made of: CE 0.17862725257873535, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.1892349138855934
Loss made of: CE 0.15108685195446014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2105425000190735, Reg Loss=0.0
Clinet index 23, End of Epoch 1/6, Average Loss=0.2105425000190735, Class Loss=0.2105425000190735, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.15556206405162812
Loss made of: CE 0.13040980696678162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.16266344487667084
Loss made of: CE 0.16449511051177979, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.1508081704378128
Loss made of: CE 0.11567014455795288, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.163309545814991
Loss made of: CE 0.1971260905265808, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.1522790879011154
Loss made of: CE 0.14748546481132507, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.14149049147963524
Loss made of: CE 0.14419546723365784, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.17442671880125998
Loss made of: CE 0.19150066375732422, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.18416704535484313
Loss made of: CE 0.14168405532836914, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.17755060344934465
Loss made of: CE 0.20029008388519287, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16080033779144287, Reg Loss=0.0
Clinet index 23, End of Epoch 2/6, Average Loss=0.16080033779144287, Class Loss=0.16080033779144287, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.1476634830236435
Loss made of: CE 0.1603916734457016, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.1465754620730877
Loss made of: CE 0.21162758767604828, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.16892701238393784
Loss made of: CE 0.14562161266803741, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.16534259617328645
Loss made of: CE 0.22117261588573456, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.15151158347725868
Loss made of: CE 0.16683219373226166, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.1551337569952011
Loss made of: CE 0.16032370924949646, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.1454798810184002
Loss made of: CE 0.1638593226671219, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.14114125967025756
Loss made of: CE 0.1320938915014267, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.1549534559249878
Loss made of: CE 0.12076874822378159, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15254774689674377, Reg Loss=0.0
Clinet index 23, End of Epoch 3/6, Average Loss=0.15254774689674377, Class Loss=0.15254774689674377, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.14834877699613572
Loss made of: CE 0.157518669962883, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.1466376282274723
Loss made of: CE 0.1587923765182495, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.13839773684740067
Loss made of: CE 0.12804362177848816, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.14134967401623727
Loss made of: CE 0.17750369012355804, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.14882626980543137
Loss made of: CE 0.14517144858837128, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.14766319394111632
Loss made of: CE 0.16425786912441254, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.13565815165638923
Loss made of: CE 0.11292357742786407, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.14912907481193544
Loss made of: CE 0.11131110787391663, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.14413853362202644
Loss made of: CE 0.14059048891067505, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1440242975950241, Reg Loss=0.0
Clinet index 23, End of Epoch 4/6, Average Loss=0.1440242975950241, Class Loss=0.1440242975950241, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.15258224457502365
Loss made of: CE 0.13517341017723083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.1396779738366604
Loss made of: CE 0.1635768711566925, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.1549527734518051
Loss made of: CE 0.17092347145080566, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.12794732674956322
Loss made of: CE 0.10550712049007416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.135148137062788
Loss made of: CE 0.13763748109340668, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.14755165800452233
Loss made of: CE 0.15060515701770782, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.1393085815012455
Loss made of: CE 0.1315086930990219, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.13688664212822915
Loss made of: CE 0.14539925754070282, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.14704780727624894
Loss made of: CE 0.12785771489143372, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14141260087490082, Reg Loss=0.0
Clinet index 23, End of Epoch 5/6, Average Loss=0.14141260087490082, Class Loss=0.14141260087490082, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.13262655064463616
Loss made of: CE 0.1309579312801361, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.15682073310017586
Loss made of: CE 0.12876474857330322, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.15602076053619385
Loss made of: CE 0.13005584478378296, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.12270896509289742
Loss made of: CE 0.08237695693969727, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.14431872367858886
Loss made of: CE 0.12067203968763351, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.12817223146557807
Loss made of: CE 0.1296035498380661, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.15720954537391663
Loss made of: CE 0.18749594688415527, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.12766927480697632
Loss made of: CE 0.13302215933799744, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.13835516944527626
Loss made of: CE 0.1795368641614914, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13938800990581512, Reg Loss=0.0
Clinet index 23, End of Epoch 6/6, Average Loss=0.13938800990581512, Class Loss=0.13938800990581512, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.9316298961639404, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.757888
Mean Acc: 0.111269
FreqW Acc: 0.576839
Mean IoU: 0.087176
Class IoU:
	class 0: 0.74883974
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.7329922
	class 16: 0.00015425966
Class Acc:
	class 0: 0.99000055
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.9014125
	class 16: 0.0001542617

federated global round: 23, step: 4
select part of clients to conduct local training
[17, 3, 5, 22]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.13480961993336676
Loss made of: CE 0.17841240763664246, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.13867978304624556
Loss made of: CE 0.14645318686962128, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.14571042060852052
Loss made of: CE 0.13639064133167267, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.1426319159567356
Loss made of: CE 0.12439841032028198, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.12850402444601058
Loss made of: CE 0.10326631367206573, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.14560372158885002
Loss made of: CE 0.15465693175792694, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.13593712449073792
Loss made of: CE 0.0919041633605957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.12076515629887581
Loss made of: CE 0.12406188249588013, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.13682535365223886
Loss made of: CE 0.13680782914161682, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.13588717579841614, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.13588717579841614, Class Loss=0.13588717579841614, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=0.1257631830871105
Loss made of: CE 0.11871038377285004, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.11550752148032188
Loss made of: CE 0.11699619889259338, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.13026490136981012
Loss made of: CE 0.12336768954992294, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.14702798947691917
Loss made of: CE 0.13169270753860474, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.12223345786333084
Loss made of: CE 0.125186488032341, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.14963809847831727
Loss made of: CE 0.12751665711402893, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.13723313435912132
Loss made of: CE 0.12724052369594574, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.12569779828190802
Loss made of: CE 0.11376626789569855, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.11704415157437324
Loss made of: CE 0.1078847274184227, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.12885235249996185, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.12885235249996185, Class Loss=0.12885235249996185, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=0.12708989083766936
Loss made of: CE 0.13062557578086853, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.12914825305342675
Loss made of: CE 0.20304225385189056, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.1258947029709816
Loss made of: CE 0.11012618988752365, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.13125082552433015
Loss made of: CE 0.18574903905391693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.11650212109088898
Loss made of: CE 0.10990117490291595, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.12269449084997178
Loss made of: CE 0.11548491567373276, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.13316708207130432
Loss made of: CE 0.12746590375900269, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.1296881303191185
Loss made of: CE 0.10832905769348145, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.12470080628991127
Loss made of: CE 0.14815813302993774, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.12650802731513977, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.12650802731513977, Class Loss=0.12650802731513977, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=0.1268569588661194
Loss made of: CE 0.15920548141002655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.12288297414779663
Loss made of: CE 0.13270549476146698, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.12215010970830917
Loss made of: CE 0.14461691677570343, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.12189863249659538
Loss made of: CE 0.10579749196767807, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.13399877399206161
Loss made of: CE 0.11213020980358124, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.12572673708200455
Loss made of: CE 0.10288670659065247, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.12526707872748374
Loss made of: CE 0.1016417145729065, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.11442147940397263
Loss made of: CE 0.11116628348827362, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.11972567811608315
Loss made of: CE 0.11638464778661728, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.12314219027757645, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.12314219027757645, Class Loss=0.12314219027757645, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=0.11228498071432114
Loss made of: CE 0.1249358057975769, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.14799248576164245
Loss made of: CE 0.09294740855693817, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.12447663471102714
Loss made of: CE 0.14288750290870667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.12187041267752648
Loss made of: CE 0.12488623708486557, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.12712836191058158
Loss made of: CE 0.10756003856658936, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.14126003682613372
Loss made of: CE 0.16693244874477386, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.132930226624012
Loss made of: CE 0.13379129767417908, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.1244556613266468
Loss made of: CE 0.10758906602859497, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.12154484242200851
Loss made of: CE 0.16395384073257446, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.12717337906360626, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.12717337906360626, Class Loss=0.12717337906360626, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=0.12760072723031043
Loss made of: CE 0.13563257455825806, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.13515631929039956
Loss made of: CE 0.12510578334331512, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.11965959668159484
Loss made of: CE 0.10419593751430511, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.11816575825214386
Loss made of: CE 0.16868937015533447, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.10798003375530243
Loss made of: CE 0.09719769656658173, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.11832662373781204
Loss made of: CE 0.07404014468193054, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.10958503857254982
Loss made of: CE 0.13031579554080963, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.11226271539926529
Loss made of: CE 0.12734901905059814, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.11205401793122291
Loss made of: CE 0.10249702632427216, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.12003865092992783, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.12003865092992783, Class Loss=0.12003865092992783, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.7704542189836502
Loss made of: CE 0.4410651624202728, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7322472929954529, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.7322472929954529, Class Loss=0.7322472929954529, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.4183238446712494
Loss made of: CE 0.3375966250896454, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.40690740942955017, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.40690740942955017, Class Loss=0.40690740942955017, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.28801605105400085
Loss made of: CE 0.23304447531700134, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3040020167827606, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.3040020167827606, Class Loss=0.3040020167827606, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.27793910950422285
Loss made of: CE 0.2153259515762329, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2648763954639435, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.2648763954639435, Class Loss=0.2648763954639435, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.23090553134679795
Loss made of: CE 0.19457530975341797, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23043571412563324, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.23043571412563324, Class Loss=0.23043571412563324, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.23080836981534958
Loss made of: CE 0.23265795409679413, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22265353798866272, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.22265353798866272, Class Loss=0.22265353798866272, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.144859878718853
Loss made of: CE 0.12339359521865845, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.1593519404530525
Loss made of: CE 0.2867915630340576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.12572566643357277
Loss made of: CE 0.11619638651609421, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.13028136268258095
Loss made of: CE 0.13681483268737793, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.12641556933522224
Loss made of: CE 0.10666966438293457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.1278179854154587
Loss made of: CE 0.11404629051685333, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.1458052061498165
Loss made of: CE 0.15280497074127197, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.14286719784140586
Loss made of: CE 0.1772870272397995, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.13984841853380203
Loss made of: CE 0.14777839183807373, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.13765393197536469, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.13765393197536469, Class Loss=0.13765393197536469, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=0.1234383039176464
Loss made of: CE 0.132867693901062, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.12791431099176406
Loss made of: CE 0.1116185113787651, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.132150612026453
Loss made of: CE 0.13940854370594025, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.13266512230038643
Loss made of: CE 0.13082978129386902, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.1440628722310066
Loss made of: CE 0.16188006103038788, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.1350063532590866
Loss made of: CE 0.11672526597976685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.13544534146785736
Loss made of: CE 0.10874741524457932, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.1329724207520485
Loss made of: CE 0.11486997455358505, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.12787434607744216
Loss made of: CE 0.15984901785850525, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.13377240300178528, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.13377240300178528, Class Loss=0.13377240300178528, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=0.1339162454009056
Loss made of: CE 0.10365788638591766, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.13153856620192528
Loss made of: CE 0.13448771834373474, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.12065141126513482
Loss made of: CE 0.1214568167924881, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.145084385573864
Loss made of: CE 0.13538478314876556, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.13048662841320038
Loss made of: CE 0.12086914479732513, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.14373520016670227
Loss made of: CE 0.36684364080429077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.12791906595230101
Loss made of: CE 0.1018725037574768, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.13632371723651887
Loss made of: CE 0.12423872202634811, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.11613994836807251
Loss made of: CE 0.12277184426784515, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1317250281572342, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.1317250281572342, Class Loss=0.1317250281572342, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=0.12149595469236374
Loss made of: CE 0.13537560403347015, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.12131011039018631
Loss made of: CE 0.12217473983764648, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.12735536620020865
Loss made of: CE 0.1490367352962494, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.11786072701215744
Loss made of: CE 0.13604244589805603, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.13870356902480124
Loss made of: CE 0.15123823285102844, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.13477324470877647
Loss made of: CE 0.14392684400081635, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.12714034765958787
Loss made of: CE 0.15781418979167938, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.1325927421450615
Loss made of: CE 0.11923155188560486, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.13493694886565208
Loss made of: CE 0.11535821855068207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.12911728024482727, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.12911728024482727, Class Loss=0.12911728024482727, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=0.12879730835556985
Loss made of: CE 0.11314167082309723, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.1209582231938839
Loss made of: CE 0.13082212209701538, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.10872374847531319
Loss made of: CE 0.1249982938170433, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.12289685606956482
Loss made of: CE 0.1375941038131714, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.14031419083476065
Loss made of: CE 0.1253049373626709, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.11714783832430839
Loss made of: CE 0.12699295580387115, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.11855296865105629
Loss made of: CE 0.09521272778511047, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.12106107622385025
Loss made of: CE 0.12925413250923157, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.12827549651265144
Loss made of: CE 0.14040161669254303, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1219555139541626, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.1219555139541626, Class Loss=0.1219555139541626, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=0.12188497632741928
Loss made of: CE 0.11161571741104126, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.12308361306786537
Loss made of: CE 0.10866373777389526, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.1176655188202858
Loss made of: CE 0.12121187895536423, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.11801997050642968
Loss made of: CE 0.12628036737442017, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.11663726419210434
Loss made of: CE 0.09958456456661224, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.12060979455709457
Loss made of: CE 0.10352838039398193, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.10745121911168098
Loss made of: CE 0.10886716842651367, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.12089093625545502
Loss made of: CE 0.13849052786827087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.12796717062592505
Loss made of: CE 0.1354813277721405, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.11960144340991974, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.11960144340991974, Class Loss=0.11960144340991974, Reg Loss=0.0
Current Client Index:  22
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.8095712542533875
Loss made of: CE 0.9485997557640076, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7528043985366821, Reg Loss=0.0
Clinet index 22, End of Epoch 1/6, Average Loss=0.7528043985366821, Class Loss=0.7528043985366821, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.44463749825954435
Loss made of: CE 0.30903440713882446, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.43231770396232605, Reg Loss=0.0
Clinet index 22, End of Epoch 2/6, Average Loss=0.43231770396232605, Class Loss=0.43231770396232605, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.28651571422815325
Loss made of: CE 0.33375459909439087, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2854471206665039, Reg Loss=0.0
Clinet index 22, End of Epoch 3/6, Average Loss=0.2854471206665039, Class Loss=0.2854471206665039, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.27297102510929105
Loss made of: CE 0.19832730293273926, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26626741886138916, Reg Loss=0.0
Clinet index 22, End of Epoch 4/6, Average Loss=0.26626741886138916, Class Loss=0.26626741886138916, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.2397458717226982
Loss made of: CE 0.17904576659202576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23181597888469696, Reg Loss=0.0
Clinet index 22, End of Epoch 5/6, Average Loss=0.23181597888469696, Class Loss=0.23181597888469696, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.21788837313652037
Loss made of: CE 0.2389105260372162, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22349902987480164, Reg Loss=0.0
Clinet index 22, End of Epoch 6/6, Average Loss=0.22349902987480164, Class Loss=0.22349902987480164, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.9666287899017334, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.759325
Mean Acc: 0.133752
FreqW Acc: 0.580348
Mean IoU: 0.106908
Class IoU:
	class 0: 0.74636406
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.7799339
	class 16: 0.29114383
Class Acc:
	class 0: 0.9885847
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.89873105
	class 16: 0.38647068

federated global round: 24, step: 4
select part of clients to conduct local training
[16, 9, 12, 2]
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.17414878979325293
Loss made of: CE 0.16972391307353973, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.14453129842877388
Loss made of: CE 0.14345896244049072, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.14649643152952194
Loss made of: CE 0.11692178249359131, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.12716024816036225
Loss made of: CE 0.15994179248809814, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.14475572779774665
Loss made of: CE 0.22112725675106049, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.14432571232318878
Loss made of: CE 0.1416192501783371, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.13830622285604477
Loss made of: CE 0.1054084300994873, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.135105412453413
Loss made of: CE 0.13786958158016205, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.12886540591716766
Loss made of: CE 0.1218893975019455, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.14251162111759186, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.14251162111759186, Class Loss=0.14251162111759186, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/97, Loss=0.13675653785467148
Loss made of: CE 0.11368629336357117, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.12906272038817407
Loss made of: CE 0.11560547351837158, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.14092039093375205
Loss made of: CE 0.1306425780057907, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.1313965290784836
Loss made of: CE 0.13455252349376678, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.11846421509981156
Loss made of: CE 0.09459209442138672, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.1227246068418026
Loss made of: CE 0.1598927229642868, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.13718538880348205
Loss made of: CE 0.11956453323364258, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.13058096542954445
Loss made of: CE 0.14201822876930237, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.12332979589700699
Loss made of: CE 0.12102609127759933, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.12933233380317688, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.12933233380317688, Class Loss=0.12933233380317688, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/97, Loss=0.11443538293242454
Loss made of: CE 0.1250881552696228, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.12115683853626251
Loss made of: CE 0.13424783945083618, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.12007841467857361
Loss made of: CE 0.1486506462097168, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.14855049699544906
Loss made of: CE 0.1220577210187912, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.11358453929424286
Loss made of: CE 0.10574755072593689, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.1356751061975956
Loss made of: CE 0.12396550178527832, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.13034676834940911
Loss made of: CE 0.1490650773048401, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.1386507399380207
Loss made of: CE 0.16644933819770813, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.10824417099356651
Loss made of: CE 0.088660828769207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.12604396045207977, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.12604396045207977, Class Loss=0.12604396045207977, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/97, Loss=0.11703141927719116
Loss made of: CE 0.12524859607219696, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.12377060577273369
Loss made of: CE 0.0994783565402031, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.12538430020213126
Loss made of: CE 0.14503434300422668, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.12025106549263001
Loss made of: CE 0.11751066148281097, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.1066128022968769
Loss made of: CE 0.09382139146327972, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.13749320134520532
Loss made of: CE 0.10977288335561752, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.12057837098836899
Loss made of: CE 0.116241455078125, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.12524548843502997
Loss made of: CE 0.1747705042362213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.1186193585395813
Loss made of: CE 0.1238662451505661, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.12440795451402664, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.12440795451402664, Class Loss=0.12440795451402664, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/97, Loss=0.11894094571471214
Loss made of: CE 0.12561021745204926, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.13561080619692803
Loss made of: CE 0.1790637969970703, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.1409163437783718
Loss made of: CE 0.17750820517539978, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.12918733209371566
Loss made of: CE 0.13440072536468506, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.11103332415223122
Loss made of: CE 0.09702201187610626, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.11763453781604767
Loss made of: CE 0.11220620572566986, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.11131339594721794
Loss made of: CE 0.0882461816072464, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.12725578472018242
Loss made of: CE 0.14163947105407715, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.12007462754845619
Loss made of: CE 0.1785927414894104, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.12331788241863251, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.12331788241863251, Class Loss=0.12331788241863251, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/97, Loss=0.1278474025428295
Loss made of: CE 0.13090065121650696, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.11993451490998268
Loss made of: CE 0.13341039419174194, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.11899162977933883
Loss made of: CE 0.10163465142250061, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.116935146600008
Loss made of: CE 0.12237109988927841, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.11579918414354325
Loss made of: CE 0.08637641370296478, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.12900218069553376
Loss made of: CE 0.11305975914001465, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.12151331603527069
Loss made of: CE 0.12365683913230896, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.13409214615821838
Loss made of: CE 0.09158426523208618, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.12615983411669732
Loss made of: CE 0.12180213630199432, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.12269122898578644, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.12269122898578644, Class Loss=0.12269122898578644, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.34651694595813753
Loss made of: CE 0.48541784286499023, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3409114480018616, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.3409114480018616, Class Loss=0.3409114480018616, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.27608477622270583
Loss made of: CE 0.3351249694824219, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27095097303390503, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.27095097303390503, Class Loss=0.27095097303390503, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.24161509573459625
Loss made of: CE 0.2560226023197174, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24155926704406738, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.24155926704406738, Class Loss=0.24155926704406738, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.2185112476348877
Loss made of: CE 0.214599609375, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2191331386566162, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.2191331386566162, Class Loss=0.2191331386566162, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.22189191728830338
Loss made of: CE 0.20618604123592377, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21714948117733002, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.21714948117733002, Class Loss=0.21714948117733002, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.2168971210718155
Loss made of: CE 0.16125887632369995, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21642053127288818, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.21642053127288818, Class Loss=0.21642053127288818, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.3320891857147217
Loss made of: CE 0.2778571546077728, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33609604835510254, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.33609604835510254, Class Loss=0.33609604835510254, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.2666278645396233
Loss made of: CE 0.2483786791563034, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26376259326934814, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.26376259326934814, Class Loss=0.26376259326934814, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.23858078420162201
Loss made of: CE 0.2533697485923767, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22571095824241638, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.22571095824241638, Class Loss=0.22571095824241638, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.2200462907552719
Loss made of: CE 0.1998724639415741, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21714264154434204, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.21714264154434204, Class Loss=0.21714264154434204, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.20789154320955278
Loss made of: CE 0.2383967638015747, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2030520737171173, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.2030520737171173, Class Loss=0.2030520737171173, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.1994788318872452
Loss made of: CE 0.1932871788740158, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2026696652173996, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.2026696652173996, Class Loss=0.2026696652173996, Reg Loss=0.0
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/12, Loss=0.3514628499746323
Loss made of: CE 0.3823649287223816, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3533099293708801, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.3533099293708801, Class Loss=0.3533099293708801, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000536
Epoch 2, Batch 10/12, Loss=0.32214507311582563
Loss made of: CE 0.350167840719223, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31010955572128296, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.31010955572128296, Class Loss=0.31010955572128296, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000438
Epoch 3, Batch 10/12, Loss=0.2640251204371452
Loss made of: CE 0.2410774528980255, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26121142506599426, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.26121142506599426, Class Loss=0.26121142506599426, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/12, Loss=0.24174746870994568
Loss made of: CE 0.25019571185112, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24384936690330505, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.24384936690330505, Class Loss=0.24384936690330505, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000235
Epoch 5, Batch 10/12, Loss=0.24729523956775665
Loss made of: CE 0.29179859161376953, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23456323146820068, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.23456323146820068, Class Loss=0.23456323146820068, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000126
Epoch 6, Batch 10/12, Loss=0.25162940174341203
Loss made of: CE 0.2085360288619995, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24495702981948853, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.24495702981948853, Class Loss=0.24495702981948853, Reg Loss=0.0
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=2.0119247436523438, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.758013
Mean Acc: 0.142998
FreqW Acc: 0.579545
Mean IoU: 0.108715
Class IoU:
	class 0: 0.74463314
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.78299063
	class 16: 0.32052958
Class Acc:
	class 0: 0.98585135
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.8911535
	class 16: 0.5539556

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 25, step: 5
select part of clients to conduct local training
[24, 7, 4, 12]
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.1785447716712953
Loss made of: CE 1.930846929550171, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.1118221282958984, Reg Loss=0.0
Clinet index 24, End of Epoch 1/6, Average Loss=2.1118221282958984, Class Loss=2.1118221282958984, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.3842267394065857
Loss made of: CE 1.2668004035949707, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3067708015441895, Reg Loss=0.0
Clinet index 24, End of Epoch 2/6, Average Loss=1.3067708015441895, Class Loss=1.3067708015441895, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.823048985004425
Loss made of: CE 0.6150176525115967, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7867263555526733, Reg Loss=0.0
Clinet index 24, End of Epoch 3/6, Average Loss=0.7867263555526733, Class Loss=0.7867263555526733, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.5117004752159119
Loss made of: CE 0.49538272619247437, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4997282922267914, Reg Loss=0.0
Clinet index 24, End of Epoch 4/6, Average Loss=0.4997282922267914, Class Loss=0.4997282922267914, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.37438562214374543
Loss made of: CE 0.3873072564601898, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.36710262298583984, Reg Loss=0.0
Clinet index 24, End of Epoch 5/6, Average Loss=0.36710262298583984, Class Loss=0.36710262298583984, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.35260993242263794
Loss made of: CE 0.2751006782054901, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35574042797088623, Reg Loss=0.0
Clinet index 24, End of Epoch 6/6, Average Loss=0.35574042797088623, Class Loss=0.35574042797088623, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.6489180326461792, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=1.6489180326461792, Class Loss=1.6489180326461792, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.2011728286743164, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=1.2011728286743164, Class Loss=1.2011728286743164, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.8454107046127319, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.8454107046127319, Class Loss=0.8454107046127319, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.5124779939651489, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.5124779939651489, Class Loss=0.5124779939651489, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.3025556206703186, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.3025556206703186, Class Loss=0.3025556206703186, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.2164788544178009, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.2164788544178009, Class Loss=0.2164788544178009, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.2505863904953003
Loss made of: CE 1.7724374532699585, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.190378427505493, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=2.190378427505493, Class Loss=2.190378427505493, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.321969175338745
Loss made of: CE 1.076065182685852, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3149008750915527, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=1.3149008750915527, Class Loss=1.3149008750915527, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.8069181323051453
Loss made of: CE 0.5017306804656982, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7847890257835388, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.7847890257835388, Class Loss=0.7847890257835388, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.5010409265756607
Loss made of: CE 0.4503093659877777, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.48491787910461426, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.48491787910461426, Class Loss=0.48491787910461426, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.3878252774477005
Loss made of: CE 0.3733604848384857, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.38106462359428406, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.38106462359428406, Class Loss=0.38106462359428406, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.3229456663131714
Loss made of: CE 0.3204437494277954, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32109886407852173, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.32109886407852173, Class Loss=0.32109886407852173, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.0015022993087768
Loss made of: CE 2.0099096298217773, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.011911392211914, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=2.011911392211914, Class Loss=2.011911392211914, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.3649232029914855
Loss made of: CE 1.0776805877685547, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3130362033843994, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=1.3130362033843994, Class Loss=1.3130362033843994, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.7697866797447205
Loss made of: CE 0.7020220160484314, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7581709623336792, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.7581709623336792, Class Loss=0.7581709623336792, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.5276706337928772
Loss made of: CE 0.364785373210907, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5072190761566162, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.5072190761566162, Class Loss=0.5072190761566162, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.38198637068271635
Loss made of: CE 0.33243274688720703, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3720289170742035, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.3720289170742035, Class Loss=0.3720289170742035, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.34745555818080903
Loss made of: CE 0.3136870563030243, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.340668261051178, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.340668261051178, Class Loss=0.340668261051178, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.6570546627044678, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.687514
Mean Acc: 0.088837
FreqW Acc: 0.484908
Mean IoU: 0.058276
Class IoU:
	class 0: 0.6933889
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.00050315866
	class 5: 0.0
	class 6: 7.9346304e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0005847324
	class 16: 0.25108504
	class 17: 0.0
	class 18: 0.16160072
Class Acc:
	class 0: 0.97933865
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.00050315866
	class 5: 0.0
	class 6: 7.9346304e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0005847369
	class 16: 0.2854923
	class 17: 0.0
	class 18: 0.42189598

federated global round: 26, step: 5
select part of clients to conduct local training
[6, 28, 20, 4]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.4638690024614334
Loss made of: CE 0.4071826934814453, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.45897626876831055, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.45897626876831055, Class Loss=0.45897626876831055, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.3813842684030533
Loss made of: CE 0.32757049798965454, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.37715157866477966, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.37715157866477966, Class Loss=0.37715157866477966, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.3160577952861786
Loss made of: CE 0.3425152897834778, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.32252052426338196, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.32252052426338196, Class Loss=0.32252052426338196, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.2868232250213623
Loss made of: CE 0.3089178204536438, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2861402630805969, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.2861402630805969, Class Loss=0.2861402630805969, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.28629339337348936
Loss made of: CE 0.35248860716819763, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27589815855026245, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.27589815855026245, Class Loss=0.27589815855026245, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.2531676411628723
Loss made of: CE 0.220376119017601, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2514866888523102, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.2514866888523102, Class Loss=0.2514866888523102, Reg Loss=0.0
Current Client Index:  28
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.0784727334976196, Reg Loss=0.0
Clinet index 28, End of Epoch 1/6, Average Loss=1.0784727334976196, Class Loss=1.0784727334976196, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7609503269195557, Reg Loss=0.0
Clinet index 28, End of Epoch 2/6, Average Loss=0.7609503269195557, Class Loss=0.7609503269195557, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.4890247881412506, Reg Loss=0.0
Clinet index 28, End of Epoch 3/6, Average Loss=0.4890247881412506, Class Loss=0.4890247881412506, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.33440718054771423, Reg Loss=0.0
Clinet index 28, End of Epoch 4/6, Average Loss=0.33440718054771423, Class Loss=0.33440718054771423, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.2185850441455841, Reg Loss=0.0
Clinet index 28, End of Epoch 5/6, Average Loss=0.2185850441455841, Class Loss=0.2185850441455841, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.17141808569431305, Reg Loss=0.0
Clinet index 28, End of Epoch 6/6, Average Loss=0.17141808569431305, Class Loss=0.17141808569431305, Reg Loss=0.0
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.072967290878296, Reg Loss=0.0
Clinet index 20, End of Epoch 1/6, Average Loss=1.072967290878296, Class Loss=1.072967290878296, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7735941410064697, Reg Loss=0.0
Clinet index 20, End of Epoch 2/6, Average Loss=0.7735941410064697, Class Loss=0.7735941410064697, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.46845492720603943, Reg Loss=0.0
Clinet index 20, End of Epoch 3/6, Average Loss=0.46845492720603943, Class Loss=0.46845492720603943, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.31807270646095276, Reg Loss=0.0
Clinet index 20, End of Epoch 4/6, Average Loss=0.31807270646095276, Class Loss=0.31807270646095276, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.22408029437065125, Reg Loss=0.0
Clinet index 20, End of Epoch 5/6, Average Loss=0.22408029437065125, Class Loss=0.22408029437065125, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.19482196867465973, Reg Loss=0.0
Clinet index 20, End of Epoch 6/6, Average Loss=0.19482196867465973, Class Loss=0.19482196867465973, Reg Loss=0.0
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.4518460541963577
Loss made of: CE 0.45553427934646606, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4514918327331543, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.4514918327331543, Class Loss=0.4514918327331543, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=0.36286311149597167
Loss made of: CE 0.41112565994262695, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3750450611114502, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.3750450611114502, Class Loss=0.3750450611114502, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=0.32367217540740967
Loss made of: CE 0.25062286853790283, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3316528797149658, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.3316528797149658, Class Loss=0.3316528797149658, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=0.32579993903636933
Loss made of: CE 0.33478856086730957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3173302412033081, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.3173302412033081, Class Loss=0.3173302412033081, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.28624495714902876
Loss made of: CE 0.2938709259033203, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2825712561607361, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.2825712561607361, Class Loss=0.2825712561607361, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=0.25814332962036135
Loss made of: CE 0.27027714252471924, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2610440254211426, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.2610440254211426, Class Loss=0.2610440254211426, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.6328058242797852, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.685371
Mean Acc: 0.079229
FreqW Acc: 0.489648
Mean IoU: 0.048782
Class IoU:
	class 0: 0.70234025
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 3.7642792e-05
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 1.0920694e-05
	class 16: 0.049056135
	class 17: 0.058731377
	class 18: 0.11668542
Class Acc:
	class 0: 0.9779871
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 3.7642792e-05
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 1.0920694e-05
	class 16: 0.049117297
	class 17: 0.09222391
	class 18: 0.3859667

federated global round: 27, step: 5
select part of clients to conduct local training
[24, 8, 26, 0]
Current Client Index:  24
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.41938878893852233
Loss made of: CE 0.3952774703502655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4042299687862396, Reg Loss=0.0
Clinet index 24, End of Epoch 1/6, Average Loss=0.4042299687862396, Class Loss=0.4042299687862396, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/12, Loss=0.36944150626659394
Loss made of: CE 0.37684449553489685, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3644769787788391, Reg Loss=0.0
Clinet index 24, End of Epoch 2/6, Average Loss=0.3644769787788391, Class Loss=0.3644769787788391, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/12, Loss=0.3128417909145355
Loss made of: CE 0.2654706537723541, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.30658042430877686, Reg Loss=0.0
Clinet index 24, End of Epoch 3/6, Average Loss=0.30658042430877686, Class Loss=0.30658042430877686, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/12, Loss=0.2897045612335205
Loss made of: CE 0.2588270902633667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28791722655296326, Reg Loss=0.0
Clinet index 24, End of Epoch 4/6, Average Loss=0.28791722655296326, Class Loss=0.28791722655296326, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/12, Loss=0.26313167810440063
Loss made of: CE 0.2871329188346863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2601836323738098, Reg Loss=0.0
Clinet index 24, End of Epoch 5/6, Average Loss=0.2601836323738098, Class Loss=0.2601836323738098, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/12, Loss=0.27698629200458524
Loss made of: CE 0.23185548186302185, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2779995799064636, Reg Loss=0.0
Clinet index 24, End of Epoch 6/6, Average Loss=0.2779995799064636, Class Loss=0.2779995799064636, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.49030977487564087, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.49030977487564087, Class Loss=0.49030977487564087, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.3674217164516449, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.3674217164516449, Class Loss=0.3674217164516449, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.25650492310523987, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.25650492310523987, Class Loss=0.25650492310523987, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.1986134797334671, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.1986134797334671, Class Loss=0.1986134797334671, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.17468228936195374, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.17468228936195374, Class Loss=0.17468228936195374, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.15411214530467987, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.15411214530467987, Class Loss=0.15411214530467987, Reg Loss=0.0
Current Client Index:  26
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.3943534016609192
Loss made of: CE 0.33065861463546753, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39929425716400146, Reg Loss=0.0
Clinet index 26, End of Epoch 1/6, Average Loss=0.39929425716400146, Class Loss=0.39929425716400146, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=0.3380418688058853
Loss made of: CE 0.31431570649147034, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.33080020546913147, Reg Loss=0.0
Clinet index 26, End of Epoch 2/6, Average Loss=0.33080020546913147, Class Loss=0.33080020546913147, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=0.3040361315011978
Loss made of: CE 0.27476248145103455, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29962360858917236, Reg Loss=0.0
Clinet index 26, End of Epoch 3/6, Average Loss=0.29962360858917236, Class Loss=0.29962360858917236, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.2607992708683014
Loss made of: CE 0.2273411750793457, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25819334387779236, Reg Loss=0.0
Clinet index 26, End of Epoch 4/6, Average Loss=0.25819334387779236, Class Loss=0.25819334387779236, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.24502025693655013
Loss made of: CE 0.2207786738872528, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2565292418003082, Reg Loss=0.0
Clinet index 26, End of Epoch 5/6, Average Loss=0.2565292418003082, Class Loss=0.2565292418003082, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.2484724387526512
Loss made of: CE 0.21851846575737, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24366925656795502, Reg Loss=0.0
Clinet index 26, End of Epoch 6/6, Average Loss=0.24366925656795502, Class Loss=0.24366925656795502, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.4314067304134369
Loss made of: CE 0.4029647707939148, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4292531907558441, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.4292531907558441, Class Loss=0.4292531907558441, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=0.33648868799209597
Loss made of: CE 0.28879666328430176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3425893485546112, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.3425893485546112, Class Loss=0.3425893485546112, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=0.302092170715332
Loss made of: CE 0.23481929302215576, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29841506481170654, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.29841506481170654, Class Loss=0.29841506481170654, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.275542625784874
Loss made of: CE 0.25811338424682617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2745877504348755, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.2745877504348755, Class Loss=0.2745877504348755, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.25313952565193176
Loss made of: CE 0.24087610840797424, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2509942054748535, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.2509942054748535, Class Loss=0.2509942054748535, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.24557725191116334
Loss made of: CE 0.22590026259422302, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24385671317577362, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.24385671317577362, Class Loss=0.24385671317577362, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.8200052976608276, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.677419
Mean Acc: 0.085321
FreqW Acc: 0.480246
Mean IoU: 0.045000
Class IoU:
	class 0: 0.6889492
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 9.619825e-06
	class 5: 0.0
	class 6: 1.1316388e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 9.1710455e-05
	class 17: 0.0010881448
	class 18: 0.164845
Class Acc:
	class 0: 0.96201724
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 9.619825e-06
	class 5: 0.0
	class 6: 1.1316388e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 9.1710455e-05
	class 17: 0.0010933238
	class 18: 0.6578759

federated global round: 28, step: 5
select part of clients to conduct local training
[8, 9, 16, 3]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.6348311305046082, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.6348311305046082, Class Loss=0.6348311305046082, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.4800417423248291, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.4800417423248291, Class Loss=0.4800417423248291, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.3487458825111389, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.3487458825111389, Class Loss=0.3487458825111389, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.25820788741111755, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.25820788741111755, Class Loss=0.25820788741111755, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.21258708834648132, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.21258708834648132, Class Loss=0.21258708834648132, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.19289177656173706, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.19289177656173706, Class Loss=0.19289177656173706, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.636379063129425, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.636379063129425, Class Loss=0.636379063129425, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.4377678632736206, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.4377678632736206, Class Loss=0.4377678632736206, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.2756556570529938, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.2756556570529938, Class Loss=0.2756556570529938, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.21297340095043182, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.21297340095043182, Class Loss=0.21297340095043182, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.166363924741745, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.166363924741745, Class Loss=0.166363924741745, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.16960372030735016, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.16960372030735016, Class Loss=0.16960372030735016, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.3173960864543915
Loss made of: CE 0.26919201016426086, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3127889931201935, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.3127889931201935, Class Loss=0.3127889931201935, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.2735911086201668
Loss made of: CE 0.2401285618543625, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2668849527835846, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.2668849527835846, Class Loss=0.2668849527835846, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.24306804984807967
Loss made of: CE 0.25557103753089905, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2493973672389984, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.2493973672389984, Class Loss=0.2493973672389984, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.24470063894987107
Loss made of: CE 0.24828597903251648, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2391989529132843, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.2391989529132843, Class Loss=0.2391989529132843, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.23342892676591873
Loss made of: CE 0.19118455052375793, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2291172593832016, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.2291172593832016, Class Loss=0.2291172593832016, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.2285858139395714
Loss made of: CE 0.22668051719665527, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23083244264125824, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.23083244264125824, Class Loss=0.23083244264125824, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.2933051735162735
Loss made of: CE 0.30254706740379333, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2852495312690735, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.2852495312690735, Class Loss=0.2852495312690735, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.2619644343852997
Loss made of: CE 0.2821154296398163, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26612603664398193, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.26612603664398193, Class Loss=0.26612603664398193, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.24370302259922028
Loss made of: CE 0.2496112883090973, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24722719192504883, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.24722719192504883, Class Loss=0.24722719192504883, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.24282585829496384
Loss made of: CE 0.21671807765960693, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23830881714820862, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.23830881714820862, Class Loss=0.23830881714820862, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.2192017361521721
Loss made of: CE 0.21335995197296143, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21835857629776, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.21835857629776, Class Loss=0.21835857629776, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.22374683618545532
Loss made of: CE 0.22784551978111267, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22909793257713318, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.22909793257713318, Class Loss=0.22909793257713318, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.7936524152755737, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.684477
Mean Acc: 0.091409
FreqW Acc: 0.490629
Mean IoU: 0.050836
Class IoU:
	class 0: 0.70258105
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.10467452
	class 18: 0.15862626
Class Acc:
	class 0: 0.9720981
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.27112085
	class 18: 0.493555

federated global round: 29, step: 5
select part of clients to conduct local training
[29, 27, 26, 18]
Current Client Index:  29
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.3416667222976685
Loss made of: CE 0.3423585891723633, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33352038264274597, Reg Loss=0.0
Clinet index 29, End of Epoch 1/6, Average Loss=0.33352038264274597, Class Loss=0.33352038264274597, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.2859240099787712
Loss made of: CE 0.22719614207744598, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28121232986450195, Reg Loss=0.0
Clinet index 29, End of Epoch 2/6, Average Loss=0.28121232986450195, Class Loss=0.28121232986450195, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.24504937827587128
Loss made of: CE 0.24253466725349426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.247669979929924, Reg Loss=0.0
Clinet index 29, End of Epoch 3/6, Average Loss=0.247669979929924, Class Loss=0.247669979929924, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.2350077360868454
Loss made of: CE 0.2343566119670868, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23483292758464813, Reg Loss=0.0
Clinet index 29, End of Epoch 4/6, Average Loss=0.23483292758464813, Class Loss=0.23483292758464813, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.23045099675655364
Loss made of: CE 0.19455496966838837, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22639384865760803, Reg Loss=0.0
Clinet index 29, End of Epoch 5/6, Average Loss=0.22639384865760803, Class Loss=0.22639384865760803, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.24012814909219743
Loss made of: CE 0.19909578561782837, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23538099229335785, Reg Loss=0.0
Clinet index 29, End of Epoch 6/6, Average Loss=0.23538099229335785, Class Loss=0.23538099229335785, Reg Loss=0.0
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.4062526524066925, Reg Loss=0.0
Clinet index 27, End of Epoch 1/6, Average Loss=0.4062526524066925, Class Loss=0.4062526524066925, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.3117479681968689, Reg Loss=0.0
Clinet index 27, End of Epoch 2/6, Average Loss=0.3117479681968689, Class Loss=0.3117479681968689, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.2187129259109497, Reg Loss=0.0
Clinet index 27, End of Epoch 3/6, Average Loss=0.2187129259109497, Class Loss=0.2187129259109497, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.18896064162254333, Reg Loss=0.0
Clinet index 27, End of Epoch 4/6, Average Loss=0.18896064162254333, Class Loss=0.18896064162254333, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.18625964224338531, Reg Loss=0.0
Clinet index 27, End of Epoch 5/6, Average Loss=0.18625964224338531, Class Loss=0.18625964224338531, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.16966049373149872, Reg Loss=0.0
Clinet index 27, End of Epoch 6/6, Average Loss=0.16966049373149872, Class Loss=0.16966049373149872, Reg Loss=0.0
Current Client Index:  26
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/12, Loss=0.3135020315647125
Loss made of: CE 0.24949774146080017, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3238743543624878, Reg Loss=0.0
Clinet index 26, End of Epoch 1/6, Average Loss=0.3238743543624878, Class Loss=0.3238743543624878, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/12, Loss=0.2969085216522217
Loss made of: CE 0.3170664310455322, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2900776267051697, Reg Loss=0.0
Clinet index 26, End of Epoch 2/6, Average Loss=0.2900776267051697, Class Loss=0.2900776267051697, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/12, Loss=0.26134029775857925
Loss made of: CE 0.23972195386886597, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.260270357131958, Reg Loss=0.0
Clinet index 26, End of Epoch 3/6, Average Loss=0.260270357131958, Class Loss=0.260270357131958, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/12, Loss=0.2423252895474434
Loss made of: CE 0.21756073832511902, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2457883208990097, Reg Loss=0.0
Clinet index 26, End of Epoch 4/6, Average Loss=0.2457883208990097, Class Loss=0.2457883208990097, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/12, Loss=0.23283912241458893
Loss made of: CE 0.21454155445098877, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2502034306526184, Reg Loss=0.0
Clinet index 26, End of Epoch 5/6, Average Loss=0.2502034306526184, Class Loss=0.2502034306526184, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/12, Loss=0.24335877150297164
Loss made of: CE 0.21827326714992523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2407469004392624, Reg Loss=0.0
Clinet index 26, End of Epoch 6/6, Average Loss=0.2407469004392624, Class Loss=0.2407469004392624, Reg Loss=0.0
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.33212681114673615
Loss made of: CE 0.2369837760925293, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.336769700050354, Reg Loss=0.0
Clinet index 18, End of Epoch 1/6, Average Loss=0.336769700050354, Class Loss=0.336769700050354, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.2825585722923279
Loss made of: CE 0.25282084941864014, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2751353085041046, Reg Loss=0.0
Clinet index 18, End of Epoch 2/6, Average Loss=0.2751353085041046, Class Loss=0.2751353085041046, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.2589401304721832
Loss made of: CE 0.22007064521312714, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25082898139953613, Reg Loss=0.0
Clinet index 18, End of Epoch 3/6, Average Loss=0.25082898139953613, Class Loss=0.25082898139953613, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.24518063068389892
Loss made of: CE 0.2240990251302719, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24749046564102173, Reg Loss=0.0
Clinet index 18, End of Epoch 4/6, Average Loss=0.24749046564102173, Class Loss=0.24749046564102173, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.2320214718580246
Loss made of: CE 0.19789598882198334, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23104789853096008, Reg Loss=0.0
Clinet index 18, End of Epoch 5/6, Average Loss=0.23104789853096008, Class Loss=0.23104789853096008, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.22488796710968018
Loss made of: CE 0.23748186230659485, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22739210724830627, Reg Loss=0.0
Clinet index 18, End of Epoch 6/6, Average Loss=0.22739210724830627, Class Loss=0.22739210724830627, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=1.8776723146438599, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.676339
Mean Acc: 0.090457
FreqW Acc: 0.480715
Mean IoU: 0.047464
Class IoU:
	class 0: 0.68889785
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 1.605348e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.04187467
	class 18: 0.17102553
Class Acc:
	class 0: 0.9585532
	class 1: 0.0
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 1.605348e-05
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.05021403
	class 18: 0.7098943

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 30, step: 6
select part of clients to conduct local training
[10, 30, 4, 33]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.1583055377006533
Loss made of: CE 2.2138686180114746, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.127800941467285, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=2.127800941467285, Class Loss=2.127800941467285, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.3102632403373717
Loss made of: CE 1.3716129064559937, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.23604416847229, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=1.23604416847229, Class Loss=1.23604416847229, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.5716977059841156
Loss made of: CE 0.5056900382041931, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5433884263038635, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.5433884263038635, Class Loss=0.5433884263038635, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.3089960694313049
Loss made of: CE 0.2015964388847351, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2973118722438812, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.2973118722438812, Class Loss=0.2973118722438812, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.22237870693206788
Loss made of: CE 0.184446781873703, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22099384665489197, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.22099384665489197, Class Loss=0.22099384665489197, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.19993274807929992
Loss made of: CE 0.20658943057060242, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19537696242332458, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.19537696242332458, Class Loss=0.19537696242332458, Reg Loss=0.0
Current Client Index:  30
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.4335852026939393
Loss made of: CE 1.2030730247497559, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.3480713367462158, Reg Loss=0.0
Clinet index 30, End of Epoch 1/6, Average Loss=1.3480713367462158, Class Loss=1.3480713367462158, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=0.9876255869865418
Loss made of: CE 0.825843334197998, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9323586821556091, Reg Loss=0.0
Clinet index 30, End of Epoch 2/6, Average Loss=0.9323586821556091, Class Loss=0.9323586821556091, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=0.6475678354501724
Loss made of: CE 0.49815917015075684, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6493633985519409, Reg Loss=0.0
Clinet index 30, End of Epoch 3/6, Average Loss=0.6493633985519409, Class Loss=0.6493633985519409, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=0.46319299638271333
Loss made of: CE 0.5302118062973022, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4678015112876892, Reg Loss=0.0
Clinet index 30, End of Epoch 4/6, Average Loss=0.4678015112876892, Class Loss=0.4678015112876892, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=0.3617775082588196
Loss made of: CE 0.4473946690559387, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.36029550433158875, Reg Loss=0.0
Clinet index 30, End of Epoch 5/6, Average Loss=0.36029550433158875, Class Loss=0.36029550433158875, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=0.31019224524497985
Loss made of: CE 0.33127984404563904, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2993735373020172, Reg Loss=0.0
Clinet index 30, End of Epoch 6/6, Average Loss=0.2993735373020172, Class Loss=0.2993735373020172, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.202612018585205
Loss made of: CE 2.3494722843170166, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.1221513748168945, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=2.1221513748168945, Class Loss=2.1221513748168945, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2175208926200867
Loss made of: CE 0.9808874130249023, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.202774167060852, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=1.202774167060852, Class Loss=1.202774167060852, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.6079923629760742
Loss made of: CE 0.5686846971511841, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.571678638458252, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.571678638458252, Class Loss=0.571678638458252, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.30866740345954896
Loss made of: CE 0.2523638606071472, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2999500036239624, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.2999500036239624, Class Loss=0.2999500036239624, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.21475483924150468
Loss made of: CE 0.1851893663406372, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21577434241771698, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.21577434241771698, Class Loss=0.21577434241771698, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.20394020080566405
Loss made of: CE 0.18212154507637024, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19584672152996063, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.19584672152996063, Class Loss=0.19584672152996063, Reg Loss=0.0
Current Client Index:  33
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.180364763736725
Loss made of: CE 1.6737722158432007, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.1243069171905518, Reg Loss=0.0
Clinet index 33, End of Epoch 1/6, Average Loss=2.1243069171905518, Class Loss=2.1243069171905518, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2467373132705688
Loss made of: CE 0.9750890731811523, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.1842122077941895, Reg Loss=0.0
Clinet index 33, End of Epoch 2/6, Average Loss=1.1842122077941895, Class Loss=1.1842122077941895, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.5572233766317367
Loss made of: CE 0.3858395516872406, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5305695533752441, Reg Loss=0.0
Clinet index 33, End of Epoch 3/6, Average Loss=0.5305695533752441, Class Loss=0.5305695533752441, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.2847612425684929
Loss made of: CE 0.19443315267562866, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28806498646736145, Reg Loss=0.0
Clinet index 33, End of Epoch 4/6, Average Loss=0.28806498646736145, Class Loss=0.28806498646736145, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.23054565340280533
Loss made of: CE 0.2709553837776184, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22298423945903778, Reg Loss=0.0
Clinet index 33, End of Epoch 5/6, Average Loss=0.22298423945903778, Class Loss=0.22298423945903778, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.19231312870979309
Loss made of: CE 0.16081193089485168, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.185843825340271, Reg Loss=0.0
Clinet index 33, End of Epoch 6/6, Average Loss=0.185843825340271, Class Loss=0.185843825340271, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=2.200509786605835, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.692225
Mean Acc: 0.084190
FreqW Acc: 0.499245
Mean IoU: 0.045812
Class IoU:
	class 0: 0.7212256
	class 1: 0.00021253654
	class 2: 0.0
	class 3: 0.0
	class 4: 0.042226467
	class 5: 0.0
	class 6: 0.005271463
	class 7: 0.0001560285
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.00029889372
	class 18: 0.0
	class 19: 0.19266157
	class 20: 0.0
Class Acc:
	class 0: 0.986965
	class 1: 0.00021253654
	class 2: 0.0
	class 3: 0.0
	class 4: 0.042241905
	class 5: 0.0
	class 6: 0.005271463
	class 7: 0.0001560285
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0002989181
	class 18: 0.0
	class 19: 0.73285407
	class 20: 0.0

federated global round: 31, step: 6
select part of clients to conduct local training
[9, 17, 14, 1]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.9784303724765777
Loss made of: CE 1.1204116344451904, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.941071093082428, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.941071093082428, Class Loss=0.941071093082428, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.7113211512565613
Loss made of: CE 0.4805779457092285, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.67360919713974, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.67360919713974, Class Loss=0.67360919713974, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.443413507938385
Loss made of: CE 0.3940311670303345, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4293239414691925, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.4293239414691925, Class Loss=0.4293239414691925, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.3270899564027786
Loss made of: CE 0.30059438943862915, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3158239722251892, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.3158239722251892, Class Loss=0.3158239722251892, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.26118893921375275
Loss made of: CE 0.18746134638786316, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25850608944892883, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.25850608944892883, Class Loss=0.25850608944892883, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.25200308561325074
Loss made of: CE 0.17372488975524902, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23801188170909882, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.23801188170909882, Class Loss=0.23801188170909882, Reg Loss=0.0
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.3097875252366066
Loss made of: CE 0.23996607959270477, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3018445372581482, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.3018445372581482, Class Loss=0.3018445372581482, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.20996922254562378
Loss made of: CE 0.16592656075954437, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21392515301704407, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.21392515301704407, Class Loss=0.21392515301704407, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.18013617247343064
Loss made of: CE 0.20870642364025116, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.17733703553676605, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.17733703553676605, Class Loss=0.17733703553676605, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.17369958013296127
Loss made of: CE 0.13795480132102966, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.16882848739624023, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.16882848739624023, Class Loss=0.16882848739624023, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.1547447808086872
Loss made of: CE 0.17620167136192322, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15378981828689575, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.15378981828689575, Class Loss=0.15378981828689575, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.1394789010286331
Loss made of: CE 0.11790069192647934, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13784587383270264, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.13784587383270264, Class Loss=0.13784587383270264, Reg Loss=0.0
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.9520577132701874
Loss made of: CE 0.9967045783996582, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8981980681419373, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.8981980681419373, Class Loss=0.8981980681419373, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.6460635632276535
Loss made of: CE 0.35998106002807617, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6232973337173462, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.6232973337173462, Class Loss=0.6232973337173462, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.4523708313703537
Loss made of: CE 0.2927500605583191, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4308236837387085, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.4308236837387085, Class Loss=0.4308236837387085, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.3290759488940239
Loss made of: CE 0.24642662703990936, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3284621834754944, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.3284621834754944, Class Loss=0.3284621834754944, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.2614576131105423
Loss made of: CE 0.20559915900230408, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26374420523643494, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.26374420523643494, Class Loss=0.26374420523643494, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.24111513644456864
Loss made of: CE 0.3323948383331299, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23555243015289307, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.23555243015289307, Class Loss=0.23555243015289307, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.3162229239940643
Loss made of: CE 0.26296108961105347, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3153369128704071, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.3153369128704071, Class Loss=0.3153369128704071, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.23409093767404557
Loss made of: CE 0.23928287625312805, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22758188843727112, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.22758188843727112, Class Loss=0.22758188843727112, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.18694547861814498
Loss made of: CE 0.15682989358901978, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18097899854183197, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.18097899854183197, Class Loss=0.18097899854183197, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.15988366603851317
Loss made of: CE 0.12495766580104828, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15641507506370544, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.15641507506370544, Class Loss=0.15641507506370544, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.15585327744483948
Loss made of: CE 0.16687695682048798, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15786772966384888, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.15786772966384888, Class Loss=0.15786772966384888, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.14711666703224183
Loss made of: CE 0.15856893360614777, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14897306263446808, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.14897306263446808, Class Loss=0.14897306263446808, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=2.210033893585205, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.692901
Mean Acc: 0.079138
FreqW Acc: 0.495773
Mean IoU: 0.045295
Class IoU:
	class 0: 0.71618944
	class 1: 0.0012454423
	class 2: 0.0
	class 3: 0.0
	class 4: 0.03291481
	class 5: 0.0
	class 6: 0.0043164124
	class 7: 0.00033979898
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 2.4082024e-06
	class 18: 0.0
	class 19: 0.19509834
	class 20: 0.0010856937
Class Acc:
	class 0: 0.9909428
	class 1: 0.0012454423
	class 2: 0.0
	class 3: 0.0
	class 4: 0.03291653
	class 5: 0.0
	class 6: 0.0043164124
	class 7: 0.00033979898
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 2.4082024e-06
	class 18: 0.0
	class 19: 0.63105214
	class 20: 0.0010923714

federated global round: 32, step: 6
select part of clients to conduct local training
[3, 8, 27, 7]
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.34950230419635775
Loss made of: CE 0.2749604880809784, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3336836099624634, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.3336836099624634, Class Loss=0.3336836099624634, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=0.20097673535346985
Loss made of: CE 0.20071719586849213, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.201416015625, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.201416015625, Class Loss=0.201416015625, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=0.17485748529434203
Loss made of: CE 0.13171783089637756, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.173574298620224, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.173574298620224, Class Loss=0.173574298620224, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.15784100592136383
Loss made of: CE 0.1354803889989853, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1567634642124176, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.1567634642124176, Class Loss=0.1567634642124176, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.15405771136283875
Loss made of: CE 0.1309148073196411, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15039311349391937, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.15039311349391937, Class Loss=0.15039311349391937, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.13514968678355216
Loss made of: CE 0.13535434007644653, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.13319279253482819, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.13319279253482819, Class Loss=0.13319279253482819, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.5389617055654525
Loss made of: CE 0.33232957124710083, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5096341967582703, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.5096341967582703, Class Loss=0.5096341967582703, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.3681711494922638
Loss made of: CE 0.3429921269416809, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3482503890991211, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.3482503890991211, Class Loss=0.3482503890991211, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.26389799267053604
Loss made of: CE 0.22324979305267334, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25703760981559753, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.25703760981559753, Class Loss=0.25703760981559753, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.21425997018814086
Loss made of: CE 0.32154393196105957, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21754325926303864, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.21754325926303864, Class Loss=0.21754325926303864, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.1923822671175003
Loss made of: CE 0.2162397801876068, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.193966805934906, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.193966805934906, Class Loss=0.193966805934906, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.17278483808040618
Loss made of: CE 0.2055443972349167, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17912276089191437, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.17912276089191437, Class Loss=0.17912276089191437, Reg Loss=0.0
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.5455183565616608
Loss made of: CE 0.39490920305252075, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5222154259681702, Reg Loss=0.0
Clinet index 27, End of Epoch 1/6, Average Loss=0.5222154259681702, Class Loss=0.5222154259681702, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.3620084494352341
Loss made of: CE 0.5138673782348633, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35840269923210144, Reg Loss=0.0
Clinet index 27, End of Epoch 2/6, Average Loss=0.35840269923210144, Class Loss=0.35840269923210144, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.2636924937367439
Loss made of: CE 0.2632569968700409, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27105632424354553, Reg Loss=0.0
Clinet index 27, End of Epoch 3/6, Average Loss=0.27105632424354553, Class Loss=0.27105632424354553, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.22522401958703994
Loss made of: CE 0.2057543694972992, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22458496689796448, Reg Loss=0.0
Clinet index 27, End of Epoch 4/6, Average Loss=0.22458496689796448, Class Loss=0.22458496689796448, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.2208794191479683
Loss made of: CE 0.19142353534698486, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21212023496627808, Reg Loss=0.0
Clinet index 27, End of Epoch 5/6, Average Loss=0.21212023496627808, Class Loss=0.21212023496627808, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.1775910347700119
Loss made of: CE 0.19654220342636108, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18373629450798035, Reg Loss=0.0
Clinet index 27, End of Epoch 6/6, Average Loss=0.18373629450798035, Class Loss=0.18373629450798035, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.5221764087677002
Loss made of: CE 0.5166893005371094, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5127004384994507, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.5127004384994507, Class Loss=0.5127004384994507, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.40958908200263977
Loss made of: CE 0.3521218001842499, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3726009130477905, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.3726009130477905, Class Loss=0.3726009130477905, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.2457357496023178
Loss made of: CE 0.22826123237609863, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25355038046836853, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.25355038046836853, Class Loss=0.25355038046836853, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.24186025857925414
Loss made of: CE 0.19550976157188416, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23821628093719482, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.23821628093719482, Class Loss=0.23821628093719482, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.20755488872528077
Loss made of: CE 0.19298593699932098, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20218251645565033, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.20218251645565033, Class Loss=0.20218251645565033, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.18482683300971986
Loss made of: CE 0.19155573844909668, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18140855431556702, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.18140855431556702, Class Loss=0.18140855431556702, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=2.2225570678710938, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.687212
Mean Acc: 0.080919
FreqW Acc: 0.485360
Mean IoU: 0.041556
Class IoU:
	class 0: 0.7047121
	class 1: 0.0036521864
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0014622133
	class 5: 0.0
	class 6: 0.00081372727
	class 7: 9.621491e-07
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.022026038
	class 20: 0.14000346
Class Acc:
	class 0: 0.9924255
	class 1: 0.0036521864
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0014622133
	class 5: 0.0
	class 6: 0.00081372727
	class 7: 9.621491e-07
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.023927014
	class 20: 0.6770265

federated global round: 33, step: 6
select part of clients to conduct local training
[6, 20, 13, 10]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.24581514298915863
Loss made of: CE 0.23121099174022675, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.24087144434452057, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.24087144434452057, Class Loss=0.24087144434452057, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=0.21355316042900085
Loss made of: CE 0.200190469622612, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21056009829044342, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.21056009829044342, Class Loss=0.21056009829044342, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=0.18651128858327864
Loss made of: CE 0.1574854701757431, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18040624260902405, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.18040624260902405, Class Loss=0.18040624260902405, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=0.17780470550060273
Loss made of: CE 0.15768097341060638, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17525923252105713, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.17525923252105713, Class Loss=0.17525923252105713, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=0.1636037029325962
Loss made of: CE 0.15811969339847565, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16125279664993286, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.16125279664993286, Class Loss=0.16125279664993286, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=0.14518463462591172
Loss made of: CE 0.10404916852712631, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15073613822460175, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.15073613822460175, Class Loss=0.15073613822460175, Reg Loss=0.0
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.23713981956243516
Loss made of: CE 0.18894317746162415, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2382027506828308, Reg Loss=0.0
Clinet index 20, End of Epoch 1/6, Average Loss=0.2382027506828308, Class Loss=0.2382027506828308, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=0.2181701973080635
Loss made of: CE 0.2187516689300537, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21332122385501862, Reg Loss=0.0
Clinet index 20, End of Epoch 2/6, Average Loss=0.21332122385501862, Class Loss=0.21332122385501862, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=0.19156138896942138
Loss made of: CE 0.15014642477035522, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19043099880218506, Reg Loss=0.0
Clinet index 20, End of Epoch 3/6, Average Loss=0.19043099880218506, Class Loss=0.19043099880218506, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=0.17807787358760835
Loss made of: CE 0.19206011295318604, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1772967427968979, Reg Loss=0.0
Clinet index 20, End of Epoch 4/6, Average Loss=0.1772967427968979, Class Loss=0.1772967427968979, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=0.1670205071568489
Loss made of: CE 0.17662525177001953, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16803662478923798, Reg Loss=0.0
Clinet index 20, End of Epoch 5/6, Average Loss=0.16803662478923798, Class Loss=0.16803662478923798, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=0.14827893376350404
Loss made of: CE 0.11567853391170502, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1519194096326828, Reg Loss=0.0
Clinet index 20, End of Epoch 6/6, Average Loss=0.1519194096326828, Class Loss=0.1519194096326828, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.5655476182699204
Loss made of: CE 0.434802383184433, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5241050124168396, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.5241050124168396, Class Loss=0.5241050124168396, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.24592501372098924
Loss made of: CE 0.22741512954235077, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23788784444332123, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.23788784444332123, Class Loss=0.23788784444332123, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.17189329266548156
Loss made of: CE 0.20855939388275146, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1705130785703659, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.1705130785703659, Class Loss=0.1705130785703659, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.15341628938913346
Loss made of: CE 0.1262737661600113, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15020444989204407, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.15020444989204407, Class Loss=0.15020444989204407, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.14068913236260414
Loss made of: CE 0.13897962868213654, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.14145305752754211, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.14145305752754211, Class Loss=0.14145305752754211, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.1454554796218872
Loss made of: CE 0.12993848323822021, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.14529724419116974, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.14529724419116974, Class Loss=0.14529724419116974, Reg Loss=0.0
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.5547163337469101
Loss made of: CE 0.6406183242797852, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5509271621704102, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.5509271621704102, Class Loss=0.5509271621704102, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/12, Loss=0.2876272648572922
Loss made of: CE 0.39326542615890503, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27521222829818726, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.27521222829818726, Class Loss=0.27521222829818726, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.18818536549806594
Loss made of: CE 0.20607684552669525, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18390938639640808, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.18390938639640808, Class Loss=0.18390938639640808, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/12, Loss=0.1672302469611168
Loss made of: CE 0.11978532373905182, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1661100536584854, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.1661100536584854, Class Loss=0.1661100536584854, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/12, Loss=0.1576802209019661
Loss made of: CE 0.15392902493476868, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15635362267494202, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.15635362267494202, Class Loss=0.15635362267494202, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/12, Loss=0.16002570241689681
Loss made of: CE 0.164812833070755, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1555330902338028, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.1555330902338028, Class Loss=0.1555330902338028, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=2.365297317504883, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.695295
Mean Acc: 0.101925
FreqW Acc: 0.498659
Mean IoU: 0.055601
Class IoU:
	class 0: 0.71746856
	class 1: 2.6498772e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.005101435
	class 5: 0.0
	class 6: 0.0002708038
	class 7: 6.4303626e-05
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.22103728
	class 20: 0.2236539
Class Acc:
	class 0: 0.98960495
	class 1: 2.6498772e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.005101435
	class 5: 0.0
	class 6: 0.0002708038
	class 7: 6.4303626e-05
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.5854227
	class 20: 0.5599394

federated global round: 34, step: 6
select part of clients to conduct local training
[19, 18, 27, 14]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.30046838372945783
Loss made of: CE 0.23493944108486176, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2892453968524933, Reg Loss=0.0
Clinet index 19, End of Epoch 1/6, Average Loss=0.2892453968524933, Class Loss=0.2892453968524933, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=0.2240806445479393
Loss made of: CE 0.2615053653717041, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2217104732990265, Reg Loss=0.0
Clinet index 19, End of Epoch 2/6, Average Loss=0.2217104732990265, Class Loss=0.2217104732990265, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.18848541676998137
Loss made of: CE 0.16202516853809357, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18550147116184235, Reg Loss=0.0
Clinet index 19, End of Epoch 3/6, Average Loss=0.18550147116184235, Class Loss=0.18550147116184235, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=0.17737063020467758
Loss made of: CE 0.1839095652103424, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17666363716125488, Reg Loss=0.0
Clinet index 19, End of Epoch 4/6, Average Loss=0.17666363716125488, Class Loss=0.17666363716125488, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=0.17569674402475358
Loss made of: CE 0.15476451814174652, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1689322292804718, Reg Loss=0.0
Clinet index 19, End of Epoch 5/6, Average Loss=0.1689322292804718, Class Loss=0.1689322292804718, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=0.16073080003261567
Loss made of: CE 0.18556413054466248, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17047756910324097, Reg Loss=0.0
Clinet index 19, End of Epoch 6/6, Average Loss=0.17047756910324097, Class Loss=0.17047756910324097, Reg Loss=0.0
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.2819238230586052
Loss made of: CE 0.2773190438747406, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.27550655603408813, Reg Loss=0.0
Clinet index 18, End of Epoch 1/6, Average Loss=0.27550655603408813, Class Loss=0.27550655603408813, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=0.21573814153671264
Loss made of: CE 0.200261652469635, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20984847843647003, Reg Loss=0.0
Clinet index 18, End of Epoch 2/6, Average Loss=0.20984847843647003, Class Loss=0.20984847843647003, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.19075192213058473
Loss made of: CE 0.16251522302627563, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18519742786884308, Reg Loss=0.0
Clinet index 18, End of Epoch 3/6, Average Loss=0.18519742786884308, Class Loss=0.18519742786884308, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=0.16666429191827775
Loss made of: CE 0.15196174383163452, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.17001651227474213, Reg Loss=0.0
Clinet index 18, End of Epoch 4/6, Average Loss=0.17001651227474213, Class Loss=0.17001651227474213, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=0.16485251039266585
Loss made of: CE 0.208317369222641, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.16000951826572418, Reg Loss=0.0
Clinet index 18, End of Epoch 5/6, Average Loss=0.16000951826572418, Class Loss=0.16000951826572418, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=0.16345937699079513
Loss made of: CE 0.18213626742362976, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16848593950271606, Reg Loss=0.0
Clinet index 18, End of Epoch 6/6, Average Loss=0.16848593950271606, Class Loss=0.16848593950271606, Reg Loss=0.0
Current Client Index:  27
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/13, Loss=0.27858558148145673
Loss made of: CE 0.20975539088249207, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.27497580647468567, Reg Loss=0.0
Clinet index 27, End of Epoch 1/6, Average Loss=0.27497580647468567, Class Loss=0.27497580647468567, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/13, Loss=0.2413995236158371
Loss made of: CE 0.3294034004211426, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2443009614944458, Reg Loss=0.0
Clinet index 27, End of Epoch 2/6, Average Loss=0.2443009614944458, Class Loss=0.2443009614944458, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/13, Loss=0.20375047177076339
Loss made of: CE 0.20093819499015808, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21111300587654114, Reg Loss=0.0
Clinet index 27, End of Epoch 3/6, Average Loss=0.21111300587654114, Class Loss=0.21111300587654114, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/13, Loss=0.18429792672395706
Loss made of: CE 0.179072767496109, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18808069825172424, Reg Loss=0.0
Clinet index 27, End of Epoch 4/6, Average Loss=0.18808069825172424, Class Loss=0.18808069825172424, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/13, Loss=0.20425311774015426
Loss made of: CE 0.15893104672431946, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19911497831344604, Reg Loss=0.0
Clinet index 27, End of Epoch 5/6, Average Loss=0.19911497831344604, Class Loss=0.19911497831344604, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/13, Loss=0.17314772456884384
Loss made of: CE 0.18429724872112274, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1814015954732895, Reg Loss=0.0
Clinet index 27, End of Epoch 6/6, Average Loss=0.1814015954732895, Class Loss=0.1814015954732895, Reg Loss=0.0
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/13, Loss=0.283254998922348
Loss made of: CE 0.2905411422252655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2753905653953552, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.2753905653953552, Class Loss=0.2753905653953552, Reg Loss=0.0
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/13, Loss=0.236037378013134
Loss made of: CE 0.16339531540870667, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22887025773525238, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.22887025773525238, Class Loss=0.22887025773525238, Reg Loss=0.0
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/13, Loss=0.20920997112989426
Loss made of: CE 0.14705033600330353, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.20040348172187805, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.20040348172187805, Class Loss=0.20040348172187805, Reg Loss=0.0
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/13, Loss=0.18444674462080002
Loss made of: CE 0.16140922904014587, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18606747686862946, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.18606747686862946, Class Loss=0.18606747686862946, Reg Loss=0.0
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/13, Loss=0.17055705040693284
Loss made of: CE 0.1448925882577896, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17210735380649567, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.17210735380649567, Class Loss=0.17210735380649567, Reg Loss=0.0
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/13, Loss=0.17017461508512496
Loss made of: CE 0.21373409032821655, LKD 0.0, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17087943851947784, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.17087943851947784, Class Loss=0.17087943851947784, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=2.3076798915863037, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.682702
Mean Acc: 0.084160
FreqW Acc: 0.482042
Mean IoU: 0.039854
Class IoU:
	class 0: 0.70064044
	class 1: 2.9230605e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.00022870454
	class 20: 0.13602611
Class Acc:
	class 0: 0.9853977
	class 1: 2.9230605e-05
	class 2: 0.0
	class 3: 0.0
	class 4: 0.0
	class 5: 0.0
	class 6: 0.0
	class 7: 0.0
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.0
	class 14: 0.0
	class 15: 0.0
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.00023035101
	class 20: 0.78169394

voc_8-2_FT On GPUs 2
Run in 41397s
