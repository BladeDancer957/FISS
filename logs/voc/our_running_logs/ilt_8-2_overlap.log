nohup: ignoring input
35
kvoc_8-2_ILT On GPUs 2\Writing in results/seed_2023-ov/2023-03-13_voc_8-2_ILT.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[4, 3, 1, 2]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[0, 4, 7, 2]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  4
Current Client Index:  7
Current Client Index:  2
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[1, 9, 3, 8]
Current Client Index:  1
Current Client Index:  9
Current Client Index:  3
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[5, 9, 0, 4]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Current Client Index:  0
Current Client Index:  4
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.11884414404630661, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.959771
Mean Acc: 0.898867
FreqW Acc: 0.927997
Mean IoU: 0.803600
Class IoU:
	class 0: 0.9505860659032771
	class 1: 0.9002121543757099
	class 2: 0.3911996045853578
	class 3: 0.7886755539422873
	class 4: 0.7227948650191602
	class 5: 0.777020491034379
	class 6: 0.9452273228283382
	class 7: 0.8680230685934628
	class 8: 0.8886579855388657
Class Acc:
	class 0: 0.9742031520387592
	class 1: 0.9505188705401268
	class 2: 0.8333169681087177
	class 3: 0.7954920085182839
	class 4: 0.8649138231019398
	class 5: 0.839701567241524
	class 6: 0.9766569231687022
	class 7: 0.9440467027150332
	class 8: 0.910953836504121

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[5, 11, 7, 1]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Epoch 1, Batch 10/27, Loss=27.038890194892883
Loss made of: CE 0.7402534484863281, LKD 0.501995861530304, LDE 20.50090217590332, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=19.216155177354814
Loss made of: CE 0.7005658149719238, LKD 1.5152215957641602, LDE 16.62281608581543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9798991680145264, Reg Loss=20.772375106811523
Clinet index 5, End of Epoch 1/6, Average Loss=21.752273559570312, Class Loss=0.9798991680145264, Reg Loss=20.772375106811523
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=16.13163141012192
Loss made of: CE 0.5566720366477966, LKD 0.8947773575782776, LDE 15.698941230773926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=15.252555596828461
Loss made of: CE 0.4925577640533447, LKD 0.5783993601799011, LDE 13.076892852783203, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6790774464607239, Reg Loss=15.066699028015137
Clinet index 5, End of Epoch 2/6, Average Loss=15.745776176452637, Class Loss=0.6790774464607239, Reg Loss=15.066699028015137
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=14.800563901662827
Loss made of: CE 0.7375969886779785, LKD 0.5847882628440857, LDE 13.79230785369873, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=12.99608226120472
Loss made of: CE 0.36833667755126953, LKD 0.8020980954170227, LDE 11.247085571289062, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4690316319465637, Reg Loss=13.267264366149902
Clinet index 5, End of Epoch 3/6, Average Loss=13.736295700073242, Class Loss=0.4690316319465637, Reg Loss=13.267264366149902
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=13.512007683515549
Loss made of: CE 0.356559693813324, LKD 0.4900890290737152, LDE 11.770169258117676, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=12.895879736542701
Loss made of: CE 0.2890487313270569, LKD 0.5077875852584839, LDE 11.20699691772461, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.39259180426597595, Reg Loss=12.76746940612793
Clinet index 5, End of Epoch 4/6, Average Loss=13.16006088256836, Class Loss=0.39259180426597595, Reg Loss=12.76746940612793
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=12.46433747112751
Loss made of: CE 0.2705405652523041, LKD 0.6954837441444397, LDE 11.601736068725586, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=11.853324991464614
Loss made of: CE 0.2806552052497864, LKD 0.5712793469429016, LDE 11.186501502990723, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.35747668147087097, Reg Loss=11.672889709472656
Clinet index 5, End of Epoch 5/6, Average Loss=12.030365943908691, Class Loss=0.35747668147087097, Reg Loss=11.672889709472656
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=11.99348267018795
Loss made of: CE 0.4962301254272461, LKD 1.2537157535552979, LDE 10.22697639465332, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=12.086589255928994
Loss made of: CE 0.3293505907058716, LKD 0.33269426226615906, LDE 10.357975959777832, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34587186574935913, Reg Loss=11.602652549743652
Clinet index 5, End of Epoch 6/6, Average Loss=11.948524475097656, Class Loss=0.34587186574935913, Reg Loss=11.602652549743652
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.3345773220062256, Reg Loss=42.19751739501953
Clinet index 11, End of Epoch 1/6, Average Loss=43.5320930480957, Class Loss=1.3345773220062256, Reg Loss=42.19751739501953
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.4662742614746094, Reg Loss=29.260862350463867
Clinet index 11, End of Epoch 2/6, Average Loss=30.727136611938477, Class Loss=1.4662742614746094, Reg Loss=29.260862350463867
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.2000091075897217, Reg Loss=25.263099670410156
Clinet index 11, End of Epoch 3/6, Average Loss=26.46310806274414, Class Loss=1.2000091075897217, Reg Loss=25.263099670410156
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8206357955932617, Reg Loss=21.930171966552734
Clinet index 11, End of Epoch 4/6, Average Loss=22.750808715820312, Class Loss=0.8206357955932617, Reg Loss=21.930171966552734
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.5341828465461731, Reg Loss=19.781818389892578
Clinet index 11, End of Epoch 5/6, Average Loss=20.316001892089844, Class Loss=0.5341828465461731, Reg Loss=19.781818389892578
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.4442388713359833, Reg Loss=18.20263671875
Clinet index 11, End of Epoch 6/6, Average Loss=18.646875381469727, Class Loss=0.4442388713359833, Reg Loss=18.20263671875
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/27, Loss=26.65141070783138
Loss made of: CE 0.8765465617179871, LKD 0.43308743834495544, LDE 21.074831008911133, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=18.691008341312408
Loss made of: CE 0.9934481382369995, LKD 0.6272181272506714, LDE 15.36395263671875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.981411337852478, Reg Loss=20.419008255004883
Clinet index 7, End of Epoch 1/6, Average Loss=21.400419235229492, Class Loss=0.981411337852478, Reg Loss=20.419008255004883
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=16.855089810490608
Loss made of: CE 1.2290699481964111, LKD 0.9526044130325317, LDE 14.088111877441406, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=15.180981451272965
Loss made of: CE 0.6019601821899414, LKD 0.6258310675621033, LDE 15.733763694763184, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7005707025527954, Reg Loss=14.933649063110352
Clinet index 7, End of Epoch 2/6, Average Loss=15.634220123291016, Class Loss=0.7005707025527954, Reg Loss=14.933649063110352
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=13.798769530653953
Loss made of: CE 0.49340397119522095, LKD 0.5752898454666138, LDE 12.694707870483398, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=13.993654605746269
Loss made of: CE 0.4774753451347351, LKD 0.5938994884490967, LDE 12.217116355895996, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.49214881658554077, Reg Loss=13.366789817810059
Clinet index 7, End of Epoch 3/6, Average Loss=13.858938217163086, Class Loss=0.49214881658554077, Reg Loss=13.366789817810059
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=13.02234066426754
Loss made of: CE 0.46006959676742554, LKD 0.46761706471443176, LDE 11.885327339172363, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=13.06026299893856
Loss made of: CE 0.5596599578857422, LKD 1.0554922819137573, LDE 12.01986026763916, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.39633211493492126, Reg Loss=12.56980037689209
Clinet index 7, End of Epoch 4/6, Average Loss=12.966132164001465, Class Loss=0.39633211493492126, Reg Loss=12.56980037689209
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=12.421456807851792
Loss made of: CE 0.32043468952178955, LKD 0.48937350511550903, LDE 9.718212127685547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=11.367818355560303
Loss made of: CE 0.3153805136680603, LKD 0.6826420426368713, LDE 10.877645492553711, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.36599183082580566, Reg Loss=11.698644638061523
Clinet index 7, End of Epoch 5/6, Average Loss=12.06463623046875, Class Loss=0.36599183082580566, Reg Loss=11.698644638061523
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=11.585025504231453
Loss made of: CE 0.4674496650695801, LKD 0.6956997513771057, LDE 11.457404136657715, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=12.828441235423089
Loss made of: CE 0.23931679129600525, LKD 0.6039334535598755, LDE 11.95847225189209, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35510343313217163, Reg Loss=11.659391403198242
Clinet index 7, End of Epoch 6/6, Average Loss=12.014494895935059, Class Loss=0.35510343313217163, Reg Loss=11.659391403198242
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/27, Loss=27.07433359324932
Loss made of: CE 0.8496512770652771, LKD 0.4640931189060211, LDE 18.686370849609375, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=19.549517863988875
Loss made of: CE 0.8300930857658386, LKD 0.7293516993522644, LDE 17.006092071533203, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9560868144035339, Reg Loss=20.541614532470703
Clinet index 1, End of Epoch 1/6, Average Loss=21.49770164489746, Class Loss=0.9560868144035339, Reg Loss=20.541614532470703
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=15.781678891181945
Loss made of: CE 0.6273075938224792, LKD 0.5466338396072388, LDE 14.191877365112305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=15.648804733157158
Loss made of: CE 0.5720207095146179, LKD 0.4075544476509094, LDE 14.390661239624023, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6671959161758423, Reg Loss=14.76007080078125
Clinet index 1, End of Epoch 2/6, Average Loss=15.427267074584961, Class Loss=0.6671959161758423, Reg Loss=14.76007080078125
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=13.552989813685418
Loss made of: CE 0.5327849984169006, LKD 0.37460678815841675, LDE 13.277620315551758, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=13.511776560544968
Loss made of: CE 0.45940083265304565, LKD 0.7659816741943359, LDE 11.662628173828125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4680316746234894, Reg Loss=12.902740478515625
Clinet index 1, End of Epoch 3/6, Average Loss=13.370772361755371, Class Loss=0.4680316746234894, Reg Loss=12.902740478515625
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=13.013265931606293
Loss made of: CE 0.34561532735824585, LKD 0.43771663308143616, LDE 11.011902809143066, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=12.7219922631979
Loss made of: CE 0.32960090041160583, LKD 0.32587018609046936, LDE 12.067359924316406, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3791784644126892, Reg Loss=12.474000930786133
Clinet index 1, End of Epoch 4/6, Average Loss=12.853178977966309, Class Loss=0.3791784644126892, Reg Loss=12.474000930786133
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=11.704084441065788
Loss made of: CE 0.3620395064353943, LKD 0.38437774777412415, LDE 10.574298858642578, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=11.848348453640938
Loss made of: CE 0.3075212240219116, LKD 0.40801945328712463, LDE 10.623719215393066, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34360507130622864, Reg Loss=11.53325080871582
Clinet index 1, End of Epoch 5/6, Average Loss=11.876855850219727, Class Loss=0.34360507130622864, Reg Loss=11.53325080871582
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=11.566353143751622
Loss made of: CE 0.32121580839157104, LKD 0.36263442039489746, LDE 9.895235061645508, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=11.335783782601357
Loss made of: CE 0.44108831882476807, LKD 1.820095419883728, LDE 11.407150268554688, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.33573344349861145, Reg Loss=11.020483016967773
Clinet index 1, End of Epoch 6/6, Average Loss=11.356216430664062, Class Loss=0.33573344349861145, Reg Loss=11.020483016967773
federated aggregation...
Validation, Class Loss=0.31541019678115845, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.909878
Mean Acc: 0.641780
FreqW Acc: 0.849755
Mean IoU: 0.583227
Class IoU:
	class 0: 0.91114616
	class 1: 0.83687156
	class 2: 0.35366893
	class 3: 0.39819437
	class 4: 0.7025901
	class 5: 0.6108818
	class 6: 0.90834266
	class 7: 0.82106006
	class 8: 0.8549148
	class 9: 0.01782534
	class 10: 0.0
Class Acc:
	class 0: 0.9796195
	class 1: 0.8586837
	class 2: 0.71466887
	class 3: 0.39887226
	class 4: 0.7928814
	class 5: 0.6332652
	class 6: 0.9205525
	class 7: 0.83857095
	class 8: 0.88049734
	class 9: 0.041964974
	class 10: 0.0

federated global round: 6, step: 1
select part of clients to conduct local training
[1, 6, 7, 3]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=12.151651158928871
Loss made of: CE 0.41030868887901306, LKD 0.43246951699256897, LDE 10.602387428283691, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=11.352041509747504
Loss made of: CE 0.3870045840740204, LKD 0.6346083283424377, LDE 10.914340019226074, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.39268893003463745, Reg Loss=10.976574897766113
Clinet index 1, End of Epoch 1/6, Average Loss=11.369263648986816, Class Loss=0.39268893003463745, Reg Loss=10.976574897766113
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=10.341836887598038
Loss made of: CE 0.35989558696746826, LKD 0.48547351360321045, LDE 9.596802711486816, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=10.768375039100647
Loss made of: CE 0.2753438949584961, LKD 0.3778786063194275, LDE 9.656146049499512, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3420785665512085, Reg Loss=10.076854705810547
Clinet index 1, End of Epoch 2/6, Average Loss=10.418932914733887, Class Loss=0.3420785665512085, Reg Loss=10.076854705810547
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=10.131040289998055
Loss made of: CE 0.36794623732566833, LKD 0.4430641829967499, LDE 9.83952522277832, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=9.875974902510643
Loss made of: CE 0.32181546092033386, LKD 0.4934685230255127, LDE 8.605294227600098, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3388354480266571, Reg Loss=9.612656593322754
Clinet index 1, End of Epoch 3/6, Average Loss=9.951492309570312, Class Loss=0.3388354480266571, Reg Loss=9.612656593322754
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=10.01522805094719
Loss made of: CE 0.2676711082458496, LKD 0.4877196252346039, LDE 8.255474090576172, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=10.226422575116157
Loss made of: CE 0.3028181791305542, LKD 0.2517375946044922, LDE 9.835404396057129, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.32209864258766174, Reg Loss=9.913248062133789
Clinet index 1, End of Epoch 4/6, Average Loss=10.235346794128418, Class Loss=0.32209864258766174, Reg Loss=9.913248062133789
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=9.568576881289482
Loss made of: CE 0.3119674324989319, LKD 0.3855833411216736, LDE 8.10855770111084, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=9.493540561199188
Loss made of: CE 0.2731817364692688, LKD 0.38858360052108765, LDE 8.769546508789062, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.31525737047195435, Reg Loss=9.325721740722656
Clinet index 1, End of Epoch 5/6, Average Loss=9.640978813171387, Class Loss=0.31525737047195435, Reg Loss=9.325721740722656
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Batch 10/27, Loss=9.681038461625576
Loss made of: CE 0.29659807682037354, LKD 0.3237784504890442, LDE 8.564539909362793, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=9.28408453464508
Loss made of: CE 0.39580869674682617, LKD 1.7665256261825562, LDE 9.563562393188477, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3060922920703888, Reg Loss=9.102259635925293
Clinet index 1, End of Epoch 6/6, Average Loss=9.40835189819336, Class Loss=0.3060922920703888, Reg Loss=9.102259635925293
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=12.073933485150338
Loss made of: CE 0.2882189154624939, LKD 0.8301059007644653, LDE 9.485477447509766, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=11.595765036344527
Loss made of: CE 0.36375319957733154, LKD 0.6639574766159058, LDE 10.544344902038574, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4250343143939972, Reg Loss=11.3367280960083
Clinet index 6, End of Epoch 1/6, Average Loss=11.761762619018555, Class Loss=0.4250343143939972, Reg Loss=11.3367280960083
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/27, Loss=11.220416924357414
Loss made of: CE 0.3148272633552551, LKD 0.48739370703697205, LDE 11.229082107543945, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=11.487429517507554
Loss made of: CE 0.4189267158508301, LKD 0.5012417435646057, LDE 10.822181701660156, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.37674325704574585, Reg Loss=10.980714797973633
Clinet index 6, End of Epoch 2/6, Average Loss=11.357458114624023, Class Loss=0.37674325704574585, Reg Loss=10.980714797973633
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/27, Loss=10.780174893140792
Loss made of: CE 0.34954023361206055, LKD 0.5113798975944519, LDE 11.833503723144531, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=10.711961609125137
Loss made of: CE 0.3105580508708954, LKD 0.6495959162712097, LDE 9.208457946777344, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3480182886123657, Reg Loss=10.44113826751709
Clinet index 6, End of Epoch 3/6, Average Loss=10.789156913757324, Class Loss=0.3480182886123657, Reg Loss=10.44113826751709
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/27, Loss=10.899360033869744
Loss made of: CE 0.39206939935684204, LKD 1.1824464797973633, LDE 9.196918487548828, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Batch 20/27, Loss=9.936802846193313
Loss made of: CE 0.2525915503501892, LKD 0.6359056830406189, LDE 9.06719970703125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.34103891253471375, Reg Loss=10.11037540435791
Clinet index 6, End of Epoch 4/6, Average Loss=10.451414108276367, Class Loss=0.34103891253471375, Reg Loss=10.11037540435791
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/27, Loss=10.068442749977113
Loss made of: CE 0.3094838857650757, LKD 0.7912046313285828, LDE 8.217693328857422, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=10.573678433895111
Loss made of: CE 0.3132161498069763, LKD 0.5041012167930603, LDE 10.940780639648438, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33172541856765747, Reg Loss=9.907670021057129
Clinet index 6, End of Epoch 5/6, Average Loss=10.239395141601562, Class Loss=0.33172541856765747, Reg Loss=9.907670021057129
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/27, Loss=10.047669632732868
Loss made of: CE 0.29143911600112915, LKD 0.6404306292533875, LDE 8.162604331970215, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=9.807066649198532
Loss made of: CE 0.2646326422691345, LKD 0.6026710271835327, LDE 7.978085994720459, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3317958116531372, Reg Loss=9.519401550292969
Clinet index 6, End of Epoch 6/6, Average Loss=9.851197242736816, Class Loss=0.3317958116531372, Reg Loss=9.519401550292969
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=12.168753385543823
Loss made of: CE 0.31175118684768677, LKD 0.42186239361763, LDE 11.577632904052734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=10.890056917071343
Loss made of: CE 0.3956170082092285, LKD 0.4605121910572052, LDE 9.052863121032715, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.41417521238327026, Reg Loss=11.191102027893066
Clinet index 7, End of Epoch 1/6, Average Loss=11.605277061462402, Class Loss=0.41417521238327026, Reg Loss=11.191102027893066
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=11.679151424765587
Loss made of: CE 0.6001476645469666, LKD 1.0759198665618896, LDE 10.798649787902832, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=10.622147703170777
Loss made of: CE 0.3363965153694153, LKD 0.5142881274223328, LDE 11.841755867004395, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.36857926845550537, Reg Loss=10.644989967346191
Clinet index 7, End of Epoch 2/6, Average Loss=11.013568878173828, Class Loss=0.36857926845550537, Reg Loss=10.644989967346191
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=10.076904606819152
Loss made of: CE 0.335545152425766, LKD 0.4845585823059082, LDE 9.67418384552002, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=10.349329441785812
Loss made of: CE 0.35512444376945496, LKD 0.5165930390357971, LDE 8.596960067749023, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3548389673233032, Reg Loss=9.832198143005371
Clinet index 7, End of Epoch 3/6, Average Loss=10.187037467956543, Class Loss=0.3548389673233032, Reg Loss=9.832198143005371
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=9.960645452141762
Loss made of: CE 0.400989294052124, LKD 0.4300348460674286, LDE 8.63593864440918, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=10.179128885269165
Loss made of: CE 0.42938143014907837, LKD 1.0504504442214966, LDE 9.329547882080078, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3410181701183319, Reg Loss=9.670516014099121
Clinet index 7, End of Epoch 4/6, Average Loss=10.011533737182617, Class Loss=0.3410181701183319, Reg Loss=9.670516014099121
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=9.874708539247512
Loss made of: CE 0.29727137088775635, LKD 0.5488287806510925, LDE 8.043575286865234, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=9.254970622062682
Loss made of: CE 0.3250052034854889, LKD 0.8003330826759338, LDE 8.878777503967285, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33172407746315, Reg Loss=9.350236892700195
Clinet index 7, End of Epoch 5/6, Average Loss=9.681961059570312, Class Loss=0.33172407746315, Reg Loss=9.350236892700195
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=9.629791766405106
Loss made of: CE 0.45677489042282104, LKD 0.672694206237793, LDE 9.455086708068848, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=10.74582332521677
Loss made of: CE 0.23993241786956787, LKD 0.7089337110519409, LDE 9.940752029418945, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32582929730415344, Reg Loss=9.746747016906738
Clinet index 7, End of Epoch 6/6, Average Loss=10.072576522827148, Class Loss=0.32582929730415344, Reg Loss=9.746747016906738
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.1851584911346436, Reg Loss=33.25162887573242
Clinet index 3, End of Epoch 1/6, Average Loss=34.43678665161133, Class Loss=1.1851584911346436, Reg Loss=33.25162887573242
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9838260412216187, Reg Loss=25.8643798828125
Clinet index 3, End of Epoch 2/6, Average Loss=26.84820556640625, Class Loss=0.9838260412216187, Reg Loss=25.8643798828125
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7608084082603455, Reg Loss=21.402587890625
Clinet index 3, End of Epoch 3/6, Average Loss=22.16339683532715, Class Loss=0.7608084082603455, Reg Loss=21.402587890625
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.5820201635360718, Reg Loss=19.88517189025879
Clinet index 3, End of Epoch 4/6, Average Loss=20.467191696166992, Class Loss=0.5820201635360718, Reg Loss=19.88517189025879
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.45114120841026306, Reg Loss=18.420982360839844
Clinet index 3, End of Epoch 5/6, Average Loss=18.87212371826172, Class Loss=0.45114120841026306, Reg Loss=18.420982360839844
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.2924083471298218, Reg Loss=16.504810333251953
Clinet index 3, End of Epoch 6/6, Average Loss=16.797218322753906, Class Loss=0.2924083471298218, Reg Loss=16.504810333251953
federated aggregation...
Validation, Class Loss=0.32615262269973755, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.893497
Mean Acc: 0.596315
FreqW Acc: 0.840747
Mean IoU: 0.537976
Class IoU:
	class 0: 0.9125087
	class 1: 0.807397
	class 2: 0.3138468
	class 3: 0.16196772
	class 4: 0.69845635
	class 5: 0.47515523
	class 6: 0.88970494
	class 7: 0.799054
	class 8: 0.81309307
	class 9: 0.046555452
	class 10: 0.0
Class Acc:
	class 0: 0.9709487
	class 1: 0.828333
	class 2: 0.58562607
	class 3: 0.16202635
	class 4: 0.7864788
	class 5: 0.48562512
	class 6: 0.89871633
	class 7: 0.8159494
	class 8: 0.8301648
	class 9: 0.19559707
	class 10: 0.0

federated global round: 7, step: 1
select part of clients to conduct local training
[13, 8, 0, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Class Loss=1.0296132564544678, Reg Loss=34.67106246948242
Clinet index 13, End of Epoch 1/6, Average Loss=35.70067596435547, Class Loss=1.0296132564544678, Reg Loss=34.67106246948242
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.9123196601867676, Reg Loss=26.314659118652344
Clinet index 13, End of Epoch 2/6, Average Loss=27.226978302001953, Class Loss=0.9123196601867676, Reg Loss=26.314659118652344
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.688857913017273, Reg Loss=22.546924591064453
Clinet index 13, End of Epoch 3/6, Average Loss=23.235782623291016, Class Loss=0.688857913017273, Reg Loss=22.546924591064453
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.5003407597541809, Reg Loss=20.14025115966797
Clinet index 13, End of Epoch 4/6, Average Loss=20.640592575073242, Class Loss=0.5003407597541809, Reg Loss=20.14025115966797
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.37620243430137634, Reg Loss=17.867584228515625
Clinet index 13, End of Epoch 5/6, Average Loss=18.243785858154297, Class Loss=0.37620243430137634, Reg Loss=17.867584228515625
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.3231486678123474, Reg Loss=17.321929931640625
Clinet index 13, End of Epoch 6/6, Average Loss=17.645078659057617, Class Loss=0.3231486678123474, Reg Loss=17.321929931640625
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Class Loss=1.1801955699920654, Reg Loss=35.913116455078125
Clinet index 8, End of Epoch 1/6, Average Loss=37.09331130981445, Class Loss=1.1801955699920654, Reg Loss=35.913116455078125
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.9708968997001648, Reg Loss=25.67217254638672
Clinet index 8, End of Epoch 2/6, Average Loss=26.643070220947266, Class Loss=0.9708968997001648, Reg Loss=25.67217254638672
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.7709156274795532, Reg Loss=22.116918563842773
Clinet index 8, End of Epoch 3/6, Average Loss=22.887834548950195, Class Loss=0.7709156274795532, Reg Loss=22.116918563842773
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.5754296779632568, Reg Loss=19.415477752685547
Clinet index 8, End of Epoch 4/6, Average Loss=19.990907669067383, Class Loss=0.5754296779632568, Reg Loss=19.415477752685547
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.4081518054008484, Reg Loss=18.60114097595215
Clinet index 8, End of Epoch 5/6, Average Loss=19.009292602539062, Class Loss=0.4081518054008484, Reg Loss=18.60114097595215
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.30074214935302734, Reg Loss=17.360105514526367
Clinet index 8, End of Epoch 6/6, Average Loss=17.660846710205078, Class Loss=0.30074214935302734, Reg Loss=17.360105514526367
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.1088052988052368, Reg Loss=33.679649353027344
Clinet index 0, End of Epoch 1/6, Average Loss=34.788455963134766, Class Loss=1.1088052988052368, Reg Loss=33.679649353027344
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.9362198710441589, Reg Loss=25.534564971923828
Clinet index 0, End of Epoch 2/6, Average Loss=26.47078514099121, Class Loss=0.9362198710441589, Reg Loss=25.534564971923828
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6658701300621033, Reg Loss=21.898296356201172
Clinet index 0, End of Epoch 3/6, Average Loss=22.564167022705078, Class Loss=0.6658701300621033, Reg Loss=21.898296356201172
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=0.4964398145675659, Reg Loss=20.586605072021484
Clinet index 0, End of Epoch 4/6, Average Loss=21.083044052124023, Class Loss=0.4964398145675659, Reg Loss=20.586605072021484
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.3631264865398407, Reg Loss=18.304264068603516
Clinet index 0, End of Epoch 5/6, Average Loss=18.667390823364258, Class Loss=0.3631264865398407, Reg Loss=18.304264068603516
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.3312188982963562, Reg Loss=16.998428344726562
Clinet index 0, End of Epoch 6/6, Average Loss=17.329647064208984, Class Loss=0.3312188982963562, Reg Loss=16.998428344726562
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=11.0627820789814
Loss made of: CE 0.2634323537349701, LKD 0.37982654571533203, LDE 9.231595993041992, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=10.076746690273286
Loss made of: CE 0.34674400091171265, LKD 1.2220425605773926, LDE 8.857282638549805, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.3333128094673157, Reg Loss=10.140990257263184
Clinet index 5, End of Epoch 1/6, Average Loss=10.474303245544434, Class Loss=0.3333128094673157, Reg Loss=10.140990257263184
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/27, Loss=9.719295053184032
Loss made of: CE 0.27581340074539185, LKD 0.7748551368713379, LDE 9.407901763916016, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=9.498529735207558
Loss made of: CE 0.29253077507019043, LKD 0.4142160415649414, LDE 7.870422840118408, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32089734077453613, Reg Loss=9.413243293762207
Clinet index 5, End of Epoch 2/6, Average Loss=9.734140396118164, Class Loss=0.32089734077453613, Reg Loss=9.413243293762207
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/27, Loss=9.975838005542755
Loss made of: CE 0.45410966873168945, LKD 0.687828540802002, LDE 9.106823921203613, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=9.005177995562553
Loss made of: CE 0.25270408391952515, LKD 0.7282383441925049, LDE 7.926454544067383, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31243976950645447, Reg Loss=9.165742874145508
Clinet index 5, End of Epoch 3/6, Average Loss=9.478182792663574, Class Loss=0.31243976950645447, Reg Loss=9.165742874145508
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/27, Loss=9.626850444078446
Loss made of: CE 0.2899909019470215, LKD 0.3963480591773987, LDE 8.724274635314941, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=9.34911654740572
Loss made of: CE 0.2508743405342102, LKD 0.5274323225021362, LDE 7.67229700088501, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.30342379212379456, Reg Loss=9.145442962646484
Clinet index 5, End of Epoch 4/6, Average Loss=9.448866844177246, Class Loss=0.30342379212379456, Reg Loss=9.145442962646484
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/27, Loss=9.405396348237991
Loss made of: CE 0.27026593685150146, LKD 0.6233672499656677, LDE 8.413865089416504, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=8.945207335054874
Loss made of: CE 0.26326584815979004, LKD 0.6650257110595703, LDE 8.162283897399902, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29974567890167236, Reg Loss=8.701620101928711
Clinet index 5, End of Epoch 5/6, Average Loss=9.001365661621094, Class Loss=0.29974567890167236, Reg Loss=8.701620101928711
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/27, Loss=9.070596648752689
Loss made of: CE 0.4108319878578186, LKD 0.8656435608863831, LDE 6.882847785949707, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=9.604425159096717
Loss made of: CE 0.28565770387649536, LKD 0.32348576188087463, LDE 7.512732028961182, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2964620292186737, Reg Loss=8.96438980102539
Clinet index 5, End of Epoch 6/6, Average Loss=9.260851860046387, Class Loss=0.2964620292186737, Reg Loss=8.96438980102539
federated aggregation...
Validation, Class Loss=0.26281216740608215, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.907155
Mean Acc: 0.643575
FreqW Acc: 0.849234
Mean IoU: 0.574021
Class IoU:
	class 0: 0.9171474
	class 1: 0.82191676
	class 2: 0.36115053
	class 3: 0.28612396
	class 4: 0.6871522
	class 5: 0.5404258
	class 6: 0.8897632
	class 7: 0.8420764
	class 8: 0.69432926
	class 9: 0.055918515
	class 10: 0.21822341
Class Acc:
	class 0: 0.9794582
	class 1: 0.83849543
	class 2: 0.70399684
	class 3: 0.28619665
	class 4: 0.7864984
	class 5: 0.5539174
	class 6: 0.89874256
	class 7: 0.8630761
	class 8: 0.70140404
	class 9: 0.111970246
	class 10: 0.3555693

federated global round: 8, step: 1
select part of clients to conduct local training
[12, 9, 4, 13]
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=19.560782754421233
Loss made of: CE 0.39447757601737976, LKD 0.7965366244316101, LDE 13.170513153076172, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=12.296240544319152
Loss made of: CE 0.2956722676753998, LKD 0.39104098081588745, LDE 10.884153366088867, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3619084656238556, Reg Loss=14.396455764770508
Clinet index 12, End of Epoch 1/6, Average Loss=14.7583646774292, Class Loss=0.3619084656238556, Reg Loss=14.396455764770508
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=10.348745635151863
Loss made of: CE 0.25353509187698364, LKD 0.5287300944328308, LDE 9.251411437988281, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=10.364286595582962
Loss made of: CE 0.37934887409210205, LKD 0.7955915927886963, LDE 10.149173736572266, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31604018807411194, Reg Loss=9.851703643798828
Clinet index 12, End of Epoch 2/6, Average Loss=10.167743682861328, Class Loss=0.31604018807411194, Reg Loss=9.851703643798828
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=9.635348054766656
Loss made of: CE 0.3264646828174591, LKD 0.7609948515892029, LDE 8.209417343139648, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=9.796619814634322
Loss made of: CE 0.2556965947151184, LKD 0.47061267495155334, LDE 8.979557037353516, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3087882697582245, Reg Loss=9.540361404418945
Clinet index 12, End of Epoch 3/6, Average Loss=9.849149703979492, Class Loss=0.3087882697582245, Reg Loss=9.540361404418945
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=9.21065384298563
Loss made of: CE 0.22976183891296387, LKD 0.6648666858673096, LDE 8.889266014099121, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=8.838842645287514
Loss made of: CE 0.2726859450340271, LKD 0.6494618654251099, LDE 7.919559478759766, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3020744323730469, Reg Loss=8.797501564025879
Clinet index 12, End of Epoch 4/6, Average Loss=9.099575996398926, Class Loss=0.3020744323730469, Reg Loss=8.797501564025879
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=9.332920217514038
Loss made of: CE 0.30171284079551697, LKD 0.47229471802711487, LDE 8.755823135375977, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 5, Batch 20/27, Loss=9.672919534146786
Loss made of: CE 0.3035913109779358, LKD 0.4269406199455261, LDE 7.8544182777404785, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29969164729118347, Reg Loss=9.252748489379883
Clinet index 12, End of Epoch 5/6, Average Loss=9.55243968963623, Class Loss=0.29969164729118347, Reg Loss=9.252748489379883
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=8.750484739243984
Loss made of: CE 0.2822045683860779, LKD 0.698443591594696, LDE 7.07871675491333, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=8.480902481079102
Loss made of: CE 0.35248813033103943, LKD 0.6395851373672485, LDE 7.9816670417785645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2970060110092163, Reg Loss=8.317218780517578
Clinet index 12, End of Epoch 6/6, Average Loss=8.614224433898926, Class Loss=0.2970060110092163, Reg Loss=8.317218780517578
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.4152016341686249, Reg Loss=18.283071517944336
Clinet index 9, End of Epoch 1/6, Average Loss=18.698272705078125, Class Loss=0.4152016341686249, Reg Loss=18.283071517944336
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.35010072588920593, Reg Loss=17.29829216003418
Clinet index 9, End of Epoch 2/6, Average Loss=17.648393630981445, Class Loss=0.35010072588920593, Reg Loss=17.29829216003418
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.2749907970428467, Reg Loss=16.662124633789062
Clinet index 9, End of Epoch 3/6, Average Loss=16.937114715576172, Class Loss=0.2749907970428467, Reg Loss=16.662124633789062
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=0.2364683747291565, Reg Loss=15.96948528289795
Clinet index 9, End of Epoch 4/6, Average Loss=16.20595359802246, Class Loss=0.2364683747291565, Reg Loss=15.96948528289795
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.2351665496826172, Reg Loss=15.424872398376465
Clinet index 9, End of Epoch 5/6, Average Loss=15.660038948059082, Class Loss=0.2351665496826172, Reg Loss=15.424872398376465
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.1908327341079712, Reg Loss=13.926534652709961
Clinet index 9, End of Epoch 6/6, Average Loss=14.1173677444458, Class Loss=0.1908327341079712, Reg Loss=13.926534652709961
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=18.979276540875436
Loss made of: CE 0.5061932802200317, LKD 0.5579604506492615, LDE 13.112336158752441, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=12.19471628665924
Loss made of: CE 0.36220258474349976, LKD 0.6238003969192505, LDE 9.609236717224121, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.37678998708724976, Reg Loss=14.121739387512207
Clinet index 4, End of Epoch 1/6, Average Loss=14.498529434204102, Class Loss=0.37678998708724976, Reg Loss=14.121739387512207
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=10.495278716087341
Loss made of: CE 0.29453322291374207, LKD 0.711457371711731, LDE 7.679754257202148, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=10.11993611752987
Loss made of: CE 0.3876085877418518, LKD 0.6543192267417908, LDE 7.894583225250244, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32769399881362915, Reg Loss=9.899845123291016
Clinet index 4, End of Epoch 2/6, Average Loss=10.2275390625, Class Loss=0.32769399881362915, Reg Loss=9.899845123291016
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=9.206358668208122
Loss made of: CE 0.2425784319639206, LKD 0.6459190249443054, LDE 8.327670097351074, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=10.215797334909439
Loss made of: CE 0.3667646646499634, LKD 0.698847234249115, LDE 7.931958198547363, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31124502420425415, Reg Loss=9.363341331481934
Clinet index 4, End of Epoch 3/6, Average Loss=9.674586296081543, Class Loss=0.31124502420425415, Reg Loss=9.363341331481934
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=9.534880955517291
Loss made of: CE 0.3576708734035492, LKD 1.02155339717865, LDE 9.021594047546387, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=9.521550092101098
Loss made of: CE 0.2687539756298065, LKD 0.6898587346076965, LDE 7.559054374694824, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.30470314621925354, Reg Loss=9.419161796569824
Clinet index 4, End of Epoch 4/6, Average Loss=9.723864555358887, Class Loss=0.30470314621925354, Reg Loss=9.419161796569824
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=9.362540997564793
Loss made of: CE 0.2862306833267212, LKD 0.8282866477966309, LDE 9.678860664367676, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=9.065845295786858
Loss made of: CE 0.33149588108062744, LKD 0.44568297266960144, LDE 7.978697299957275, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3059118390083313, Reg Loss=8.987458229064941
Clinet index 4, End of Epoch 5/6, Average Loss=9.293370246887207, Class Loss=0.3059118390083313, Reg Loss=8.987458229064941
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=9.102519899606705
Loss made of: CE 0.29394954442977905, LKD 0.34114137291908264, LDE 8.59182357788086, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=8.784399235248566
Loss made of: CE 0.26121455430984497, LKD 0.616532564163208, LDE 6.743584632873535, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2976471185684204, Reg Loss=8.563516616821289
Clinet index 4, End of Epoch 6/6, Average Loss=8.861164093017578, Class Loss=0.2976471185684204, Reg Loss=8.563516616821289
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.3953462541103363, Reg Loss=18.113967895507812
Clinet index 13, End of Epoch 1/6, Average Loss=18.509313583374023, Class Loss=0.3953462541103363, Reg Loss=18.113967895507812
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.3629259467124939, Reg Loss=17.121356964111328
Clinet index 13, End of Epoch 2/6, Average Loss=17.484283447265625, Class Loss=0.3629259467124939, Reg Loss=17.121356964111328
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.2957630753517151, Reg Loss=16.529449462890625
Clinet index 13, End of Epoch 3/6, Average Loss=16.825212478637695, Class Loss=0.2957630753517151, Reg Loss=16.529449462890625
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.29018634557724, Reg Loss=16.03936004638672
Clinet index 13, End of Epoch 4/6, Average Loss=16.329545974731445, Class Loss=0.29018634557724, Reg Loss=16.03936004638672
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.2581418752670288, Reg Loss=15.210979461669922
Clinet index 13, End of Epoch 5/6, Average Loss=15.469120979309082, Class Loss=0.2581418752670288, Reg Loss=15.210979461669922
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.24318228662014008, Reg Loss=15.095645904541016
Clinet index 13, End of Epoch 6/6, Average Loss=15.338828086853027, Class Loss=0.24318228662014008, Reg Loss=15.095645904541016
federated aggregation...
Validation, Class Loss=0.2678801417350769, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.905300
Mean Acc: 0.636411
FreqW Acc: 0.849417
Mean IoU: 0.569248
Class IoU:
	class 0: 0.9160115
	class 1: 0.81752384
	class 2: 0.3448342
	class 3: 0.21140876
	class 4: 0.69657457
	class 5: 0.5276722
	class 6: 0.8930074
	class 7: 0.8383635
	class 8: 0.7701948
	class 9: 0.0687383
	class 10: 0.17739634
Class Acc:
	class 0: 0.9764072
	class 1: 0.83169484
	class 2: 0.6738126
	class 3: 0.21144855
	class 4: 0.78798074
	class 5: 0.5414224
	class 6: 0.90250236
	class 7: 0.86061364
	class 8: 0.7808055
	class 9: 0.1684279
	class 10: 0.2654037

federated global round: 9, step: 1
select part of clients to conduct local training
[4, 6, 13, 12]
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=13.718496425449848
Loss made of: CE 0.4287782907485962, LKD 0.46729493141174316, LDE 10.137516021728516, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=10.180104687809944
Loss made of: CE 0.36046403646469116, LKD 0.7380515336990356, LDE 8.189079284667969, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3466876149177551, Reg Loss=11.073835372924805
Clinet index 4, End of Epoch 1/6, Average Loss=11.420522689819336, Class Loss=0.3466876149177551, Reg Loss=11.073835372924805
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=8.974037654697895
Loss made of: CE 0.2879076600074768, LKD 0.4993692934513092, LDE 6.499326229095459, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=8.69499783217907
Loss made of: CE 0.38731035590171814, LKD 0.6199793219566345, LDE 6.6592559814453125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.33216091990470886, Reg Loss=8.473353385925293
Clinet index 4, End of Epoch 2/6, Average Loss=8.805514335632324, Class Loss=0.33216091990470886, Reg Loss=8.473353385925293
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=7.808476477861404
Loss made of: CE 0.26515302062034607, LKD 0.6254897713661194, LDE 7.110570907592773, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=8.75377644598484
Loss made of: CE 0.36324000358581543, LKD 0.5722818970680237, LDE 6.774260997772217, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3172851502895355, Reg Loss=8.00939655303955
Clinet index 4, End of Epoch 3/6, Average Loss=8.326682090759277, Class Loss=0.3172851502895355, Reg Loss=8.00939655303955
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=8.130662441253662
Loss made of: CE 0.41378289461135864, LKD 0.9273972511291504, LDE 8.666807174682617, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=8.32760995477438
Loss made of: CE 0.25951865315437317, LKD 0.5717359781265259, LDE 6.619110107421875, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.31309980154037476, Reg Loss=8.084153175354004
Clinet index 4, End of Epoch 4/6, Average Loss=8.397253036499023, Class Loss=0.31309980154037476, Reg Loss=8.084153175354004
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=8.110931894183159
Loss made of: CE 0.25835976004600525, LKD 0.7257541418075562, LDE 8.110225677490234, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=7.89235921651125
Loss made of: CE 0.34712693095207214, LKD 0.44223684072494507, LDE 6.978166103363037, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3112255036830902, Reg Loss=7.728310585021973
Clinet index 4, End of Epoch 5/6, Average Loss=8.039536476135254, Class Loss=0.3112255036830902, Reg Loss=7.728310585021973
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=7.786654777824879
Loss made of: CE 0.31284546852111816, LKD 0.2923016846179962, LDE 6.736662864685059, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=7.8862548306584355
Loss made of: CE 0.2820114493370056, LKD 0.6805295944213867, LDE 5.811789512634277, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3100120723247528, Reg Loss=7.550994396209717
Clinet index 4, End of Epoch 6/6, Average Loss=7.861006259918213, Class Loss=0.3100120723247528, Reg Loss=7.550994396209717
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/27, Loss=13.360042563080787
Loss made of: CE 0.2784201502799988, LKD 0.7762865424156189, LDE 9.020769119262695, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=10.102841287851334
Loss made of: CE 0.353886216878891, LKD 0.6882095336914062, LDE 9.134684562683105, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3643040955066681, Reg Loss=10.726700782775879
Clinet index 6, End of Epoch 1/6, Average Loss=11.091005325317383, Class Loss=0.3643040955066681, Reg Loss=10.726700782775879
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/27, Loss=8.830798049271106
Loss made of: CE 0.2589537799358368, LKD 0.44584837555885315, LDE 8.976995468139648, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=9.134737405180932
Loss made of: CE 0.3760261535644531, LKD 0.4646558165550232, LDE 8.891352653503418, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.33694934844970703, Reg Loss=8.663166046142578
Clinet index 6, End of Epoch 2/6, Average Loss=9.000115394592285, Class Loss=0.33694934844970703, Reg Loss=8.663166046142578
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/27, Loss=8.540067380666732
Loss made of: CE 0.3451912999153137, LKD 0.4681340456008911, LDE 8.302431106567383, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=8.39307555258274
Loss made of: CE 0.2792125642299652, LKD 0.5906270146369934, LDE 7.079067230224609, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3236255347728729, Reg Loss=8.22056770324707
Clinet index 6, End of Epoch 3/6, Average Loss=8.544193267822266, Class Loss=0.3236255347728729, Reg Loss=8.22056770324707
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/27, Loss=8.504697060585022
Loss made of: CE 0.3537275791168213, LKD 1.2799537181854248, LDE 7.037087440490723, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Batch 20/27, Loss=8.022609592974186
Loss made of: CE 0.23879918456077576, LKD 0.5138612985610962, LDE 6.943076133728027, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3225288689136505, Reg Loss=7.993648529052734
Clinet index 6, End of Epoch 4/6, Average Loss=8.316177368164062, Class Loss=0.3225288689136505, Reg Loss=7.993648529052734
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/27, Loss=8.123690782487392
Loss made of: CE 0.3162234425544739, LKD 0.7055885791778564, LDE 6.063457012176514, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=8.411781692504883
Loss made of: CE 0.29717013239860535, LKD 0.5375714898109436, LDE 8.191911697387695, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3234102427959442, Reg Loss=7.833377838134766
Clinet index 6, End of Epoch 5/6, Average Loss=8.156787872314453, Class Loss=0.3234102427959442, Reg Loss=7.833377838134766
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/27, Loss=8.108275210857391
Loss made of: CE 0.2913933992385864, LKD 0.7110313773155212, LDE 6.939389705657959, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=7.679754507541657
Loss made of: CE 0.2635796070098877, LKD 0.646112322807312, LDE 6.060547828674316, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32007506489753723, Reg Loss=7.579580783843994
Clinet index 6, End of Epoch 6/6, Average Loss=7.899655818939209, Class Loss=0.32007506489753723, Reg Loss=7.579580783843994
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000372
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.45504260063171387, Reg Loss=24.23542594909668
Clinet index 13, End of Epoch 1/6, Average Loss=24.690467834472656, Class Loss=0.45504260063171387, Reg Loss=24.23542594909668
Pseudo labeling is: None
Epoch 2, lr = 0.000316
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 2, Class Loss=0.382846474647522, Reg Loss=20.40314292907715
Clinet index 13, End of Epoch 2/6, Average Loss=20.78598976135254, Class Loss=0.382846474647522, Reg Loss=20.40314292907715
Pseudo labeling is: None
Epoch 3, lr = 0.000258
Epoch 3, Class Loss=0.35049182176589966, Reg Loss=19.369098663330078
Clinet index 13, End of Epoch 3/6, Average Loss=19.71959114074707, Class Loss=0.35049182176589966, Reg Loss=19.369098663330078
Pseudo labeling is: None
Epoch 4, lr = 0.000199
Epoch 4, Class Loss=0.33488380908966064, Reg Loss=17.890729904174805
Clinet index 13, End of Epoch 4/6, Average Loss=18.225614547729492, Class Loss=0.33488380908966064, Reg Loss=17.890729904174805
Pseudo labeling is: None
Epoch 5, lr = 0.000138
Epoch 5, Class Loss=0.3354472815990448, Reg Loss=17.03757667541504
Clinet index 13, End of Epoch 5/6, Average Loss=17.373023986816406, Class Loss=0.3354472815990448, Reg Loss=17.03757667541504
Pseudo labeling is: None
Epoch 6, lr = 0.000074
Epoch 6, Class Loss=0.3410571813583374, Reg Loss=17.368284225463867
Clinet index 13, End of Epoch 6/6, Average Loss=17.709341049194336, Class Loss=0.3410571813583374, Reg Loss=17.368284225463867
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=13.786507073044778
Loss made of: CE 0.3730638921260834, LKD 0.9057769775390625, LDE 9.993404388427734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=10.104605540633202
Loss made of: CE 0.29295778274536133, LKD 0.4197964370250702, LDE 8.557450294494629, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3467622697353363, Reg Loss=11.005125045776367
Clinet index 12, End of Epoch 1/6, Average Loss=11.351887702941895, Class Loss=0.3467622697353363, Reg Loss=11.005125045776367
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=8.795448605716228
Loss made of: CE 0.276231050491333, LKD 0.44737765192985535, LDE 8.387279510498047, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=9.010005459189415
Loss made of: CE 0.3799228072166443, LKD 0.729045569896698, LDE 8.537225723266602, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3192947506904602, Reg Loss=8.440279006958008
Clinet index 12, End of Epoch 2/6, Average Loss=8.759573936462402, Class Loss=0.3192947506904602, Reg Loss=8.440279006958008
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Batch 10/27, Loss=8.521514953672886
Loss made of: CE 0.35196614265441895, LKD 0.8329922556877136, LDE 6.947055339813232, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=8.538588464260101
Loss made of: CE 0.2647712528705597, LKD 0.49623265862464905, LDE 6.984859466552734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31167975068092346, Reg Loss=8.27778434753418
Clinet index 12, End of Epoch 3/6, Average Loss=8.58946418762207, Class Loss=0.31167975068092346, Reg Loss=8.27778434753418
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=8.08413553237915
Loss made of: CE 0.22302332520484924, LKD 0.4763898551464081, LDE 7.702091217041016, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=7.840884113311768
Loss made of: CE 0.26090845465660095, LKD 0.5340743064880371, LDE 6.762704849243164, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.30337682366371155, Reg Loss=7.713200569152832
Clinet index 12, End of Epoch 4/6, Average Loss=8.01657772064209, Class Loss=0.30337682366371155, Reg Loss=7.713200569152832
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=8.070229423046111
Loss made of: CE 0.2955901622772217, LKD 0.4334275722503662, LDE 7.281215667724609, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=8.364063499867916
Loss made of: CE 0.3136187195777893, LKD 0.510845959186554, LDE 6.800952434539795, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3072417676448822, Reg Loss=7.984932899475098
Clinet index 12, End of Epoch 5/6, Average Loss=8.292174339294434, Class Loss=0.3072417676448822, Reg Loss=7.984932899475098
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=7.620117531716824
Loss made of: CE 0.2978496253490448, LKD 0.6707679033279419, LDE 5.882255554199219, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=7.574308860301971
Loss made of: CE 0.3273768424987793, LKD 0.5805778503417969, LDE 6.755349159240723, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.30579468607902527, Reg Loss=7.354419708251953
Clinet index 12, End of Epoch 6/6, Average Loss=7.660214424133301, Class Loss=0.30579468607902527, Reg Loss=7.354419708251953
federated aggregation...
Validation, Class Loss=0.28385862708091736, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.898600
Mean Acc: 0.626821
FreqW Acc: 0.844643
Mean IoU: 0.559761
Class IoU:
	class 0: 0.9119084
	class 1: 0.81751925
	class 2: 0.33029425
	class 3: 0.19583358
	class 4: 0.6878298
	class 5: 0.52814496
	class 6: 0.875614
	class 7: 0.81522626
	class 8: 0.80611897
	class 9: 0.07838285
	class 10: 0.11049715
Class Acc:
	class 0: 0.970364
	class 1: 0.8342428
	class 2: 0.63640535
	class 3: 0.19588745
	class 4: 0.7690234
	class 5: 0.5435138
	class 6: 0.88290066
	class 7: 0.83198375
	class 8: 0.82187897
	class 9: 0.28396404
	class 10: 0.12486515

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[10, 14, 16, 7]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=24.474344086647033
Loss made of: CE 1.1940932273864746, LKD 4.221327304840088, LDE 12.495063781738281, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=17.070516633987427
Loss made of: CE 1.073686122894287, LKD 4.805586814880371, LDE 9.619160652160645, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Class Loss=1.2894830703735352, Reg Loss=17.866819381713867
Clinet index 10, End of Epoch 1/6, Average Loss=19.15630340576172, Class Loss=1.2894830703735352, Reg Loss=17.866819381713867
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=14.458778414130212
Loss made of: CE 0.3678455352783203, LKD 4.952424049377441, LDE 7.944136619567871, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=13.777763149142265
Loss made of: CE 0.3198908567428589, LKD 4.723639488220215, LDE 7.696314811706543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.37916892766952515, Reg Loss=13.487374305725098
Clinet index 10, End of Epoch 2/6, Average Loss=13.86654281616211, Class Loss=0.37916892766952515, Reg Loss=13.487374305725098
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=13.2113302603364
Loss made of: CE 0.2841794490814209, LKD 4.510855674743652, LDE 6.920263290405273, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=12.201567877829074
Loss made of: CE 0.23954105377197266, LKD 4.586132526397705, LDE 6.444206237792969, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2886165976524353, Reg Loss=12.323309898376465
Clinet index 10, End of Epoch 3/6, Average Loss=12.611926078796387, Class Loss=0.2886165976524353, Reg Loss=12.323309898376465
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=12.192009291052818
Loss made of: CE 0.29644566774368286, LKD 5.748281955718994, LDE 7.321116924285889, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=11.918466511368752
Loss made of: CE 0.20869217813014984, LKD 4.955773830413818, LDE 7.282491683959961, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 4, Class Loss=0.27921074628829956, Reg Loss=11.92856502532959
Clinet index 10, End of Epoch 4/6, Average Loss=12.207776069641113, Class Loss=0.27921074628829956, Reg Loss=11.92856502532959
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=12.184890262782574
Loss made of: CE 0.30944061279296875, LKD 4.400433540344238, LDE 7.074399471282959, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch 5, Batch 20/29, Loss=11.588839919865132
Loss made of: CE 0.21487346291542053, LKD 4.734982490539551, LDE 6.360970497131348, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2766466438770294, Reg Loss=11.550145149230957
Clinet index 10, End of Epoch 5/6, Average Loss=11.826791763305664, Class Loss=0.2766466438770294, Reg Loss=11.550145149230957
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=11.266443525254726
Loss made of: CE 0.18823502957820892, LKD 4.741180896759033, LDE 6.027118682861328, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=11.084654648602008
Loss made of: CE 0.2500746250152588, LKD 4.669895172119141, LDE 6.1772847175598145, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25907957553863525, Reg Loss=11.11050033569336
Clinet index 10, End of Epoch 6/6, Average Loss=11.369580268859863, Class Loss=0.25907957553863525, Reg Loss=11.11050033569336
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=11.390482139587402
Loss made of: CE 1.5422325134277344, LKD 2.632174491882324, LDE 6.14985466003418, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6768471002578735, Reg Loss=9.417871475219727
Clinet index 14, End of Epoch 1/6, Average Loss=11.094718933105469, Class Loss=1.6768471002578735, Reg Loss=9.417871475219727
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=9.368245708942414
Loss made of: CE 1.0883891582489014, LKD 2.269299030303955, LDE 4.860418319702148, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2253350019454956, Reg Loss=8.172940254211426
Clinet index 14, End of Epoch 2/6, Average Loss=9.398275375366211, Class Loss=1.2253350019454956, Reg Loss=8.172940254211426
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=8.022625207901001
Loss made of: CE 0.8021129369735718, LKD 2.2813615798950195, LDE 4.685420989990234, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8721833229064941, Reg Loss=7.190869331359863
Clinet index 14, End of Epoch 3/6, Average Loss=8.063053131103516, Class Loss=0.8721833229064941, Reg Loss=7.190869331359863
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=7.866186571121216
Loss made of: CE 0.49974244832992554, LKD 1.9652804136276245, LDE 4.875405788421631, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6282608509063721, Reg Loss=7.12743616104126
Clinet index 14, End of Epoch 4/6, Average Loss=7.755697250366211, Class Loss=0.6282608509063721, Reg Loss=7.12743616104126
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=7.419420725107193
Loss made of: CE 0.5243582129478455, LKD 2.746053695678711, LDE 5.7367706298828125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.48054611682891846, Reg Loss=6.952152252197266
Clinet index 14, End of Epoch 5/6, Average Loss=7.4326982498168945, Class Loss=0.48054611682891846, Reg Loss=6.952152252197266
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=7.245822414755821
Loss made of: CE 0.3892526626586914, LKD 1.816654920578003, LDE 4.029386520385742, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4417227506637573, Reg Loss=6.923834323883057
Clinet index 14, End of Epoch 6/6, Average Loss=7.3655571937561035, Class Loss=0.4417227506637573, Reg Loss=6.923834323883057
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=25.936094951629638
Loss made of: CE 1.5384416580200195, LKD 4.943352699279785, LDE 13.603788375854492, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Batch 20/29, Loss=18.423453080654145
Loss made of: CE 1.098254680633545, LKD 5.1945648193359375, LDE 10.501358985900879, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.339216709136963, Reg Loss=18.91312599182129
Clinet index 16, End of Epoch 1/6, Average Loss=20.252342224121094, Class Loss=1.339216709136963, Reg Loss=18.91312599182129
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=13.951377040147781
Loss made of: CE 0.3609418272972107, LKD 5.1542649269104, LDE 8.179862022399902, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=13.952734589576721
Loss made of: CE 0.26361119747161865, LKD 4.7692694664001465, LDE 8.37370777130127, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.38458168506622314, Reg Loss=13.36616325378418
Clinet index 16, End of Epoch 2/6, Average Loss=13.750744819641113, Class Loss=0.38458168506622314, Reg Loss=13.36616325378418
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=13.089163003861904
Loss made of: CE 0.33598339557647705, LKD 5.420792102813721, LDE 8.231225967407227, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=12.638892844319344
Loss made of: CE 0.2025797814130783, LKD 4.015248775482178, LDE 9.18090534210205, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2847599685192108, Reg Loss=12.513413429260254
Clinet index 16, End of Epoch 3/6, Average Loss=12.798172950744629, Class Loss=0.2847599685192108, Reg Loss=12.513413429260254
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=12.221049198508263
Loss made of: CE 0.3360702395439148, LKD 4.384663105010986, LDE 6.660963535308838, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=12.183045783638955
Loss made of: CE 0.27334797382354736, LKD 5.291220188140869, LDE 6.39734411239624, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2712846100330353, Reg Loss=11.835187911987305
Clinet index 16, End of Epoch 4/6, Average Loss=12.106472969055176, Class Loss=0.2712846100330353, Reg Loss=11.835187911987305
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=11.649156028032303
Loss made of: CE 0.2796633243560791, LKD 5.08745813369751, LDE 6.798864841461182, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=11.593030387163163
Loss made of: CE 0.19012144207954407, LKD 3.5795319080352783, LDE 7.213747501373291, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26880258321762085, Reg Loss=11.469000816345215
Clinet index 16, End of Epoch 5/6, Average Loss=11.73780345916748, Class Loss=0.26880258321762085, Reg Loss=11.469000816345215
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=11.202594915032387
Loss made of: CE 0.2813373804092407, LKD 5.066577911376953, LDE 5.0132341384887695, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=11.44112803786993
Loss made of: CE 0.24199382960796356, LKD 4.783539295196533, LDE 7.298999309539795, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26680317521095276, Reg Loss=11.149593353271484
Clinet index 16, End of Epoch 6/6, Average Loss=11.416396141052246, Class Loss=0.26680317521095276, Reg Loss=11.149593353271484
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=11.434952473640442
Loss made of: CE 1.4359300136566162, LKD 2.1132736206054688, LDE 5.929787635803223, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6346375942230225, Reg Loss=9.441027641296387
Clinet index 7, End of Epoch 1/6, Average Loss=11.075665473937988, Class Loss=1.6346375942230225, Reg Loss=9.441027641296387
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=9.163684284687042
Loss made of: CE 1.2028782367706299, LKD 2.219179153442383, LDE 4.818434715270996, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2131662368774414, Reg Loss=8.066049575805664
Clinet index 7, End of Epoch 2/6, Average Loss=9.279215812683105, Class Loss=1.2131662368774414, Reg Loss=8.066049575805664
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=8.550907760858536
Loss made of: CE 0.7160396575927734, LKD 2.69107723236084, LDE 5.159209251403809, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8916243314743042, Reg Loss=7.585546970367432
Clinet index 7, End of Epoch 3/6, Average Loss=8.477170944213867, Class Loss=0.8916243314743042, Reg Loss=7.585546970367432
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=8.160887691378594
Loss made of: CE 0.5283593535423279, LKD 2.430290460586548, LDE 5.376806259155273, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.612470805644989, Reg Loss=7.342051982879639
Clinet index 7, End of Epoch 4/6, Average Loss=7.954522609710693, Class Loss=0.612470805644989, Reg Loss=7.342051982879639
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=7.821065199375153
Loss made of: CE 0.4362289309501648, LKD 1.84347665309906, LDE 5.039761543273926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4919646978378296, Reg Loss=7.376170635223389
Clinet index 7, End of Epoch 5/6, Average Loss=7.868135452270508, Class Loss=0.4919646978378296, Reg Loss=7.376170635223389
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=7.725915586948394
Loss made of: CE 0.4127735495567322, LKD 1.9260447025299072, LDE 4.752340793609619, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.44073164463043213, Reg Loss=7.2031731605529785
Clinet index 7, End of Epoch 6/6, Average Loss=7.643904685974121, Class Loss=0.44073164463043213, Reg Loss=7.2031731605529785
federated aggregation...
Validation, Class Loss=0.3954890966415405, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.871301
Mean Acc: 0.554089
FreqW Acc: 0.783062
Mean IoU: 0.492019
Class IoU:
	class 0: 0.87399566
	class 1: 0.8568307
	class 2: 0.35148975
	class 3: 0.30533993
	class 4: 0.6925701
	class 5: 0.52816814
	class 6: 0.89833313
	class 7: 0.8292115
	class 8: 0.76945347
	class 9: 0.077911735
	class 10: 0.005559803
	class 11: 3.2639447e-05
	class 12: 0.20735657
Class Acc:
	class 0: 0.9794816
	class 1: 0.8807432
	class 2: 0.7098761
	class 3: 0.3055036
	class 4: 0.7816279
	class 5: 0.54110396
	class 6: 0.906047
	class 7: 0.8457194
	class 8: 0.8037483
	class 9: 0.19775659
	class 10: 0.005696677
	class 11: 3.3132415e-05
	class 12: 0.24582276

federated global round: 11, step: 2
select part of clients to conduct local training
[10, 13, 6, 1]
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Batch 10/29, Loss=16.47159925699234
Loss made of: CE 0.4404541850090027, LKD 4.4116644859313965, LDE 8.577804565429688, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=12.827195286750793
Loss made of: CE 0.3692009449005127, LKD 4.649689197540283, LDE 6.657519817352295, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.49282747507095337, Reg Loss=13.61194133758545
Clinet index 10, End of Epoch 1/6, Average Loss=14.104768753051758, Class Loss=0.49282747507095337, Reg Loss=13.61194133758545
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/29, Loss=12.74917533993721
Loss made of: CE 0.29479849338531494, LKD 5.022662162780762, LDE 6.546918869018555, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=12.241860096156596
Loss made of: CE 0.3085181415081024, LKD 4.591831684112549, LDE 6.9625959396362305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29627397656440735, Reg Loss=12.081073760986328
Clinet index 10, End of Epoch 2/6, Average Loss=12.377347946166992, Class Loss=0.29627397656440735, Reg Loss=12.081073760986328
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/29, Loss=11.866278314590454
Loss made of: CE 0.2653917968273163, LKD 4.4212188720703125, LDE 5.680801868438721, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=11.384043441712857
Loss made of: CE 0.2542385458946228, LKD 4.375272750854492, LDE 5.970301628112793, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.28015774488449097, Reg Loss=11.235562324523926
Clinet index 10, End of Epoch 3/6, Average Loss=11.51572036743164, Class Loss=0.28015774488449097, Reg Loss=11.235562324523926
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/29, Loss=11.076609002053738
Loss made of: CE 0.28970593214035034, LKD 5.341737747192383, LDE 5.792913913726807, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=11.197333709895611
Loss made of: CE 0.20396284759044647, LKD 4.687097549438477, LDE 6.3342390060424805, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.272731214761734, Reg Loss=11.021990776062012
Clinet index 10, End of Epoch 4/6, Average Loss=11.294721603393555, Class Loss=0.272731214761734, Reg Loss=11.021990776062012
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=11.535799580812455
Loss made of: CE 0.2845227122306824, LKD 4.158630847930908, LDE 6.182784080505371, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 5, Batch 20/29, Loss=10.935867123305798
Loss made of: CE 0.2134421169757843, LKD 4.667262554168701, LDE 6.061524391174316, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2660714387893677, Reg Loss=10.97498893737793
Clinet index 10, End of Epoch 5/6, Average Loss=11.241060256958008, Class Loss=0.2660714387893677, Reg Loss=10.97498893737793
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/29, Loss=10.811116184294224
Loss made of: CE 0.19056157767772675, LKD 4.975081920623779, LDE 5.773582935333252, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=10.767346328496933
Loss made of: CE 0.24395829439163208, LKD 4.723748683929443, LDE 6.257499694824219, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.265682190656662, Reg Loss=10.714698791503906
Clinet index 10, End of Epoch 6/6, Average Loss=10.98038101196289, Class Loss=0.265682190656662, Reg Loss=10.714698791503906
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=16.20658544301987
Loss made of: CE 0.4956059455871582, LKD 4.318597793579102, LDE 8.03320598602295, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=13.573955330252648
Loss made of: CE 0.32071584463119507, LKD 5.202057838439941, LDE 7.072209358215332, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4789462983608246, Reg Loss=13.547313690185547
Clinet index 13, End of Epoch 1/6, Average Loss=14.026260375976562, Class Loss=0.4789462983608246, Reg Loss=13.547313690185547
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/29, Loss=12.268848195672035
Loss made of: CE 0.35141462087631226, LKD 5.5605316162109375, LDE 6.133260726928711, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=11.723345766961575
Loss made of: CE 0.2764437198638916, LKD 5.195541858673096, LDE 6.844293117523193, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 2, Class Loss=0.2896137237548828, Reg Loss=11.771543502807617
Clinet index 13, End of Epoch 2/6, Average Loss=12.0611572265625, Class Loss=0.2896137237548828, Reg Loss=11.771543502807617
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/29, Loss=12.620679439604283
Loss made of: CE 0.2316269725561142, LKD 5.478968620300293, LDE 8.235523223876953, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=13.00234596133232
Loss made of: CE 0.23306581377983093, LKD 4.988429069519043, LDE 6.86467981338501, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2789566218852997, Reg Loss=12.136726379394531
Clinet index 13, End of Epoch 3/6, Average Loss=12.415682792663574, Class Loss=0.2789566218852997, Reg Loss=12.136726379394531
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 4, Batch 10/29, Loss=12.07816896289587
Loss made of: CE 0.23278316855430603, LKD 4.886424541473389, LDE 6.221284866333008, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=11.604874719679355
Loss made of: CE 0.2262246012687683, LKD 5.046969413757324, LDE 5.502480983734131, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26683393120765686, Reg Loss=11.371492385864258
Clinet index 13, End of Epoch 4/6, Average Loss=11.638326644897461, Class Loss=0.26683393120765686, Reg Loss=11.371492385864258
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/29, Loss=11.247781333327293
Loss made of: CE 0.21068191528320312, LKD 5.705937385559082, LDE 6.8741230964660645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=11.373362511396408
Loss made of: CE 0.22219717502593994, LKD 4.776787757873535, LDE 7.466626167297363, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2590995728969574, Reg Loss=11.072651863098145
Clinet index 13, End of Epoch 5/6, Average Loss=11.331751823425293, Class Loss=0.2590995728969574, Reg Loss=11.072651863098145
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/29, Loss=10.997945937514306
Loss made of: CE 0.21556983888149261, LKD 4.407360553741455, LDE 5.883633136749268, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=10.955075648427009
Loss made of: CE 0.29229068756103516, LKD 5.383114337921143, LDE 5.612644672393799, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2562766373157501, Reg Loss=10.708576202392578
Clinet index 13, End of Epoch 6/6, Average Loss=10.964853286743164, Class Loss=0.2562766373157501, Reg Loss=10.708576202392578
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=12.036526674032212
Loss made of: CE 0.9276679754257202, LKD 2.2131667137145996, LDE 6.316882133483887, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8402180075645447, Reg Loss=11.033782005310059
Clinet index 6, End of Epoch 1/6, Average Loss=11.87399959564209, Class Loss=0.8402180075645447, Reg Loss=11.033782005310059
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=9.249619257450103
Loss made of: CE 0.5333389639854431, LKD 2.322489023208618, LDE 5.340962886810303, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6226513385772705, Reg Loss=8.623124122619629
Clinet index 6, End of Epoch 2/6, Average Loss=9.24577522277832, Class Loss=0.6226513385772705, Reg Loss=8.623124122619629
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=8.083372017741203
Loss made of: CE 0.3472110629081726, LKD 2.0784554481506348, LDE 5.7768778800964355, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4721510112285614, Reg Loss=7.674663066864014
Clinet index 6, End of Epoch 3/6, Average Loss=8.146814346313477, Class Loss=0.4721510112285614, Reg Loss=7.674663066864014
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=8.002169933915138
Loss made of: CE 0.4567767083644867, LKD 1.9047942161560059, LDE 5.017827033996582, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.45734190940856934, Reg Loss=7.361907005310059
Clinet index 6, End of Epoch 4/6, Average Loss=7.819249153137207, Class Loss=0.45734190940856934, Reg Loss=7.361907005310059
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=7.523051628470421
Loss made of: CE 0.42747995257377625, LKD 2.4541702270507812, LDE 4.480437755584717, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4158410131931305, Reg Loss=7.251789569854736
Clinet index 6, End of Epoch 5/6, Average Loss=7.667630672454834, Class Loss=0.4158410131931305, Reg Loss=7.251789569854736
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=7.306530371308327
Loss made of: CE 0.3546414375305176, LKD 2.2284963130950928, LDE 4.097350597381592, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.39303314685821533, Reg Loss=6.908738613128662
Clinet index 6, End of Epoch 6/6, Average Loss=7.301771640777588, Class Loss=0.39303314685821533, Reg Loss=6.908738613128662
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=12.133747667074203
Loss made of: CE 0.8683558702468872, LKD 2.8140549659729004, LDE 7.147424697875977, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7834237217903137, Reg Loss=10.864128112792969
Clinet index 1, End of Epoch 1/6, Average Loss=11.647551536560059, Class Loss=0.7834237217903137, Reg Loss=10.864128112792969
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=8.916758039593697
Loss made of: CE 0.38009485602378845, LKD 2.317294120788574, LDE 5.64717435836792, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5498138070106506, Reg Loss=8.090208053588867
Clinet index 1, End of Epoch 2/6, Average Loss=8.640022277832031, Class Loss=0.5498138070106506, Reg Loss=8.090208053588867
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=7.653601008653641
Loss made of: CE 0.4616991877555847, LKD 2.3785085678100586, LDE 4.010262489318848, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.42527297139167786, Reg Loss=7.257512092590332
Clinet index 1, End of Epoch 3/6, Average Loss=7.6827850341796875, Class Loss=0.42527297139167786, Reg Loss=7.257512092590332
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=7.861414957046509
Loss made of: CE 0.408612459897995, LKD 2.4642322063446045, LDE 5.107332229614258, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3959397077560425, Reg Loss=7.322061061859131
Clinet index 1, End of Epoch 4/6, Average Loss=7.718000888824463, Class Loss=0.3959397077560425, Reg Loss=7.322061061859131
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=7.092933931946755
Loss made of: CE 0.3377857208251953, LKD 2.294337749481201, LDE 3.9633002281188965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3703569769859314, Reg Loss=6.731691360473633
Clinet index 1, End of Epoch 5/6, Average Loss=7.102048397064209, Class Loss=0.3703569769859314, Reg Loss=6.731691360473633
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=6.985277754068375
Loss made of: CE 0.36035531759262085, LKD 2.1152687072753906, LDE 5.369109153747559, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3630410134792328, Reg Loss=6.792145252227783
Clinet index 1, End of Epoch 6/6, Average Loss=7.155186176300049, Class Loss=0.3630410134792328, Reg Loss=6.792145252227783
federated aggregation...
Validation, Class Loss=0.43599942326545715, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.852331
Mean Acc: 0.485611
FreqW Acc: 0.775103
Mean IoU: 0.401561
Class IoU:
	class 0: 0.90800565
	class 1: 0.833509
	class 2: 0.33025375
	class 3: 0.059035692
	class 4: 0.6549788
	class 5: 0.2875464
	class 6: 0.8178931
	class 7: 0.7838686
	class 8: 0.10826635
	class 9: 0.10769451
	class 10: 0.0
	class 11: 0.02910174
	class 12: 0.30014494
Class Acc:
	class 0: 0.9778426
	class 1: 0.8516151
	class 2: 0.62662774
	class 3: 0.05903583
	class 4: 0.71893173
	class 5: 0.29073793
	class 6: 0.82338196
	class 7: 0.79214936
	class 8: 0.10833764
	class 9: 0.17750765
	class 10: 0.0
	class 11: 0.04036656
	class 12: 0.84641266

federated global round: 12, step: 2
select part of clients to conduct local training
[11, 0, 8, 14]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=11.332292902469636
Loss made of: CE 0.5913697481155396, LKD 1.9315099716186523, LDE 8.333601951599121, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6499212384223938, Reg Loss=10.423014640808105
Clinet index 11, End of Epoch 1/6, Average Loss=11.072936058044434, Class Loss=0.6499212384223938, Reg Loss=10.423014640808105
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=8.68107442855835
Loss made of: CE 0.42844653129577637, LKD 2.028855562210083, LDE 6.318753242492676, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4967714250087738, Reg Loss=8.201454162597656
Clinet index 11, End of Epoch 2/6, Average Loss=8.698225975036621, Class Loss=0.4967714250087738, Reg Loss=8.201454162597656
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=7.84625840485096
Loss made of: CE 0.47451210021972656, LKD 2.495220899581909, LDE 4.736568927764893, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4139309525489807, Reg Loss=7.480847358703613
Clinet index 11, End of Epoch 3/6, Average Loss=7.894778251647949, Class Loss=0.4139309525489807, Reg Loss=7.480847358703613
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=7.524618926644325
Loss made of: CE 0.35628455877304077, LKD 2.060743570327759, LDE 4.8986077308654785, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.402161568403244, Reg Loss=7.17362642288208
Clinet index 11, End of Epoch 4/6, Average Loss=7.5757880210876465, Class Loss=0.402161568403244, Reg Loss=7.17362642288208
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=7.262488776445389
Loss made of: CE 0.3300850987434387, LKD 1.936873435974121, LDE 5.592163562774658, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.38420045375823975, Reg Loss=6.890305519104004
Clinet index 11, End of Epoch 5/6, Average Loss=7.274506092071533, Class Loss=0.38420045375823975, Reg Loss=6.890305519104004
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=7.230173251032829
Loss made of: CE 0.3617337942123413, LKD 2.278217315673828, LDE 4.15596866607666, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.377086877822876, Reg Loss=6.793096542358398
Clinet index 11, End of Epoch 6/6, Average Loss=7.170183181762695, Class Loss=0.377086877822876, Reg Loss=6.793096542358398
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=14.84903661608696
Loss made of: CE 0.377815842628479, LKD 4.642520904541016, LDE 8.943897247314453, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Batch 20/29, Loss=13.085150504112244
Loss made of: CE 0.2968481779098511, LKD 4.681538105010986, LDE 6.894670486450195, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.34694600105285645, Reg Loss=13.027663230895996
Clinet index 0, End of Epoch 1/6, Average Loss=13.374608993530273, Class Loss=0.34694600105285645, Reg Loss=13.027663230895996
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=11.555665077269078
Loss made of: CE 0.2495579719543457, LKD 4.734127998352051, LDE 5.29391622543335, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=11.312808063626289
Loss made of: CE 0.2730523347854614, LKD 4.899531364440918, LDE 5.7009429931640625, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2826215326786041, Reg Loss=11.106363296508789
Clinet index 0, End of Epoch 2/6, Average Loss=11.388984680175781, Class Loss=0.2826215326786041, Reg Loss=11.106363296508789
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 3, Batch 10/29, Loss=11.556368654966354
Loss made of: CE 0.23310837149620056, LKD 4.386734962463379, LDE 8.629040718078613, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=10.920655973255634
Loss made of: CE 0.30314940214157104, LKD 4.682744979858398, LDE 5.74403190612793, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2707047760486603, Reg Loss=10.89889144897461
Clinet index 0, End of Epoch 3/6, Average Loss=11.169596672058105, Class Loss=0.2707047760486603, Reg Loss=10.89889144897461
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=12.413497751951217
Loss made of: CE 0.30651339888572693, LKD 6.306194305419922, LDE 9.068777084350586, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=12.412032113969326
Loss made of: CE 0.26870015263557434, LKD 5.151797294616699, LDE 6.457002639770508, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2641267478466034, Reg Loss=12.073688507080078
Clinet index 0, End of Epoch 4/6, Average Loss=12.337815284729004, Class Loss=0.2641267478466034, Reg Loss=12.073688507080078
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=11.12993569225073
Loss made of: CE 0.19609928131103516, LKD 4.192826271057129, LDE 6.284932613372803, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=11.353837203979491
Loss made of: CE 0.30100661516189575, LKD 4.851619720458984, LDE 6.039064407348633, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2550891041755676, Reg Loss=11.16422176361084
Clinet index 0, End of Epoch 5/6, Average Loss=11.419310569763184, Class Loss=0.2550891041755676, Reg Loss=11.16422176361084
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=10.735004712641238
Loss made of: CE 0.359412282705307, LKD 5.028597354888916, LDE 5.923285484313965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=11.162794175744057
Loss made of: CE 0.2337217926979065, LKD 5.592879295349121, LDE 5.533337116241455, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24727191030979156, Reg Loss=10.740323066711426
Clinet index 0, End of Epoch 6/6, Average Loss=10.987594604492188, Class Loss=0.24727191030979156, Reg Loss=10.740323066711426
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=15.107220882177353
Loss made of: CE 0.4082265794277191, LKD 4.839449405670166, LDE 8.58053970336914, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=12.378656962513924
Loss made of: CE 0.28746098279953003, LKD 4.077953338623047, LDE 6.904247283935547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3494395315647125, Reg Loss=12.856463432312012
Clinet index 8, End of Epoch 1/6, Average Loss=13.205903053283691, Class Loss=0.3494395315647125, Reg Loss=12.856463432312012
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=11.125597995519637
Loss made of: CE 0.2537315785884857, LKD 5.219870090484619, LDE 5.98347282409668, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=11.402443651854991
Loss made of: CE 0.2731044292449951, LKD 5.1505446434021, LDE 6.816781997680664, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2738315761089325, Reg Loss=11.005815505981445
Clinet index 8, End of Epoch 2/6, Average Loss=11.279646873474121, Class Loss=0.2738315761089325, Reg Loss=11.005815505981445
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=11.839925119280815
Loss made of: CE 0.3243829309940338, LKD 5.087123394012451, LDE 6.110647201538086, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=11.38322421759367
Loss made of: CE 0.28492647409439087, LKD 5.2828369140625, LDE 6.183325290679932, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27576932311058044, Reg Loss=11.130037307739258
Clinet index 8, End of Epoch 3/6, Average Loss=11.405806541442871, Class Loss=0.27576932311058044, Reg Loss=11.130037307739258
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Batch 10/29, Loss=11.137773552536965
Loss made of: CE 0.318179726600647, LKD 4.369328498840332, LDE 5.3525567054748535, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=11.099940250813962
Loss made of: CE 0.211084246635437, LKD 5.828815460205078, LDE 6.691528797149658, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2640647292137146, Reg Loss=10.682973861694336
Clinet index 8, End of Epoch 4/6, Average Loss=10.947038650512695, Class Loss=0.2640647292137146, Reg Loss=10.682973861694336
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=10.717951029539108
Loss made of: CE 0.24843618273735046, LKD 5.275033950805664, LDE 5.522253513336182, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=10.367795477807523
Loss made of: CE 0.33882936835289, LKD 5.238522052764893, LDE 4.518815517425537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24935589730739594, Reg Loss=10.459266662597656
Clinet index 8, End of Epoch 5/6, Average Loss=10.708622932434082, Class Loss=0.24935589730739594, Reg Loss=10.459266662597656
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=10.623813201487064
Loss made of: CE 0.3413406312465668, LKD 4.569431304931641, LDE 5.435208797454834, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=10.798386347293853
Loss made of: CE 0.23752766847610474, LKD 5.092909336090088, LDE 6.517495155334473, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24003219604492188, Reg Loss=10.310492515563965
Clinet index 8, End of Epoch 6/6, Average Loss=10.550524711608887, Class Loss=0.24003219604492188, Reg Loss=10.310492515563965
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=11.489870011806488
Loss made of: CE 0.6443299651145935, LKD 2.508164644241333, LDE 6.515312194824219, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6694704294204712, Reg Loss=10.366904258728027
Clinet index 14, End of Epoch 1/6, Average Loss=11.036375045776367, Class Loss=0.6694704294204712, Reg Loss=10.366904258728027
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/13, Loss=8.886684995889663
Loss made of: CE 0.501550555229187, LKD 2.2462704181671143, LDE 5.031280994415283, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5172604322433472, Reg Loss=8.300161361694336
Clinet index 14, End of Epoch 2/6, Average Loss=8.817421913146973, Class Loss=0.5172604322433472, Reg Loss=8.300161361694336
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/13, Loss=7.532374075055122
Loss made of: CE 0.44447654485702515, LKD 2.3072404861450195, LDE 4.6268792152404785, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4310193657875061, Reg Loss=7.086513519287109
Clinet index 14, End of Epoch 3/6, Average Loss=7.517532825469971, Class Loss=0.4310193657875061, Reg Loss=7.086513519287109
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/13, Loss=7.3980377405881885
Loss made of: CE 0.3478676974773407, LKD 1.770660638809204, LDE 5.027830600738525, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4006115198135376, Reg Loss=6.932040691375732
Clinet index 14, End of Epoch 4/6, Average Loss=7.3326520919799805, Class Loss=0.4006115198135376, Reg Loss=6.932040691375732
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/13, Loss=7.1419328331947325
Loss made of: CE 0.4158528745174408, LKD 2.6362850666046143, LDE 5.338871479034424, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39873313903808594, Reg Loss=6.750657558441162
Clinet index 14, End of Epoch 5/6, Average Loss=7.149390697479248, Class Loss=0.39873313903808594, Reg Loss=6.750657558441162
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/13, Loss=6.954911753535271
Loss made of: CE 0.32953310012817383, LKD 1.8574652671813965, LDE 4.03945779800415, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.39085671305656433, Reg Loss=6.675307273864746
Clinet index 14, End of Epoch 6/6, Average Loss=7.066164016723633, Class Loss=0.39085671305656433, Reg Loss=6.675307273864746
federated aggregation...
Validation, Class Loss=0.46315228939056396, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.844311
Mean Acc: 0.464858
FreqW Acc: 0.770989
Mean IoU: 0.375911
Class IoU:
	class 0: 0.91529226
	class 1: 0.812518
	class 2: 0.31514472
	class 3: 0.017618742
	class 4: 0.6367541
	class 5: 0.2557886
	class 6: 0.6262501
	class 7: 0.7705262
	class 8: 0.053778537
	class 9: 0.11606319
	class 10: 0.0
	class 11: 0.08356675
	class 12: 0.2835448
Class Acc:
	class 0: 0.97529566
	class 1: 0.8280044
	class 2: 0.57927734
	class 3: 0.017618742
	class 4: 0.69319785
	class 5: 0.25808418
	class 6: 0.6290193
	class 7: 0.77811354
	class 8: 0.05379471
	class 9: 0.18175276
	class 10: 0.0
	class 11: 0.12596028
	class 12: 0.9230358

federated global round: 13, step: 2
select part of clients to conduct local training
[13, 5, 15, 7]
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=14.862174701690673
Loss made of: CE 0.37879204750061035, LKD 4.064709663391113, LDE 6.587807655334473, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=12.223027643561363
Loss made of: CE 0.30418044328689575, LKD 5.572442531585693, LDE 6.492935657501221, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33954888582229614, Reg Loss=12.422575950622559
Clinet index 13, End of Epoch 1/6, Average Loss=12.762125015258789, Class Loss=0.33954888582229614, Reg Loss=12.422575950622559
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/29, Loss=11.207852539420127
Loss made of: CE 0.34082743525505066, LKD 5.571460247039795, LDE 4.855220794677734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=10.967597009241581
Loss made of: CE 0.2555704712867737, LKD 4.913506984710693, LDE 5.567263603210449, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 2, Class Loss=0.2854917347431183, Reg Loss=10.79883861541748
Clinet index 13, End of Epoch 2/6, Average Loss=11.084330558776855, Class Loss=0.2854917347431183, Reg Loss=10.79883861541748
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/29, Loss=10.587325923144817
Loss made of: CE 0.23531906306743622, LKD 5.231272220611572, LDE 6.314489841461182, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=11.288839018344879
Loss made of: CE 0.21376371383666992, LKD 4.595407009124756, LDE 5.114427089691162, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2738947570323944, Reg Loss=10.504203796386719
Clinet index 13, End of Epoch 3/6, Average Loss=10.778098106384277, Class Loss=0.2738947570323944, Reg Loss=10.504203796386719
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 4, Batch 10/29, Loss=10.80145396888256
Loss made of: CE 0.23124727606773376, LKD 4.657032489776611, LDE 5.097086429595947, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=10.739051188528538
Loss made of: CE 0.21067854762077332, LKD 4.938082218170166, LDE 4.991786956787109, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2608199417591095, Reg Loss=10.450197219848633
Clinet index 13, End of Epoch 4/6, Average Loss=10.711017608642578, Class Loss=0.2608199417591095, Reg Loss=10.450197219848633
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/29, Loss=10.595792618393897
Loss made of: CE 0.23374512791633606, LKD 5.449790000915527, LDE 5.905445098876953, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=10.40174718350172
Loss made of: CE 0.2191770076751709, LKD 4.737430572509766, LDE 6.367353916168213, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2551775574684143, Reg Loss=10.236528396606445
Clinet index 13, End of Epoch 5/6, Average Loss=10.491705894470215, Class Loss=0.2551775574684143, Reg Loss=10.236528396606445
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/29, Loss=10.385512503981591
Loss made of: CE 0.23949158191680908, LKD 4.266252517700195, LDE 4.962903022766113, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=10.311984607577324
Loss made of: CE 0.2821520268917084, LKD 5.451015949249268, LDE 4.906518459320068, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25498420000076294, Reg Loss=10.10471248626709
Clinet index 13, End of Epoch 6/6, Average Loss=10.359696388244629, Class Loss=0.25498420000076294, Reg Loss=10.10471248626709
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=12.957434749603271
Loss made of: CE 0.2743642330169678, LKD 4.130992412567139, LDE 6.30858039855957, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Batch 20/29, Loss=12.067079114913941
Loss made of: CE 0.3298337161540985, LKD 4.986351490020752, LDE 9.327587127685547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.31577178835868835, Reg Loss=12.089923858642578
Clinet index 5, End of Epoch 1/6, Average Loss=12.405695915222168, Class Loss=0.31577178835868835, Reg Loss=12.089923858642578
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/29, Loss=11.82974072098732
Loss made of: CE 0.2275364100933075, LKD 4.694023132324219, LDE 6.289957523345947, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=11.029701767861843
Loss made of: CE 0.23956984281539917, LKD 4.846879005432129, LDE 6.523715496063232, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2708856165409088, Reg Loss=10.944966316223145
Clinet index 5, End of Epoch 2/6, Average Loss=11.215851783752441, Class Loss=0.2708856165409088, Reg Loss=10.944966316223145
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/29, Loss=11.165133681893348
Loss made of: CE 0.24096867442131042, LKD 4.4672160148620605, LDE 5.22249698638916, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=10.434275543689727
Loss made of: CE 0.26123207807540894, LKD 3.5715370178222656, LDE 5.386086463928223, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25880202651023865, Reg Loss=10.527424812316895
Clinet index 5, End of Epoch 3/6, Average Loss=10.786227226257324, Class Loss=0.25880202651023865, Reg Loss=10.527424812316895
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/29, Loss=10.310938215255737
Loss made of: CE 0.2409575879573822, LKD 5.120134353637695, LDE 4.677521705627441, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=10.241290286183357
Loss made of: CE 0.32865089178085327, LKD 4.646169185638428, LDE 5.66529655456543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24913878738880157, Reg Loss=10.112881660461426
Clinet index 5, End of Epoch 4/6, Average Loss=10.362020492553711, Class Loss=0.24913878738880157, Reg Loss=10.112881660461426
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=10.162297327816486
Loss made of: CE 0.2537851333618164, LKD 4.495824337005615, LDE 5.026980400085449, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=10.771237628161908
Loss made of: CE 0.25934338569641113, LKD 4.653204441070557, LDE 4.889202117919922, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 5, Class Loss=0.2485673874616623, Reg Loss=10.232954978942871
Clinet index 5, End of Epoch 5/6, Average Loss=10.481522560119629, Class Loss=0.2485673874616623, Reg Loss=10.232954978942871
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/29, Loss=10.05890363752842
Loss made of: CE 0.22461096942424774, LKD 5.351579189300537, LDE 5.575669765472412, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=9.80326413065195
Loss made of: CE 0.2095988243818283, LKD 4.042407989501953, LDE 5.511125564575195, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2367512583732605, Reg Loss=9.673725128173828
Clinet index 5, End of Epoch 6/6, Average Loss=9.910476684570312, Class Loss=0.2367512583732605, Reg Loss=9.673725128173828
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=11.951496714353562
Loss made of: CE 0.4366367757320404, LKD 1.8094017505645752, LDE 7.297667980194092, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5314909815788269, Reg Loss=10.833304405212402
Clinet index 15, End of Epoch 1/6, Average Loss=11.364795684814453, Class Loss=0.5314909815788269, Reg Loss=10.833304405212402
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=9.042670968174935
Loss made of: CE 0.34333857893943787, LKD 1.8134942054748535, LDE 7.299271106719971, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.429961621761322, Reg Loss=8.347076416015625
Clinet index 15, End of Epoch 2/6, Average Loss=8.777037620544434, Class Loss=0.429961621761322, Reg Loss=8.347076416015625
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=8.048669415712357
Loss made of: CE 0.36681002378463745, LKD 2.4749903678894043, LDE 4.645042896270752, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38079211115837097, Reg Loss=7.543071269989014
Clinet index 15, End of Epoch 3/6, Average Loss=7.923863410949707, Class Loss=0.38079211115837097, Reg Loss=7.543071269989014
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=7.287773206830025
Loss made of: CE 0.40854984521865845, LKD 2.5642833709716797, LDE 4.706494331359863, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.35274675488471985, Reg Loss=6.955911636352539
Clinet index 15, End of Epoch 4/6, Average Loss=7.308658599853516, Class Loss=0.35274675488471985, Reg Loss=6.955911636352539
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=7.5960765212774275
Loss made of: CE 0.3265919089317322, LKD 2.276702880859375, LDE 6.669253349304199, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3572654128074646, Reg Loss=7.093779563903809
Clinet index 15, End of Epoch 5/6, Average Loss=7.451045036315918, Class Loss=0.3572654128074646, Reg Loss=7.093779563903809
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=7.026096990704536
Loss made of: CE 0.29511934518814087, LKD 1.8864091634750366, LDE 4.636250972747803, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3474067747592926, Reg Loss=6.610256671905518
Clinet index 15, End of Epoch 6/6, Average Loss=6.957663536071777, Class Loss=0.3474067747592926, Reg Loss=6.610256671905518
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=11.922105127573014
Loss made of: CE 0.5463956594467163, LKD 2.1763060092926025, LDE 7.251433372497559, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5905182957649231, Reg Loss=10.681032180786133
Clinet index 7, End of Epoch 1/6, Average Loss=11.271550178527832, Class Loss=0.5905182957649231, Reg Loss=10.681032180786133
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/13, Loss=8.755052930116653
Loss made of: CE 0.44933387637138367, LKD 2.2820279598236084, LDE 5.5137410163879395, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.45991477370262146, Reg Loss=8.347399711608887
Clinet index 7, End of Epoch 2/6, Average Loss=8.8073148727417, Class Loss=0.45991477370262146, Reg Loss=8.347399711608887
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=7.832087385654449
Loss made of: CE 0.3852827548980713, LKD 2.557129383087158, LDE 4.519424915313721, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.40989869832992554, Reg Loss=7.453463554382324
Clinet index 7, End of Epoch 3/6, Average Loss=7.8633623123168945, Class Loss=0.40989869832992554, Reg Loss=7.453463554382324
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/13, Loss=7.7915768176317215
Loss made of: CE 0.4315979480743408, LKD 2.5213263034820557, LDE 4.8277082443237305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3940911293029785, Reg Loss=7.198064804077148
Clinet index 7, End of Epoch 4/6, Average Loss=7.592155933380127, Class Loss=0.3940911293029785, Reg Loss=7.198064804077148
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/13, Loss=7.562677171826363
Loss made of: CE 0.34616780281066895, LKD 1.852290391921997, LDE 5.219757556915283, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.37396156787872314, Reg Loss=7.216240406036377
Clinet index 7, End of Epoch 5/6, Average Loss=7.5902018547058105, Class Loss=0.37396156787872314, Reg Loss=7.216240406036377
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/13, Loss=7.374699544906616
Loss made of: CE 0.3613753914833069, LKD 1.9370896816253662, LDE 5.084885120391846, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.37071534991264343, Reg Loss=6.97847843170166
Clinet index 7, End of Epoch 6/6, Average Loss=7.349193572998047, Class Loss=0.37071534991264343, Reg Loss=6.97847843170166
federated aggregation...
Validation, Class Loss=0.4779179096221924, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.842337
Mean Acc: 0.464573
FreqW Acc: 0.770344
Mean IoU: 0.373106
Class IoU:
	class 0: 0.91694295
	class 1: 0.7978712
	class 2: 0.31275705
	class 3: 0.0055903867
	class 4: 0.61426204
	class 5: 0.30124196
	class 6: 0.56343526
	class 7: 0.77045673
	class 8: 0.037001085
	class 9: 0.11871235
	class 10: 0.0
	class 11: 0.13295001
	class 12: 0.27915752
Class Acc:
	class 0: 0.97359055
	class 1: 0.8109859
	class 2: 0.56932056
	class 3: 0.0055903867
	class 4: 0.6618477
	class 5: 0.30479768
	class 6: 0.56556135
	class 7: 0.77822465
	class 8: 0.037006952
	class 9: 0.18177268
	class 10: 0.0
	class 11: 0.21059199
	class 12: 0.94015837

federated global round: 14, step: 2
select part of clients to conduct local training
[17, 3, 12, 16]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=14.034930035471916
Loss made of: CE 0.2791479825973511, LKD 4.158388614654541, LDE 6.45762300491333, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 20/29, Loss=12.82204303443432
Loss made of: CE 0.33848485350608826, LKD 5.088241100311279, LDE 6.353618144989014, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.32876691222190857, Reg Loss=12.736259460449219
Clinet index 17, End of Epoch 1/6, Average Loss=13.06502628326416, Class Loss=0.32876691222190857, Reg Loss=12.736259460449219
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=11.430352005362511
Loss made of: CE 0.20191757380962372, LKD 5.863504886627197, LDE 6.034937381744385, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 2, Batch 20/29, Loss=11.6232416421175
Loss made of: CE 0.2500440180301666, LKD 5.2914838790893555, LDE 5.80136251449585, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 2, Class Loss=0.2654244005680084, Reg Loss=11.403288841247559
Clinet index 17, End of Epoch 2/6, Average Loss=11.668713569641113, Class Loss=0.2654244005680084, Reg Loss=11.403288841247559
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=10.667274494469165
Loss made of: CE 0.3030754327774048, LKD 4.463303089141846, LDE 5.170987606048584, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=11.176308493316174
Loss made of: CE 0.22095060348510742, LKD 5.087937355041504, LDE 5.607390403747559, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26726052165031433, Reg Loss=10.636351585388184
Clinet index 17, End of Epoch 3/6, Average Loss=10.90361213684082, Class Loss=0.26726052165031433, Reg Loss=10.636351585388184
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=10.270957580208778
Loss made of: CE 0.2902044653892517, LKD 5.454715251922607, LDE 5.54641580581665, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=10.456525348126888
Loss made of: CE 0.18995462357997894, LKD 5.003526210784912, LDE 6.541116714477539, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25507232546806335, Reg Loss=10.374669075012207
Clinet index 17, End of Epoch 4/6, Average Loss=10.629741668701172, Class Loss=0.25507232546806335, Reg Loss=10.374669075012207
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=10.816231118142605
Loss made of: CE 0.2333163470029831, LKD 4.260309219360352, LDE 4.571983337402344, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=10.533405697345733
Loss made of: CE 0.20374493300914764, LKD 4.95627498626709, LDE 5.343907833099365, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2556677758693695, Reg Loss=10.226555824279785
Clinet index 17, End of Epoch 5/6, Average Loss=10.482223510742188, Class Loss=0.2556677758693695, Reg Loss=10.226555824279785
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=10.314571632444858
Loss made of: CE 0.27347248792648315, LKD 4.81168794631958, LDE 4.482607364654541, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=10.060314670205116
Loss made of: CE 0.273536741733551, LKD 4.877389430999756, LDE 4.987292766571045, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2538641095161438, Reg Loss=10.056397438049316
Clinet index 17, End of Epoch 6/6, Average Loss=10.310261726379395, Class Loss=0.2538641095161438, Reg Loss=10.056397438049316
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=14.289641091227532
Loss made of: CE 0.28965842723846436, LKD 4.451163291931152, LDE 7.124505996704102, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=11.912896120548249
Loss made of: CE 0.2592059373855591, LKD 4.784935474395752, LDE 7.087832450866699, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3027845621109009, Reg Loss=12.27630615234375
Clinet index 3, End of Epoch 1/6, Average Loss=12.57909107208252, Class Loss=0.3027845621109009, Reg Loss=12.27630615234375
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 2, Batch 10/29, Loss=10.966800908744336
Loss made of: CE 0.2025354951620102, LKD 4.528924942016602, LDE 5.2697577476501465, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=10.811223395168781
Loss made of: CE 0.35253453254699707, LKD 4.851314544677734, LDE 6.825383186340332, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26332995295524597, Reg Loss=10.58635425567627
Clinet index 3, End of Epoch 2/6, Average Loss=10.84968376159668, Class Loss=0.26332995295524597, Reg Loss=10.58635425567627
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=11.113213863968848
Loss made of: CE 0.35487109422683716, LKD 4.937544345855713, LDE 4.661899089813232, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 3, Batch 20/29, Loss=10.630668559670449
Loss made of: CE 0.20518887042999268, LKD 4.234635829925537, LDE 7.069039344787598, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2666751444339752, Reg Loss=10.799931526184082
Clinet index 3, End of Epoch 3/6, Average Loss=11.066606521606445, Class Loss=0.2666751444339752, Reg Loss=10.799931526184082
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=11.19614199846983
Loss made of: CE 0.23956458270549774, LKD 4.736196517944336, LDE 5.7530622482299805, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=10.764361661672591
Loss made of: CE 0.17457108199596405, LKD 4.71705436706543, LDE 4.9036102294921875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2577577531337738, Reg Loss=10.534255027770996
Clinet index 3, End of Epoch 4/6, Average Loss=10.792013168334961, Class Loss=0.2577577531337738, Reg Loss=10.534255027770996
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=10.326377971470356
Loss made of: CE 0.19338421523571014, LKD 4.495327949523926, LDE 5.503894329071045, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=10.356727509200573
Loss made of: CE 0.2275264710187912, LKD 4.819434642791748, LDE 5.767057418823242, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25131726264953613, Reg Loss=10.149956703186035
Clinet index 3, End of Epoch 5/6, Average Loss=10.401273727416992, Class Loss=0.25131726264953613, Reg Loss=10.149956703186035
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=10.284971044957638
Loss made of: CE 0.27302253246307373, LKD 4.991268157958984, LDE 5.005238056182861, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=9.810120606422425
Loss made of: CE 0.26581475138664246, LKD 4.454594612121582, LDE 5.031871795654297, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25106149911880493, Reg Loss=9.747082710266113
Clinet index 3, End of Epoch 6/6, Average Loss=9.998144149780273, Class Loss=0.25106149911880493, Reg Loss=9.747082710266113
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=11.335148194432259
Loss made of: CE 0.4033786654472351, LKD 2.053518295288086, LDE 5.626211166381836, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5685458183288574, Reg Loss=10.173489570617676
Clinet index 12, End of Epoch 1/6, Average Loss=10.742034912109375, Class Loss=0.5685458183288574, Reg Loss=10.173489570617676
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=8.391727942228318
Loss made of: CE 0.39578017592430115, LKD 1.9704089164733887, LDE 5.6770920753479, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4303444027900696, Reg Loss=7.790919303894043
Clinet index 12, End of Epoch 2/6, Average Loss=8.221263885498047, Class Loss=0.4303444027900696, Reg Loss=7.790919303894043
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=7.97584408223629
Loss made of: CE 0.3537101149559021, LKD 2.0271072387695312, LDE 6.10896635055542, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4106101095676422, Reg Loss=7.45078706741333
Clinet index 12, End of Epoch 3/6, Average Loss=7.8613972663879395, Class Loss=0.4106101095676422, Reg Loss=7.45078706741333
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=7.3035604566335675
Loss made of: CE 0.352553129196167, LKD 2.043727397918701, LDE 4.420016288757324, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.38665831089019775, Reg Loss=7.111598968505859
Clinet index 12, End of Epoch 4/6, Average Loss=7.498257160186768, Class Loss=0.38665831089019775, Reg Loss=7.111598968505859
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=7.20584083199501
Loss made of: CE 0.414456844329834, LKD 2.041419506072998, LDE 5.119325160980225, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.37490302324295044, Reg Loss=6.803062915802002
Clinet index 12, End of Epoch 5/6, Average Loss=7.177966117858887, Class Loss=0.37490302324295044, Reg Loss=6.803062915802002
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=6.945843780040741
Loss made of: CE 0.3327842354774475, LKD 2.103090286254883, LDE 3.851945638656616, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.36838117241859436, Reg Loss=6.704355716705322
Clinet index 12, End of Epoch 6/6, Average Loss=7.072736740112305, Class Loss=0.36838117241859436, Reg Loss=6.704355716705322
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/29, Loss=15.321904510259628
Loss made of: CE 0.2709064185619354, LKD 4.789726257324219, LDE 7.471895217895508, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 1, Batch 20/29, Loss=12.237850862741471
Loss made of: CE 0.3211250901222229, LKD 5.596188545227051, LDE 6.565762996673584, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.32442742586135864, Reg Loss=12.627518653869629
Clinet index 16, End of Epoch 1/6, Average Loss=12.951946258544922, Class Loss=0.32442742586135864, Reg Loss=12.627518653869629
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/29, Loss=10.804409921169281
Loss made of: CE 0.32630664110183716, LKD 4.983323097229004, LDE 5.948111057281494, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=11.097601115703583
Loss made of: CE 0.20714645087718964, LKD 5.040608882904053, LDE 5.6817216873168945, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2827746272087097, Reg Loss=10.516425132751465
Clinet index 16, End of Epoch 2/6, Average Loss=10.799200057983398, Class Loss=0.2827746272087097, Reg Loss=10.516425132751465
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/29, Loss=10.549524869024754
Loss made of: CE 0.28466516733169556, LKD 5.379149913787842, LDE 5.923748970031738, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=10.238088488578796
Loss made of: CE 0.20451949536800385, LKD 4.1447834968566895, LDE 6.4113006591796875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.263481467962265, Reg Loss=10.054198265075684
Clinet index 16, End of Epoch 3/6, Average Loss=10.317679405212402, Class Loss=0.263481467962265, Reg Loss=10.054198265075684
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/29, Loss=10.126177209615708
Loss made of: CE 0.31393569707870483, LKD 4.186610698699951, LDE 5.046932220458984, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=10.148948000371457
Loss made of: CE 0.2578642964363098, LKD 4.960540771484375, LDE 4.498802661895752, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2602236270904541, Reg Loss=9.832160949707031
Clinet index 16, End of Epoch 4/6, Average Loss=10.092384338378906, Class Loss=0.2602236270904541, Reg Loss=9.832160949707031
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/29, Loss=9.969901576638222
Loss made of: CE 0.28835010528564453, LKD 5.069779872894287, LDE 5.216406345367432, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=10.053471536934376
Loss made of: CE 0.20304159820079803, LKD 3.4876017570495605, LDE 6.456552505493164, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2578182518482208, Reg Loss=9.827220916748047
Clinet index 16, End of Epoch 5/6, Average Loss=10.085039138793945, Class Loss=0.2578182518482208, Reg Loss=9.827220916748047
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/29, Loss=9.890146467089654
Loss made of: CE 0.26227879524230957, LKD 4.973647117614746, LDE 3.7314369678497314, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=9.88835796713829
Loss made of: CE 0.22765639424324036, LKD 4.577893257141113, LDE 4.521819591522217, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.261052668094635, Reg Loss=9.68636417388916
Clinet index 16, End of Epoch 6/6, Average Loss=9.947417259216309, Class Loss=0.261052668094635, Reg Loss=9.68636417388916
federated aggregation...
Validation, Class Loss=0.5025425553321838, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.832520
Mean Acc: 0.429658
FreqW Acc: 0.760546
Mean IoU: 0.341053
Class IoU:
	class 0: 0.91768676
	class 1: 0.7727402
	class 2: 0.29572737
	class 3: 9.563247e-05
	class 4: 0.6084029
	class 5: 0.222055
	class 6: 0.35860953
	class 7: 0.7862161
	class 8: 0.010469348
	class 9: 0.10789698
	class 10: 0.0
	class 11: 0.10310322
	class 12: 0.2506844
Class Acc:
	class 0: 0.97370344
	class 1: 0.78373724
	class 2: 0.52595085
	class 3: 9.563247e-05
	class 4: 0.6595586
	class 5: 0.22329392
	class 6: 0.35948953
	class 7: 0.79595095
	class 8: 0.01046971
	class 9: 0.17978835
	class 10: 0.0
	class 11: 0.119698726
	class 12: 0.9538116

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[13, 9, 6, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=15.972770750522614
Loss made of: CE 1.374140739440918, LKD 4.211304664611816, LDE 7.977670669555664, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.7053521871566772, Reg Loss=14.050734519958496
Clinet index 13, End of Epoch 1/6, Average Loss=15.756086349487305, Class Loss=1.7053521871566772, Reg Loss=14.050734519958496
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=11.677494829893112
Loss made of: CE 0.8332779407501221, LKD 3.4545414447784424, LDE 6.391765117645264, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.1156885623931885, Reg Loss=10.415657043457031
Clinet index 13, End of Epoch 2/6, Average Loss=11.53134536743164, Class Loss=1.1156885623931885, Reg Loss=10.415657043457031
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=10.401473850011826
Loss made of: CE 0.5532902479171753, LKD 3.9267096519470215, LDE 6.624022006988525, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6352030038833618, Reg Loss=9.77800464630127
Clinet index 13, End of Epoch 3/6, Average Loss=10.4132080078125, Class Loss=0.6352030038833618, Reg Loss=9.77800464630127
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=9.560913494229316
Loss made of: CE 0.3094803988933563, LKD 4.414934158325195, LDE 5.289717197418213, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36093664169311523, Reg Loss=9.183876991271973
Clinet index 13, End of Epoch 4/6, Average Loss=9.54481315612793, Class Loss=0.36093664169311523, Reg Loss=9.183876991271973
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=8.823232233524323
Loss made of: CE 0.2821245789527893, LKD 3.5328128337860107, LDE 4.6246867179870605, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2833321690559387, Reg Loss=8.507975578308105
Clinet index 13, End of Epoch 5/6, Average Loss=8.79130744934082, Class Loss=0.2833321690559387, Reg Loss=8.507975578308105
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=8.769667676091194
Loss made of: CE 0.27447548508644104, LKD 3.874356746673584, LDE 4.437018871307373, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25391387939453125, Reg Loss=8.426953315734863
Clinet index 13, End of Epoch 6/6, Average Loss=8.680867195129395, Class Loss=0.25391387939453125, Reg Loss=8.426953315734863
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=25.844813811779023
Loss made of: CE 2.024765968322754, LKD 4.9154767990112305, LDE 12.61164379119873, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.8597314357757568, Reg Loss=22.51272964477539
Clinet index 9, End of Epoch 1/6, Average Loss=24.372461318969727, Class Loss=1.8597314357757568, Reg Loss=22.51272964477539
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=15.13227733373642
Loss made of: CE 0.8939846754074097, LKD 3.0508480072021484, LDE 9.361698150634766, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2632166147232056, Reg Loss=13.610847473144531
Clinet index 9, End of Epoch 2/6, Average Loss=14.874064445495605, Class Loss=1.2632166147232056, Reg Loss=13.610847473144531
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=11.893597215414047
Loss made of: CE 0.591812014579773, LKD 3.4418723583221436, LDE 7.121112823486328, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6751055121421814, Reg Loss=11.142898559570312
Clinet index 9, End of Epoch 3/6, Average Loss=11.81800365447998, Class Loss=0.6751055121421814, Reg Loss=11.142898559570312
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=10.806198075413704
Loss made of: CE 0.31301480531692505, LKD 3.4615538120269775, LDE 6.237725734710693, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4046346843242645, Reg Loss=10.295689582824707
Clinet index 9, End of Epoch 4/6, Average Loss=10.700324058532715, Class Loss=0.4046346843242645, Reg Loss=10.295689582824707
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=10.16185205578804
Loss made of: CE 0.23075872659683228, LKD 2.6449122428894043, LDE 6.263260364532471, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2811092138290405, Reg Loss=9.809988021850586
Clinet index 9, End of Epoch 5/6, Average Loss=10.091096878051758, Class Loss=0.2811092138290405, Reg Loss=9.809988021850586
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 6, Batch 10/12, Loss=9.702649715542794
Loss made of: CE 0.22225281596183777, LKD 3.1803159713745117, LDE 5.674771308898926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.269473671913147, Reg Loss=9.34115219116211
Clinet index 9, End of Epoch 6/6, Average Loss=9.610626220703125, Class Loss=0.269473671913147, Reg Loss=9.34115219116211
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/11, Loss=16.431588804721834
Loss made of: CE 1.6477820873260498, LKD 3.788647174835205, LDE 8.090149879455566, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.7035776376724243, Reg Loss=14.509563446044922
Clinet index 6, End of Epoch 1/6, Average Loss=16.2131404876709, Class Loss=1.7035776376724243, Reg Loss=14.509563446044922
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=12.172211730480194
Loss made of: CE 1.2243993282318115, LKD 4.084866523742676, LDE 6.864240646362305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.1528459787368774, Reg Loss=10.894989013671875
Clinet index 6, End of Epoch 2/6, Average Loss=12.047835350036621, Class Loss=1.1528459787368774, Reg Loss=10.894989013671875
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=10.377853453159332
Loss made of: CE 0.5978925228118896, LKD 3.9510397911071777, LDE 5.415874004364014, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6795462369918823, Reg Loss=9.678135871887207
Clinet index 6, End of Epoch 3/6, Average Loss=10.357682228088379, Class Loss=0.6795462369918823, Reg Loss=9.678135871887207
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=9.523099482059479
Loss made of: CE 0.3384833335876465, LKD 3.449526309967041, LDE 5.449613094329834, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3751335144042969, Reg Loss=9.075410842895508
Clinet index 6, End of Epoch 4/6, Average Loss=9.450544357299805, Class Loss=0.3751335144042969, Reg Loss=9.075410842895508
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=9.151970839500427
Loss made of: CE 0.30448874831199646, LKD 3.2772183418273926, LDE 5.450672626495361, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2853170335292816, Reg Loss=8.855367660522461
Clinet index 6, End of Epoch 5/6, Average Loss=9.140685081481934, Class Loss=0.2853170335292816, Reg Loss=8.855367660522461
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=8.538932207226754
Loss made of: CE 0.2340315580368042, LKD 3.4621849060058594, LDE 4.496650218963623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25457456707954407, Reg Loss=8.40407943725586
Clinet index 6, End of Epoch 6/6, Average Loss=8.65865421295166, Class Loss=0.25457456707954407, Reg Loss=8.40407943725586
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=25.126180398464204
Loss made of: CE 1.8558566570281982, LKD 2.6856000423431396, LDE 14.643242835998535, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.8161977529525757, Reg Loss=22.213483810424805
Clinet index 5, End of Epoch 1/6, Average Loss=24.029682159423828, Class Loss=1.8161977529525757, Reg Loss=22.213483810424805
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=14.915655982494354
Loss made of: CE 1.1143406629562378, LKD 3.3526740074157715, LDE 9.826242446899414, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2807425260543823, Reg Loss=13.419203758239746
Clinet index 5, End of Epoch 2/6, Average Loss=14.699946403503418, Class Loss=1.2807425260543823, Reg Loss=13.419203758239746
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=12.073633515834809
Loss made of: CE 0.6733341217041016, LKD 3.692056179046631, LDE 8.016464233398438, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6996080875396729, Reg Loss=11.318275451660156
Clinet index 5, End of Epoch 3/6, Average Loss=12.01788330078125, Class Loss=0.6996080875396729, Reg Loss=11.318275451660156
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=11.027783346176147
Loss made of: CE 0.3800068795681, LKD 3.739410161972046, LDE 6.013978481292725, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4039551913738251, Reg Loss=10.417020797729492
Clinet index 5, End of Epoch 4/6, Average Loss=10.820976257324219, Class Loss=0.4039551913738251, Reg Loss=10.417020797729492
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=9.915009321272374
Loss made of: CE 0.34632882475852966, LKD 3.059211015701294, LDE 5.74018669128418, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2980656027793884, Reg Loss=9.60405158996582
Clinet index 5, End of Epoch 5/6, Average Loss=9.902116775512695, Class Loss=0.2980656027793884, Reg Loss=9.60405158996582
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=9.739775559306144
Loss made of: CE 0.230476975440979, LKD 4.278566837310791, LDE 5.757560729980469, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26066333055496216, Reg Loss=9.559051513671875
Clinet index 5, End of Epoch 6/6, Average Loss=9.819714546203613, Class Loss=0.26066333055496216, Reg Loss=9.559051513671875
federated aggregation...
Validation, Class Loss=0.5013769865036011, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.836481
Mean Acc: 0.387329
FreqW Acc: 0.742253
Mean IoU: 0.327173
Class IoU:
	class 0: 0.8898115
	class 1: 0.7079615
	class 2: 0.24994203
	class 3: 0.08074329
	class 4: 0.5930857
	class 5: 0.45027632
	class 6: 0.4851411
	class 7: 0.7300189
	class 8: 0.29501447
	class 9: 0.07096255
	class 10: 0.0
	class 11: 0.0014308509
	class 12: 0.27260005
	class 13: 0.012545777
	class 14: 0.06806601
Class Acc:
	class 0: 0.9882976
	class 1: 0.7130716
	class 2: 0.4040531
	class 3: 0.08074466
	class 4: 0.6328795
	class 5: 0.45662984
	class 6: 0.4860594
	class 7: 0.7353869
	class 8: 0.29559883
	class 9: 0.09131307
	class 10: 0.0
	class 11: 0.0014399677
	class 12: 0.83105713
	class 13: 0.014852146
	class 14: 0.07855094

federated global round: 16, step: 3
select part of clients to conduct local training
[18, 5, 20, 0]
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=12.543585127592086
Loss made of: CE 0.5598534941673279, LKD 3.071216344833374, LDE 6.3135786056518555, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6545919179916382, Reg Loss=11.922255516052246
Clinet index 18, End of Epoch 1/6, Average Loss=12.576847076416016, Class Loss=0.6545919179916382, Reg Loss=11.922255516052246
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=10.34812870323658
Loss made of: CE 0.32888033986091614, LKD 3.275301218032837, LDE 6.215994834899902, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4099980592727661, Reg Loss=9.73264217376709
Clinet index 18, End of Epoch 2/6, Average Loss=10.142640113830566, Class Loss=0.4099980592727661, Reg Loss=9.73264217376709
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=9.54215746819973
Loss made of: CE 0.22816860675811768, LKD 2.30135440826416, LDE 5.427736282348633, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27009934186935425, Reg Loss=9.298049926757812
Clinet index 18, End of Epoch 3/6, Average Loss=9.56814956665039, Class Loss=0.27009934186935425, Reg Loss=9.298049926757812
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=9.223112155497073
Loss made of: CE 0.2507703900337219, LKD 3.4350321292877197, LDE 5.091230392456055, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2511333227157593, Reg Loss=8.854623794555664
Clinet index 18, End of Epoch 4/6, Average Loss=9.105756759643555, Class Loss=0.2511333227157593, Reg Loss=8.854623794555664
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=8.662769429385662
Loss made of: CE 0.25399941205978394, LKD 2.4224753379821777, LDE 4.911541938781738, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23633620142936707, Reg Loss=8.63711929321289
Clinet index 18, End of Epoch 5/6, Average Loss=8.873455047607422, Class Loss=0.23633620142936707, Reg Loss=8.63711929321289
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=8.642059263586997
Loss made of: CE 0.24479858577251434, LKD 2.3728833198547363, LDE 5.669313430786133, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23769959807395935, Reg Loss=8.351446151733398
Clinet index 18, End of Epoch 6/6, Average Loss=8.58914566040039, Class Loss=0.23769959807395935, Reg Loss=8.351446151733398
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=12.499496346712112
Loss made of: CE 0.6338434219360352, LKD 2.5275118350982666, LDE 8.349250793457031, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6642625331878662, Reg Loss=11.727519035339355
Clinet index 5, End of Epoch 1/6, Average Loss=12.3917818069458, Class Loss=0.6642625331878662, Reg Loss=11.727519035339355
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=10.223727467656136
Loss made of: CE 0.4011392295360565, LKD 3.225942611694336, LDE 6.424339771270752, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4434133470058441, Reg Loss=9.715902328491211
Clinet index 5, End of Epoch 2/6, Average Loss=10.159316062927246, Class Loss=0.4434133470058441, Reg Loss=9.715902328491211
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=9.776190173625945
Loss made of: CE 0.28929534554481506, LKD 3.886582612991333, LDE 6.384706497192383, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.312718003988266, Reg Loss=9.548683166503906
Clinet index 5, End of Epoch 3/6, Average Loss=9.861401557922363, Class Loss=0.312718003988266, Reg Loss=9.548683166503906
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=9.469993548095227
Loss made of: CE 0.33490845561027527, LKD 3.8032100200653076, LDE 5.142131328582764, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27594131231307983, Reg Loss=9.044877052307129
Clinet index 5, End of Epoch 4/6, Average Loss=9.320817947387695, Class Loss=0.27594131231307983, Reg Loss=9.044877052307129
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=9.00647547841072
Loss made of: CE 0.35116681456565857, LKD 3.2812089920043945, LDE 4.823800086975098, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2621763050556183, Reg Loss=8.791553497314453
Clinet index 5, End of Epoch 5/6, Average Loss=9.053730010986328, Class Loss=0.2621763050556183, Reg Loss=8.791553497314453
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=9.082891213893891
Loss made of: CE 0.22625832259655, LKD 4.0596699714660645, LDE 5.228770732879639, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2587706446647644, Reg Loss=8.987598419189453
Clinet index 5, End of Epoch 6/6, Average Loss=9.246369361877441, Class Loss=0.2587706446647644, Reg Loss=8.987598419189453
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=12.560373282432556
Loss made of: CE 0.7337777018547058, LKD 3.926069974899292, LDE 9.262743949890137, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6449395418167114, Reg Loss=11.6842041015625
Clinet index 20, End of Epoch 1/6, Average Loss=12.329143524169922, Class Loss=0.6449395418167114, Reg Loss=11.6842041015625
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=10.258836483955383
Loss made of: CE 0.34401464462280273, LKD 3.369938611984253, LDE 6.765119552612305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.39055106043815613, Reg Loss=9.755977630615234
Clinet index 20, End of Epoch 2/6, Average Loss=10.146528244018555, Class Loss=0.39055106043815613, Reg Loss=9.755977630615234
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=9.834562210738659
Loss made of: CE 0.29450225830078125, LKD 3.9442949295043945, LDE 7.195430278778076, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.278403103351593, Reg Loss=9.621543884277344
Clinet index 20, End of Epoch 3/6, Average Loss=9.899947166442871, Class Loss=0.278403103351593, Reg Loss=9.621543884277344
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=9.217438577115535
Loss made of: CE 0.24200066924095154, LKD 3.719957113265991, LDE 5.211817741394043, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25356340408325195, Reg Loss=8.872757911682129
Clinet index 20, End of Epoch 4/6, Average Loss=9.126321792602539, Class Loss=0.25356340408325195, Reg Loss=8.872757911682129
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=9.009323798120022
Loss made of: CE 0.20940813422203064, LKD 3.3237311840057373, LDE 6.071694850921631, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2334456443786621, Reg Loss=8.777155876159668
Clinet index 20, End of Epoch 5/6, Average Loss=9.010601043701172, Class Loss=0.2334456443786621, Reg Loss=8.777155876159668
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=8.544022271037102
Loss made of: CE 0.24729470908641815, LKD 2.8226122856140137, LDE 5.934711933135986, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2335720956325531, Reg Loss=8.395873069763184
Clinet index 20, End of Epoch 6/6, Average Loss=8.62944507598877, Class Loss=0.2335720956325531, Reg Loss=8.395873069763184
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=11.06038761138916
Loss made of: CE 0.526847243309021, LKD 3.5073678493499756, LDE 5.628938674926758, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5732848644256592, Reg Loss=10.458927154541016
Clinet index 0, End of Epoch 1/6, Average Loss=11.032212257385254, Class Loss=0.5732848644256592, Reg Loss=10.458927154541016
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/11, Loss=9.169210594892501
Loss made of: CE 0.26289066672325134, LKD 3.2488598823547363, LDE 4.295586585998535, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.39114418625831604, Reg Loss=8.746466636657715
Clinet index 0, End of Epoch 2/6, Average Loss=9.13761043548584, Class Loss=0.39114418625831604, Reg Loss=8.746466636657715
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/11, Loss=8.793043245375156
Loss made of: CE 0.27151188254356384, LKD 3.279019594192505, LDE 4.625908851623535, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2945249080657959, Reg Loss=8.454327583312988
Clinet index 0, End of Epoch 3/6, Average Loss=8.748852729797363, Class Loss=0.2945249080657959, Reg Loss=8.454327583312988
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/11, Loss=8.628381963074208
Loss made of: CE 0.2678581476211548, LKD 3.818333148956299, LDE 4.820468902587891, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27215078473091125, Reg Loss=8.382822036743164
Clinet index 0, End of Epoch 4/6, Average Loss=8.654973030090332, Class Loss=0.27215078473091125, Reg Loss=8.382822036743164
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/11, Loss=8.417058807611465
Loss made of: CE 0.248602956533432, LKD 3.5512588024139404, LDE 5.0153584480285645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2747150957584381, Reg Loss=8.201921463012695
Clinet index 0, End of Epoch 5/6, Average Loss=8.47663688659668, Class Loss=0.2747150957584381, Reg Loss=8.201921463012695
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/11, Loss=8.094331593811512
Loss made of: CE 0.21751996874809265, LKD 3.0502166748046875, LDE 4.171069622039795, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2587948441505432, Reg Loss=7.763740062713623
Clinet index 0, End of Epoch 6/6, Average Loss=8.02253532409668, Class Loss=0.2587948441505432, Reg Loss=7.763740062713623
federated aggregation...
Validation, Class Loss=0.5732805132865906, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.812231
Mean Acc: 0.315431
FreqW Acc: 0.730183
Mean IoU: 0.233238
Class IoU:
	class 0: 0.90057045
	class 1: 0.36340496
	class 2: 0.0
	class 3: 0.022332497
	class 4: 0.46075866
	class 5: 0.19056438
	class 6: 0.46325842
	class 7: 0.2872661
	class 8: 0.22881739
	class 9: 0.06575705
	class 10: 0.0
	class 11: 0.0019392037
	class 12: 0.32180372
	class 13: 0.036264725
	class 14: 0.1558365
Class Acc:
	class 0: 0.9765437
	class 1: 0.36498973
	class 2: 0.0
	class 3: 0.022332497
	class 4: 0.4834819
	class 5: 0.19070221
	class 6: 0.46410915
	class 7: 0.28753665
	class 8: 0.22911286
	class 9: 0.07263765
	class 10: 0.0
	class 11: 0.0019404787
	class 12: 0.6923312
	class 13: 0.050161332
	class 14: 0.89558566

federated global round: 17, step: 3
select part of clients to conduct local training
[1, 16, 6, 21]
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=13.974558937549592
Loss made of: CE 0.5033672451972961, LKD 3.4052398204803467, LDE 7.4862165451049805, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6484552621841431, Reg Loss=13.234697341918945
Clinet index 1, End of Epoch 1/6, Average Loss=13.883152961730957, Class Loss=0.6484552621841431, Reg Loss=13.234697341918945
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=9.803319868445396
Loss made of: CE 0.3079364001750946, LKD 3.3862314224243164, LDE 5.60299015045166, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3842073976993561, Reg Loss=9.417108535766602
Clinet index 1, End of Epoch 2/6, Average Loss=9.801316261291504, Class Loss=0.3842073976993561, Reg Loss=9.417108535766602
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Batch 10/11, Loss=9.00056745260954
Loss made of: CE 0.24961569905281067, LKD 3.316807270050049, LDE 4.3201518058776855, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2892715036869049, Reg Loss=8.64095687866211
Clinet index 1, End of Epoch 3/6, Average Loss=8.930228233337402, Class Loss=0.2892715036869049, Reg Loss=8.64095687866211
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=8.382471050322057
Loss made of: CE 0.2489134520292282, LKD 3.7062606811523438, LDE 4.0583176612854, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2596321105957031, Reg Loss=8.190678596496582
Clinet index 1, End of Epoch 4/6, Average Loss=8.450310707092285, Class Loss=0.2596321105957031, Reg Loss=8.190678596496582
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=8.141693460941315
Loss made of: CE 0.2601041793823242, LKD 3.5292725563049316, LDE 4.064188480377197, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2688857614994049, Reg Loss=7.876832008361816
Clinet index 1, End of Epoch 5/6, Average Loss=8.14571762084961, Class Loss=0.2688857614994049, Reg Loss=7.876832008361816
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=7.971889677643776
Loss made of: CE 0.25373324751853943, LKD 3.3552870750427246, LDE 4.375349521636963, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2623724043369293, Reg Loss=7.739107608795166
Clinet index 1, End of Epoch 6/6, Average Loss=8.001480102539062, Class Loss=0.2623724043369293, Reg Loss=7.739107608795166
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/11, Loss=13.983968776464462
Loss made of: CE 0.5592677593231201, LKD 3.795322895050049, LDE 7.488690376281738, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6642468571662903, Reg Loss=13.040858268737793
Clinet index 16, End of Epoch 1/6, Average Loss=13.70510482788086, Class Loss=0.6642468571662903, Reg Loss=13.040858268737793
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=10.063251760601997
Loss made of: CE 0.3478906750679016, LKD 3.66904616355896, LDE 4.94460391998291, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4048309326171875, Reg Loss=9.5878324508667
Clinet index 16, End of Epoch 2/6, Average Loss=9.992663383483887, Class Loss=0.4048309326171875, Reg Loss=9.5878324508667
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=9.01352800577879
Loss made of: CE 0.2683553397655487, LKD 3.568512201309204, LDE 5.034169673919678, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2836138606071472, Reg Loss=8.66649055480957
Clinet index 16, End of Epoch 3/6, Average Loss=8.950104713439941, Class Loss=0.2836138606071472, Reg Loss=8.66649055480957
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=8.613194718956947
Loss made of: CE 0.2768334150314331, LKD 3.0742063522338867, LDE 6.251936435699463, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.27846717834472656, Reg Loss=8.400091171264648
Clinet index 16, End of Epoch 4/6, Average Loss=8.678558349609375, Class Loss=0.27846717834472656, Reg Loss=8.400091171264648
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=8.268401412665844
Loss made of: CE 0.257739782333374, LKD 3.741469621658325, LDE 4.198609828948975, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26123300194740295, Reg Loss=8.055133819580078
Clinet index 16, End of Epoch 5/6, Average Loss=8.316367149353027, Class Loss=0.26123300194740295, Reg Loss=8.055133819580078
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=7.806695325672626
Loss made of: CE 0.21347343921661377, LKD 3.5267739295959473, LDE 3.899604082107544, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25208336114883423, Reg Loss=7.605844020843506
Clinet index 16, End of Epoch 6/6, Average Loss=7.857927322387695, Class Loss=0.25208336114883423, Reg Loss=7.605844020843506
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/11, Loss=15.21855857372284
Loss made of: CE 0.6486420631408691, LKD 3.823681116104126, LDE 7.081442356109619, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7083104252815247, Reg Loss=14.257726669311523
Clinet index 6, End of Epoch 1/6, Average Loss=14.966036796569824, Class Loss=0.7083104252815247, Reg Loss=14.257726669311523
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/11, Loss=10.599060961604119
Loss made of: CE 0.4726420044898987, LKD 4.075708866119385, LDE 6.316725730895996, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4580918848514557, Reg Loss=10.070871353149414
Clinet index 6, End of Epoch 2/6, Average Loss=10.528963088989258, Class Loss=0.4580918848514557, Reg Loss=10.070871353149414
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/11, Loss=9.099009078741073
Loss made of: CE 0.3621608018875122, LKD 3.9458513259887695, LDE 5.433051109313965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3206525444984436, Reg Loss=8.758111953735352
Clinet index 6, End of Epoch 3/6, Average Loss=9.078764915466309, Class Loss=0.3206525444984436, Reg Loss=8.758111953735352
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/11, Loss=8.597336733341217
Loss made of: CE 0.27027738094329834, LKD 3.3994414806365967, LDE 5.1748247146606445, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28101736307144165, Reg Loss=8.258892059326172
Clinet index 6, End of Epoch 4/6, Average Loss=8.539909362792969, Class Loss=0.28101736307144165, Reg Loss=8.258892059326172
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/11, Loss=8.616613198816776
Loss made of: CE 0.3230579197406769, LKD 3.1326606273651123, LDE 4.930095195770264, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27884161472320557, Reg Loss=8.27812385559082
Clinet index 6, End of Epoch 5/6, Average Loss=8.556965827941895, Class Loss=0.27884161472320557, Reg Loss=8.27812385559082
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/11, Loss=8.08319986462593
Loss made of: CE 0.2333112210035324, LKD 3.526259183883667, LDE 4.053140640258789, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2585293650627136, Reg Loss=7.9106879234313965
Clinet index 6, End of Epoch 6/6, Average Loss=8.169217109680176, Class Loss=0.2585293650627136, Reg Loss=7.9106879234313965
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=9.276172935962677
Loss made of: CE 0.24546043574810028, LKD 3.0854570865631104, LDE 5.195316314697266, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2863895893096924, Reg Loss=9.085164070129395
Clinet index 21, End of Epoch 1/6, Average Loss=9.371553421020508, Class Loss=0.2863895893096924, Reg Loss=9.085164070129395
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=8.833965514600276
Loss made of: CE 0.30570870637893677, LKD 3.2316434383392334, LDE 5.561335563659668, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.26282376050949097, Reg Loss=8.650036811828613
Clinet index 21, End of Epoch 2/6, Average Loss=8.912860870361328, Class Loss=0.26282376050949097, Reg Loss=8.650036811828613
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Batch 10/12, Loss=8.981774528324603
Loss made of: CE 0.25354477763175964, LKD 4.346843719482422, LDE 5.525821685791016, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26027971506118774, Reg Loss=8.783817291259766
Clinet index 21, End of Epoch 3/6, Average Loss=9.044096946716309, Class Loss=0.26027971506118774, Reg Loss=8.783817291259766
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=8.518757459521293
Loss made of: CE 0.19765472412109375, LKD 3.0869295597076416, LDE 4.992288112640381, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24412190914154053, Reg Loss=8.210368156433105
Clinet index 21, End of Epoch 4/6, Average Loss=8.454489707946777, Class Loss=0.24412190914154053, Reg Loss=8.210368156433105
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=8.155599154531956
Loss made of: CE 0.22415995597839355, LKD 2.9473965167999268, LDE 4.767043590545654, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23561522364616394, Reg Loss=8.06821346282959
Clinet index 21, End of Epoch 5/6, Average Loss=8.303828239440918, Class Loss=0.23561522364616394, Reg Loss=8.06821346282959
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=8.53753060400486
Loss made of: CE 0.19705581665039062, LKD 3.035546064376831, LDE 4.374638080596924, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23438504338264465, Reg Loss=8.159093856811523
Clinet index 21, End of Epoch 6/6, Average Loss=8.393479347229004, Class Loss=0.23438504338264465, Reg Loss=8.159093856811523
federated aggregation...
Validation, Class Loss=0.6939049959182739, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.780161
Mean Acc: 0.272457
FreqW Acc: 0.720541
Mean IoU: 0.191206
Class IoU:
	class 0: 0.91411054
	class 1: 0.16518876
	class 2: 0.007428803
	class 3: 0.0
	class 4: 0.5152773
	class 5: 0.020131113
	class 6: 0.23953898
	class 7: 0.4555425
	class 8: 0.0
	class 9: 0.04039168
	class 10: 0.0
	class 11: 0.0026548891
	class 12: 0.03315705
	class 13: 0.08844448
	class 14: 0.38622198
Class Acc:
	class 0: 0.96736854
	class 1: 0.16555722
	class 2: 0.0075320643
	class 3: 0.0
	class 4: 0.54430974
	class 5: 0.020142527
	class 6: 0.23977387
	class 7: 0.457003
	class 8: 0.0
	class 9: 0.042712674
	class 10: 0.0
	class 11: 0.002655528
	class 12: 0.03381586
	class 13: 0.9187311
	class 14: 0.6872539

federated global round: 18, step: 3
select part of clients to conduct local training
[8, 2, 17, 14]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=8.679221290349961
Loss made of: CE 0.26275262236595154, LKD 3.2733094692230225, LDE 4.8276686668396, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2962303161621094, Reg Loss=8.367630004882812
Clinet index 8, End of Epoch 1/6, Average Loss=8.663860321044922, Class Loss=0.2962303161621094, Reg Loss=8.367630004882812
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=8.111009314656258
Loss made of: CE 0.26832568645477295, LKD 3.925678253173828, LDE 4.202154159545898, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2740960121154785, Reg Loss=7.761475563049316
Clinet index 8, End of Epoch 2/6, Average Loss=8.035572052001953, Class Loss=0.2740960121154785, Reg Loss=7.761475563049316
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=7.979958622157573
Loss made of: CE 0.27514979243278503, LKD 3.524285078048706, LDE 4.0778703689575195, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2682461738586426, Reg Loss=7.781758785247803
Clinet index 8, End of Epoch 3/6, Average Loss=8.050004959106445, Class Loss=0.2682461738586426, Reg Loss=7.781758785247803
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=7.481450037658215
Loss made of: CE 0.22192329168319702, LKD 2.91837739944458, LDE 4.141876697540283, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25671789050102234, Reg Loss=7.17113733291626
Clinet index 8, End of Epoch 4/6, Average Loss=7.427855014801025, Class Loss=0.25671789050102234, Reg Loss=7.17113733291626
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=7.519148106873035
Loss made of: CE 0.25119397044181824, LKD 3.3396430015563965, LDE 4.884303569793701, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24599537253379822, Reg Loss=7.288758277893066
Clinet index 8, End of Epoch 5/6, Average Loss=7.534753799438477, Class Loss=0.24599537253379822, Reg Loss=7.288758277893066
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=7.655432310700417
Loss made of: CE 0.22976362705230713, LKD 3.4783096313476562, LDE 4.154562473297119, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24411046504974365, Reg Loss=7.372988224029541
Clinet index 8, End of Epoch 6/6, Average Loss=7.617098808288574, Class Loss=0.24411046504974365, Reg Loss=7.372988224029541
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=9.035570257902146
Loss made of: CE 0.31439441442489624, LKD 3.698991537094116, LDE 5.041406631469727, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.29993322491645813, Reg Loss=8.704282760620117
Clinet index 2, End of Epoch 1/6, Average Loss=9.004216194152832, Class Loss=0.29993322491645813, Reg Loss=8.704282760620117
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=8.300111135840416
Loss made of: CE 0.23719422519207, LKD 3.4456841945648193, LDE 3.8561582565307617, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2862202227115631, Reg Loss=7.950634479522705
Clinet index 2, End of Epoch 2/6, Average Loss=8.236854553222656, Class Loss=0.2862202227115631, Reg Loss=7.950634479522705
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Batch 10/11, Loss=8.057339531183242
Loss made of: CE 0.2470545470714569, LKD 3.570230007171631, LDE 3.394221067428589, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2636348605155945, Reg Loss=7.823068141937256
Clinet index 2, End of Epoch 3/6, Average Loss=8.086703300476074, Class Loss=0.2636348605155945, Reg Loss=7.823068141937256
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=7.963064044713974
Loss made of: CE 0.26144570112228394, LKD 3.5500361919403076, LDE 3.7951924800872803, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2646830677986145, Reg Loss=7.747804164886475
Clinet index 2, End of Epoch 4/6, Average Loss=8.012487411499023, Class Loss=0.2646830677986145, Reg Loss=7.747804164886475
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=7.703538200259208
Loss made of: CE 0.2505062520503998, LKD 3.2245912551879883, LDE 4.2863593101501465, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25751838088035583, Reg Loss=7.392088890075684
Clinet index 2, End of Epoch 5/6, Average Loss=7.649607181549072, Class Loss=0.25751838088035583, Reg Loss=7.392088890075684
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=7.684275281429291
Loss made of: CE 0.25923192501068115, LKD 3.471583604812622, LDE 4.61530065536499, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25596728920936584, Reg Loss=7.383923053741455
Clinet index 2, End of Epoch 6/6, Average Loss=7.639890193939209, Class Loss=0.25596728920936584, Reg Loss=7.383923053741455
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=13.946173071861267
Loss made of: CE 0.45574018359184265, LKD 4.713440895080566, LDE 7.027198314666748, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5012920498847961, Reg Loss=12.819633483886719
Clinet index 17, End of Epoch 1/6, Average Loss=13.32092571258545, Class Loss=0.5012920498847961, Reg Loss=12.819633483886719
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=10.131899227201938
Loss made of: CE 0.2095154970884323, LKD 4.044841766357422, LDE 5.844717979431152, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3166656196117401, Reg Loss=9.728431701660156
Clinet index 17, End of Epoch 2/6, Average Loss=10.045097351074219, Class Loss=0.3166656196117401, Reg Loss=9.728431701660156
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=9.17759395390749
Loss made of: CE 0.2686448097229004, LKD 3.600640296936035, LDE 5.010397434234619, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2551841735839844, Reg Loss=8.900426864624023
Clinet index 17, End of Epoch 3/6, Average Loss=9.155611038208008, Class Loss=0.2551841735839844, Reg Loss=8.900426864624023
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=9.064032208919524
Loss made of: CE 0.1839667558670044, LKD 2.7715039253234863, LDE 5.722070693969727, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2548764944076538, Reg Loss=8.620223045349121
Clinet index 17, End of Epoch 4/6, Average Loss=8.875099182128906, Class Loss=0.2548764944076538, Reg Loss=8.620223045349121
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=8.265813672542572
Loss made of: CE 0.3207123875617981, LKD 3.335718870162964, LDE 3.875622272491455, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2573630213737488, Reg Loss=8.474621772766113
Clinet index 17, End of Epoch 5/6, Average Loss=8.731985092163086, Class Loss=0.2573630213737488, Reg Loss=8.474621772766113
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Batch 10/12, Loss=8.486113642156123
Loss made of: CE 0.22022494673728943, LKD 2.588463306427002, LDE 4.468799591064453, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2520286738872528, Reg Loss=8.237293243408203
Clinet index 17, End of Epoch 6/6, Average Loss=8.4893217086792, Class Loss=0.2520286738872528, Reg Loss=8.237293243408203
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=8.828791955113411
Loss made of: CE 0.29154983162879944, LKD 3.200227737426758, LDE 4.956610202789307, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2995792329311371, Reg Loss=8.48058032989502
Clinet index 14, End of Epoch 1/6, Average Loss=8.780159950256348, Class Loss=0.2995792329311371, Reg Loss=8.48058032989502
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=8.26170036047697
Loss made of: CE 0.24913601577281952, LKD 3.8260498046875, LDE 4.007079601287842, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2869085371494293, Reg Loss=7.997620582580566
Clinet index 14, End of Epoch 2/6, Average Loss=8.284528732299805, Class Loss=0.2869085371494293, Reg Loss=7.997620582580566
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=8.185293357074261
Loss made of: CE 0.25151699781417847, LKD 3.476925849914551, LDE 4.716001987457275, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2665413022041321, Reg Loss=7.858194828033447
Clinet index 14, End of Epoch 3/6, Average Loss=8.124735832214355, Class Loss=0.2665413022041321, Reg Loss=7.858194828033447
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=8.468454137444496
Loss made of: CE 0.2648257613182068, LKD 3.6219582557678223, LDE 3.66286563873291, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2731534540653229, Reg Loss=8.206875801086426
Clinet index 14, End of Epoch 4/6, Average Loss=8.480029106140137, Class Loss=0.2731534540653229, Reg Loss=8.206875801086426
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=7.857832257449627
Loss made of: CE 0.2677513360977173, LKD 3.4509458541870117, LDE 3.7608697414398193, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2517283260822296, Reg Loss=7.615047931671143
Clinet index 14, End of Epoch 5/6, Average Loss=7.866776466369629, Class Loss=0.2517283260822296, Reg Loss=7.615047931671143
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=7.817864726483822
Loss made of: CE 0.23634254932403564, LKD 3.312537908554077, LDE 4.42960786819458, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24601306021213531, Reg Loss=7.728085994720459
Clinet index 14, End of Epoch 6/6, Average Loss=7.974099159240723, Class Loss=0.24601306021213531, Reg Loss=7.728085994720459
federated aggregation...
Validation, Class Loss=0.7332056760787964, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.776300
Mean Acc: 0.258523
FreqW Acc: 0.716263
Mean IoU: 0.178314
Class IoU:
	class 0: 0.9130381
	class 1: 0.10059498
	class 2: 0.0026748183
	class 3: 0.0
	class 4: 0.47442704
	class 5: 0.0062773
	class 6: 0.18526119
	class 7: 0.46105883
	class 8: 0.0
	class 9: 0.045326035
	class 10: 0.0
	class 11: 0.0031419082
	class 12: 0.009157401
	class 13: 0.08692957
	class 14: 0.38682577
Class Acc:
	class 0: 0.96718055
	class 1: 0.10074915
	class 2: 0.0026898694
	class 3: 0.0
	class 4: 0.4998833
	class 5: 0.006278363
	class 6: 0.185416
	class 7: 0.46254787
	class 8: 0.0
	class 9: 0.048000243
	class 10: 0.0
	class 11: 0.0031428798
	class 12: 0.009219993
	class 13: 0.92565703
	class 14: 0.66708446

federated global round: 19, step: 3
select part of clients to conduct local training
[1, 9, 8, 0]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/11, Loss=8.031044580042362
Loss made of: CE 0.23301152884960175, LKD 3.189146041870117, LDE 4.293720245361328, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2723054885864258, Reg Loss=7.8962225914001465
Clinet index 1, End of Epoch 1/6, Average Loss=8.168527603149414, Class Loss=0.2723054885864258, Reg Loss=7.8962225914001465
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/11, Loss=7.669369068741799
Loss made of: CE 0.25758644938468933, LKD 3.4657042026519775, LDE 4.184658050537109, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2681240141391754, Reg Loss=7.404079437255859
Clinet index 1, End of Epoch 2/6, Average Loss=7.672203540802002, Class Loss=0.2681240141391754, Reg Loss=7.404079437255859
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/11, Loss=7.839292176067829
Loss made of: CE 0.23273232579231262, LKD 3.190823554992676, LDE 3.450564384460449, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2662244439125061, Reg Loss=7.504238128662109
Clinet index 1, End of Epoch 3/6, Average Loss=7.770462512969971, Class Loss=0.2662244439125061, Reg Loss=7.504238128662109
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/11, Loss=7.327581191062928
Loss made of: CE 0.2549034357070923, LKD 3.490368366241455, LDE 3.4019556045532227, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2541835308074951, Reg Loss=7.20403528213501
Clinet index 1, End of Epoch 4/6, Average Loss=7.458218574523926, Class Loss=0.2541835308074951, Reg Loss=7.20403528213501
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/11, Loss=7.437106850743294
Loss made of: CE 0.27367347478866577, LKD 3.5068984031677246, LDE 3.5196077823638916, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2613184452056885, Reg Loss=7.165375709533691
Clinet index 1, End of Epoch 5/6, Average Loss=7.426693916320801, Class Loss=0.2613184452056885, Reg Loss=7.165375709533691
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/11, Loss=7.44742428958416
Loss made of: CE 0.2578738331794739, LKD 3.3340628147125244, LDE 3.9380760192871094, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25705599784851074, Reg Loss=7.22360897064209
Clinet index 1, End of Epoch 6/6, Average Loss=7.48066520690918, Class Loss=0.25705599784851074, Reg Loss=7.22360897064209
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=13.89355502128601
Loss made of: CE 0.5179173946380615, LKD 4.312118053436279, LDE 6.936731338500977, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5495089292526245, Reg Loss=12.798041343688965
Clinet index 9, End of Epoch 1/6, Average Loss=13.347550392150879, Class Loss=0.5495089292526245, Reg Loss=12.798041343688965
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/12, Loss=10.08506737947464
Loss made of: CE 0.26739031076431274, LKD 3.0474584102630615, LDE 5.791581630706787, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35073941946029663, Reg Loss=9.690753936767578
Clinet index 9, End of Epoch 2/6, Average Loss=10.04149341583252, Class Loss=0.35073941946029663, Reg Loss=9.690753936767578
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Batch 10/12, Loss=9.098733787238597
Loss made of: CE 0.3281722366809845, LKD 3.3637986183166504, LDE 5.275796413421631, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2987448275089264, Reg Loss=8.666635513305664
Clinet index 9, End of Epoch 3/6, Average Loss=8.965380668640137, Class Loss=0.2987448275089264, Reg Loss=8.666635513305664
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/12, Loss=8.822680774331094
Loss made of: CE 0.3033568263053894, LKD 3.2847886085510254, LDE 5.08529806137085, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2802225351333618, Reg Loss=8.491588592529297
Clinet index 9, End of Epoch 4/6, Average Loss=8.771811485290527, Class Loss=0.2802225351333618, Reg Loss=8.491588592529297
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/12, Loss=8.83243830949068
Loss made of: CE 0.23034797608852386, LKD 2.7973031997680664, LDE 5.4829607009887695, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2621968388557434, Reg Loss=8.537569999694824
Clinet index 9, End of Epoch 5/6, Average Loss=8.799766540527344, Class Loss=0.2621968388557434, Reg Loss=8.537569999694824
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/12, Loss=8.575343511998653
Loss made of: CE 0.23235872387886047, LKD 3.1887431144714355, LDE 4.826498031616211, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2692564129829407, Reg Loss=8.265110969543457
Clinet index 9, End of Epoch 6/6, Average Loss=8.534367561340332, Class Loss=0.2692564129829407, Reg Loss=8.265110969543457
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/11, Loss=8.088789315521717
Loss made of: CE 0.24852530658245087, LKD 3.318715810775757, LDE 4.609748840332031, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2717299163341522, Reg Loss=7.801759243011475
Clinet index 8, End of Epoch 1/6, Average Loss=8.07348918914795, Class Loss=0.2717299163341522, Reg Loss=7.801759243011475
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/11, Loss=7.5050606489181515
Loss made of: CE 0.2463054358959198, LKD 3.8159072399139404, LDE 3.6375298500061035, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2639979124069214, Reg Loss=7.1951470375061035
Clinet index 8, End of Epoch 2/6, Average Loss=7.4591450691223145, Class Loss=0.2639979124069214, Reg Loss=7.1951470375061035
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/11, Loss=7.540394634008408
Loss made of: CE 0.27261289954185486, LKD 3.3730528354644775, LDE 3.6987550258636475, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2649049758911133, Reg Loss=7.3296990394592285
Clinet index 8, End of Epoch 3/6, Average Loss=7.594604015350342, Class Loss=0.2649049758911133, Reg Loss=7.3296990394592285
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/11, Loss=7.290697558224201
Loss made of: CE 0.2227012813091278, LKD 2.992405652999878, LDE 3.6416637897491455, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26136401295661926, Reg Loss=6.9932661056518555
Clinet index 8, End of Epoch 4/6, Average Loss=7.254630088806152, Class Loss=0.26136401295661926, Reg Loss=6.9932661056518555
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/11, Loss=7.37076556533575
Loss made of: CE 0.259880393743515, LKD 3.2860894203186035, LDE 4.541562080383301, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2603716254234314, Reg Loss=7.156787872314453
Clinet index 8, End of Epoch 5/6, Average Loss=7.417159557342529, Class Loss=0.2603716254234314, Reg Loss=7.156787872314453
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/11, Loss=7.489894224703312
Loss made of: CE 0.22902441024780273, LKD 3.513132095336914, LDE 3.925485610961914, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2530944347381592, Reg Loss=7.197993278503418
Clinet index 8, End of Epoch 6/6, Average Loss=7.451087951660156, Class Loss=0.2530944347381592, Reg Loss=7.197993278503418
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/11, Loss=8.113887178897858
Loss made of: CE 0.27706798911094666, LKD 3.538351535797119, LDE 4.222167491912842, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2879043519496918, Reg Loss=7.82363224029541
Clinet index 0, End of Epoch 1/6, Average Loss=8.111536979675293, Class Loss=0.2879043519496918, Reg Loss=7.82363224029541
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/11, Loss=7.7244005382061
Loss made of: CE 0.24993345141410828, LKD 3.2771668434143066, LDE 3.3182311058044434, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28916603326797485, Reg Loss=7.45886754989624
Clinet index 0, End of Epoch 2/6, Average Loss=7.74803352355957, Class Loss=0.28916603326797485, Reg Loss=7.45886754989624
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/11, Loss=7.772159546613693
Loss made of: CE 0.27078521251678467, LKD 3.147007465362549, LDE 3.749469757080078, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2727716565132141, Reg Loss=7.467772960662842
Clinet index 0, End of Epoch 3/6, Average Loss=7.74054479598999, Class Loss=0.2727716565132141, Reg Loss=7.467772960662842
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/11, Loss=7.562858244776725
Loss made of: CE 0.2705917954444885, LKD 3.796571969985962, LDE 4.230782985687256, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2649688720703125, Reg Loss=7.31541109085083
Clinet index 0, End of Epoch 4/6, Average Loss=7.580379962921143, Class Loss=0.2649688720703125, Reg Loss=7.31541109085083
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 5, Batch 10/11, Loss=7.544345273077488
Loss made of: CE 0.23411160707473755, LKD 3.1376938819885254, LDE 4.277896404266357, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26718565821647644, Reg Loss=7.332161903381348
Clinet index 0, End of Epoch 5/6, Average Loss=7.5993475914001465, Class Loss=0.26718565821647644, Reg Loss=7.332161903381348
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/11, Loss=7.4544338315725325
Loss made of: CE 0.22449955344200134, LKD 3.061018705368042, LDE 3.777906656265259, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26822832226753235, Reg Loss=7.12054967880249
Clinet index 0, End of Epoch 6/6, Average Loss=7.388778209686279, Class Loss=0.26822832226753235, Reg Loss=7.12054967880249
federated aggregation...
Validation, Class Loss=0.7440609335899353, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.777833
Mean Acc: 0.270011
FreqW Acc: 0.717593
Mean IoU: 0.181498
Class IoU:
	class 0: 0.9137933
	class 1: 0.11891455
	class 2: 0.00066036574
	class 3: 0.0
	class 4: 0.4826909
	class 5: 0.0061835484
	class 6: 0.18596072
	class 7: 0.47824985
	class 8: 0.0
	class 9: 0.048764057
	class 10: 0.0
	class 11: 0.004471657
	class 12: 0.009409633
	class 13: 0.090108484
	class 14: 0.38326508
Class Acc:
	class 0: 0.965419
	class 1: 0.11914367
	class 2: 0.0006608206
	class 3: 0.0
	class 4: 0.5083362
	class 5: 0.0061849956
	class 6: 0.18612128
	class 7: 0.47991675
	class 8: 0.0
	class 9: 0.05175513
	class 10: 0.0
	class 11: 0.004473816
	class 12: 0.009527232
	class 13: 0.9334509
	class 14: 0.78517663

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[11, 2, 15, 6]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=16.34098598957062
Loss made of: CE 1.9427590370178223, LKD 3.763292074203491, LDE 8.792444229125977, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.651059627532959, Reg Loss=14.156477928161621
Clinet index 11, End of Epoch 1/6, Average Loss=15.807537078857422, Class Loss=1.651059627532959, Reg Loss=14.156477928161621
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=11.636078971624375
Loss made of: CE 1.2485498189926147, LKD 3.902778148651123, LDE 5.834582328796387, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3368948698043823, Reg Loss=10.23265266418457
Clinet index 11, End of Epoch 2/6, Average Loss=11.569547653198242, Class Loss=1.3368948698043823, Reg Loss=10.23265266418457
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=9.767816472053529
Loss made of: CE 1.0988718271255493, LKD 3.5657973289489746, LDE 4.177318096160889, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.1094245910644531, Reg Loss=8.827180862426758
Clinet index 11, End of Epoch 3/6, Average Loss=9.936605453491211, Class Loss=1.1094245910644531, Reg Loss=8.827180862426758
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=9.117044031620026
Loss made of: CE 0.8941870927810669, LKD 3.8776657581329346, LDE 4.470690727233887, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.9526964426040649, Reg Loss=8.139932632446289
Clinet index 11, End of Epoch 4/6, Average Loss=9.092629432678223, Class Loss=0.9526964426040649, Reg Loss=8.139932632446289
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=8.754395693540573
Loss made of: CE 0.6513990163803101, LKD 3.877156972885132, LDE 3.7296485900878906, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.8221461176872253, Reg Loss=7.847447872161865
Clinet index 11, End of Epoch 5/6, Average Loss=8.669593811035156, Class Loss=0.8221461176872253, Reg Loss=7.847447872161865
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=8.373216527700425
Loss made of: CE 1.0077452659606934, LKD 4.035544395446777, LDE 3.4802656173706055, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.7453712821006775, Reg Loss=7.640083312988281
Clinet index 11, End of Epoch 6/6, Average Loss=8.385454177856445, Class Loss=0.7453712821006775, Reg Loss=7.640083312988281
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=16.409399604797365
Loss made of: CE 1.797973394393921, LKD 3.9950947761535645, LDE 8.015682220458984, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.648175597190857, Reg Loss=14.251514434814453
Clinet index 2, End of Epoch 1/6, Average Loss=15.899689674377441, Class Loss=1.648175597190857, Reg Loss=14.251514434814453
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=11.470091509819031
Loss made of: CE 1.1263854503631592, LKD 3.3580820560455322, LDE 5.129209041595459, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.2958284616470337, Reg Loss=9.933375358581543
Clinet index 2, End of Epoch 2/6, Average Loss=11.229204177856445, Class Loss=1.2958284616470337, Reg Loss=9.933375358581543
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=9.962698173522949
Loss made of: CE 0.9754847288131714, LKD 3.5518693923950195, LDE 5.01696252822876, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.0893810987472534, Reg Loss=8.802593231201172
Clinet index 2, End of Epoch 3/6, Average Loss=9.891974449157715, Class Loss=1.0893810987472534, Reg Loss=8.802593231201172
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=8.976830905675888
Loss made of: CE 0.8596908450126648, LKD 3.993807792663574, LDE 4.059167861938477, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.9174022674560547, Reg Loss=8.101507186889648
Clinet index 2, End of Epoch 4/6, Average Loss=9.018909454345703, Class Loss=0.9174022674560547, Reg Loss=8.101507186889648
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=8.518719285726547
Loss made of: CE 0.8222131729125977, LKD 4.163254737854004, LDE 3.8173251152038574, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7874205112457275, Reg Loss=7.705692291259766
Clinet index 2, End of Epoch 5/6, Average Loss=8.493112564086914, Class Loss=0.7874205112457275, Reg Loss=7.705692291259766
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=8.419049298763275
Loss made of: CE 0.8164435625076294, LKD 3.7796549797058105, LDE 3.8632941246032715, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.7197815179824829, Reg Loss=7.768601894378662
Clinet index 2, End of Epoch 6/6, Average Loss=8.488383293151855, Class Loss=0.7197815179824829, Reg Loss=7.768601894378662
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=16.706434643268587
Loss made of: CE 1.9887967109680176, LKD 4.4756646156311035, LDE 7.419002056121826, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.6268541812896729, Reg Loss=14.454893112182617
Clinet index 15, End of Epoch 1/6, Average Loss=16.08174705505371, Class Loss=1.6268541812896729, Reg Loss=14.454893112182617
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=11.670539236068725
Loss made of: CE 1.3129792213439941, LKD 3.8858935832977295, LDE 5.252460956573486, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3175972700119019, Reg Loss=10.185807228088379
Clinet index 15, End of Epoch 2/6, Average Loss=11.50340461730957, Class Loss=1.3175972700119019, Reg Loss=10.185807228088379
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=9.938922715187072
Loss made of: CE 1.1616184711456299, LKD 3.5694162845611572, LDE 4.6156697273254395, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.0965142250061035, Reg Loss=8.920247077941895
Clinet index 15, End of Epoch 3/6, Average Loss=10.016761779785156, Class Loss=1.0965142250061035, Reg Loss=8.920247077941895
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=9.329934358596802
Loss made of: CE 0.7092081904411316, LKD 3.0897719860076904, LDE 4.792409896850586, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.9514220952987671, Reg Loss=8.41663932800293
Clinet index 15, End of Epoch 4/6, Average Loss=9.368061065673828, Class Loss=0.9514220952987671, Reg Loss=8.41663932800293
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=8.795042544603348
Loss made of: CE 0.8576735258102417, LKD 3.20929217338562, LDE 4.3835015296936035, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.8397547006607056, Reg Loss=7.9550700187683105
Clinet index 15, End of Epoch 5/6, Average Loss=8.794824600219727, Class Loss=0.8397547006607056, Reg Loss=7.9550700187683105
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=8.57951717376709
Loss made of: CE 0.6622363328933716, LKD 2.9065098762512207, LDE 4.534996509552002, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.7092791795730591, Reg Loss=7.845137596130371
Clinet index 15, End of Epoch 6/6, Average Loss=8.55441665649414, Class Loss=0.7092791795730591, Reg Loss=7.845137596130371
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=13.78637112379074
Loss made of: CE 1.5978145599365234, LKD 3.4812800884246826, LDE 6.544595241546631, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=11.424154365062714
Loss made of: CE 1.5361618995666504, LKD 3.4968628883361816, LDE 5.691740989685059, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=9.965586364269257
Loss made of: CE 1.2184510231018066, LKD 4.036430835723877, LDE 4.126192569732666, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=9.445477014780044
Loss made of: CE 0.8565255999565125, LKD 3.197930097579956, LDE 4.0428876876831055, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=8.725820845365524
Loss made of: CE 0.7133097648620605, LKD 3.675175428390503, LDE 3.5371146202087402, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=8.681755530834199
Loss made of: CE 0.7527269124984741, LKD 4.5034637451171875, LDE 5.0084919929504395, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=8.323535573482513
Loss made of: CE 0.6241030693054199, LKD 3.450251340866089, LDE 4.207974433898926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.753687661886215
Loss made of: CE 0.5727393627166748, LKD 3.318181276321411, LDE 4.098750591278076, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=7.967407855391502
Loss made of: CE 0.530597448348999, LKD 3.5177674293518066, LDE 3.6329195499420166, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.976791501045227, Reg Loss=8.48083782196045
Clinet index 6, End of Epoch 1/6, Average Loss=9.457629203796387, Class Loss=0.976791501045227, Reg Loss=8.48083782196045
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/97, Loss=7.7926718384027485
Loss made of: CE 0.47641608119010925, LKD 3.4744999408721924, LDE 4.251258850097656, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=7.571506878733635
Loss made of: CE 0.5160537362098694, LKD 3.451530694961548, LDE 4.381678104400635, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=7.614242196083069
Loss made of: CE 0.4920130670070648, LKD 3.5408968925476074, LDE 3.6801111698150635, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=7.61602908372879
Loss made of: CE 0.4585443437099457, LKD 3.4916326999664307, LDE 3.126443862915039, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=7.863677084445953
Loss made of: CE 0.46917518973350525, LKD 3.1752214431762695, LDE 3.1109025478363037, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=7.651065078377724
Loss made of: CE 0.492992103099823, LKD 3.484570264816284, LDE 4.033271312713623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=7.347346141934395
Loss made of: CE 0.42204076051712036, LKD 3.329620599746704, LDE 3.7328202724456787, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=7.785607469081879
Loss made of: CE 0.44342300295829773, LKD 3.406118869781494, LDE 3.5409085750579834, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=8.00723139345646
Loss made of: CE 0.519049882888794, LKD 3.6260604858398438, LDE 3.245250940322876, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.49424469470977783, Reg Loss=7.17521333694458
Clinet index 6, End of Epoch 2/6, Average Loss=7.669457912445068, Class Loss=0.49424469470977783, Reg Loss=7.17521333694458
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/97, Loss=7.18167405128479
Loss made of: CE 0.4483938217163086, LKD 3.6190342903137207, LDE 2.9489784240722656, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=7.400225961208344
Loss made of: CE 0.465221643447876, LKD 3.0713818073272705, LDE 3.251370906829834, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=7.4266420066356655
Loss made of: CE 0.3429308831691742, LKD 3.4635753631591797, LDE 3.7410125732421875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=7.5581427931785585
Loss made of: CE 0.4446175992488861, LKD 3.431942939758301, LDE 3.0868663787841797, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=7.938575127720833
Loss made of: CE 0.4437992572784424, LKD 3.6516480445861816, LDE 3.3105697631835938, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=7.597716158628463
Loss made of: CE 0.5287401080131531, LKD 4.057296276092529, LDE 5.020656585693359, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=7.388940438628197
Loss made of: CE 0.465218722820282, LKD 3.7563488483428955, LDE 2.7718818187713623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=7.403821197152138
Loss made of: CE 0.42931804060935974, LKD 3.2373876571655273, LDE 3.5148091316223145, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=7.5957384437322615
Loss made of: CE 0.4254028797149658, LKD 2.978118896484375, LDE 3.1311213970184326, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4574030637741089, Reg Loss=7.041122913360596
Clinet index 6, End of Epoch 3/6, Average Loss=7.498526096343994, Class Loss=0.4574030637741089, Reg Loss=7.041122913360596
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/97, Loss=7.484935873746872
Loss made of: CE 0.4070611596107483, LKD 3.612196445465088, LDE 2.820528745651245, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=7.09575529396534
Loss made of: CE 0.424360990524292, LKD 3.4734721183776855, LDE 2.8979177474975586, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=6.967181786894798
Loss made of: CE 0.4117233157157898, LKD 4.309099197387695, LDE 2.6489202976226807, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=7.237359911203384
Loss made of: CE 0.4006617069244385, LKD 3.2637693881988525, LDE 4.210935592651367, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=7.218805918097496
Loss made of: CE 0.38551855087280273, LKD 3.0431292057037354, LDE 2.874041795730591, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=7.026201614737511
Loss made of: CE 0.4181106984615326, LKD 3.9976558685302734, LDE 3.307286262512207, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=6.920905616879463
Loss made of: CE 0.3718908727169037, LKD 3.4081199169158936, LDE 3.3435800075531006, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=7.593575966358185
Loss made of: CE 0.40380510687828064, LKD 3.106689453125, LDE 3.6487221717834473, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=7.093009707331658
Loss made of: CE 0.5111274123191833, LKD 3.9073545932769775, LDE 2.7140986919403076, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.44240066409111023, Reg Loss=6.7076873779296875
Clinet index 6, End of Epoch 4/6, Average Loss=7.150087833404541, Class Loss=0.44240066409111023, Reg Loss=6.7076873779296875
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/97, Loss=7.158200335502625
Loss made of: CE 0.45170098543167114, LKD 3.4780702590942383, LDE 2.7913763523101807, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=7.114280754327774
Loss made of: CE 0.4395166337490082, LKD 3.5047755241394043, LDE 3.3312253952026367, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=7.194329020380974
Loss made of: CE 0.4152795672416687, LKD 4.375247478485107, LDE 3.50793719291687, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=6.907053729891777
Loss made of: CE 0.40814492106437683, LKD 3.461825132369995, LDE 3.4195914268493652, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=7.203780797123909
Loss made of: CE 0.41344818472862244, LKD 3.5440146923065186, LDE 2.595935106277466, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=7.060563644766807
Loss made of: CE 0.35499823093414307, LKD 3.2419590950012207, LDE 2.924609661102295, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.984605967998505
Loss made of: CE 0.42509645223617554, LKD 3.717322587966919, LDE 2.913893461227417, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=7.2551598936319355
Loss made of: CE 0.35651683807373047, LKD 3.360196590423584, LDE 2.7653276920318604, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.9245971769094465
Loss made of: CE 0.4127347469329834, LKD 3.8909547328948975, LDE 2.5104336738586426, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4290039539337158, Reg Loss=6.659749984741211
Clinet index 6, End of Epoch 5/6, Average Loss=7.088753700256348, Class Loss=0.4290039539337158, Reg Loss=6.659749984741211
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/97, Loss=7.045363080501557
Loss made of: CE 0.3564731478691101, LKD 3.164137840270996, LDE 2.585543394088745, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.793544003367424
Loss made of: CE 0.38229984045028687, LKD 3.607178211212158, LDE 2.835171937942505, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=7.179342290759086
Loss made of: CE 0.4249367117881775, LKD 3.9050042629241943, LDE 3.0333032608032227, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=7.20084872841835
Loss made of: CE 0.39488404989242554, LKD 3.527085065841675, LDE 2.9869160652160645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=7.061816021800041
Loss made of: CE 0.40522950887680054, LKD 3.467433452606201, LDE 2.638256072998047, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=7.256381988525391
Loss made of: CE 0.402294397354126, LKD 3.577418565750122, LDE 3.5084002017974854, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.985746136307716
Loss made of: CE 0.4673026502132416, LKD 3.831148147583008, LDE 2.581132173538208, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=7.0515019476413725
Loss made of: CE 0.44051140546798706, LKD 3.2188143730163574, LDE 2.8107857704162598, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=7.0043893426656725
Loss made of: CE 0.4366207718849182, LKD 3.234879732131958, LDE 3.619846820831299, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.42243945598602295, Reg Loss=6.632154941558838
Clinet index 6, End of Epoch 6/6, Average Loss=7.05459451675415, Class Loss=0.42243945598602295, Reg Loss=6.632154941558838
federated aggregation...
Validation, Class Loss=0.8130200505256653, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.742671
Mean Acc: 0.269016
FreqW Acc: 0.618087
Mean IoU: 0.201948
Class IoU:
	class 0: 0.8243182
	class 1: 0.5241585
	class 2: 0.002973789
	class 3: 0.00022905521
	class 4: 0.5261306
	class 5: 0.07817847
	class 6: 0.4557018
	class 7: 0.5160827
	class 8: 0.0
	class 9: 0.018758914
	class 10: 0.0
	class 11: 4.3230728e-05
	class 12: 0.004578496
	class 13: 0.096798666
	class 14: 0.3290878
	class 15: 0.0012986329
	class 16: 0.054774586
Class Acc:
	class 0: 0.98084736
	class 1: 0.527278
	class 2: 0.0030088122
	class 3: 0.00022905521
	class 4: 0.55155015
	class 5: 0.07823208
	class 6: 0.45658705
	class 7: 0.5176578
	class 8: 0.0
	class 9: 0.01937651
	class 10: 0.0
	class 11: 4.323663e-05
	class 12: 0.004590501
	class 13: 0.7993048
	class 14: 0.57252485
	class 15: 0.0012987857
	class 16: 0.060741954

federated global round: 21, step: 4
select part of clients to conduct local training
[20, 2, 24, 4]
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=10.343803238868713
Loss made of: CE 0.8439791202545166, LKD 3.43810772895813, LDE 3.9633941650390625, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=8.673781198263168
Loss made of: CE 0.7526445388793945, LKD 3.979637384414673, LDE 3.646979808807373, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=8.327302438020705
Loss made of: CE 0.5098699331283569, LKD 3.5582199096679688, LDE 3.1799018383026123, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=8.155316704511643
Loss made of: CE 0.5659862756729126, LKD 3.739184856414795, LDE 2.8877463340759277, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=8.167788049578666
Loss made of: CE 0.6027287244796753, LKD 3.907813787460327, LDE 3.3850536346435547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=7.734817215800286
Loss made of: CE 0.43726786971092224, LKD 3.1401209831237793, LDE 3.6023383140563965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=7.99049337208271
Loss made of: CE 0.5829622745513916, LKD 3.6315717697143555, LDE 3.880974769592285, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.5319078236818315
Loss made of: CE 0.4668233394622803, LKD 3.2727625370025635, LDE 3.2357168197631836, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=7.532075974345207
Loss made of: CE 0.5325344204902649, LKD 4.621179103851318, LDE 3.0322587490081787, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.608275294303894, Reg Loss=7.604562282562256
Clinet index 20, End of Epoch 1/6, Average Loss=8.212837219238281, Class Loss=0.608275294303894, Reg Loss=7.604562282562256
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/97, Loss=7.242356291413307
Loss made of: CE 0.4581395983695984, LKD 3.340261459350586, LDE 4.608341217041016, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=7.313790625333786
Loss made of: CE 0.5286086797714233, LKD 4.426216125488281, LDE 3.3931984901428223, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=7.393895253539085
Loss made of: CE 0.5093019604682922, LKD 4.79296875, LDE 3.2599635124206543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=7.244213101267815
Loss made of: CE 0.49727970361709595, LKD 4.089560508728027, LDE 3.089749813079834, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=7.350543287396431
Loss made of: CE 0.4820067882537842, LKD 4.078714370727539, LDE 2.5068788528442383, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=7.488761538267136
Loss made of: CE 0.41500675678253174, LKD 3.201413154602051, LDE 3.175572395324707, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=7.711180949211121
Loss made of: CE 0.47298142313957214, LKD 3.2765395641326904, LDE 4.8126749992370605, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=7.2886223018169405
Loss made of: CE 0.45171475410461426, LKD 3.5099830627441406, LDE 3.2164323329925537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=7.009331533312798
Loss made of: CE 0.4204372763633728, LKD 3.829037666320801, LDE 2.828430652618408, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4619903564453125, Reg Loss=6.853050231933594
Clinet index 20, End of Epoch 2/6, Average Loss=7.315040588378906, Class Loss=0.4619903564453125, Reg Loss=6.853050231933594
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/97, Loss=7.401263767480851
Loss made of: CE 0.46625643968582153, LKD 3.3347244262695312, LDE 3.2877817153930664, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=7.297901254892349
Loss made of: CE 0.441666841506958, LKD 2.916992425918579, LDE 3.752471446990967, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=7.1869003683328625
Loss made of: CE 0.4464852213859558, LKD 3.7416703701019287, LDE 2.621920108795166, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=6.957065355777741
Loss made of: CE 0.3904169499874115, LKD 2.786935806274414, LDE 4.998821258544922, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=6.955727139115334
Loss made of: CE 0.35582876205444336, LKD 3.7611610889434814, LDE 2.7847890853881836, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=7.740391027927399
Loss made of: CE 0.422768771648407, LKD 4.184966564178467, LDE 2.7148079872131348, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=7.2376627057790754
Loss made of: CE 0.43552833795547485, LKD 3.2670981884002686, LDE 2.7112629413604736, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=7.0290958195924755
Loss made of: CE 0.41000258922576904, LKD 3.7450292110443115, LDE 2.6672708988189697, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=7.358149093389511
Loss made of: CE 0.46503299474716187, LKD 3.0203278064727783, LDE 2.642392158508301, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.44592422246932983, Reg Loss=6.789404392242432
Clinet index 20, End of Epoch 3/6, Average Loss=7.235328674316406, Class Loss=0.44592422246932983, Reg Loss=6.789404392242432
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/97, Loss=7.235784670710563
Loss made of: CE 0.475322961807251, LKD 4.118964672088623, LDE 3.2690179347991943, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=7.530515030026436
Loss made of: CE 0.4418291449546814, LKD 3.8680419921875, LDE 2.863456964492798, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=7.348585796356201
Loss made of: CE 0.3971545100212097, LKD 3.326406717300415, LDE 3.050950765609741, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=7.227140867710114
Loss made of: CE 0.4032263159751892, LKD 3.469644546508789, LDE 2.8545897006988525, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=6.9799968093633655
Loss made of: CE 0.40134209394454956, LKD 3.4311819076538086, LDE 3.1049184799194336, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.8923611521720884
Loss made of: CE 0.47387760877609253, LKD 3.599905490875244, LDE 2.8476080894470215, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=7.035973918437958
Loss made of: CE 0.3746599853038788, LKD 3.9305567741394043, LDE 3.649592876434326, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=7.147333070635796
Loss made of: CE 0.4068695902824402, LKD 2.90492582321167, LDE 3.2841219902038574, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=6.995120674371719
Loss made of: CE 0.4758675992488861, LKD 3.9437994956970215, LDE 3.2067816257476807, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4298131465911865, Reg Loss=6.66900634765625
Clinet index 20, End of Epoch 4/6, Average Loss=7.098819732666016, Class Loss=0.4298131465911865, Reg Loss=6.66900634765625
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/97, Loss=7.204523959755898
Loss made of: CE 0.4820738732814789, LKD 4.096217155456543, LDE 2.8468549251556396, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=7.1366339266300205
Loss made of: CE 0.41482433676719666, LKD 3.6828861236572266, LDE 3.3358824253082275, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=6.9157488465309145
Loss made of: CE 0.3872705399990082, LKD 3.2620272636413574, LDE 3.030914545059204, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=7.015526235103607
Loss made of: CE 0.3758111894130707, LKD 4.383273124694824, LDE 3.035841941833496, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=7.1684101819992065
Loss made of: CE 0.4789831042289734, LKD 4.312938690185547, LDE 2.9508516788482666, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=6.870056295394898
Loss made of: CE 0.4492151737213135, LKD 3.4206464290618896, LDE 2.7827625274658203, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=7.120521533489227
Loss made of: CE 0.42122769355773926, LKD 3.8107781410217285, LDE 2.485414981842041, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.797303861379623
Loss made of: CE 0.36003512144088745, LKD 3.1269333362579346, LDE 2.8786449432373047, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.951662701368332
Loss made of: CE 0.39820510149002075, LKD 3.3268749713897705, LDE 2.258875846862793, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.427626371383667, Reg Loss=6.589592456817627
Clinet index 20, End of Epoch 5/6, Average Loss=7.017218589782715, Class Loss=0.427626371383667, Reg Loss=6.589592456817627
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/97, Loss=6.69238657951355
Loss made of: CE 0.4294295012950897, LKD 3.2468180656433105, LDE 2.6638083457946777, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.973155426979065
Loss made of: CE 0.46456918120384216, LKD 3.895277261734009, LDE 2.9049429893493652, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.548684886097908
Loss made of: CE 0.3818082809448242, LKD 3.0192596912384033, LDE 3.0329864025115967, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.8323861956596375
Loss made of: CE 0.4274062514305115, LKD 3.777937650680542, LDE 2.7017440795898438, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=7.110891515016556
Loss made of: CE 0.337724894285202, LKD 3.2263240814208984, LDE 2.4337596893310547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.933144089579582
Loss made of: CE 0.4331350028514862, LKD 3.6419124603271484, LDE 2.881406784057617, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=7.097000932693481
Loss made of: CE 0.4540456235408783, LKD 3.3744797706604004, LDE 2.6925048828125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=7.033063128590584
Loss made of: CE 0.4604547917842865, LKD 3.980353355407715, LDE 3.4804024696350098, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.864095318317413
Loss made of: CE 0.4193190932273865, LKD 3.3255279064178467, LDE 2.3642961978912354, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.42246925830841064, Reg Loss=6.440406799316406
Clinet index 20, End of Epoch 6/6, Average Loss=6.862875938415527, Class Loss=0.42246925830841064, Reg Loss=6.440406799316406
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=8.251855117082595
Loss made of: CE 0.7659591436386108, LKD 3.849499225616455, LDE 3.313978433609009, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7036380767822266, Reg Loss=7.537134170532227
Clinet index 2, End of Epoch 1/6, Average Loss=8.240772247314453, Class Loss=0.7036380767822266, Reg Loss=7.537134170532227
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=7.873628556728363
Loss made of: CE 0.6735002398490906, LKD 3.3635876178741455, LDE 3.181981325149536, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6302647590637207, Reg Loss=7.180825710296631
Clinet index 2, End of Epoch 2/6, Average Loss=7.811090469360352, Class Loss=0.6302647590637207, Reg Loss=7.180825710296631
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=7.7144779622554776
Loss made of: CE 0.5739530324935913, LKD 3.4453206062316895, LDE 3.4325485229492188, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5651856660842896, Reg Loss=7.144327163696289
Clinet index 2, End of Epoch 3/6, Average Loss=7.709512710571289, Class Loss=0.5651856660842896, Reg Loss=7.144327163696289
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=7.528235700726509
Loss made of: CE 0.501329779624939, LKD 4.198024749755859, LDE 3.0523524284362793, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5482288599014282, Reg Loss=7.053756237030029
Clinet index 2, End of Epoch 4/6, Average Loss=7.601984977722168, Class Loss=0.5482288599014282, Reg Loss=7.053756237030029
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=7.376519322395325
Loss made of: CE 0.5462639331817627, LKD 4.094327449798584, LDE 3.2601747512817383, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.535353422164917, Reg Loss=6.836825847625732
Clinet index 2, End of Epoch 5/6, Average Loss=7.37217903137207, Class Loss=0.535353422164917, Reg Loss=6.836825847625732
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=7.654367935657501
Loss made of: CE 0.49299490451812744, LKD 4.056328296661377, LDE 3.2631452083587646, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5084967613220215, Reg Loss=7.197324752807617
Clinet index 2, End of Epoch 6/6, Average Loss=7.705821514129639, Class Loss=0.5084967613220215, Reg Loss=7.197324752807617
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=8.148649156093597
Loss made of: CE 0.6150612831115723, LKD 3.475297212600708, LDE 3.286921262741089, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.68243408203125, Reg Loss=7.517219066619873
Clinet index 24, End of Epoch 1/6, Average Loss=8.199653625488281, Class Loss=0.68243408203125, Reg Loss=7.517219066619873
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=7.82701521217823
Loss made of: CE 0.5835983753204346, LKD 4.0166802406311035, LDE 4.585992336273193, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.571759045124054, Reg Loss=7.199586391448975
Clinet index 24, End of Epoch 2/6, Average Loss=7.771345615386963, Class Loss=0.571759045124054, Reg Loss=7.199586391448975
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=7.378544574975967
Loss made of: CE 0.5365033149719238, LKD 3.82985520362854, LDE 3.876796245574951, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.537350058555603, Reg Loss=6.915902137756348
Clinet index 24, End of Epoch 3/6, Average Loss=7.45325231552124, Class Loss=0.537350058555603, Reg Loss=6.915902137756348
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=7.8477044075727465
Loss made of: CE 0.3810313642024994, LKD 2.8584930896759033, LDE 4.369361400604248, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5275832414627075, Reg Loss=7.251769065856934
Clinet index 24, End of Epoch 4/6, Average Loss=7.779352188110352, Class Loss=0.5275832414627075, Reg Loss=7.251769065856934
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=7.696230006217957
Loss made of: CE 0.4636093080043793, LKD 3.2290940284729004, LDE 3.754901170730591, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.49014198780059814, Reg Loss=7.109273433685303
Clinet index 24, End of Epoch 5/6, Average Loss=7.599415302276611, Class Loss=0.49014198780059814, Reg Loss=7.109273433685303
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Batch 10/12, Loss=7.657957309484482
Loss made of: CE 0.5551488399505615, LKD 3.0957720279693604, LDE 3.3754169940948486, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5053572654724121, Reg Loss=7.027329444885254
Clinet index 24, End of Epoch 6/6, Average Loss=7.532686710357666, Class Loss=0.5053572654724121, Reg Loss=7.027329444885254
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=7.9749518752098085
Loss made of: CE 0.6004064679145813, LKD 2.9109179973602295, LDE 3.897099256515503, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6941978931427002, Reg Loss=7.309247016906738
Clinet index 4, End of Epoch 1/6, Average Loss=8.00344467163086, Class Loss=0.6941978931427002, Reg Loss=7.309247016906738
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=7.877792608737946
Loss made of: CE 0.727860152721405, LKD 4.392066478729248, LDE 4.53629207611084, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6071271896362305, Reg Loss=7.301753997802734
Clinet index 4, End of Epoch 2/6, Average Loss=7.908881187438965, Class Loss=0.6071271896362305, Reg Loss=7.301753997802734
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=7.6757978856563565
Loss made of: CE 0.6361055970191956, LKD 3.6033458709716797, LDE 4.241164684295654, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5607291460037231, Reg Loss=7.172370433807373
Clinet index 4, End of Epoch 3/6, Average Loss=7.733099460601807, Class Loss=0.5607291460037231, Reg Loss=7.172370433807373
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=7.359804296493531
Loss made of: CE 0.6783997416496277, LKD 3.12955379486084, LDE 3.79099702835083, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5295936465263367, Reg Loss=6.926576614379883
Clinet index 4, End of Epoch 4/6, Average Loss=7.456170082092285, Class Loss=0.5295936465263367, Reg Loss=6.926576614379883
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=7.3080173343420025
Loss made of: CE 0.5029222965240479, LKD 3.761112689971924, LDE 3.736435651779175, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5209759473800659, Reg Loss=6.9579877853393555
Clinet index 4, End of Epoch 5/6, Average Loss=7.478963851928711, Class Loss=0.5209759473800659, Reg Loss=6.9579877853393555
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=7.027844956517219
Loss made of: CE 0.45733731985092163, LKD 3.0901710987091064, LDE 3.3637986183166504, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.49256157875061035, Reg Loss=6.714153289794922
Clinet index 4, End of Epoch 6/6, Average Loss=7.206714630126953, Class Loss=0.49256157875061035, Reg Loss=6.714153289794922
federated aggregation...
Validation, Class Loss=0.7490764260292053, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.778266
Mean Acc: 0.314232
FreqW Acc: 0.682062
Mean IoU: 0.234441
Class IoU:
	class 0: 0.8642784
	class 1: 0.47822505
	class 2: 0.00017408324
	class 3: 0.0
	class 4: 0.50144947
	class 5: 0.037141602
	class 6: 0.43710133
	class 7: 0.5367948
	class 8: 0.0
	class 9: 0.01664991
	class 10: 0.0
	class 11: 9.399267e-07
	class 12: 0.0035049901
	class 13: 0.10556601
	class 14: 0.36840367
	class 15: 0.5180443
	class 16: 0.11816652
Class Acc:
	class 0: 0.97232527
	class 1: 0.48085162
	class 2: 0.0001741642
	class 3: 0.0
	class 4: 0.5230859
	class 5: 0.03714454
	class 6: 0.43785882
	class 7: 0.5384975
	class 8: 0.0
	class 9: 0.01707684
	class 10: 0.0
	class 11: 9.399267e-07
	class 12: 0.0035102104
	class 13: 0.8239786
	class 14: 0.6285681
	class 15: 0.5751887
	class 16: 0.30367637

federated global round: 22, step: 4
select part of clients to conduct local training
[21, 0, 25, 23]
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=9.346217346191406
Loss made of: CE 0.6413880586624146, LKD 3.071687698364258, LDE 5.767614841461182, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=8.667308473587036
Loss made of: CE 0.6476876139640808, LKD 4.7361040115356445, LDE 3.9173147678375244, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=7.4306935399770735
Loss made of: CE 0.4312436580657959, LKD 2.8412883281707764, LDE 3.2732772827148438, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=7.488926333189011
Loss made of: CE 0.4575040936470032, LKD 3.8939754962921143, LDE 4.14568567276001, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=7.514859300851822
Loss made of: CE 0.4495354890823364, LKD 4.345378398895264, LDE 3.1811654567718506, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=7.51992826461792
Loss made of: CE 0.515243411064148, LKD 4.371817111968994, LDE 3.1903152465820312, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=7.49090892970562
Loss made of: CE 0.4342813491821289, LKD 2.7120893001556396, LDE 3.4247026443481445, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.011270439624786
Loss made of: CE 0.4275226294994354, LKD 4.325603485107422, LDE 3.064286708831787, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=7.44312998354435
Loss made of: CE 0.472745418548584, LKD 3.7835910320281982, LDE 2.864763021469116, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.49926838278770447, Reg Loss=7.234036922454834
Clinet index 21, End of Epoch 1/6, Average Loss=7.73330545425415, Class Loss=0.49926838278770447, Reg Loss=7.234036922454834
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=7.146922248601913
Loss made of: CE 0.4269251525402069, LKD 3.2340667247772217, LDE 3.060340642929077, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=7.200322046875954
Loss made of: CE 0.4964061677455902, LKD 4.106583595275879, LDE 2.7523012161254883, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=7.182742232084275
Loss made of: CE 0.44128522276878357, LKD 3.828662157058716, LDE 3.063678741455078, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=7.3859931290149685
Loss made of: CE 0.4190201461315155, LKD 3.046518087387085, LDE 2.6862528324127197, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=6.882807058095932
Loss made of: CE 0.4662033021450043, LKD 4.0754523277282715, LDE 2.6544933319091797, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=7.131310111284256
Loss made of: CE 0.4444260597229004, LKD 3.676352024078369, LDE 2.7371420860290527, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=6.839904898405075
Loss made of: CE 0.39312058687210083, LKD 4.201708793640137, LDE 2.9132182598114014, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=7.163210988044739
Loss made of: CE 0.4985625743865967, LKD 3.6014833450317383, LDE 3.4881577491760254, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=7.157896730303764
Loss made of: CE 0.46443819999694824, LKD 3.5021491050720215, LDE 2.763166904449463, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.44288551807403564, Reg Loss=6.679529190063477
Clinet index 21, End of Epoch 2/6, Average Loss=7.122414588928223, Class Loss=0.44288551807403564, Reg Loss=6.679529190063477
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=7.106330081820488
Loss made of: CE 0.45653241872787476, LKD 3.339931011199951, LDE 3.4790515899658203, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=7.086555829644203
Loss made of: CE 0.47470563650131226, LKD 3.7347614765167236, LDE 3.1879775524139404, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=6.780705198645592
Loss made of: CE 0.3625747561454773, LKD 2.911806583404541, LDE 2.60456919670105, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=6.578890550136566
Loss made of: CE 0.36226385831832886, LKD 3.665151357650757, LDE 2.653860569000244, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=7.129661363363266
Loss made of: CE 0.45842915773391724, LKD 3.6767489910125732, LDE 2.768923759460449, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=6.884464359283447
Loss made of: CE 0.4093264937400818, LKD 3.4000656604766846, LDE 2.7501041889190674, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=6.952478656172753
Loss made of: CE 0.4212944209575653, LKD 3.4100234508514404, LDE 2.870900869369507, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=7.094854599237442
Loss made of: CE 0.4730263352394104, LKD 3.2419183254241943, LDE 3.082219362258911, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=6.90423694550991
Loss made of: CE 0.4514351785182953, LKD 3.366485118865967, LDE 2.5446465015411377, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4280816912651062, Reg Loss=6.523311614990234
Clinet index 21, End of Epoch 3/6, Average Loss=6.951393127441406, Class Loss=0.4280816912651062, Reg Loss=6.523311614990234
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=7.334862142801285
Loss made of: CE 0.42948517203330994, LKD 4.376554489135742, LDE 2.9364287853240967, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=6.7820095986127855
Loss made of: CE 0.3598840832710266, LKD 3.5168285369873047, LDE 2.6625733375549316, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=7.266406762599945
Loss made of: CE 0.4097040295600891, LKD 2.997910976409912, LDE 3.1543776988983154, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=6.7621162921190265
Loss made of: CE 0.4119233787059784, LKD 3.336150646209717, LDE 2.7675492763519287, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=7.086826607584953
Loss made of: CE 0.4322468638420105, LKD 3.58921217918396, LDE 2.5651609897613525, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.959793424606323
Loss made of: CE 0.4618740677833557, LKD 3.1800317764282227, LDE 3.370051860809326, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=7.096709057688713
Loss made of: CE 0.42752885818481445, LKD 3.9019153118133545, LDE 2.832979440689087, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=7.0170011699199675
Loss made of: CE 0.3644983768463135, LKD 3.458831787109375, LDE 2.612517833709717, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=7.156526982784271
Loss made of: CE 0.5034528970718384, LKD 3.6812450885772705, LDE 2.810866117477417, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.42171964049339294, Reg Loss=6.618748188018799
Clinet index 21, End of Epoch 4/6, Average Loss=7.040467739105225, Class Loss=0.42171964049339294, Reg Loss=6.618748188018799
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=6.995956388115883
Loss made of: CE 0.42915159463882446, LKD 4.089012145996094, LDE 3.642484664916992, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=6.82904344201088
Loss made of: CE 0.4600076675415039, LKD 3.9080522060394287, LDE 3.082447052001953, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=6.813120889663696
Loss made of: CE 0.45378780364990234, LKD 3.4550905227661133, LDE 3.2337658405303955, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=7.139948335289955
Loss made of: CE 0.3410535752773285, LKD 2.9145076274871826, LDE 4.145900249481201, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=6.866396322846413
Loss made of: CE 0.4134089946746826, LKD 3.9210519790649414, LDE 2.714348316192627, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=6.989038974046707
Loss made of: CE 0.4380798935890198, LKD 3.8799450397491455, LDE 2.5725927352905273, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=7.1893850564956665
Loss made of: CE 0.43330222368240356, LKD 3.35583233833313, LDE 2.8172125816345215, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.843941789865494
Loss made of: CE 0.4190429449081421, LKD 3.6801702976226807, LDE 2.7387242317199707, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.92023486495018
Loss made of: CE 0.4242806136608124, LKD 3.7206225395202637, LDE 3.840947151184082, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4168330132961273, Reg Loss=6.515716075897217
Clinet index 21, End of Epoch 5/6, Average Loss=6.932548999786377, Class Loss=0.4168330132961273, Reg Loss=6.515716075897217
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=6.677247217297554
Loss made of: CE 0.36992010474205017, LKD 3.4064881801605225, LDE 2.7970757484436035, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.656897455453873
Loss made of: CE 0.4410277307033539, LKD 3.785229206085205, LDE 2.0413718223571777, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.921791809797287
Loss made of: CE 0.3958650827407837, LKD 3.3407225608825684, LDE 2.496035099029541, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.891161939501762
Loss made of: CE 0.4432011842727661, LKD 4.493551731109619, LDE 2.680145263671875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=6.682059893012047
Loss made of: CE 0.389382004737854, LKD 3.2179064750671387, LDE 2.827592134475708, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.847531458735466
Loss made of: CE 0.46568435430526733, LKD 4.276835918426514, LDE 3.487926721572876, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.521152609586716
Loss made of: CE 0.39131292700767517, LKD 3.459782600402832, LDE 2.3946688175201416, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=6.779961702227593
Loss made of: CE 0.42809760570526123, LKD 3.5450572967529297, LDE 2.775252342224121, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.707944375276566
Loss made of: CE 0.44666919112205505, LKD 3.7549397945404053, LDE 2.5200045108795166, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4076443314552307, Reg Loss=6.336454391479492
Clinet index 21, End of Epoch 6/6, Average Loss=6.744098663330078, Class Loss=0.4076443314552307, Reg Loss=6.336454391479492
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=8.61827620267868
Loss made of: CE 0.7442641258239746, LKD 3.164365530014038, LDE 4.618520259857178, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=8.013900914788247
Loss made of: CE 0.5471261739730835, LKD 3.6623387336730957, LDE 2.6526598930358887, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=7.588157272338867
Loss made of: CE 0.4701527953147888, LKD 3.675424337387085, LDE 3.0080151557922363, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=7.720232063531876
Loss made of: CE 0.467648983001709, LKD 3.503632068634033, LDE 4.746848106384277, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=7.2975961655378345
Loss made of: CE 0.5254796743392944, LKD 3.686323404312134, LDE 4.319746494293213, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=7.297033169865609
Loss made of: CE 0.44838541746139526, LKD 3.884209632873535, LDE 3.133990526199341, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=7.159234294295311
Loss made of: CE 0.48952919244766235, LKD 3.6500587463378906, LDE 4.067928791046143, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.17302385866642
Loss made of: CE 0.42487096786499023, LKD 3.313749313354492, LDE 2.849090576171875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=7.539551216363907
Loss made of: CE 0.41258344054222107, LKD 3.416637420654297, LDE 3.3945329189300537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4994944930076599, Reg Loss=7.05987024307251
Clinet index 0, End of Epoch 1/6, Average Loss=7.5593647956848145, Class Loss=0.4994944930076599, Reg Loss=7.05987024307251
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=7.397817558050155
Loss made of: CE 0.44757816195487976, LKD 3.124911069869995, LDE 2.7000620365142822, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=7.090222060680389
Loss made of: CE 0.4790896773338318, LKD 3.2789599895477295, LDE 2.9570629596710205, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=7.3169905751943585
Loss made of: CE 0.45083504915237427, LKD 3.466679096221924, LDE 2.359220027923584, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=7.080107793211937
Loss made of: CE 0.3719669282436371, LKD 3.376349449157715, LDE 2.9379775524139404, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=7.325036272406578
Loss made of: CE 0.41471466422080994, LKD 3.2640912532806396, LDE 2.9427132606506348, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=7.269933128356934
Loss made of: CE 0.47004103660583496, LKD 4.511866569519043, LDE 3.666261911392212, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=7.2664764553308485
Loss made of: CE 0.4561924934387207, LKD 3.7491137981414795, LDE 2.8471839427948, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=6.78213629424572
Loss made of: CE 0.3671172559261322, LKD 3.235790252685547, LDE 3.761817455291748, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=7.368972373008728
Loss made of: CE 0.4309176802635193, LKD 3.674252986907959, LDE 3.4796535968780518, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.43961840867996216, Reg Loss=6.731645107269287
Clinet index 0, End of Epoch 2/6, Average Loss=7.171263694763184, Class Loss=0.43961840867996216, Reg Loss=6.731645107269287
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=6.921038481593132
Loss made of: CE 0.4068478047847748, LKD 3.3285470008850098, LDE 2.441859245300293, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=6.962234008312225
Loss made of: CE 0.46429285407066345, LKD 4.1529130935668945, LDE 2.5113067626953125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=7.317435368895531
Loss made of: CE 0.4967152774333954, LKD 4.17578125, LDE 2.978397846221924, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=7.05960299372673
Loss made of: CE 0.4060835540294647, LKD 3.0869345664978027, LDE 2.9690239429473877, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=7.243256866931915
Loss made of: CE 0.4664946496486664, LKD 4.44114351272583, LDE 3.709733486175537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=7.3720200806856155
Loss made of: CE 0.432403028011322, LKD 3.4137494564056396, LDE 3.0644123554229736, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=7.08889202773571
Loss made of: CE 0.41034406423568726, LKD 4.128915309906006, LDE 2.6669507026672363, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=7.229063108563423
Loss made of: CE 0.4257071912288666, LKD 3.7715976238250732, LDE 2.241351366043091, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=6.931778880953789
Loss made of: CE 0.40883493423461914, LKD 3.4483578205108643, LDE 2.6317522525787354, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4270898401737213, Reg Loss=6.712771415710449
Clinet index 0, End of Epoch 3/6, Average Loss=7.139861106872559, Class Loss=0.4270898401737213, Reg Loss=6.712771415710449
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=6.615190774202347
Loss made of: CE 0.3539451062679291, LKD 3.295565366744995, LDE 2.518500328063965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=7.031372252106666
Loss made of: CE 0.4773455560207367, LKD 3.916478157043457, LDE 3.160245418548584, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=7.220043617486954
Loss made of: CE 0.43242210149765015, LKD 3.9630048274993896, LDE 2.5713493824005127, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=7.070343893766403
Loss made of: CE 0.43422040343284607, LKD 4.289829730987549, LDE 2.48769211769104, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=6.921939036250114
Loss made of: CE 0.4199702739715576, LKD 3.283374786376953, LDE 3.584728717803955, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.63470843732357
Loss made of: CE 0.4247432351112366, LKD 3.854072093963623, LDE 2.98754620552063, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=6.726939830183983
Loss made of: CE 0.37790530920028687, LKD 3.737027645111084, LDE 2.906682014465332, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=6.5412227600812916
Loss made of: CE 0.432388037443161, LKD 3.9991047382354736, LDE 2.282503128051758, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=7.052449890971184
Loss made of: CE 0.38066333532333374, LKD 3.9184834957122803, LDE 2.4412007331848145, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41741377115249634, Reg Loss=6.480046272277832
Clinet index 0, End of Epoch 4/6, Average Loss=6.897459983825684, Class Loss=0.41741377115249634, Reg Loss=6.480046272277832
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=6.708726140856743
Loss made of: CE 0.5039914846420288, LKD 4.417394638061523, LDE 3.484123945236206, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=6.991430556774139
Loss made of: CE 0.3692108988761902, LKD 3.079813241958618, LDE 2.770848512649536, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=6.787402182817459
Loss made of: CE 0.2882377505302429, LKD 2.8849332332611084, LDE 2.8373892307281494, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=7.091495150327683
Loss made of: CE 0.44361385703086853, LKD 3.735588550567627, LDE 3.184662342071533, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=6.579389014840126
Loss made of: CE 0.3730241656303406, LKD 3.5403363704681396, LDE 2.5367465019226074, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=6.914620423316956
Loss made of: CE 0.42422744631767273, LKD 3.279838800430298, LDE 3.683013439178467, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.900048047304153
Loss made of: CE 0.39732784032821655, LKD 4.03939151763916, LDE 2.2476234436035156, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.748135808110237
Loss made of: CE 0.38718995451927185, LKD 3.219085931777954, LDE 2.142946243286133, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.6589368224143985
Loss made of: CE 0.4075445830821991, LKD 3.066004753112793, LDE 2.8111071586608887, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.41705572605133057, Reg Loss=6.40912389755249
Clinet index 0, End of Epoch 5/6, Average Loss=6.826179504394531, Class Loss=0.41705572605133057, Reg Loss=6.40912389755249
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=6.411357980966568
Loss made of: CE 0.39423656463623047, LKD 4.007866382598877, LDE 2.287916421890259, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.895085495710373
Loss made of: CE 0.35560524463653564, LKD 2.991179943084717, LDE 2.248913526535034, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.9498458951711655
Loss made of: CE 0.44389602541923523, LKD 3.9136149883270264, LDE 3.0225212574005127, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.898481169342995
Loss made of: CE 0.39418572187423706, LKD 3.3303980827331543, LDE 2.427699327468872, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=7.0395988583564755
Loss made of: CE 0.4525338113307953, LKD 3.0068438053131104, LDE 2.5922656059265137, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=7.1708883315324785
Loss made of: CE 0.357893705368042, LKD 2.8626513481140137, LDE 2.495053291320801, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.510894557833671
Loss made of: CE 0.40280911326408386, LKD 3.3451199531555176, LDE 3.0066049098968506, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=7.060729667544365
Loss made of: CE 0.3866313397884369, LKD 3.3742871284484863, LDE 3.139693260192871, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.7575295805931095
Loss made of: CE 0.42082127928733826, LKD 3.1521060466766357, LDE 2.795076847076416, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4100334644317627, Reg Loss=6.462513446807861
Clinet index 0, End of Epoch 6/6, Average Loss=6.872547149658203, Class Loss=0.4100334644317627, Reg Loss=6.462513446807861
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=9.187701559066772
Loss made of: CE 0.6209153532981873, LKD 3.8002755641937256, LDE 4.030457973480225, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=8.270138049125672
Loss made of: CE 0.5872020721435547, LKD 3.9823334217071533, LDE 4.126507759094238, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=7.753126114606857
Loss made of: CE 0.4101375341415405, LKD 4.0673041343688965, LDE 3.2479026317596436, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=7.692313605546952
Loss made of: CE 0.5139784216880798, LKD 4.191513538360596, LDE 3.0523314476013184, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=7.423100087046623
Loss made of: CE 0.5389841794967651, LKD 3.45035982131958, LDE 2.6821188926696777, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=7.688829493522644
Loss made of: CE 0.45177626609802246, LKD 3.633598566055298, LDE 3.2370545864105225, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=7.370626583695412
Loss made of: CE 0.40681061148643494, LKD 3.431042194366455, LDE 3.0832555294036865, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.404163146018982
Loss made of: CE 0.4641730785369873, LKD 3.4970388412475586, LDE 3.58854603767395, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=7.237274575233459
Loss made of: CE 0.4378642439842224, LKD 3.4502341747283936, LDE 2.9707393646240234, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5117390155792236, Reg Loss=7.204436779022217
Clinet index 25, End of Epoch 1/6, Average Loss=7.7161760330200195, Class Loss=0.5117390155792236, Reg Loss=7.204436779022217
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=7.269314226508141
Loss made of: CE 0.500676155090332, LKD 3.8765065670013428, LDE 3.087580680847168, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=7.2299585282802585
Loss made of: CE 0.454070508480072, LKD 3.891249656677246, LDE 2.7011449337005615, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=7.250527641177177
Loss made of: CE 0.4885656237602234, LKD 4.215482711791992, LDE 2.6440269947052, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=7.54529078900814
Loss made of: CE 0.500409722328186, LKD 4.198889255523682, LDE 3.260545492172241, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=7.056749641895294
Loss made of: CE 0.4400608241558075, LKD 3.405571699142456, LDE 2.7379539012908936, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=7.336498552560807
Loss made of: CE 0.4714040756225586, LKD 3.5951573848724365, LDE 3.524628162384033, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=6.88287428021431
Loss made of: CE 0.5104947090148926, LKD 3.892200469970703, LDE 3.4093358516693115, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=7.288602021336556
Loss made of: CE 0.4300936162471771, LKD 3.7060275077819824, LDE 2.521937847137451, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=7.119691786170006
Loss made of: CE 0.4912603795528412, LKD 3.425172805786133, LDE 3.0526022911071777, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.45218661427497864, Reg Loss=6.738921642303467
Clinet index 25, End of Epoch 2/6, Average Loss=7.191108226776123, Class Loss=0.45218661427497864, Reg Loss=6.738921642303467
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=6.768092882633209
Loss made of: CE 0.3898746371269226, LKD 3.0202105045318604, LDE 3.089350461959839, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=7.2140061289072035
Loss made of: CE 0.5137525796890259, LKD 3.727830171585083, LDE 3.0546875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=6.953930595517159
Loss made of: CE 0.4499623775482178, LKD 3.530999183654785, LDE 2.476475477218628, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=7.122652497887612
Loss made of: CE 0.41393083333969116, LKD 3.6559202671051025, LDE 4.006466865539551, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=7.541036373376846
Loss made of: CE 0.40356749296188354, LKD 4.345991611480713, LDE 3.7713043689727783, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=6.885336181521415
Loss made of: CE 0.4684332311153412, LKD 3.2383337020874023, LDE 2.6986756324768066, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=6.925909748673439
Loss made of: CE 0.4578876197338104, LKD 3.3621816635131836, LDE 2.8730597496032715, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=7.29365399479866
Loss made of: CE 0.40802428126335144, LKD 3.446876287460327, LDE 3.24660325050354, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=7.0046336382627485
Loss made of: CE 0.39160817861557007, LKD 3.3292160034179688, LDE 2.808321237564087, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.43055441975593567, Reg Loss=6.662548542022705
Clinet index 25, End of Epoch 3/6, Average Loss=7.093102931976318, Class Loss=0.43055441975593567, Reg Loss=6.662548542022705
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=6.945165455341339
Loss made of: CE 0.3881504535675049, LKD 3.7998058795928955, LDE 2.870288133621216, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=7.2028209418058395
Loss made of: CE 0.471362829208374, LKD 3.4092884063720703, LDE 3.527360439300537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=6.954189494252205
Loss made of: CE 0.40667054057121277, LKD 3.403592824935913, LDE 3.24674916267395, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=6.851721212267876
Loss made of: CE 0.37496674060821533, LKD 3.0403316020965576, LDE 2.6662042140960693, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=7.2225891828536986
Loss made of: CE 0.4626966416835785, LKD 3.3985581398010254, LDE 4.6272406578063965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=7.827627393603325
Loss made of: CE 0.4055609405040741, LKD 3.947840929031372, LDE 4.215905666351318, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=7.116106939315796
Loss made of: CE 0.42676401138305664, LKD 4.421743869781494, LDE 2.667961597442627, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=6.75753208398819
Loss made of: CE 0.44108980894088745, LKD 3.7919983863830566, LDE 2.3867313861846924, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=6.784549108147621
Loss made of: CE 0.327502965927124, LKD 3.0547962188720703, LDE 2.7968902587890625, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.42899027466773987, Reg Loss=6.6469197273254395
Clinet index 25, End of Epoch 4/6, Average Loss=7.0759100914001465, Class Loss=0.42899027466773987, Reg Loss=6.6469197273254395
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=6.819520679116249
Loss made of: CE 0.4388121962547302, LKD 3.2166268825531006, LDE 2.650707244873047, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=6.8106238573789595
Loss made of: CE 0.43624347448349, LKD 4.285811424255371, LDE 2.2427785396575928, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=7.273348408937454
Loss made of: CE 0.43015190958976746, LKD 3.728921413421631, LDE 2.941781759262085, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=6.975641763210296
Loss made of: CE 0.3297805190086365, LKD 3.313462734222412, LDE 3.533411741256714, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=6.839793145656586
Loss made of: CE 0.39980894327163696, LKD 3.636326313018799, LDE 2.557826042175293, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=7.0255284160375595
Loss made of: CE 0.4579956531524658, LKD 4.026322841644287, LDE 2.949985980987549, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.6300578117370605
Loss made of: CE 0.4767141044139862, LKD 4.300296306610107, LDE 2.5102481842041016, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.615544033050537
Loss made of: CE 0.3432670831680298, LKD 3.089517831802368, LDE 2.83634614944458, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.9448828279972075
Loss made of: CE 0.4632543921470642, LKD 3.2679450511932373, LDE 3.353890895843506, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4225400686264038, Reg Loss=6.5024285316467285
Clinet index 25, End of Epoch 5/6, Average Loss=6.924968719482422, Class Loss=0.4225400686264038, Reg Loss=6.5024285316467285
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=6.820037090778351
Loss made of: CE 0.46563929319381714, LKD 4.1512675285339355, LDE 2.578251600265503, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.790192320942879
Loss made of: CE 0.4628453850746155, LKD 3.772995710372925, LDE 2.2368109226226807, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.69383879005909
Loss made of: CE 0.35161179304122925, LKD 3.359567403793335, LDE 2.5614664554595947, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.500817432999611
Loss made of: CE 0.3418925702571869, LKD 3.637836217880249, LDE 2.6403586864471436, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=6.816323110461235
Loss made of: CE 0.33734768629074097, LKD 3.141307830810547, LDE 2.982320547103882, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.6852740287780765
Loss made of: CE 0.47286590933799744, LKD 4.053559303283691, LDE 2.7551910877227783, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.62955838739872
Loss made of: CE 0.44122666120529175, LKD 3.424117088317871, LDE 2.3640222549438477, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=6.673473498225212
Loss made of: CE 0.4364006519317627, LKD 4.639488220214844, LDE 3.014665365219116, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.617112049460411
Loss made of: CE 0.4251219928264618, LKD 3.4526607990264893, LDE 2.8195767402648926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.41952165961265564, Reg Loss=6.284751892089844
Clinet index 25, End of Epoch 6/6, Average Loss=6.704273700714111, Class Loss=0.41952165961265564, Reg Loss=6.284751892089844
Current Client Index:  23
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=9.94511806666851
Loss made of: CE 0.4750405251979828, LKD 3.878776788711548, LDE 5.186788558959961, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=7.8911456048488615
Loss made of: CE 0.4630574584007263, LKD 3.514707088470459, LDE 3.307741165161133, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=7.324752050638199
Loss made of: CE 0.4914833903312683, LKD 3.4007058143615723, LDE 3.468454599380493, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=7.64635511636734
Loss made of: CE 0.4912813603878021, LKD 3.860062837600708, LDE 4.024838447570801, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=7.379733601212502
Loss made of: CE 0.41190260648727417, LKD 3.298797369003296, LDE 3.519339084625244, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=7.180272951722145
Loss made of: CE 0.4487226903438568, LKD 3.2885167598724365, LDE 3.1812338829040527, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=7.23391126692295
Loss made of: CE 0.4581185579299927, LKD 3.548851490020752, LDE 3.0959856510162354, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.276594799757004
Loss made of: CE 0.46714144945144653, LKD 3.787458658218384, LDE 3.353822946548462, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=7.451415607333184
Loss made of: CE 0.4696297347545624, LKD 4.06358003616333, LDE 2.6019585132598877, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4953794479370117, Reg Loss=7.160149574279785
Clinet index 23, End of Epoch 1/6, Average Loss=7.655529022216797, Class Loss=0.4953794479370117, Reg Loss=7.160149574279785
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=6.9874099642038345
Loss made of: CE 0.3923015594482422, LKD 4.835907459259033, LDE 3.488948106765747, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=7.299542894959449
Loss made of: CE 0.4628724455833435, LKD 4.309026718139648, LDE 3.5584330558776855, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=6.855378594994545
Loss made of: CE 0.4223373532295227, LKD 3.285083293914795, LDE 2.698890209197998, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=7.352615520358086
Loss made of: CE 0.482024610042572, LKD 4.141263961791992, LDE 4.063364505767822, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=7.239508059620857
Loss made of: CE 0.4581199884414673, LKD 4.0955424308776855, LDE 3.0353095531463623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=7.189213851094246
Loss made of: CE 0.4757033586502075, LKD 3.771047353744507, LDE 2.9528112411499023, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=7.052993988990783
Loss made of: CE 0.3959086835384369, LKD 3.34702205657959, LDE 3.490882635116577, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=7.398553258180618
Loss made of: CE 0.413222074508667, LKD 3.378736972808838, LDE 3.0392940044403076, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=7.338222452998162
Loss made of: CE 0.4439705014228821, LKD 3.2319791316986084, LDE 3.8612172603607178, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4380338490009308, Reg Loss=6.734240531921387
Clinet index 23, End of Epoch 2/6, Average Loss=7.172274589538574, Class Loss=0.4380338490009308, Reg Loss=6.734240531921387
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=6.948793837428093
Loss made of: CE 0.4043203294277191, LKD 3.3054492473602295, LDE 2.684415578842163, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=7.097724774479866
Loss made of: CE 0.5226256847381592, LKD 3.6880156993865967, LDE 3.8578081130981445, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=7.396962910890579
Loss made of: CE 0.49601590633392334, LKD 3.512267827987671, LDE 2.931319236755371, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=6.89360223710537
Loss made of: CE 0.44290482997894287, LKD 3.037233591079712, LDE 3.207545042037964, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=6.883731973171234
Loss made of: CE 0.4103466868400574, LKD 4.030883312225342, LDE 3.439777374267578, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=7.117905914783478
Loss made of: CE 0.43067294359207153, LKD 3.832963466644287, LDE 2.7237281799316406, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=6.753180688619613
Loss made of: CE 0.46162542700767517, LKD 4.059530258178711, LDE 3.0172040462493896, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=6.767286106944084
Loss made of: CE 0.5034162998199463, LKD 4.193655967712402, LDE 3.060837745666504, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=7.36072014272213
Loss made of: CE 0.38022512197494507, LKD 2.8475677967071533, LDE 3.6937899589538574, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4262598752975464, Reg Loss=6.599587917327881
Clinet index 23, End of Epoch 3/6, Average Loss=7.025847911834717, Class Loss=0.4262598752975464, Reg Loss=6.599587917327881
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=7.04038265645504
Loss made of: CE 0.3849292993545532, LKD 3.6742589473724365, LDE 2.703016996383667, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=7.24418531358242
Loss made of: CE 0.43244630098342896, LKD 4.414877414703369, LDE 2.989370822906494, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=6.736643904447556
Loss made of: CE 0.43547695875167847, LKD 3.1157186031341553, LDE 3.2775990962982178, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=7.141647845506668
Loss made of: CE 0.45580586791038513, LKD 3.2289459705352783, LDE 2.7764785289764404, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=7.047838568687439
Loss made of: CE 0.4069691598415375, LKD 3.210003614425659, LDE 2.7764899730682373, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.761960795521736
Loss made of: CE 0.4827573299407959, LKD 3.5986673831939697, LDE 2.936474084854126, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=6.904070970416069
Loss made of: CE 0.349029541015625, LKD 3.0946812629699707, LDE 2.4899418354034424, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=7.136778700351715
Loss made of: CE 0.3691411018371582, LKD 3.9592902660369873, LDE 2.449235200881958, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=6.752471402287483
Loss made of: CE 0.4193410277366638, LKD 3.574723720550537, LDE 2.8849756717681885, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41696402430534363, Reg Loss=6.540773868560791
Clinet index 23, End of Epoch 4/6, Average Loss=6.957737922668457, Class Loss=0.41696402430534363, Reg Loss=6.540773868560791
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=6.923768535256386
Loss made of: CE 0.41214072704315186, LKD 3.6477699279785156, LDE 2.5481953620910645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=7.03196322619915
Loss made of: CE 0.47936344146728516, LKD 4.315864086151123, LDE 3.0287790298461914, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=7.236622360348702
Loss made of: CE 0.4825868010520935, LKD 3.5259881019592285, LDE 2.656761407852173, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=6.783577325940132
Loss made of: CE 0.36943674087524414, LKD 3.198270559310913, LDE 3.0900051593780518, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=6.389730316400528
Loss made of: CE 0.37167495489120483, LKD 3.3202669620513916, LDE 2.7852063179016113, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=6.6200125426054
Loss made of: CE 0.38382577896118164, LKD 3.5059497356414795, LDE 2.371155023574829, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.758933442831039
Loss made of: CE 0.4137611389160156, LKD 3.5517354011535645, LDE 2.1309566497802734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.488636839389801
Loss made of: CE 0.41704100370407104, LKD 3.355593204498291, LDE 3.0037217140197754, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.861966076493263
Loss made of: CE 0.38908058404922485, LKD 3.6397290229797363, LDE 2.9742329120635986, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.41243013739585876, Reg Loss=6.390726566314697
Clinet index 23, End of Epoch 5/6, Average Loss=6.803156852722168, Class Loss=0.41243013739585876, Reg Loss=6.390726566314697
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=6.715856748819351
Loss made of: CE 0.3936413526535034, LKD 3.297976016998291, LDE 2.4915947914123535, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=7.187344133853912
Loss made of: CE 0.3917521834373474, LKD 3.6061718463897705, LDE 2.4922473430633545, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.879946678876877
Loss made of: CE 0.3919474482536316, LKD 3.4231655597686768, LDE 2.5431900024414062, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.78016896545887
Loss made of: CE 0.36122795939445496, LKD 3.437073230743408, LDE 2.2718517780303955, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=6.898365363478661
Loss made of: CE 0.36376136541366577, LKD 3.509765863418579, LDE 2.7557997703552246, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.4142176628112795
Loss made of: CE 0.4087126851081848, LKD 3.436464548110962, LDE 2.7477011680603027, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.992836412787438
Loss made of: CE 0.5059431195259094, LKD 4.250545024871826, LDE 2.4860780239105225, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=6.536534938216209
Loss made of: CE 0.3177197277545929, LKD 2.9117684364318848, LDE 2.985299825668335, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.8577431589365005
Loss made of: CE 0.43339842557907104, LKD 4.04808235168457, LDE 2.7371761798858643, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4114619195461273, Reg Loss=6.379875659942627
Clinet index 23, End of Epoch 6/6, Average Loss=6.791337490081787, Class Loss=0.4114619195461273, Reg Loss=6.379875659942627
federated aggregation...
Validation, Class Loss=0.7530986070632935, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.780775
Mean Acc: 0.283844
FreqW Acc: 0.693732
Mean IoU: 0.200204
Class IoU:
	class 0: 0.884299
	class 1: 0.21172021
	class 2: 0.0
	class 3: 0.0
	class 4: 0.49544242
	class 5: 0.007614157
	class 6: 0.16991921
	class 7: 0.49150148
	class 8: 0.0
	class 9: 0.019229628
	class 10: 0.0
	class 11: 1.1749015e-06
	class 12: 0.002499426
	class 13: 0.10093479
	class 14: 0.36839098
	class 15: 0.6519125
	class 16: 0.0
Class Acc:
	class 0: 0.9620434
	class 1: 0.21208142
	class 2: 0.0
	class 3: 0.0
	class 4: 0.5199632
	class 5: 0.007614166
	class 6: 0.1700278
	class 7: 0.4929933
	class 8: 0.0
	class 9: 0.019804364
	class 10: 0.0
	class 11: 1.1749083e-06
	class 12: 0.0025051772
	class 13: 0.89492667
	class 14: 0.66716325
	class 15: 0.87623155
	class 16: 0.0

federated global round: 23, step: 4
select part of clients to conduct local training
[17, 3, 5, 22]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=6.784859603643417
Loss made of: CE 0.41610845923423767, LKD 2.845391273498535, LDE 2.702601671218872, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=6.65655432343483
Loss made of: CE 0.4235090911388397, LKD 3.8904361724853516, LDE 2.1619691848754883, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=6.981920942664146
Loss made of: CE 0.43923062086105347, LKD 4.269730091094971, LDE 2.508175849914551, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=6.9412806123495105
Loss made of: CE 0.4532334804534912, LKD 3.4351046085357666, LDE 2.3075039386749268, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=6.828305056691169
Loss made of: CE 0.37898606061935425, LKD 3.5490944385528564, LDE 2.1238393783569336, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=6.76553047299385
Loss made of: CE 0.40414631366729736, LKD 3.66443133354187, LDE 2.712967872619629, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=6.619358533620835
Loss made of: CE 0.31201666593551636, LKD 3.2900657653808594, LDE 2.7697672843933105, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=6.984740427136421
Loss made of: CE 0.4120301604270935, LKD 3.771780014038086, LDE 2.7097489833831787, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=6.679415827989578
Loss made of: CE 0.4091639518737793, LKD 3.3928751945495605, LDE 2.5790586471557617, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.410539835691452, Reg Loss=6.38478946685791
Clinet index 17, End of Epoch 1/6, Average Loss=6.7953290939331055, Class Loss=0.410539835691452, Reg Loss=6.38478946685791
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=6.3448015481233595
Loss made of: CE 0.294175922870636, LKD 3.693380117416382, LDE 3.1582958698272705, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=6.697571471333504
Loss made of: CE 0.39255452156066895, LKD 4.0048980712890625, LDE 2.1685986518859863, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=7.019105526804924
Loss made of: CE 0.41538238525390625, LKD 4.915090560913086, LDE 2.786543607711792, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=6.816112196445465
Loss made of: CE 0.3909214735031128, LKD 3.867824077606201, LDE 2.4492738246917725, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=6.463251164555549
Loss made of: CE 0.43928617238998413, LKD 3.481790542602539, LDE 2.664808511734009, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=6.777595093846321
Loss made of: CE 0.4144640862941742, LKD 3.4786787033081055, LDE 3.0980184078216553, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=7.189944159984589
Loss made of: CE 0.4677242934703827, LKD 4.0641961097717285, LDE 2.4012951850891113, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=6.8112339794635774
Loss made of: CE 0.40769335627555847, LKD 4.080026626586914, LDE 2.562774419784546, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=6.333732622861862
Loss made of: CE 0.34128281474113464, LKD 3.0658020973205566, LDE 2.2466256618499756, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4014325439929962, Reg Loss=6.321891784667969
Clinet index 17, End of Epoch 2/6, Average Loss=6.723324298858643, Class Loss=0.4014325439929962, Reg Loss=6.321891784667969
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=6.770726570487023
Loss made of: CE 0.36902427673339844, LKD 3.7645421028137207, LDE 2.566082715988159, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=6.914285245537758
Loss made of: CE 0.4157359004020691, LKD 3.74107027053833, LDE 4.013741970062256, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=6.727627405524254
Loss made of: CE 0.3932027518749237, LKD 3.728921413421631, LDE 2.2975375652313232, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=6.899269181489944
Loss made of: CE 0.5086047649383545, LKD 4.025668621063232, LDE 2.517622709274292, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=6.642853391170502
Loss made of: CE 0.43258413672447205, LKD 3.4556283950805664, LDE 2.602027416229248, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=6.787576520442963
Loss made of: CE 0.3537193536758423, LKD 3.1846723556518555, LDE 2.97349214553833, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=6.768451234698295
Loss made of: CE 0.4441169202327728, LKD 3.38508939743042, LDE 2.8664469718933105, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=6.492675733566284
Loss made of: CE 0.4097867012023926, LKD 3.9215095043182373, LDE 2.628603935241699, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=6.713965535163879
Loss made of: CE 0.41859686374664307, LKD 3.752969980239868, LDE 2.438084363937378, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4027046263217926, Reg Loss=6.37036657333374
Clinet index 17, End of Epoch 3/6, Average Loss=6.7730712890625, Class Loss=0.4027046263217926, Reg Loss=6.37036657333374
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=6.387145680189133
Loss made of: CE 0.4562253952026367, LKD 3.9842188358306885, LDE 2.644061803817749, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=7.0626368671655655
Loss made of: CE 0.4371975064277649, LKD 3.5104897022247314, LDE 3.2998039722442627, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=6.592439684271812
Loss made of: CE 0.4273468255996704, LKD 3.397268056869507, LDE 3.379037857055664, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=6.649948433041573
Loss made of: CE 0.44771814346313477, LKD 4.6166863441467285, LDE 2.4558846950531006, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=6.926171910762787
Loss made of: CE 0.3651880919933319, LKD 2.8361623287200928, LDE 2.667571544647217, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.880790144205093
Loss made of: CE 0.4109240472316742, LKD 4.203237056732178, LDE 3.049351215362549, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=6.7099525958299635
Loss made of: CE 0.4850824475288391, LKD 4.277613639831543, LDE 2.336505889892578, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=6.691226553916931
Loss made of: CE 0.3755537271499634, LKD 3.6173815727233887, LDE 2.65516996383667, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=6.521534541249276
Loss made of: CE 0.4335901737213135, LKD 3.9222445487976074, LDE 2.4507789611816406, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4006842374801636, Reg Loss=6.295014381408691
Clinet index 17, End of Epoch 4/6, Average Loss=6.6956987380981445, Class Loss=0.4006842374801636, Reg Loss=6.295014381408691
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=6.267823475599289
Loss made of: CE 0.352298378944397, LKD 2.9428353309631348, LDE 2.6037354469299316, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=6.68769249022007
Loss made of: CE 0.42057347297668457, LKD 3.883422613143921, LDE 3.060126781463623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=6.982124680280686
Loss made of: CE 0.4288729429244995, LKD 3.9401979446411133, LDE 3.2597548961639404, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=6.806237897276878
Loss made of: CE 0.38274115324020386, LKD 3.510422945022583, LDE 3.0628414154052734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=7.160864627361297
Loss made of: CE 0.42100274562835693, LKD 3.994743585586548, LDE 2.778766393661499, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=6.7313536465168
Loss made of: CE 0.43313246965408325, LKD 4.025008678436279, LDE 2.6989660263061523, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.849694249033928
Loss made of: CE 0.4130999743938446, LKD 3.095533609390259, LDE 3.4063234329223633, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.756313934922218
Loss made of: CE 0.37245988845825195, LKD 3.243792772293091, LDE 2.8083584308624268, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.68550126850605
Loss made of: CE 0.43903350830078125, LKD 3.668351888656616, LDE 3.2401838302612305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39945700764656067, Reg Loss=6.365218639373779
Clinet index 17, End of Epoch 5/6, Average Loss=6.764675617218018, Class Loss=0.39945700764656067, Reg Loss=6.365218639373779
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=6.7261497467756275
Loss made of: CE 0.3655116558074951, LKD 4.011119842529297, LDE 3.2897801399230957, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.563899424672127
Loss made of: CE 0.4024471640586853, LKD 3.579099178314209, LDE 2.095724582672119, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.372348701953888
Loss made of: CE 0.37668758630752563, LKD 3.7188515663146973, LDE 2.3446884155273438, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.684057721495629
Loss made of: CE 0.42139431834220886, LKD 3.74075984954834, LDE 2.188511848449707, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=6.586423143744469
Loss made of: CE 0.34465211629867554, LKD 3.5564136505126953, LDE 3.0597712993621826, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.905953669548035
Loss made of: CE 0.3263121247291565, LKD 2.909158706665039, LDE 2.821727752685547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.442339155077934
Loss made of: CE 0.3954894542694092, LKD 2.740356922149658, LDE 2.2197585105895996, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=6.66416275203228
Loss made of: CE 0.37317997217178345, LKD 4.041936874389648, LDE 2.3085832595825195, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.6579345792531965
Loss made of: CE 0.37454313039779663, LKD 3.4554195404052734, LDE 2.8695333003997803, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.39660462737083435, Reg Loss=6.2684807777404785
Clinet index 17, End of Epoch 6/6, Average Loss=6.665085315704346, Class Loss=0.39660462737083435, Reg Loss=6.2684807777404785
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=11.052629202604294
Loss made of: CE 0.6724678874015808, LKD 3.0887162685394287, LDE 5.657577037811279, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9037365913391113, Reg Loss=9.868083953857422
Clinet index 3, End of Epoch 1/6, Average Loss=10.771820068359375, Class Loss=0.9037365913391113, Reg Loss=9.868083953857422
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=8.939871746301652
Loss made of: CE 0.546106219291687, LKD 3.7507455348968506, LDE 3.967550277709961, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6940957307815552, Reg Loss=8.1517333984375
Clinet index 3, End of Epoch 2/6, Average Loss=8.845829010009766, Class Loss=0.6940957307815552, Reg Loss=8.1517333984375
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=8.109914645552635
Loss made of: CE 0.40761393308639526, LKD 3.5608270168304443, LDE 3.324047803878784, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5895699262619019, Reg Loss=7.465576171875
Clinet index 3, End of Epoch 3/6, Average Loss=8.055146217346191, Class Loss=0.5895699262619019, Reg Loss=7.465576171875
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=7.864658299088478
Loss made of: CE 0.4465646743774414, LKD 4.121488571166992, LDE 3.7674214839935303, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5246292948722839, Reg Loss=7.253915786743164
Clinet index 3, End of Epoch 4/6, Average Loss=7.778544902801514, Class Loss=0.5246292948722839, Reg Loss=7.253915786743164
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=7.264486616849899
Loss made of: CE 0.5100592970848083, LKD 3.6456034183502197, LDE 3.133472442626953, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.47064661979675293, Reg Loss=6.819602012634277
Clinet index 3, End of Epoch 5/6, Average Loss=7.290248870849609, Class Loss=0.47064661979675293, Reg Loss=6.819602012634277
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=7.698446699976921
Loss made of: CE 0.5093119144439697, LKD 3.6982216835021973, LDE 3.214822769165039, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.46356022357940674, Reg Loss=7.068423748016357
Clinet index 3, End of Epoch 6/6, Average Loss=7.531983852386475, Class Loss=0.46356022357940674, Reg Loss=7.068423748016357
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=6.755216827988624
Loss made of: CE 0.4028503894805908, LKD 3.816453456878662, LDE 2.420870065689087, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=7.095241722464562
Loss made of: CE 0.5199251174926758, LKD 4.114535331726074, LDE 3.1585330963134766, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=7.030890375375748
Loss made of: CE 0.3685429096221924, LKD 3.8084254264831543, LDE 3.1410627365112305, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=6.835926157236099
Loss made of: CE 0.5254232883453369, LKD 4.651298522949219, LDE 2.652066469192505, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=6.7858179181814196
Loss made of: CE 0.4103439748287201, LKD 3.798784017562866, LDE 2.8845458030700684, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=6.714951846003532
Loss made of: CE 0.4065096080303192, LKD 3.984593629837036, LDE 2.4200539588928223, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=7.314543029665947
Loss made of: CE 0.46871933341026306, LKD 3.507575750350952, LDE 2.0864129066467285, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=7.073601740598678
Loss made of: CE 0.5121454000473022, LKD 3.6947474479675293, LDE 2.7999725341796875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=6.890818628668785
Loss made of: CE 0.42726266384124756, LKD 4.09561824798584, LDE 2.893339157104492, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.42116689682006836, Reg Loss=6.5281267166137695
Clinet index 5, End of Epoch 1/6, Average Loss=6.949293613433838, Class Loss=0.42116689682006836, Reg Loss=6.5281267166137695
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=6.264593082666397
Loss made of: CE 0.37392327189445496, LKD 3.6907076835632324, LDE 2.787706136703491, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=6.714103558659554
Loss made of: CE 0.39081597328186035, LKD 3.4618582725524902, LDE 2.736177921295166, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=6.770825493335724
Loss made of: CE 0.4173353612422943, LKD 4.20306921005249, LDE 2.85595703125, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=6.800134280323983
Loss made of: CE 0.4215874671936035, LKD 3.749194383621216, LDE 2.695262908935547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=7.162341529130936
Loss made of: CE 0.4550964832305908, LKD 3.7761173248291016, LDE 2.7674031257629395, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=6.868710535764694
Loss made of: CE 0.40277737379074097, LKD 3.166593551635742, LDE 2.2850699424743652, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=6.812720984220505
Loss made of: CE 0.3704911172389984, LKD 3.5419206619262695, LDE 2.912381649017334, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=6.873584863543511
Loss made of: CE 0.37187036871910095, LKD 3.5960099697113037, LDE 3.9163570404052734, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=7.04647858440876
Loss made of: CE 0.45103126764297485, LKD 3.84718656539917, LDE 4.1306586265563965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.419516921043396, Reg Loss=6.423523426055908
Clinet index 5, End of Epoch 2/6, Average Loss=6.843040466308594, Class Loss=0.419516921043396, Reg Loss=6.423523426055908
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=7.128554823994636
Loss made of: CE 0.3961435556411743, LKD 3.7608602046966553, LDE 2.6730549335479736, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=7.2374587029218675
Loss made of: CE 0.41235217452049255, LKD 3.523801326751709, LDE 2.9877912998199463, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=6.911725512146949
Loss made of: CE 0.38532400131225586, LKD 3.1239001750946045, LDE 2.907174825668335, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=7.094938713312149
Loss made of: CE 0.38345226645469666, LKD 4.236131191253662, LDE 3.281984567642212, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=7.05237135887146
Loss made of: CE 0.3377145230770111, LKD 3.3352322578430176, LDE 2.805392026901245, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=6.885401606559753
Loss made of: CE 0.5956069827079773, LKD 4.116758346557617, LDE 4.800778388977051, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=6.533999261260033
Loss made of: CE 0.3343953490257263, LKD 3.319615125656128, LDE 2.719660758972168, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=6.618999636173248
Loss made of: CE 0.36059173941612244, LKD 2.945793390274048, LDE 2.408175230026245, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=6.762626597285271
Loss made of: CE 0.334169864654541, LKD 3.5905141830444336, LDE 2.556835889816284, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4159203767776489, Reg Loss=6.466883659362793
Clinet index 5, End of Epoch 3/6, Average Loss=6.882803916931152, Class Loss=0.4159203767776489, Reg Loss=6.466883659362793
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=6.795399388670921
Loss made of: CE 0.44125983119010925, LKD 3.557020902633667, LDE 2.5021939277648926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=6.772110298275948
Loss made of: CE 0.4235163927078247, LKD 3.9984893798828125, LDE 2.506363868713379, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=6.667981716990471
Loss made of: CE 0.411348819732666, LKD 3.196432113647461, LDE 2.716499090194702, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=6.778865468502045
Loss made of: CE 0.4631497263908386, LKD 4.406605243682861, LDE 2.306330680847168, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=6.570309370756149
Loss made of: CE 0.48757147789001465, LKD 4.260570526123047, LDE 2.5920588970184326, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.812896576523781
Loss made of: CE 0.3857262134552002, LKD 3.2908029556274414, LDE 3.4601733684539795, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=7.143731817603111
Loss made of: CE 0.40302154421806335, LKD 3.565899610519409, LDE 3.858187437057495, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=6.460347041487694
Loss made of: CE 0.4292033314704895, LKD 3.5254814624786377, LDE 2.083831548690796, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=6.881544530391693
Loss made of: CE 0.42214399576187134, LKD 3.4266974925994873, LDE 2.567662239074707, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41401907801628113, Reg Loss=6.392541885375977
Clinet index 5, End of Epoch 4/6, Average Loss=6.80656099319458, Class Loss=0.41401907801628113, Reg Loss=6.392541885375977
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=6.899688345193863
Loss made of: CE 0.4154324233531952, LKD 2.9669647216796875, LDE 2.8779592514038086, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=6.689788499474526
Loss made of: CE 0.4048628509044647, LKD 3.6141297817230225, LDE 2.735365152359009, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=6.649064356088639
Loss made of: CE 0.343003511428833, LKD 3.204455614089966, LDE 2.7490458488464355, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=6.4412951409816745
Loss made of: CE 0.4070872664451599, LKD 3.6049258708953857, LDE 2.8401761054992676, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=6.759351122379303
Loss made of: CE 0.39167365431785583, LKD 3.184286117553711, LDE 2.2320590019226074, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=7.050094401836395
Loss made of: CE 0.3651934564113617, LKD 3.714916944503784, LDE 3.8814122676849365, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.741967958211899
Loss made of: CE 0.3965146243572235, LKD 4.137110233306885, LDE 2.3973896503448486, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.462145230174064
Loss made of: CE 0.39670801162719727, LKD 3.2070345878601074, LDE 2.3025898933410645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=7.017785349488259
Loss made of: CE 0.4025214612483978, LKD 3.910414218902588, LDE 2.758733034133911, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.40467149019241333, Reg Loss=6.325694561004639
Clinet index 5, End of Epoch 5/6, Average Loss=6.730366230010986, Class Loss=0.40467149019241333, Reg Loss=6.325694561004639
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=6.639848077297211
Loss made of: CE 0.4225723147392273, LKD 3.8779191970825195, LDE 2.182623863220215, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.637265250086784
Loss made of: CE 0.36031121015548706, LKD 3.4179768562316895, LDE 2.3658246994018555, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.340049314498901
Loss made of: CE 0.3830934166908264, LKD 4.076200485229492, LDE 3.0967538356781006, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.801072606444359
Loss made of: CE 0.43678849935531616, LKD 3.577660083770752, LDE 2.5849368572235107, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=6.638994765281677
Loss made of: CE 0.3484896123409271, LKD 3.4154787063598633, LDE 2.6828370094299316, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.787960070371628
Loss made of: CE 0.32689374685287476, LKD 3.303487539291382, LDE 3.6513290405273438, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.6267492294311525
Loss made of: CE 0.33801501989364624, LKD 3.401003837585449, LDE 2.8086369037628174, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=6.743036916851997
Loss made of: CE 0.4251057505607605, LKD 4.444166660308838, LDE 2.8848018646240234, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.874184608459473
Loss made of: CE 0.483366459608078, LKD 3.603705406188965, LDE 1.9787043333053589, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4067295789718628, Reg Loss=6.252963066101074
Clinet index 5, End of Epoch 6/6, Average Loss=6.659692764282227, Class Loss=0.4067295789718628, Reg Loss=6.252963066101074
Current Client Index:  22
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=10.99422840476036
Loss made of: CE 1.0305708646774292, LKD 4.308917999267578, LDE 5.564115524291992, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9434472918510437, Reg Loss=9.783931732177734
Clinet index 22, End of Epoch 1/6, Average Loss=10.727378845214844, Class Loss=0.9434472918510437, Reg Loss=9.783931732177734
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=8.606047976016999
Loss made of: CE 0.5468093752861023, LKD 3.4380953311920166, LDE 3.402923822402954, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7249132394790649, Reg Loss=7.973492622375488
Clinet index 22, End of Epoch 2/6, Average Loss=8.698406219482422, Class Loss=0.7249132394790649, Reg Loss=7.973492622375488
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=7.9027657330036165
Loss made of: CE 0.6732556223869324, LKD 3.9056334495544434, LDE 3.7178895473480225, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5795763731002808, Reg Loss=7.321828365325928
Clinet index 22, End of Epoch 3/6, Average Loss=7.901404857635498, Class Loss=0.5795763731002808, Reg Loss=7.321828365325928
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=7.7666126757860185
Loss made of: CE 0.5252560377120972, LKD 3.3577165603637695, LDE 3.6534833908081055, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5273531675338745, Reg Loss=7.181305885314941
Clinet index 22, End of Epoch 4/6, Average Loss=7.7086591720581055, Class Loss=0.5273531675338745, Reg Loss=7.181305885314941
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=7.252901872992515
Loss made of: CE 0.3842768669128418, LKD 2.9451165199279785, LDE 4.247535228729248, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4856402277946472, Reg Loss=6.830251216888428
Clinet index 22, End of Epoch 5/6, Average Loss=7.315891265869141, Class Loss=0.4856402277946472, Reg Loss=6.830251216888428
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=7.231470957398415
Loss made of: CE 0.5344018936157227, LKD 3.9976863861083984, LDE 3.015770673751831, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4625956416130066, Reg Loss=6.9120988845825195
Clinet index 22, End of Epoch 6/6, Average Loss=7.374694347381592, Class Loss=0.4625956416130066, Reg Loss=6.9120988845825195
federated aggregation...
Validation, Class Loss=0.7353774905204773, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.786762
Mean Acc: 0.301723
FreqW Acc: 0.701196
Mean IoU: 0.221735
Class IoU:
	class 0: 0.88469946
	class 1: 0.31240687
	class 2: 2.9373246e-05
	class 3: 0.0
	class 4: 0.48349935
	class 5: 0.011008116
	class 6: 0.23383208
	class 7: 0.52615386
	class 8: 0.0
	class 9: 0.018869685
	class 10: 0.0
	class 11: 0.00011819567
	class 12: 0.002133558
	class 13: 0.10124661
	class 14: 0.35674
	class 15: 0.69537085
	class 16: 0.14337993
Class Acc:
	class 0: 0.9645141
	class 1: 0.3132551
	class 2: 2.938573e-05
	class 3: 0.0
	class 4: 0.50156593
	class 5: 0.011009369
	class 6: 0.23404619
	class 7: 0.5278571
	class 8: 0.0
	class 9: 0.019435015
	class 10: 0.0
	class 11: 0.000118195785
	class 12: 0.0021380372
	class 13: 0.8812676
	class 14: 0.64155066
	class 15: 0.88371545
	class 16: 0.14879622

federated global round: 24, step: 4
select part of clients to conduct local training
[16, 9, 12, 2]
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=7.380410411953926
Loss made of: CE 0.4622821807861328, LKD 4.086655616760254, LDE 2.6820104122161865, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=6.71366203725338
Loss made of: CE 0.3973684310913086, LKD 3.4770798683166504, LDE 2.5338616371154785, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=6.9163637399673465
Loss made of: CE 0.42336708307266235, LKD 4.0078349113464355, LDE 2.5994672775268555, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=6.623711243271828
Loss made of: CE 0.44046449661254883, LKD 3.284770965576172, LDE 2.967862367630005, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=6.73502502143383
Loss made of: CE 0.42766469717025757, LKD 3.43144154548645, LDE 3.3972079753875732, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=7.214228871464729
Loss made of: CE 0.46856099367141724, LKD 3.9834070205688477, LDE 2.919156551361084, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=6.729244023561478
Loss made of: CE 0.3844773769378662, LKD 3.678323984146118, LDE 2.1310579776763916, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=6.7875468790531155
Loss made of: CE 0.3881666660308838, LKD 3.1456515789031982, LDE 2.286267042160034, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=6.598948422074318
Loss made of: CE 0.4409998059272766, LKD 3.5550079345703125, LDE 2.6252434253692627, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.41907888650894165, Reg Loss=6.4217352867126465
Clinet index 16, End of Epoch 1/6, Average Loss=6.840814113616943, Class Loss=0.41907888650894165, Reg Loss=6.4217352867126465
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/97, Loss=6.672230741381645
Loss made of: CE 0.3826938569545746, LKD 4.272106170654297, LDE 3.164876937866211, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=6.871672722697258
Loss made of: CE 0.476253479719162, LKD 4.500153064727783, LDE 2.697054147720337, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=6.59028557240963
Loss made of: CE 0.41052770614624023, LKD 3.538689374923706, LDE 2.7094743251800537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=6.6374211490154265
Loss made of: CE 0.371934175491333, LKD 3.2866291999816895, LDE 2.8026175498962402, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=6.771071490645409
Loss made of: CE 0.34178394079208374, LKD 3.63653564453125, LDE 3.1393275260925293, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=6.599078780412674
Loss made of: CE 0.47409889101982117, LKD 4.096837520599365, LDE 2.734463691711426, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=6.6991109400987625
Loss made of: CE 0.4279448986053467, LKD 4.449064254760742, LDE 2.325267791748047, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=6.434937241673469
Loss made of: CE 0.4091007113456726, LKD 3.841512680053711, LDE 2.7631278038024902, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=6.681191030144691
Loss made of: CE 0.41213345527648926, LKD 3.471614122390747, LDE 2.8579070568084717, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4067181646823883, Reg Loss=6.261035442352295
Clinet index 16, End of Epoch 2/6, Average Loss=6.66775369644165, Class Loss=0.4067181646823883, Reg Loss=6.261035442352295
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/97, Loss=6.39631407558918
Loss made of: CE 0.37051981687545776, LKD 3.168766975402832, LDE 2.205854654312134, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=6.448783484101296
Loss made of: CE 0.42273998260498047, LKD 3.5126852989196777, LDE 2.46112060546875, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=7.194796368479729
Loss made of: CE 0.4020465016365051, LKD 3.5930230617523193, LDE 3.936565399169922, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=6.994154080748558
Loss made of: CE 0.40451380610466003, LKD 3.6631009578704834, LDE 2.5382182598114014, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=6.564881089329719
Loss made of: CE 0.33601176738739014, LKD 3.8159046173095703, LDE 2.918797492980957, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=6.555695798993111
Loss made of: CE 0.41997918486595154, LKD 3.155555248260498, LDE 2.480924129486084, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=6.9410086393356325
Loss made of: CE 0.4351266324520111, LKD 3.772580623626709, LDE 2.4789347648620605, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=7.132897999882698
Loss made of: CE 0.42927050590515137, LKD 3.5192906856536865, LDE 3.269014835357666, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=6.42849877178669
Loss made of: CE 0.4086627960205078, LKD 3.786346435546875, LDE 2.1708850860595703, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4059603810310364, Reg Loss=6.3260498046875
Clinet index 16, End of Epoch 3/6, Average Loss=6.732010364532471, Class Loss=0.4059603810310364, Reg Loss=6.3260498046875
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/97, Loss=6.448568522930145
Loss made of: CE 0.3562377393245697, LKD 3.545515298843384, LDE 2.6997885704040527, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=6.78385654091835
Loss made of: CE 0.3949694335460663, LKD 3.7686567306518555, LDE 2.3792896270751953, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=6.505947032570839
Loss made of: CE 0.43716925382614136, LKD 3.7730612754821777, LDE 3.034003734588623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=6.478651782870292
Loss made of: CE 0.38696202635765076, LKD 3.4332408905029297, LDE 2.8795790672302246, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=6.492021745443344
Loss made of: CE 0.3471883237361908, LKD 3.7592973709106445, LDE 2.0229880809783936, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=6.41283152103424
Loss made of: CE 0.41167622804641724, LKD 3.4755430221557617, LDE 2.961486577987671, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=6.48896721303463
Loss made of: CE 0.39746445417404175, LKD 3.065359592437744, LDE 2.9493038654327393, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=6.733705309033394
Loss made of: CE 0.3938460350036621, LKD 3.109884738922119, LDE 4.111569404602051, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=6.239343148469925
Loss made of: CE 0.39541396498680115, LKD 3.5398061275482178, LDE 2.499508857727051, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4026816189289093, Reg Loss=6.130438804626465
Clinet index 16, End of Epoch 4/6, Average Loss=6.533120632171631, Class Loss=0.4026816189289093, Reg Loss=6.130438804626465
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/97, Loss=6.649939489364624
Loss made of: CE 0.43841394782066345, LKD 3.4185643196105957, LDE 2.522844076156616, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=6.634925445914268
Loss made of: CE 0.46072858572006226, LKD 3.6160848140716553, LDE 3.3888697624206543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=6.7910782307386395
Loss made of: CE 0.4561912715435028, LKD 3.7892346382141113, LDE 2.6665103435516357, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=6.422449159622192
Loss made of: CE 0.39413243532180786, LKD 3.632744073867798, LDE 2.5476043224334717, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=6.325726774334908
Loss made of: CE 0.33302611112594604, LKD 3.197826385498047, LDE 2.546172857284546, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=6.489024269580841
Loss made of: CE 0.38399815559387207, LKD 3.7033751010894775, LDE 2.7852914333343506, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=6.338788345456123
Loss made of: CE 0.28640016913414, LKD 3.2791175842285156, LDE 2.5918002128601074, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=6.618489441275597
Loss made of: CE 0.4685758054256439, LKD 4.170459270477295, LDE 2.256075143814087, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=6.527719333767891
Loss made of: CE 0.46244966983795166, LKD 4.040448188781738, LDE 3.097703695297241, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4035467505455017, Reg Loss=6.113384246826172
Clinet index 16, End of Epoch 5/6, Average Loss=6.516931056976318, Class Loss=0.4035467505455017, Reg Loss=6.113384246826172
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/97, Loss=6.390724313259125
Loss made of: CE 0.3714246153831482, LKD 2.984203815460205, LDE 2.5519204139709473, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=6.5684684664011
Loss made of: CE 0.39675816893577576, LKD 2.6124205589294434, LDE 3.5618748664855957, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=6.455354765057564
Loss made of: CE 0.4055774211883545, LKD 3.9701521396636963, LDE 2.0931293964385986, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=6.188700515031814
Loss made of: CE 0.40226030349731445, LKD 3.697605848312378, LDE 2.631802558898926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=6.15816401541233
Loss made of: CE 0.338606595993042, LKD 3.331022024154663, LDE 2.0538759231567383, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=6.442935442924499
Loss made of: CE 0.41136738657951355, LKD 3.845898151397705, LDE 2.5332305431365967, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=6.483328205347061
Loss made of: CE 0.33912426233291626, LKD 3.046313524246216, LDE 2.663145065307617, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=6.286000588536263
Loss made of: CE 0.3316592872142792, LKD 2.890286445617676, LDE 2.1686365604400635, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=6.71409033536911
Loss made of: CE 0.42976149916648865, LKD 3.4029488563537598, LDE 2.335785388946533, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4010944366455078, Reg Loss=5.9890265464782715
Clinet index 16, End of Epoch 6/6, Average Loss=6.390120983123779, Class Loss=0.4010944366455078, Reg Loss=5.9890265464782715
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=8.213397634029388
Loss made of: CE 0.6560397148132324, LKD 3.5297882556915283, LDE 2.9947688579559326, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.601494312286377, Reg Loss=7.615507125854492
Clinet index 9, End of Epoch 1/6, Average Loss=8.217000961303711, Class Loss=0.601494312286377, Reg Loss=7.615507125854492
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=7.4991018831729885
Loss made of: CE 0.5010817050933838, LKD 3.4701004028320312, LDE 3.7148654460906982, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.527209460735321, Reg Loss=6.9372477531433105
Clinet index 9, End of Epoch 2/6, Average Loss=7.464457035064697, Class Loss=0.527209460735321, Reg Loss=6.9372477531433105
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=7.416019609570503
Loss made of: CE 0.4447515904903412, LKD 3.1845078468322754, LDE 3.447507381439209, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.48875492811203003, Reg Loss=6.931802749633789
Clinet index 9, End of Epoch 3/6, Average Loss=7.420557498931885, Class Loss=0.48875492811203003, Reg Loss=6.931802749633789
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=7.256400102376938
Loss made of: CE 0.4636847972869873, LKD 3.6855366230010986, LDE 2.9136664867401123, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46072858572006226, Reg Loss=6.923095703125
Clinet index 9, End of Epoch 4/6, Average Loss=7.383824348449707, Class Loss=0.46072858572006226, Reg Loss=6.923095703125
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=7.186284738779068
Loss made of: CE 0.46257755160331726, LKD 4.042372703552246, LDE 3.460169553756714, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.45395147800445557, Reg Loss=6.72679328918457
Clinet index 9, End of Epoch 5/6, Average Loss=7.180744647979736, Class Loss=0.45395147800445557, Reg Loss=6.72679328918457
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=7.091780877113342
Loss made of: CE 0.41257965564727783, LKD 3.564518690109253, LDE 3.629647970199585, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4553205668926239, Reg Loss=6.696435928344727
Clinet index 9, End of Epoch 6/6, Average Loss=7.151756286621094, Class Loss=0.4553205668926239, Reg Loss=6.696435928344727
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=8.37289696931839
Loss made of: CE 0.5272502303123474, LKD 3.232663154602051, LDE 4.155064105987549, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.610049307346344, Reg Loss=7.659352779388428
Clinet index 12, End of Epoch 1/6, Average Loss=8.269402503967285, Class Loss=0.610049307346344, Reg Loss=7.659352779388428
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=7.444723385572433
Loss made of: CE 0.5117444396018982, LKD 3.2534241676330566, LDE 3.4625165462493896, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5076225399971008, Reg Loss=6.972447872161865
Clinet index 12, End of Epoch 2/6, Average Loss=7.4800705909729, Class Loss=0.5076225399971008, Reg Loss=6.972447872161865
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=7.154652985930443
Loss made of: CE 0.5596343278884888, LKD 3.7818875312805176, LDE 3.0952377319335938, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.46675556898117065, Reg Loss=6.660307884216309
Clinet index 12, End of Epoch 3/6, Average Loss=7.127063274383545, Class Loss=0.46675556898117065, Reg Loss=6.660307884216309
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=7.043420225381851
Loss made of: CE 0.49335044622421265, LKD 3.398604393005371, LDE 3.018340587615967, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4517483115196228, Reg Loss=6.6501994132995605
Clinet index 12, End of Epoch 4/6, Average Loss=7.101947784423828, Class Loss=0.4517483115196228, Reg Loss=6.6501994132995605
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=7.08221914768219
Loss made of: CE 0.4960366487503052, LKD 3.727491855621338, LDE 2.8604111671447754, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.44559359550476074, Reg Loss=6.698869705200195
Clinet index 12, End of Epoch 5/6, Average Loss=7.144463539123535, Class Loss=0.44559359550476074, Reg Loss=6.698869705200195
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=6.885942524671554
Loss made of: CE 0.38067540526390076, LKD 3.0943267345428467, LDE 3.2296836376190186, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.44389399886131287, Reg Loss=6.539981365203857
Clinet index 12, End of Epoch 6/6, Average Loss=6.983875274658203, Class Loss=0.44389399886131287, Reg Loss=6.539981365203857
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/12, Loss=8.381133550405503
Loss made of: CE 0.612023115158081, LKD 3.835789203643799, LDE 3.15661358833313, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6351030468940735, Reg Loss=7.7307658195495605
Clinet index 2, End of Epoch 1/6, Average Loss=8.36586856842041, Class Loss=0.6351030468940735, Reg Loss=7.7307658195495605
Pseudo labeling is: None
Epoch 2, lr = 0.000536
Epoch 2, Batch 10/12, Loss=7.731697940826416
Loss made of: CE 0.5911571979522705, LKD 3.1851491928100586, LDE 2.945854902267456, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5708507299423218, Reg Loss=7.102723121643066
Clinet index 2, End of Epoch 2/6, Average Loss=7.673573970794678, Class Loss=0.5708507299423218, Reg Loss=7.102723121643066
Pseudo labeling is: None
Epoch 3, lr = 0.000438
Epoch 3, Batch 10/12, Loss=7.599728834629059
Loss made of: CE 0.5289407968521118, LKD 3.4613256454467773, LDE 3.3787832260131836, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5136097073554993, Reg Loss=7.065099239349365
Clinet index 2, End of Epoch 3/6, Average Loss=7.578709125518799, Class Loss=0.5136097073554993, Reg Loss=7.065099239349365
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/12, Loss=7.242473909258843
Loss made of: CE 0.4938657879829407, LKD 3.9106569290161133, LDE 2.973177194595337, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5006718039512634, Reg Loss=6.850648880004883
Clinet index 2, End of Epoch 4/6, Average Loss=7.351320743560791, Class Loss=0.5006718039512634, Reg Loss=6.850648880004883
Pseudo labeling is: None
Epoch 5, lr = 0.000235
Epoch 5, Batch 10/12, Loss=7.109484001994133
Loss made of: CE 0.5456621646881104, LKD 4.242833614349365, LDE 3.4098169803619385, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4869345426559448, Reg Loss=6.571453094482422
Clinet index 2, End of Epoch 5/6, Average Loss=7.058387756347656, Class Loss=0.4869345426559448, Reg Loss=6.571453094482422
Pseudo labeling is: None
Epoch 6, lr = 0.000126
Epoch 6, Batch 10/12, Loss=7.1909948080778126
Loss made of: CE 0.44309481978416443, LKD 3.766932249069214, LDE 2.7677700519561768, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5009822845458984, Reg Loss=6.784339427947998
Clinet index 2, End of Epoch 6/6, Average Loss=7.2853217124938965, Class Loss=0.5009822845458984, Reg Loss=6.784339427947998
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=0.7411888241767883, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.787874
Mean Acc: 0.318563
FreqW Acc: 0.702934
Mean IoU: 0.231780
Class IoU:
	class 0: 0.88423145
	class 1: 0.34140205
	class 2: 0.00013819266
	class 3: 0.0
	class 4: 0.48365906
	class 5: 0.009065627
	class 6: 0.28329423
	class 7: 0.49313435
	class 8: 0.0
	class 9: 0.02024115
	class 10: 0.0
	class 11: 0.00026905382
	class 12: 0.0023479378
	class 13: 0.10260205
	class 14: 0.3627519
	class 15: 0.69969726
	class 16: 0.25743064
Class Acc:
	class 0: 0.961626
	class 1: 0.34248924
	class 2: 0.00013832795
	class 3: 0.0
	class 4: 0.50143003
	class 5: 0.009066382
	class 6: 0.28359646
	class 7: 0.49455085
	class 8: 0.0
	class 9: 0.020909518
	class 10: 0.0
	class 11: 0.00026905403
	class 12: 0.0023523746
	class 13: 0.8768111
	class 14: 0.64148253
	class 15: 0.8939481
	class 16: 0.38690808

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 25, step: 5
select part of clients to conduct local training
[24, 7, 4, 12]
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=10.922212111949921
Loss made of: CE 1.8528339862823486, LKD 4.101797580718994, LDE 3.676581859588623, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9723247289657593, Reg Loss=8.566000938415527
Clinet index 24, End of Epoch 1/6, Average Loss=10.538325309753418, Class Loss=1.9723247289657593, Reg Loss=8.566000938415527
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=8.56197361946106
Loss made of: CE 1.5925743579864502, LKD 4.059668064117432, LDE 3.0105998516082764, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.5244783163070679, Reg Loss=6.942421913146973
Clinet index 24, End of Epoch 2/6, Average Loss=8.466899871826172, Class Loss=1.5244783163070679, Reg Loss=6.942421913146973
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=7.604277265071869
Loss made of: CE 1.0206716060638428, LKD 4.102780342102051, LDE 2.2473714351654053, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.1782561540603638, Reg Loss=6.3126678466796875
Clinet index 24, End of Epoch 3/6, Average Loss=7.490923881530762, Class Loss=1.1782561540603638, Reg Loss=6.3126678466796875
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=7.218654841184616
Loss made of: CE 0.9564594626426697, LKD 3.8296992778778076, LDE 3.0161335468292236, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.8774776458740234, Reg Loss=6.321813106536865
Clinet index 24, End of Epoch 4/6, Average Loss=7.199290752410889, Class Loss=0.8774776458740234, Reg Loss=6.321813106536865
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=6.706050503253937
Loss made of: CE 0.7605094909667969, LKD 3.9962198734283447, LDE 2.3181099891662598, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7502453327178955, Reg Loss=5.935603618621826
Clinet index 24, End of Epoch 5/6, Average Loss=6.685849189758301, Class Loss=0.7502453327178955, Reg Loss=5.935603618621826
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=6.653136658668518
Loss made of: CE 0.6369298696517944, LKD 3.2530975341796875, LDE 2.096895456314087, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.726639986038208, Reg Loss=6.05283260345459
Clinet index 24, End of Epoch 6/6, Average Loss=6.779472351074219, Class Loss=0.726639986038208, Reg Loss=6.05283260345459
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.4426400661468506, Reg Loss=17.83353042602539
Clinet index 7, End of Epoch 1/6, Average Loss=19.27617073059082, Class Loss=1.4426400661468506, Reg Loss=17.83353042602539
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.2199921607971191, Reg Loss=12.516282081604004
Clinet index 7, End of Epoch 2/6, Average Loss=13.736274719238281, Class Loss=1.2199921607971191, Reg Loss=12.516282081604004
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.9868290424346924, Reg Loss=11.05418872833252
Clinet index 7, End of Epoch 3/6, Average Loss=12.041017532348633, Class Loss=0.9868290424346924, Reg Loss=11.05418872833252
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.703137993812561, Reg Loss=10.150842666625977
Clinet index 7, End of Epoch 4/6, Average Loss=10.853981018066406, Class Loss=0.703137993812561, Reg Loss=10.150842666625977
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 5, Class Loss=0.5151039361953735, Reg Loss=9.466763496398926
Clinet index 7, End of Epoch 5/6, Average Loss=9.981867790222168, Class Loss=0.5151039361953735, Reg Loss=9.466763496398926
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.409066766500473, Reg Loss=9.015588760375977
Clinet index 7, End of Epoch 6/6, Average Loss=9.42465591430664, Class Loss=0.409066766500473, Reg Loss=9.015588760375977
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=10.846837520599365
Loss made of: CE 1.6961419582366943, LKD 4.103798866271973, LDE 3.7987477779388428, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.0104494094848633, Reg Loss=8.59600830078125
Clinet index 4, End of Epoch 1/6, Average Loss=10.606457710266113, Class Loss=2.0104494094848633, Reg Loss=8.59600830078125
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=8.316788995265961
Loss made of: CE 1.52530038356781, LKD 4.054760456085205, LDE 2.77567982673645, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.5296895503997803, Reg Loss=6.926695823669434
Clinet index 4, End of Epoch 2/6, Average Loss=8.456385612487793, Class Loss=1.5296895503997803, Reg Loss=6.926695823669434
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=7.550623768568039
Loss made of: CE 0.8259164690971375, LKD 3.7194035053253174, LDE 2.2125091552734375, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.1768717765808105, Reg Loss=6.338496685028076
Clinet index 4, End of Epoch 3/6, Average Loss=7.515368461608887, Class Loss=1.1768717765808105, Reg Loss=6.338496685028076
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=7.331674355268478
Loss made of: CE 0.8005017042160034, LKD 3.7034616470336914, LDE 2.4911961555480957, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.8383068442344666, Reg Loss=6.387585639953613
Clinet index 4, End of Epoch 4/6, Average Loss=7.225892543792725, Class Loss=0.8383068442344666, Reg Loss=6.387585639953613
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=6.851214092969895
Loss made of: CE 0.7530169486999512, LKD 3.9074461460113525, LDE 2.592374324798584, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7400326132774353, Reg Loss=6.040708065032959
Clinet index 4, End of Epoch 5/6, Average Loss=6.780740737915039, Class Loss=0.7400326132774353, Reg Loss=6.040708065032959
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=6.524998426437378
Loss made of: CE 0.6430251002311707, LKD 3.8528494834899902, LDE 1.900009036064148, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6613790988922119, Reg Loss=5.965392589569092
Clinet index 4, End of Epoch 6/6, Average Loss=6.626771926879883, Class Loss=0.6613790988922119, Reg Loss=5.965392589569092
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=10.283478033542632
Loss made of: CE 1.9762916564941406, LKD 3.8852810859680176, LDE 4.892943859100342, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.8822264671325684, Reg Loss=8.277820587158203
Clinet index 12, End of Epoch 1/6, Average Loss=10.16004753112793, Class Loss=1.8822264671325684, Reg Loss=8.277820587158203
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=8.55951339006424
Loss made of: CE 1.361584186553955, LKD 3.542309284210205, LDE 3.0161890983581543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.5381077527999878, Reg Loss=6.942132472991943
Clinet index 12, End of Epoch 2/6, Average Loss=8.480239868164062, Class Loss=1.5381077527999878, Reg Loss=6.942132472991943
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=7.431682646274567
Loss made of: CE 1.1190426349639893, LKD 3.4739131927490234, LDE 2.341952085494995, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=1.1575334072113037, Reg Loss=6.3395280838012695
Clinet index 12, End of Epoch 3/6, Average Loss=7.497061729431152, Class Loss=1.1575334072113037, Reg Loss=6.3395280838012695
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=7.130250561237335
Loss made of: CE 0.7289762496948242, LKD 3.7486684322357178, LDE 2.363004446029663, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.909174382686615, Reg Loss=6.202875137329102
Clinet index 12, End of Epoch 4/6, Average Loss=7.112049579620361, Class Loss=0.909174382686615, Reg Loss=6.202875137329102
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=6.717658770084381
Loss made of: CE 0.7224339246749878, LKD 3.3350820541381836, LDE 1.8401986360549927, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7663032412528992, Reg Loss=5.985867500305176
Clinet index 12, End of Epoch 5/6, Average Loss=6.752170562744141, Class Loss=0.7663032412528992, Reg Loss=5.985867500305176
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=6.766075021028518
Loss made of: CE 0.6105818152427673, LKD 3.4624874591827393, LDE 2.243726968765259, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6980790495872498, Reg Loss=6.073802471160889
Clinet index 12, End of Epoch 6/6, Average Loss=6.771881580352783, Class Loss=0.6980790495872498, Reg Loss=6.073802471160889
federated aggregation...
Validation, Class Loss=0.8062270283699036, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.771332
Mean Acc: 0.264862
FreqW Acc: 0.676741
Mean IoU: 0.215377
Class IoU:
	class 0: 0.85668695
	class 1: 0.5107945
	class 2: 0.052351244
	class 3: 0.0
	class 4: 0.509702
	class 5: 0.024126789
	class 6: 0.50209534
	class 7: 0.4578672
	class 8: 0.0
	class 9: 0.009324332
	class 10: 0.0
	class 11: 0.0
	class 12: 0.00013221813
	class 13: 0.115750864
	class 14: 0.1502088
	class 15: 0.72671705
	class 16: 0.14348057
	class 17: 0.0
	class 18: 0.032926653
Class Acc:
	class 0: 0.97054136
	class 1: 0.5126652
	class 2: 0.05806047
	class 3: 0.0
	class 4: 0.5309938
	class 5: 0.024127482
	class 6: 0.50302005
	class 7: 0.45893836
	class 8: 0.0
	class 9: 0.009370982
	class 10: 0.0
	class 11: 0.0
	class 12: 0.00013221828
	class 13: 0.6863219
	class 14: 0.18479277
	class 15: 0.8009589
	class 16: 0.14775024
	class 17: 0.0
	class 18: 0.14470175

federated global round: 26, step: 5
select part of clients to conduct local training
[6, 28, 20, 4]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=7.393147295713424
Loss made of: CE 0.7415758967399597, LKD 3.7559759616851807, LDE 2.248962163925171, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.812098503112793, Reg Loss=6.568515300750732
Clinet index 6, End of Epoch 1/6, Average Loss=7.380613803863525, Class Loss=0.812098503112793, Reg Loss=6.568515300750732
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=7.101118528842926
Loss made of: CE 0.7135318517684937, LKD 3.1292922496795654, LDE 2.630270004272461, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7312462329864502, Reg Loss=6.385181427001953
Clinet index 6, End of Epoch 2/6, Average Loss=7.116427421569824, Class Loss=0.7312462329864502, Reg Loss=6.385181427001953
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=6.6333163022995
Loss made of: CE 0.6551244258880615, LKD 4.600829124450684, LDE 2.4804513454437256, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6553045511245728, Reg Loss=6.093074798583984
Clinet index 6, End of Epoch 3/6, Average Loss=6.748379230499268, Class Loss=0.6553045511245728, Reg Loss=6.093074798583984
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=6.395182794332504
Loss made of: CE 0.6596792340278625, LKD 3.8590750694274902, LDE 1.9280598163604736, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6451170444488525, Reg Loss=5.750835418701172
Clinet index 6, End of Epoch 4/6, Average Loss=6.395952224731445, Class Loss=0.6451170444488525, Reg Loss=5.750835418701172
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=6.750404703617096
Loss made of: CE 0.735966682434082, LKD 4.206645488739014, LDE 2.7667124271392822, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6287441849708557, Reg Loss=6.08399772644043
Clinet index 6, End of Epoch 5/6, Average Loss=6.712741851806641, Class Loss=0.6287441849708557, Reg Loss=6.08399772644043
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=6.322781884670258
Loss made of: CE 0.5123990774154663, LKD 3.56292986869812, LDE 1.95940363407135, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6179525256156921, Reg Loss=5.727962017059326
Clinet index 6, End of Epoch 6/6, Average Loss=6.345914363861084, Class Loss=0.6179525256156921, Reg Loss=5.727962017059326
Current Client Index:  28
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.181725263595581, Reg Loss=15.370417594909668
Clinet index 28, End of Epoch 1/6, Average Loss=16.552143096923828, Class Loss=1.181725263595581, Reg Loss=15.370417594909668
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9761311411857605, Reg Loss=12.006731986999512
Clinet index 28, End of Epoch 2/6, Average Loss=12.982863426208496, Class Loss=0.9761311411857605, Reg Loss=12.006731986999512
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 3, Class Loss=0.7253766655921936, Reg Loss=10.773824691772461
Clinet index 28, End of Epoch 3/6, Average Loss=11.499201774597168, Class Loss=0.7253766655921936, Reg Loss=10.773824691772461
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.5702334642410278, Reg Loss=10.612022399902344
Clinet index 28, End of Epoch 4/6, Average Loss=11.182255744934082, Class Loss=0.5702334642410278, Reg Loss=10.612022399902344
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.41942062973976135, Reg Loss=9.590789794921875
Clinet index 28, End of Epoch 5/6, Average Loss=10.010210037231445, Class Loss=0.41942062973976135, Reg Loss=9.590789794921875
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.348282128572464, Reg Loss=8.828043937683105
Clinet index 28, End of Epoch 6/6, Average Loss=9.176325798034668, Class Loss=0.348282128572464, Reg Loss=8.828043937683105
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.1458725929260254, Reg Loss=15.036980628967285
Clinet index 20, End of Epoch 1/6, Average Loss=16.18285369873047, Class Loss=1.1458725929260254, Reg Loss=15.036980628967285
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9667349457740784, Reg Loss=11.957460403442383
Clinet index 20, End of Epoch 2/6, Average Loss=12.924195289611816, Class Loss=0.9667349457740784, Reg Loss=11.957460403442383
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6688816547393799, Reg Loss=10.566793441772461
Clinet index 20, End of Epoch 3/6, Average Loss=11.235674858093262, Class Loss=0.6688816547393799, Reg Loss=10.566793441772461
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=0.5212991237640381, Reg Loss=10.07278823852539
Clinet index 20, End of Epoch 4/6, Average Loss=10.594087600708008, Class Loss=0.5212991237640381, Reg Loss=10.07278823852539
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.40232476592063904, Reg Loss=9.32152271270752
Clinet index 20, End of Epoch 5/6, Average Loss=9.723847389221191, Class Loss=0.40232476592063904, Reg Loss=9.32152271270752
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 6, Class Loss=0.36759817600250244, Reg Loss=8.99792766571045
Clinet index 20, End of Epoch 6/6, Average Loss=9.36552619934082, Class Loss=0.36759817600250244, Reg Loss=8.99792766571045
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=7.2661116361618046
Loss made of: CE 0.7745003700256348, LKD 3.9892594814300537, LDE 2.339128017425537, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8226974010467529, Reg Loss=6.404101371765137
Clinet index 4, End of Epoch 1/6, Average Loss=7.226799011230469, Class Loss=0.8226974010467529, Reg Loss=6.404101371765137
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=6.71260034441948
Loss made of: CE 0.787463903427124, LKD 4.173649311065674, LDE 2.199038505554199, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7079706192016602, Reg Loss=6.152522563934326
Clinet index 4, End of Epoch 2/6, Average Loss=6.860493183135986, Class Loss=0.7079706192016602, Reg Loss=6.152522563934326
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=6.579895532131195
Loss made of: CE 0.5321807861328125, LKD 3.7531659603118896, LDE 2.007115602493286, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6863827109336853, Reg Loss=5.933481216430664
Clinet index 4, End of Epoch 3/6, Average Loss=6.619863986968994, Class Loss=0.6863827109336853, Reg Loss=5.933481216430664
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=6.7342109978199005
Loss made of: CE 0.6513900756835938, LKD 3.739264488220215, LDE 2.077944278717041, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6435601711273193, Reg Loss=5.989013195037842
Clinet index 4, End of Epoch 4/6, Average Loss=6.632573127746582, Class Loss=0.6435601711273193, Reg Loss=5.989013195037842
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=6.566975164413452
Loss made of: CE 0.6760863065719604, LKD 3.794978618621826, LDE 2.4987785816192627, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.659852147102356, Reg Loss=5.824002742767334
Clinet index 4, End of Epoch 5/6, Average Loss=6.4838547706604, Class Loss=0.659852147102356, Reg Loss=5.824002742767334
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=6.254050123691559
Loss made of: CE 0.6137038469314575, LKD 3.9769232273101807, LDE 1.7017937898635864, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6223847270011902, Reg Loss=5.723027229309082
Clinet index 4, End of Epoch 6/6, Average Loss=6.345411777496338, Class Loss=0.6223847270011902, Reg Loss=5.723027229309082
federated aggregation...
Validation, Class Loss=0.8123430609703064, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.769832
Mean Acc: 0.279965
FreqW Acc: 0.683684
Mean IoU: 0.226388
Class IoU:
	class 0: 0.8615984
	class 1: 0.5459554
	class 2: 0.034137506
	class 3: 0.0
	class 4: 0.5200559
	class 5: 0.024101505
	class 6: 0.62330395
	class 7: 0.4013159
	class 8: 0.0
	class 9: 0.0079269875
	class 10: 0.0
	class 11: 0.0
	class 12: 0.00036299814
	class 13: 0.12451497
	class 14: 0.13402644
	class 15: 0.73099613
	class 16: 0.14287418
	class 17: 0.1000507
	class 18: 0.05015915
Class Acc:
	class 0: 0.9623056
	class 1: 0.5486136
	class 2: 0.036438305
	class 3: 0.0
	class 4: 0.54290736
	class 5: 0.024102366
	class 6: 0.6253294
	class 7: 0.40204987
	class 8: 0.0
	class 9: 0.007942126
	class 10: 0.0
	class 11: 0.0
	class 12: 0.00036300128
	class 13: 0.6662282
	class 14: 0.15637608
	class 15: 0.79026705
	class 16: 0.14762515
	class 17: 0.12176654
	class 18: 0.2870232

federated global round: 27, step: 5
select part of clients to conduct local training
[24, 8, 26, 0]
Current Client Index:  24
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=8.539296531677246
Loss made of: CE 0.7815299034118652, LKD 4.00227165222168, LDE 2.807884693145752, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7533001899719238, Reg Loss=7.582082271575928
Clinet index 24, End of Epoch 1/6, Average Loss=8.335382461547852, Class Loss=0.7533001899719238, Reg Loss=7.582082271575928
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/12, Loss=7.177748948335648
Loss made of: CE 0.7046465277671814, LKD 3.9475207328796387, LDE 2.794881820678711, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7124148607254028, Reg Loss=6.477628707885742
Clinet index 24, End of Epoch 2/6, Average Loss=7.1900434494018555, Class Loss=0.7124148607254028, Reg Loss=6.477628707885742
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/12, Loss=6.742420476675034
Loss made of: CE 0.6699268221855164, LKD 3.8951244354248047, LDE 2.000678062438965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6815627813339233, Reg Loss=5.989909648895264
Clinet index 24, End of Epoch 3/6, Average Loss=6.671472549438477, Class Loss=0.6815627813339233, Reg Loss=5.989909648895264
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/12, Loss=6.704584330320358
Loss made of: CE 0.6531907320022583, LKD 3.9087414741516113, LDE 2.26674485206604, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6546948552131653, Reg Loss=6.032733917236328
Clinet index 24, End of Epoch 4/6, Average Loss=6.687428951263428, Class Loss=0.6546948552131653, Reg Loss=6.032733917236328
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/12, Loss=6.362725752592087
Loss made of: CE 0.6960394382476807, LKD 4.131493091583252, LDE 2.341644525527954, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6477593779563904, Reg Loss=5.702220916748047
Clinet index 24, End of Epoch 5/6, Average Loss=6.349980354309082, Class Loss=0.6477593779563904, Reg Loss=5.702220916748047
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/12, Loss=6.414721661806107
Loss made of: CE 0.5927751064300537, LKD 3.2318830490112305, LDE 2.0960564613342285, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6653634309768677, Reg Loss=5.82850980758667
Clinet index 24, End of Epoch 6/6, Average Loss=6.493873119354248, Class Loss=0.6653634309768677, Reg Loss=5.82850980758667
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6510138511657715, Reg Loss=10.921835899353027
Clinet index 8, End of Epoch 1/6, Average Loss=11.57284927368164, Class Loss=0.6510138511657715, Reg Loss=10.921835899353027
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.549631655216217, Reg Loss=9.618258476257324
Clinet index 8, End of Epoch 2/6, Average Loss=10.167890548706055, Class Loss=0.549631655216217, Reg Loss=9.618258476257324
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Class Loss=0.4342910647392273, Reg Loss=9.335836410522461
Clinet index 8, End of Epoch 3/6, Average Loss=9.770127296447754, Class Loss=0.4342910647392273, Reg Loss=9.335836410522461
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.3748575747013092, Reg Loss=8.549118041992188
Clinet index 8, End of Epoch 4/6, Average Loss=8.923975944519043, Class Loss=0.3748575747013092, Reg Loss=8.549118041992188
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.34184762835502625, Reg Loss=8.668907165527344
Clinet index 8, End of Epoch 5/6, Average Loss=9.010754585266113, Class Loss=0.34184762835502625, Reg Loss=8.668907165527344
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.31680887937545776, Reg Loss=8.376440048217773
Clinet index 8, End of Epoch 6/6, Average Loss=8.693248748779297, Class Loss=0.31680887937545776, Reg Loss=8.376440048217773
Current Client Index:  26
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=8.324642568826675
Loss made of: CE 0.7115961909294128, LKD 3.6158628463745117, LDE 2.746389389038086, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7377245426177979, Reg Loss=7.473658561706543
Clinet index 26, End of Epoch 1/6, Average Loss=8.211382865905762, Class Loss=0.7377245426177979, Reg Loss=7.473658561706543
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=6.972252869606018
Loss made of: CE 0.6172165870666504, LKD 3.8375587463378906, LDE 2.9049642086029053, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6786544322967529, Reg Loss=6.2230682373046875
Clinet index 26, End of Epoch 2/6, Average Loss=6.9017229080200195, Class Loss=0.6786544322967529, Reg Loss=6.2230682373046875
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=6.649804323911667
Loss made of: CE 0.6615408658981323, LKD 3.0821688175201416, LDE 2.339930534362793, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6404480934143066, Reg Loss=5.944705009460449
Clinet index 26, End of Epoch 3/6, Average Loss=6.585153102874756, Class Loss=0.6404480934143066, Reg Loss=5.944705009460449
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=6.568454986810684
Loss made of: CE 0.5981777906417847, LKD 3.5637691020965576, LDE 2.14674973487854, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6317557692527771, Reg Loss=5.864160060882568
Clinet index 26, End of Epoch 4/6, Average Loss=6.49591588973999, Class Loss=0.6317557692527771, Reg Loss=5.864160060882568
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=6.266797548532486
Loss made of: CE 0.5212317705154419, LKD 3.358482599258423, LDE 2.4871480464935303, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6143138408660889, Reg Loss=5.748295783996582
Clinet index 26, End of Epoch 5/6, Average Loss=6.36260986328125, Class Loss=0.6143138408660889, Reg Loss=5.748295783996582
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=6.4436565101146694
Loss made of: CE 0.5263357162475586, LKD 3.4122962951660156, LDE 2.5369908809661865, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.629979133605957, Reg Loss=5.705636501312256
Clinet index 26, End of Epoch 6/6, Average Loss=6.335615634918213, Class Loss=0.629979133605957, Reg Loss=5.705636501312256
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=8.440676295757294
Loss made of: CE 0.775984525680542, LKD 3.4721150398254395, LDE 2.907106637954712, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7697101831436157, Reg Loss=7.57813024520874
Clinet index 0, End of Epoch 1/6, Average Loss=8.347840309143066, Class Loss=0.7697101831436157, Reg Loss=7.57813024520874
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=7.089871007204056
Loss made of: CE 0.5997425317764282, LKD 3.916402578353882, LDE 2.25666880607605, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6893773078918457, Reg Loss=6.407319068908691
Clinet index 0, End of Epoch 2/6, Average Loss=7.096696376800537, Class Loss=0.6893773078918457, Reg Loss=6.407319068908691
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=6.832682853937149
Loss made of: CE 0.5491723418235779, LKD 3.2756335735321045, LDE 3.5089519023895264, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.652371346950531, Reg Loss=6.21816349029541
Clinet index 0, End of Epoch 3/6, Average Loss=6.870534896850586, Class Loss=0.652371346950531, Reg Loss=6.21816349029541
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=6.471459889411927
Loss made of: CE 0.6624276041984558, LKD 3.620748519897461, LDE 2.236614227294922, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.638972282409668, Reg Loss=5.896477699279785
Clinet index 0, End of Epoch 4/6, Average Loss=6.535449981689453, Class Loss=0.638972282409668, Reg Loss=5.896477699279785
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=6.388989734649658
Loss made of: CE 0.6029000282287598, LKD 3.6594648361206055, LDE 2.0676982402801514, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6403883099555969, Reg Loss=5.726902008056641
Clinet index 0, End of Epoch 5/6, Average Loss=6.367290496826172, Class Loss=0.6403883099555969, Reg Loss=5.726902008056641
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=6.460095891356469
Loss made of: CE 0.5613887906074524, LKD 3.2280049324035645, LDE 2.3569912910461426, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6224102973937988, Reg Loss=5.821413040161133
Clinet index 0, End of Epoch 6/6, Average Loss=6.443823337554932, Class Loss=0.6224102973937988, Reg Loss=5.821413040161133
federated aggregation...
Validation, Class Loss=0.8990364670753479, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.741348
Mean Acc: 0.253443
FreqW Acc: 0.665146
Mean IoU: 0.190409
Class IoU:
	class 0: 0.84857607
	class 1: 0.38881865
	class 2: 0.0014161074
	class 3: 0.0
	class 4: 0.4427943
	class 5: 0.0013972592
	class 6: 0.52711344
	class 7: 0.11114291
	class 8: 0.0
	class 9: 0.0038253067
	class 10: 0.0
	class 11: 0.0
	class 12: 1.9604029e-06
	class 13: 0.13270183
	class 14: 0.1211502
	class 15: 0.7371543
	class 16: 0.054685358
	class 17: 0.18453765
	class 18: 0.06246242
Class Acc:
	class 0: 0.9306873
	class 1: 0.3896923
	class 2: 0.0014191158
	class 3: 0.0
	class 4: 0.45862722
	class 5: 0.00139726
	class 6: 0.528219
	class 7: 0.11120856
	class 8: 0.0
	class 9: 0.0038317132
	class 10: 0.0
	class 11: 0.0
	class 12: 1.9604029e-06
	class 13: 0.55285037
	class 14: 0.12996759
	class 15: 0.79276407
	class 16: 0.055012636
	class 17: 0.2701449
	class 18: 0.589587

federated global round: 28, step: 5
select part of clients to conduct local training
[8, 9, 16, 3]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.714910626411438, Reg Loss=13.364635467529297
Clinet index 8, End of Epoch 1/6, Average Loss=14.079545974731445, Class Loss=0.714910626411438, Reg Loss=13.364635467529297
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.588836669921875, Reg Loss=10.805100440979004
Clinet index 8, End of Epoch 2/6, Average Loss=11.393937110900879, Class Loss=0.588836669921875, Reg Loss=10.805100440979004
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.49043264985084534, Reg Loss=10.114768981933594
Clinet index 8, End of Epoch 3/6, Average Loss=10.605201721191406, Class Loss=0.49043264985084534, Reg Loss=10.114768981933594
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.4282452166080475, Reg Loss=9.455212593078613
Clinet index 8, End of Epoch 4/6, Average Loss=9.883458137512207, Class Loss=0.4282452166080475, Reg Loss=9.455212593078613
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.3798935115337372, Reg Loss=9.010869026184082
Clinet index 8, End of Epoch 5/6, Average Loss=9.390762329101562, Class Loss=0.3798935115337372, Reg Loss=9.010869026184082
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.3702913224697113, Reg Loss=8.731314659118652
Clinet index 8, End of Epoch 6/6, Average Loss=9.101606369018555, Class Loss=0.3702913224697113, Reg Loss=8.731314659118652
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.717766523361206, Reg Loss=13.04353141784668
Clinet index 9, End of Epoch 1/6, Average Loss=13.761298179626465, Class Loss=0.717766523361206, Reg Loss=13.04353141784668
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5562661290168762, Reg Loss=10.523144721984863
Clinet index 9, End of Epoch 2/6, Average Loss=11.079410552978516, Class Loss=0.5562661290168762, Reg Loss=10.523144721984863
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.43691787123680115, Reg Loss=9.595450401306152
Clinet index 9, End of Epoch 3/6, Average Loss=10.032368659973145, Class Loss=0.43691787123680115, Reg Loss=9.595450401306152
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.380153626203537, Reg Loss=9.339485168457031
Clinet index 9, End of Epoch 4/6, Average Loss=9.71963882446289, Class Loss=0.380153626203537, Reg Loss=9.339485168457031
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.32634150981903076, Reg Loss=8.553108215332031
Clinet index 9, End of Epoch 5/6, Average Loss=8.879449844360352, Class Loss=0.32634150981903076, Reg Loss=8.553108215332031
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 6, Class Loss=0.34339818358421326, Reg Loss=9.005544662475586
Clinet index 9, End of Epoch 6/6, Average Loss=9.348942756652832, Class Loss=0.34339818358421326, Reg Loss=9.005544662475586
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=6.971464079618454
Loss made of: CE 0.6616118550300598, LKD 3.193432092666626, LDE 2.816192388534546, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6719462871551514, Reg Loss=6.2289252281188965
Clinet index 16, End of Epoch 1/6, Average Loss=6.900871276855469, Class Loss=0.6719462871551514, Reg Loss=6.2289252281188965
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=6.312040185928344
Loss made of: CE 0.6144552230834961, LKD 3.4978203773498535, LDE 2.115028142929077, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6585743427276611, Reg Loss=5.644384384155273
Clinet index 16, End of Epoch 2/6, Average Loss=6.3029584884643555, Class Loss=0.6585743427276611, Reg Loss=5.644384384155273
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=6.036689248681069
Loss made of: CE 0.6591980457305908, LKD 3.471290349960327, LDE 1.8853269815444946, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6124458909034729, Reg Loss=5.489842891693115
Clinet index 16, End of Epoch 3/6, Average Loss=6.102288722991943, Class Loss=0.6124458909034729, Reg Loss=5.489842891693115
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=6.044722306728363
Loss made of: CE 0.6036688089370728, LKD 3.7037291526794434, LDE 1.9059433937072754, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6407544612884521, Reg Loss=5.4302825927734375
Clinet index 16, End of Epoch 4/6, Average Loss=6.071037292480469, Class Loss=0.6407544612884521, Reg Loss=5.4302825927734375
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=6.002589637041092
Loss made of: CE 0.6099605560302734, LKD 3.2869086265563965, LDE 1.545017957687378, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6154901385307312, Reg Loss=5.36201286315918
Clinet index 16, End of Epoch 5/6, Average Loss=5.977502822875977, Class Loss=0.6154901385307312, Reg Loss=5.36201286315918
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=6.310622918605804
Loss made of: CE 0.5958718657493591, LKD 3.633157968521118, LDE 1.8966671228408813, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6044053435325623, Reg Loss=5.655564785003662
Clinet index 16, End of Epoch 6/6, Average Loss=6.259970188140869, Class Loss=0.6044053435325623, Reg Loss=5.655564785003662
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=6.889234030246735
Loss made of: CE 0.6386999487876892, LKD 4.064464569091797, LDE 2.5471737384796143, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6392571926116943, Reg Loss=6.118865489959717
Clinet index 3, End of Epoch 1/6, Average Loss=6.758122444152832, Class Loss=0.6392571926116943, Reg Loss=6.118865489959717
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=6.54690780043602
Loss made of: CE 0.5999476909637451, LKD 3.735297203063965, LDE 2.131237745285034, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6080527305603027, Reg Loss=5.8821234703063965
Clinet index 3, End of Epoch 2/6, Average Loss=6.490176200866699, Class Loss=0.6080527305603027, Reg Loss=5.8821234703063965
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=6.40082773566246
Loss made of: CE 0.6347627639770508, LKD 4.218289375305176, LDE 2.416588306427002, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6122522354125977, Reg Loss=5.835616588592529
Clinet index 3, End of Epoch 3/6, Average Loss=6.447868824005127, Class Loss=0.6122522354125977, Reg Loss=5.835616588592529
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=6.529068148136139
Loss made of: CE 0.571629524230957, LKD 3.6577322483062744, LDE 1.86447274684906, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5914813876152039, Reg Loss=5.790938854217529
Clinet index 3, End of Epoch 4/6, Average Loss=6.382420063018799, Class Loss=0.5914813876152039, Reg Loss=5.790938854217529
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=6.178005006909371
Loss made of: CE 0.5450922250747681, LKD 3.001784086227417, LDE 2.1884732246398926, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5776985883712769, Reg Loss=5.5532546043396
Clinet index 3, End of Epoch 5/6, Average Loss=6.130953311920166, Class Loss=0.5776985883712769, Reg Loss=5.5532546043396
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=6.164619934558869
Loss made of: CE 0.6087635159492493, LKD 3.619152307510376, LDE 1.5960652828216553, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5902020931243896, Reg Loss=5.617676734924316
Clinet index 3, End of Epoch 6/6, Average Loss=6.207879066467285, Class Loss=0.5902020931243896, Reg Loss=5.617676734924316
federated aggregation...
Validation, Class Loss=0.8823291063308716, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.760012
Mean Acc: 0.292938
FreqW Acc: 0.677114
Mean IoU: 0.209464
Class IoU:
	class 0: 0.8586013
	class 1: 0.47745088
	class 2: 0.012185833
	class 3: 0.0
	class 4: 0.47939482
	class 5: 0.017051654
	class 6: 0.57622826
	class 7: 0.21669012
	class 8: 0.0
	class 9: 0.0059435787
	class 10: 0.0
	class 11: 0.0
	class 12: 9.584183e-06
	class 13: 0.142992
	class 14: 0.12959102
	class 15: 0.73726594
	class 16: 0.11474583
	class 17: 0.12360002
	class 18: 0.08806139
Class Acc:
	class 0: 0.94657874
	class 1: 0.47883826
	class 2: 0.01249897
	class 3: 0.0
	class 4: 0.49605128
	class 5: 0.017051654
	class 6: 0.5778117
	class 7: 0.21690977
	class 8: 0.0
	class 9: 0.005952335
	class 10: 0.0
	class 11: 0.0
	class 12: 9.584192e-06
	class 13: 0.42978796
	class 14: 0.15057826
	class 15: 0.7929404
	class 16: 0.117457576
	class 17: 0.81454587
	class 18: 0.5088159

federated global round: 29, step: 5
select part of clients to conduct local training
[29, 27, 26, 18]
Current Client Index:  29
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=7.800786995887757
Loss made of: CE 0.6024943590164185, LKD 3.277437448501587, LDE 3.5104289054870605, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6930906176567078, Reg Loss=6.910825729370117
Clinet index 29, End of Epoch 1/6, Average Loss=7.603916168212891, Class Loss=0.6930906176567078, Reg Loss=6.910825729370117
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=6.828029382228851
Loss made of: CE 0.5892398953437805, LKD 3.606529474258423, LDE 2.0467464923858643, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6122903227806091, Reg Loss=6.11466121673584
Clinet index 29, End of Epoch 2/6, Average Loss=6.726951599121094, Class Loss=0.6122903227806091, Reg Loss=6.11466121673584
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=6.124378180503845
Loss made of: CE 0.538906991481781, LKD 3.462038516998291, LDE 1.9009137153625488, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6158463954925537, Reg Loss=5.589315414428711
Clinet index 29, End of Epoch 3/6, Average Loss=6.205162048339844, Class Loss=0.6158463954925537, Reg Loss=5.589315414428711
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=6.2580310046672825
Loss made of: CE 0.6022524833679199, LKD 3.7419848442077637, LDE 1.8170289993286133, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.592293381690979, Reg Loss=5.600502967834473
Clinet index 29, End of Epoch 4/6, Average Loss=6.192796230316162, Class Loss=0.592293381690979, Reg Loss=5.600502967834473
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=6.264602732658386
Loss made of: CE 0.5652272701263428, LKD 3.6707234382629395, LDE 2.744680643081665, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5901619791984558, Reg Loss=5.551048278808594
Clinet index 29, End of Epoch 5/6, Average Loss=6.141210079193115, Class Loss=0.5901619791984558, Reg Loss=5.551048278808594
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=6.267164891958236
Loss made of: CE 0.6034951210021973, LKD 3.827441930770874, LDE 1.6958262920379639, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5909586548805237, Reg Loss=5.648162364959717
Clinet index 29, End of Epoch 6/6, Average Loss=6.239120960235596, Class Loss=0.5909586548805237, Reg Loss=5.648162364959717
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5473844408988953, Reg Loss=11.250558853149414
Clinet index 27, End of Epoch 1/6, Average Loss=11.797943115234375, Class Loss=0.5473844408988953, Reg Loss=11.250558853149414
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.447765588760376, Reg Loss=9.969883918762207
Clinet index 27, End of Epoch 2/6, Average Loss=10.417649269104004, Class Loss=0.447765588760376, Reg Loss=9.969883918762207
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.36604639887809753, Reg Loss=9.16804027557373
Clinet index 27, End of Epoch 3/6, Average Loss=9.534086227416992, Class Loss=0.36604639887809753, Reg Loss=9.16804027557373
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.3439905345439911, Reg Loss=8.951180458068848
Clinet index 27, End of Epoch 4/6, Average Loss=9.295170783996582, Class Loss=0.3439905345439911, Reg Loss=8.951180458068848
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.34862691164016724, Reg Loss=8.804952621459961
Clinet index 27, End of Epoch 5/6, Average Loss=9.153579711914062, Class Loss=0.34862691164016724, Reg Loss=8.804952621459961
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.3323611319065094, Reg Loss=8.675549507141113
Clinet index 27, End of Epoch 6/6, Average Loss=9.00791072845459, Class Loss=0.3323611319065094, Reg Loss=8.675549507141113
Current Client Index:  26
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/12, Loss=7.815462970733643
Loss made of: CE 0.6842947006225586, LKD 3.511777877807617, LDE 2.4865801334381104, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6841546297073364, Reg Loss=7.032703399658203
Clinet index 26, End of Epoch 1/6, Average Loss=7.71685791015625, Class Loss=0.6841546297073364, Reg Loss=7.032703399658203
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/12, Loss=6.811156171560287
Loss made of: CE 0.620006263256073, LKD 3.817363739013672, LDE 2.855417490005493, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6716370582580566, Reg Loss=6.092304229736328
Clinet index 26, End of Epoch 2/6, Average Loss=6.763941287994385, Class Loss=0.6716370582580566, Reg Loss=6.092304229736328
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/12, Loss=6.40324564576149
Loss made of: CE 0.596977174282074, LKD 3.0405681133270264, LDE 1.9880894422531128, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6135638952255249, Reg Loss=5.765161514282227
Clinet index 26, End of Epoch 3/6, Average Loss=6.378725528717041, Class Loss=0.6135638952255249, Reg Loss=5.765161514282227
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/12, Loss=6.417625570297242
Loss made of: CE 0.5987510681152344, LKD 3.60954213142395, LDE 2.0803310871124268, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6138134002685547, Reg Loss=5.760078430175781
Clinet index 26, End of Epoch 4/6, Average Loss=6.373891830444336, Class Loss=0.6138134002685547, Reg Loss=5.760078430175781
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/12, Loss=6.100109541416169
Loss made of: CE 0.5559217929840088, LKD 3.230269193649292, LDE 2.2557098865509033, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6145777702331543, Reg Loss=5.577113628387451
Clinet index 26, End of Epoch 5/6, Average Loss=6.1916913986206055, Class Loss=0.6145777702331543, Reg Loss=5.577113628387451
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/12, Loss=6.329846748709679
Loss made of: CE 0.46617135405540466, LKD 3.2563023567199707, LDE 2.3992505073547363, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6101431846618652, Reg Loss=5.6509928703308105
Clinet index 26, End of Epoch 6/6, Average Loss=6.261136054992676, Class Loss=0.6101431846618652, Reg Loss=5.6509928703308105
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=7.796544671058655
Loss made of: CE 0.6084564328193665, LKD 3.4132533073425293, LDE 2.6313891410827637, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.706979513168335, Reg Loss=6.944239616394043
Clinet index 18, End of Epoch 1/6, Average Loss=7.651219367980957, Class Loss=0.706979513168335, Reg Loss=6.944239616394043
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=6.675737476348877
Loss made of: CE 0.6219046115875244, LKD 3.1820662021636963, LDE 2.4463369846343994, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6498957872390747, Reg Loss=5.987726211547852
Clinet index 18, End of Epoch 2/6, Average Loss=6.637621879577637, Class Loss=0.6498957872390747, Reg Loss=5.987726211547852
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=6.432877004146576
Loss made of: CE 0.594103217124939, LKD 3.3103785514831543, LDE 1.9661402702331543, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6326603889465332, Reg Loss=5.74619197845459
Clinet index 18, End of Epoch 3/6, Average Loss=6.378852367401123, Class Loss=0.6326603889465332, Reg Loss=5.74619197845459
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=6.480549997091293
Loss made of: CE 0.650162935256958, LKD 3.679398536682129, LDE 2.152547597885132, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6153122782707214, Reg Loss=5.7911224365234375
Clinet index 18, End of Epoch 4/6, Average Loss=6.406434535980225, Class Loss=0.6153122782707214, Reg Loss=5.7911224365234375
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=6.460254812240601
Loss made of: CE 0.6052698493003845, LKD 3.3266096115112305, LDE 2.489955425262451, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5996654629707336, Reg Loss=5.917420387268066
Clinet index 18, End of Epoch 5/6, Average Loss=6.517086029052734, Class Loss=0.5996654629707336, Reg Loss=5.917420387268066
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=6.071723213791847
Loss made of: CE 0.6052989959716797, LKD 3.1622090339660645, LDE 2.225457191467285, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6164054870605469, Reg Loss=5.500357627868652
Clinet index 18, End of Epoch 6/6, Average Loss=6.116763114929199, Class Loss=0.6164054870605469, Reg Loss=5.500357627868652
federated aggregation...
Validation, Class Loss=0.930314838886261, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.738883
Mean Acc: 0.270176
FreqW Acc: 0.660220
Mean IoU: 0.185734
Class IoU:
	class 0: 0.8437495
	class 1: 0.397702
	class 2: 0.0013761694
	class 3: 0.0
	class 4: 0.4213237
	class 5: 0.0034808882
	class 6: 0.49341425
	class 7: 0.09363966
	class 8: 0.0
	class 9: 0.003322402
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.1311375
	class 14: 0.10934067
	class 15: 0.7334732
	class 16: 0.075874254
	class 17: 0.14036076
	class 18: 0.08075642
Class Acc:
	class 0: 0.9240029
	class 1: 0.39856583
	class 2: 0.0013804126
	class 3: 0.0
	class 4: 0.4334078
	class 5: 0.0034808882
	class 6: 0.4942855
	class 7: 0.093686216
	class 8: 0.0
	class 9: 0.00332864
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.40228805
	class 14: 0.12037281
	class 15: 0.78771496
	class 16: 0.07652368
	class 17: 0.71960306
	class 18: 0.6746964

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 30, step: 6
select part of clients to conduct local training
[10, 30, 4, 33]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 1, Batch 10/12, Loss=18.294110703468323
Loss made of: CE 2.340780258178711, LKD 4.966508388519287, LDE 10.046903610229492, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=2.046717643737793, Reg Loss=15.65937328338623
Clinet index 10, End of Epoch 1/6, Average Loss=17.706090927124023, Class Loss=2.046717643737793, Reg Loss=15.65937328338623
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=12.643948626518249
Loss made of: CE 1.86989164352417, LKD 4.78392219543457, LDE 6.679520606994629, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.4897478818893433, Reg Loss=10.930305480957031
Clinet index 10, End of Epoch 2/6, Average Loss=12.420053482055664, Class Loss=1.4897478818893433, Reg Loss=10.930305480957031
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=10.01343115568161
Loss made of: CE 0.873727023601532, LKD 4.328718185424805, LDE 4.83323335647583, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8520683646202087, Reg Loss=9.075637817382812
Clinet index 10, End of Epoch 3/6, Average Loss=9.927705764770508, Class Loss=0.8520683646202087, Reg Loss=9.075637817382812
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=8.956200620532035
Loss made of: CE 0.3381462097167969, LKD 3.655698776245117, LDE 3.9217300415039062, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch 4, Class Loss=0.48787161707878113, Reg Loss=8.461593627929688
Clinet index 10, End of Epoch 4/6, Average Loss=8.949464797973633, Class Loss=0.48787161707878113, Reg Loss=8.461593627929688
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=8.290827742218971
Loss made of: CE 0.28304538130760193, LKD 3.894561529159546, LDE 3.6796047687530518, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.332784503698349, Reg Loss=8.04755687713623
Clinet index 10, End of Epoch 5/6, Average Loss=8.380341529846191, Class Loss=0.332784503698349, Reg Loss=8.04755687713623
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=8.401060009002686
Loss made of: CE 0.301591694355011, LKD 3.214296340942383, LDE 4.642119407653809, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29399868845939636, Reg Loss=8.025636672973633
Clinet index 10, End of Epoch 6/6, Average Loss=8.319635391235352, Class Loss=0.29399868845939636, Reg Loss=8.025636672973633
Current Client Index:  30
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=10.969089674949647
Loss made of: CE 1.2088921070098877, LKD 3.558014392852783, LDE 4.469092845916748, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.3305649757385254, Reg Loss=9.11431884765625
Clinet index 30, End of Epoch 1/6, Average Loss=10.444883346557617, Class Loss=1.3305649757385254, Reg Loss=9.11431884765625
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=8.15121698975563
Loss made of: CE 0.9847835898399353, LKD 3.494849681854248, LDE 2.6499319076538086, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.113585352897644, Reg Loss=6.980331897735596
Clinet index 30, End of Epoch 2/6, Average Loss=8.093916893005371, Class Loss=1.113585352897644, Reg Loss=6.980331897735596
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=7.100555175542832
Loss made of: CE 0.7633532285690308, LKD 4.163302898406982, LDE 2.0555405616760254, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.9122551083564758, Reg Loss=6.208652973175049
Clinet index 30, End of Epoch 3/6, Average Loss=7.120908260345459, Class Loss=0.9122551083564758, Reg Loss=6.208652973175049
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=6.630268085002899
Loss made of: CE 0.8384441137313843, LKD 3.646761178970337, LDE 1.7544535398483276, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.748141884803772, Reg Loss=5.918757915496826
Clinet index 30, End of Epoch 4/6, Average Loss=6.666899681091309, Class Loss=0.748141884803772, Reg Loss=5.918757915496826
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=6.487767031788826
Loss made of: CE 0.6823204755783081, LKD 3.1861555576324463, LDE 3.0668816566467285, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6143814921379089, Reg Loss=5.83378267288208
Clinet index 30, End of Epoch 5/6, Average Loss=6.448163986206055, Class Loss=0.6143814921379089, Reg Loss=5.83378267288208
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=6.173193734884262
Loss made of: CE 0.6333405375480652, LKD 3.962963104248047, LDE 2.198622703552246, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5375692844390869, Reg Loss=5.638127326965332
Clinet index 30, End of Epoch 6/6, Average Loss=6.17569637298584, Class Loss=0.5375692844390869, Reg Loss=5.638127326965332
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Batch 10/12, Loss=18.298130130767824
Loss made of: CE 2.18985652923584, LKD 4.327154159545898, LDE 8.387004852294922, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.9855091571807861, Reg Loss=15.484161376953125
Clinet index 4, End of Epoch 1/6, Average Loss=17.46967124938965, Class Loss=1.9855091571807861, Reg Loss=15.484161376953125
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=11.821601152420044
Loss made of: CE 1.2314013242721558, LKD 3.617306709289551, LDE 6.7436652183532715, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3722513914108276, Reg Loss=10.521726608276367
Clinet index 4, End of Epoch 2/6, Average Loss=11.893978118896484, Class Loss=1.3722513914108276, Reg Loss=10.521726608276367
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 3, Batch 10/12, Loss=10.05863431096077
Loss made of: CE 0.9586997032165527, LKD 4.192417144775391, LDE 5.143797397613525, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8358883857727051, Reg Loss=9.139455795288086
Clinet index 4, End of Epoch 3/6, Average Loss=9.975343704223633, Class Loss=0.8358883857727051, Reg Loss=9.139455795288086
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=9.159292709827422
Loss made of: CE 0.38580235838890076, LKD 3.8354196548461914, LDE 5.072615623474121, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4917334318161011, Reg Loss=8.458351135253906
Clinet index 4, End of Epoch 4/6, Average Loss=8.950084686279297, Class Loss=0.4917334318161011, Reg Loss=8.458351135253906
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=8.086118334531784
Loss made of: CE 0.2919917106628418, LKD 3.811765432357788, LDE 4.1956634521484375, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.32130149006843567, Reg Loss=7.86888313293457
Clinet index 4, End of Epoch 5/6, Average Loss=8.190184593200684, Class Loss=0.32130149006843567, Reg Loss=7.86888313293457
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=8.135349708795548
Loss made of: CE 0.28247031569480896, LKD 2.860543727874756, LDE 4.9582743644714355, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.290011465549469, Reg Loss=7.8482794761657715
Clinet index 4, End of Epoch 6/6, Average Loss=8.138291358947754, Class Loss=0.290011465549469, Reg Loss=7.8482794761657715
Current Client Index:  33
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=17.23058902025223
Loss made of: CE 1.587628722190857, LKD 3.6828231811523438, LDE 8.370523452758789, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.9083020687103271, Reg Loss=14.778178215026855
Clinet index 33, End of Epoch 1/6, Average Loss=16.686479568481445, Class Loss=1.9083020687103271, Reg Loss=14.778178215026855
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=12.012773561477662
Loss made of: CE 1.2590453624725342, LKD 3.9369266033172607, LDE 5.396770477294922, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=1.3351796865463257, Reg Loss=10.466499328613281
Clinet index 33, End of Epoch 2/6, Average Loss=11.801678657531738, Class Loss=1.3351796865463257, Reg Loss=10.466499328613281
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=9.703931242227554
Loss made of: CE 0.6519361734390259, LKD 3.950007677078247, LDE 5.200320243835449, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7653861045837402, Reg Loss=8.888971328735352
Clinet index 33, End of Epoch 3/6, Average Loss=9.65435791015625, Class Loss=0.7653861045837402, Reg Loss=8.888971328735352
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=8.62509689629078
Loss made of: CE 0.28887873888015747, LKD 3.6341712474823, LDE 4.335599422454834, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.44372791051864624, Reg Loss=8.199979782104492
Clinet index 33, End of Epoch 4/6, Average Loss=8.643707275390625, Class Loss=0.44372791051864624, Reg Loss=8.199979782104492
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=8.442850854992866
Loss made of: CE 0.3337494730949402, LKD 4.090947151184082, LDE 4.079929828643799, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3064034879207611, Reg Loss=8.087946891784668
Clinet index 33, End of Epoch 5/6, Average Loss=8.394350051879883, Class Loss=0.3064034879207611, Reg Loss=8.087946891784668
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 6, Batch 10/12, Loss=8.192039355635643
Loss made of: CE 0.2645748555660248, LKD 4.013548851013184, LDE 3.8962836265563965, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch 6, Class Loss=0.2675762176513672, Reg Loss=8.022465705871582
Clinet index 33, End of Epoch 6/6, Average Loss=8.29004192352295, Class Loss=0.2675762176513672, Reg Loss=8.022465705871582
federated aggregation...
Validation, Class Loss=1.0209648609161377, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.713935
Mean Acc: 0.136120
FreqW Acc: 0.609980
Mean IoU: 0.091898
Class IoU:
	class 0: 0.83326334
	class 1: 0.053866215
	class 2: 0.0
	class 3: 0.0
	class 4: 0.10033363
	class 5: 0.0
	class 6: 0.053273972
	class 7: 0.042772636
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.016562685
	class 14: 0.0
	class 15: 0.4965343
	class 16: 0.03531608
	class 17: 0.13608891
	class 18: 0.086267926
	class 19: 0.07558707
	class 20: 0.0
Class Acc:
	class 0: 0.96352255
	class 1: 0.05387091
	class 2: 0.0
	class 3: 0.0
	class 4: 0.10068777
	class 5: 0.0
	class 6: 0.053294923
	class 7: 0.04277378
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.017681185
	class 14: 0.0
	class 15: 0.50611526
	class 16: 0.035396002
	class 17: 0.21601033
	class 18: 0.22422381
	class 19: 0.6449435
	class 20: 0.0

federated global round: 31, step: 6
select part of clients to conduct local training
[9, 17, 14, 1]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=10.07337337732315
Loss made of: CE 1.4200509786605835, LKD 3.459005832672119, LDE 3.810178518295288, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.1580880880355835, Reg Loss=8.500844955444336
Clinet index 9, End of Epoch 1/6, Average Loss=9.65893268585205, Class Loss=1.1580880880355835, Reg Loss=8.500844955444336
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=7.70515473484993
Loss made of: CE 0.7174302339553833, LKD 3.2484850883483887, LDE 2.480841875076294, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9781743288040161, Reg Loss=6.53090238571167
Clinet index 9, End of Epoch 2/6, Average Loss=7.5090765953063965, Class Loss=0.9781743288040161, Reg Loss=6.53090238571167
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=6.7456952929496765
Loss made of: CE 0.7063578367233276, LKD 3.305786371231079, LDE 2.4283266067504883, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7520531415939331, Reg Loss=5.862014293670654
Clinet index 9, End of Epoch 3/6, Average Loss=6.614067554473877, Class Loss=0.7520531415939331, Reg Loss=5.862014293670654
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=6.37720342874527
Loss made of: CE 0.5916773080825806, LKD 3.938089370727539, LDE 2.065706729888916, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6091839075088501, Reg Loss=5.69842529296875
Clinet index 9, End of Epoch 4/6, Average Loss=6.3076090812683105, Class Loss=0.6091839075088501, Reg Loss=5.69842529296875
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=6.1448404550552365
Loss made of: CE 0.4958462119102478, LKD 3.447481155395508, LDE 1.8592967987060547, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.554158091545105, Reg Loss=5.607243537902832
Clinet index 9, End of Epoch 5/6, Average Loss=6.161401748657227, Class Loss=0.554158091545105, Reg Loss=5.607243537902832
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=6.13235297203064
Loss made of: CE 0.4690401554107666, LKD 3.329911470413208, LDE 1.717379093170166, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5238520503044128, Reg Loss=5.47227668762207
Clinet index 9, End of Epoch 6/6, Average Loss=5.996128559112549, Class Loss=0.5238520503044128, Reg Loss=5.47227668762207
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=8.515886259078979
Loss made of: CE 0.29481637477874756, LKD 3.248868465423584, LDE 4.232089996337891, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.41440385580062866, Reg Loss=8.066902160644531
Clinet index 17, End of Epoch 1/6, Average Loss=8.481306076049805, Class Loss=0.41440385580062866, Reg Loss=8.066902160644531
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=7.933370307087898
Loss made of: CE 0.23345613479614258, LKD 3.688591241836548, LDE 3.704256534576416, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3251217305660248, Reg Loss=7.69832181930542
Clinet index 17, End of Epoch 2/6, Average Loss=8.023443222045898, Class Loss=0.3251217305660248, Reg Loss=7.69832181930542
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=7.463361795246601
Loss made of: CE 0.3120732307434082, LKD 4.318328857421875, LDE 2.990434169769287, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.282828688621521, Reg Loss=7.254762649536133
Clinet index 17, End of Epoch 3/6, Average Loss=7.537591457366943, Class Loss=0.282828688621521, Reg Loss=7.254762649536133
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=7.447022217512131
Loss made of: CE 0.2567477226257324, LKD 3.7906856536865234, LDE 2.9161219596862793, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=0.2569970190525055, Reg Loss=7.3074798583984375
Clinet index 17, End of Epoch 4/6, Average Loss=7.56447696685791, Class Loss=0.2569970190525055, Reg Loss=7.3074798583984375
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch 5, Batch 10/12, Loss=7.769598031044007
Loss made of: CE 0.2800241708755493, LKD 4.229704856872559, LDE 6.012768268585205, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25398313999176025, Reg Loss=7.552469253540039
Clinet index 17, End of Epoch 5/6, Average Loss=7.80645227432251, Class Loss=0.25398313999176025, Reg Loss=7.552469253540039
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=7.125485019385815
Loss made of: CE 0.20795655250549316, LKD 4.2272186279296875, LDE 2.782141923904419, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2480505108833313, Reg Loss=6.917229652404785
Clinet index 17, End of Epoch 6/6, Average Loss=7.165280342102051, Class Loss=0.2480505108833313, Reg Loss=6.917229652404785
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=9.916890239715576
Loss made of: CE 1.2741554975509644, LKD 3.7336812019348145, LDE 3.7539725303649902, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.1291989088058472, Reg Loss=8.319860458374023
Clinet index 14, End of Epoch 1/6, Average Loss=9.44905948638916, Class Loss=1.1291989088058472, Reg Loss=8.319860458374023
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=7.621831846237183
Loss made of: CE 0.6492255926132202, LKD 3.515597343444824, LDE 2.9691245555877686, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9258354306221008, Reg Loss=6.517788410186768
Clinet index 14, End of Epoch 2/6, Average Loss=7.443624019622803, Class Loss=0.9258354306221008, Reg Loss=6.517788410186768
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=6.738841319084168
Loss made of: CE 0.5902624130249023, LKD 3.5913496017456055, LDE 2.0958616733551025, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7568800449371338, Reg Loss=5.884037971496582
Clinet index 14, End of Epoch 3/6, Average Loss=6.640917778015137, Class Loss=0.7568800449371338, Reg Loss=5.884037971496582
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=6.148220586776733
Loss made of: CE 0.4916000962257385, LKD 3.4856882095336914, LDE 2.0131282806396484, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6223800778388977, Reg Loss=5.645787239074707
Clinet index 14, End of Epoch 4/6, Average Loss=6.268167495727539, Class Loss=0.6223800778388977, Reg Loss=5.645787239074707
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=6.080613660812378
Loss made of: CE 0.48252326250076294, LKD 3.295907497406006, LDE 1.67294180393219, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5530150532722473, Reg Loss=5.566817283630371
Clinet index 14, End of Epoch 5/6, Average Loss=6.119832515716553, Class Loss=0.5530150532722473, Reg Loss=5.566817283630371
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=5.930365052819252
Loss made of: CE 0.6279875040054321, LKD 3.547269821166992, LDE 3.0126543045043945, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5259791612625122, Reg Loss=5.3755388259887695
Clinet index 14, End of Epoch 6/6, Average Loss=5.901517868041992, Class Loss=0.5259791612625122, Reg Loss=5.3755388259887695
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=8.687229976058006
Loss made of: CE 0.3474613428115845, LKD 3.286590337753296, LDE 4.569351673126221, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.41878649592399597, Reg Loss=8.262725830078125
Clinet index 1, End of Epoch 1/6, Average Loss=8.681511878967285, Class Loss=0.41878649592399597, Reg Loss=8.262725830078125
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=8.000160837173462
Loss made of: CE 0.3497435748577118, LKD 3.9590067863464355, LDE 3.1339123249053955, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31883737444877625, Reg Loss=7.723240852355957
Clinet index 1, End of Epoch 2/6, Average Loss=8.042078018188477, Class Loss=0.31883737444877625, Reg Loss=7.723240852355957
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=7.729131680727005
Loss made of: CE 0.31296825408935547, LKD 4.368505954742432, LDE 3.307047128677368, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27179914712905884, Reg Loss=7.506639003753662
Clinet index 1, End of Epoch 3/6, Average Loss=7.778438091278076, Class Loss=0.27179914712905884, Reg Loss=7.506639003753662
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=7.512777034938336
Loss made of: CE 0.19782838225364685, LKD 3.8370118141174316, LDE 3.081409454345703, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24613726139068604, Reg Loss=7.244359970092773
Clinet index 1, End of Epoch 4/6, Average Loss=7.49049711227417, Class Loss=0.24613726139068604, Reg Loss=7.244359970092773
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=7.468195897340775
Loss made of: CE 0.24478237330913544, LKD 3.855454921722412, LDE 3.5738959312438965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24212151765823364, Reg Loss=7.144482612609863
Clinet index 1, End of Epoch 5/6, Average Loss=7.386604309082031, Class Loss=0.24212151765823364, Reg Loss=7.144482612609863
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 6, Batch 10/12, Loss=7.582438345253467
Loss made of: CE 0.25621092319488525, LKD 4.0673699378967285, LDE 3.1625173091888428, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24462565779685974, Reg Loss=7.2305521965026855
Clinet index 1, End of Epoch 6/6, Average Loss=7.475177764892578, Class Loss=0.24462565779685974, Reg Loss=7.2305521965026855
federated aggregation...
Validation, Class Loss=1.0325556993484497, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.712433
Mean Acc: 0.135869
FreqW Acc: 0.618765
Mean IoU: 0.091322
Class IoU:
	class 0: 0.8421365
	class 1: 0.053385615
	class 2: 0.0
	class 3: 0.0
	class 4: 0.09286069
	class 5: 0.0
	class 6: 0.013119635
	class 7: 0.017387304
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.009979478
	class 14: 1.9476086e-06
	class 15: 0.5636849
	class 16: 0.023608554
	class 17: 0.120329626
	class 18: 0.108136326
	class 19: 0.06956034
	class 20: 0.0035689238
Class Acc:
	class 0: 0.95602006
	class 1: 0.053390108
	class 2: 0.0
	class 3: 0.0
	class 4: 0.09339302
	class 5: 0.0
	class 6: 0.013122405
	class 7: 0.017387316
	class 8: 0.0
	class 9: 0.0
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.01076377
	class 14: 1.9476086e-06
	class 15: 0.5796551
	class 16: 0.023643896
	class 17: 0.15222307
	class 18: 0.30167896
	class 19: 0.6483943
	class 20: 0.0035689238

federated global round: 32, step: 6
select part of clients to conduct local training
[3, 8, 27, 7]
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=9.03187354505062
Loss made of: CE 0.3343231678009033, LKD 3.848752498626709, LDE 4.03308629989624, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4088626801967621, Reg Loss=8.411503791809082
Clinet index 3, End of Epoch 1/6, Average Loss=8.820366859436035, Class Loss=0.4088626801967621, Reg Loss=8.411503791809082
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=7.902007281780243
Loss made of: CE 0.3384801149368286, LKD 4.180093288421631, LDE 3.865241527557373, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3076314926147461, Reg Loss=7.523219585418701
Clinet index 3, End of Epoch 2/6, Average Loss=7.830851078033447, Class Loss=0.3076314926147461, Reg Loss=7.523219585418701
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=7.61969443410635
Loss made of: CE 0.2488008737564087, LKD 4.0131916999816895, LDE 3.963231325149536, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2781584858894348, Reg Loss=7.278079509735107
Clinet index 3, End of Epoch 3/6, Average Loss=7.556238174438477, Class Loss=0.2781584858894348, Reg Loss=7.278079509735107
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Batch 10/12, Loss=7.378655511140823
Loss made of: CE 0.26061949133872986, LKD 3.5742850303649902, LDE 2.9273033142089844, LReg 0.0, POD 0.0 EntMin 0.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=0.26772159337997437, Reg Loss=7.1260294914245605
Clinet index 3, End of Epoch 4/6, Average Loss=7.39375114440918, Class Loss=0.26772159337997437, Reg Loss=7.1260294914245605
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=7.237235340476036
Loss made of: CE 0.20958644151687622, LKD 3.156428098678589, LDE 3.866914749145508, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2567140460014343, Reg Loss=7.0062150955200195
Clinet index 3, End of Epoch 5/6, Average Loss=7.2629289627075195, Class Loss=0.2567140460014343, Reg Loss=7.0062150955200195
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=7.039052274823189
Loss made of: CE 0.2881070375442505, LKD 3.6169848442077637, LDE 2.775035858154297, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24498528242111206, Reg Loss=6.7886505126953125
Clinet index 3, End of Epoch 6/6, Average Loss=7.03363561630249, Class Loss=0.24498528242111206, Reg Loss=6.7886505126953125
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=7.556237030029297
Loss made of: CE 0.613798975944519, LKD 3.4466605186462402, LDE 2.555393695831299, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.783625066280365, Reg Loss=6.586122989654541
Clinet index 8, End of Epoch 1/6, Average Loss=7.369748115539551, Class Loss=0.783625066280365, Reg Loss=6.586122989654541
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=6.453523671627044
Loss made of: CE 0.6092036962509155, LKD 3.4073948860168457, LDE 2.1230313777923584, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6272223591804504, Reg Loss=5.728478908538818
Clinet index 8, End of Epoch 2/6, Average Loss=6.355701446533203, Class Loss=0.6272223591804504, Reg Loss=5.728478908538818
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=6.278886821866036
Loss made of: CE 0.561844527721405, LKD 2.999253511428833, LDE 1.7982357740402222, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5336995720863342, Reg Loss=5.646125316619873
Clinet index 8, End of Epoch 3/6, Average Loss=6.1798248291015625, Class Loss=0.5336995720863342, Reg Loss=5.646125316619873
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=5.830617848038673
Loss made of: CE 0.6251067519187927, LKD 3.432826042175293, LDE 1.8912341594696045, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4919685423374176, Reg Loss=5.312976360321045
Clinet index 8, End of Epoch 4/6, Average Loss=5.80494499206543, Class Loss=0.4919685423374176, Reg Loss=5.312976360321045
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=5.804777291417122
Loss made of: CE 0.5378175973892212, LKD 3.253740072250366, LDE 1.5913095474243164, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.48049747943878174, Reg Loss=5.272141456604004
Clinet index 8, End of Epoch 5/6, Average Loss=5.752638816833496, Class Loss=0.48049747943878174, Reg Loss=5.272141456604004
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=5.682504254579544
Loss made of: CE 0.41570281982421875, LKD 3.9674439430236816, LDE 2.2951736450195312, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4568122923374176, Reg Loss=5.229986667633057
Clinet index 8, End of Epoch 6/6, Average Loss=5.686799049377441, Class Loss=0.4568122923374176, Reg Loss=5.229986667633057
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=7.830908226966858
Loss made of: CE 0.7213060259819031, LKD 3.8138930797576904, LDE 2.680197238922119, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8330300450325012, Reg Loss=6.775971412658691
Clinet index 27, End of Epoch 1/6, Average Loss=7.609001636505127, Class Loss=0.8330300450325012, Reg Loss=6.775971412658691
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=6.776713770627976
Loss made of: CE 0.7917827367782593, LKD 3.284236431121826, LDE 3.1608872413635254, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6742945909500122, Reg Loss=6.133785247802734
Clinet index 27, End of Epoch 2/6, Average Loss=6.808079719543457, Class Loss=0.6742945909500122, Reg Loss=6.133785247802734
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=6.251449075341225
Loss made of: CE 0.5539752840995789, LKD 3.6943576335906982, LDE 2.0604870319366455, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5581212043762207, Reg Loss=5.702242374420166
Clinet index 27, End of Epoch 3/6, Average Loss=6.260363578796387, Class Loss=0.5581212043762207, Reg Loss=5.702242374420166
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=6.012413367629051
Loss made of: CE 0.47324201464653015, LKD 3.625530481338501, LDE 1.4453766345977783, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5182134509086609, Reg Loss=5.482277870178223
Clinet index 27, End of Epoch 4/6, Average Loss=6.000491142272949, Class Loss=0.5182134509086609, Reg Loss=5.482277870178223
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=6.136957600712776
Loss made of: CE 0.5041956305503845, LKD 3.692882776260376, LDE 1.5081186294555664, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5067344903945923, Reg Loss=5.614477634429932
Clinet index 27, End of Epoch 5/6, Average Loss=6.121212005615234, Class Loss=0.5067344903945923, Reg Loss=5.614477634429932
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=5.979146721959114
Loss made of: CE 0.5268366932868958, LKD 3.5773375034332275, LDE 1.8036354780197144, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.49690935015678406, Reg Loss=5.545806407928467
Clinet index 27, End of Epoch 6/6, Average Loss=6.042715549468994, Class Loss=0.49690935015678406, Reg Loss=5.545806407928467
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=7.887841528654098
Loss made of: CE 0.8725225925445557, LKD 3.3050537109375, LDE 2.9638006687164307, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8339375853538513, Reg Loss=6.8213725090026855
Clinet index 7, End of Epoch 1/6, Average Loss=7.655310153961182, Class Loss=0.8339375853538513, Reg Loss=6.8213725090026855
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=6.911677443981171
Loss made of: CE 0.6140275001525879, LKD 3.6188700199127197, LDE 1.9505963325500488, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6642194986343384, Reg Loss=6.171634197235107
Clinet index 7, End of Epoch 2/6, Average Loss=6.835853576660156, Class Loss=0.6642194986343384, Reg Loss=6.171634197235107
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=6.344213739037514
Loss made of: CE 0.482536643743515, LKD 3.7496230602264404, LDE 1.6734235286712646, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5623227953910828, Reg Loss=5.747846603393555
Clinet index 7, End of Epoch 3/6, Average Loss=6.310169219970703, Class Loss=0.5623227953910828, Reg Loss=5.747846603393555
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=6.293598788976669
Loss made of: CE 0.41489657759666443, LKD 3.299945116043091, LDE 2.0463876724243164, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5229204297065735, Reg Loss=5.748658657073975
Clinet index 7, End of Epoch 4/6, Average Loss=6.271579265594482, Class Loss=0.5229204297065735, Reg Loss=5.748658657073975
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=5.884537854790688
Loss made of: CE 0.5120633840560913, LKD 3.5609118938446045, LDE 1.905241847038269, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4846467673778534, Reg Loss=5.496334552764893
Clinet index 7, End of Epoch 5/6, Average Loss=5.980981349945068, Class Loss=0.4846467673778534, Reg Loss=5.496334552764893
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=5.8195206135511395
Loss made of: CE 0.47429680824279785, LKD 3.732053518295288, LDE 1.6926549673080444, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.47044646739959717, Reg Loss=5.415711879730225
Clinet index 7, End of Epoch 6/6, Average Loss=5.886158466339111, Class Loss=0.47044646739959717, Reg Loss=5.415711879730225
federated aggregation...
Validation, Class Loss=1.0274379253387451, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.723394
Mean Acc: 0.174782
FreqW Acc: 0.616887
Mean IoU: 0.114637
Class IoU:
	class 0: 0.8276433
	class 1: 0.17140168
	class 2: 0.0051217056
	class 3: 0.0
	class 4: 0.19165969
	class 5: 0.0
	class 6: 0.05499988
	class 7: 0.025588749
	class 8: 0.0
	class 9: 5.786144e-06
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.08413614
	class 14: 0.003881176
	class 15: 0.61334544
	class 16: 0.017323218
	class 17: 0.17444676
	class 18: 0.10753733
	class 19: 0.081237234
	class 20: 0.049045064
Class Acc:
	class 0: 0.961572
	class 1: 0.17145525
	class 2: 0.0051582707
	class 3: 0.0
	class 4: 0.19428909
	class 5: 0.0
	class 6: 0.055025015
	class 7: 0.025589155
	class 8: 0.0
	class 9: 5.786144e-06
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.12625498
	class 14: 0.0038837476
	class 15: 0.6364452
	class 16: 0.017349737
	class 17: 0.37026864
	class 18: 0.40659973
	class 19: 0.23251107
	class 20: 0.4640228

federated global round: 33, step: 6
select part of clients to conduct local training
[6, 20, 13, 10]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=6.398302948474884
Loss made of: CE 0.502842366695404, LKD 3.9461872577667236, LDE 2.085857391357422, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5272029042243958, Reg Loss=5.711060523986816
Clinet index 6, End of Epoch 1/6, Average Loss=6.2382636070251465, Class Loss=0.5272029042243958, Reg Loss=5.711060523986816
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=5.992168271541596
Loss made of: CE 0.5293450355529785, LKD 3.458638906478882, LDE 1.4710615873336792, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.49465882778167725, Reg Loss=5.468031883239746
Clinet index 6, End of Epoch 2/6, Average Loss=5.962690830230713, Class Loss=0.49465882778167725, Reg Loss=5.468031883239746
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=5.74427393078804
Loss made of: CE 0.43024906516075134, LKD 3.304088830947876, LDE 1.652787685394287, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.47847893834114075, Reg Loss=5.2455949783325195
Clinet index 6, End of Epoch 3/6, Average Loss=5.724073886871338, Class Loss=0.47847893834114075, Reg Loss=5.2455949783325195
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=5.852671828866005
Loss made of: CE 0.42025431990623474, LKD 3.220561981201172, LDE 1.9654778242111206, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46234577894210815, Reg Loss=5.348862648010254
Clinet index 6, End of Epoch 4/6, Average Loss=5.811208248138428, Class Loss=0.46234577894210815, Reg Loss=5.348862648010254
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=5.7319949001073836
Loss made of: CE 0.47350311279296875, LKD 4.133301734924316, LDE 1.8457640409469604, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4730592668056488, Reg Loss=5.252170562744141
Clinet index 6, End of Epoch 5/6, Average Loss=5.725229740142822, Class Loss=0.4730592668056488, Reg Loss=5.252170562744141
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=5.719860318303108
Loss made of: CE 0.4041914641857147, LKD 3.0661864280700684, LDE 1.5270320177078247, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.46246787905693054, Reg Loss=5.206160068511963
Clinet index 6, End of Epoch 6/6, Average Loss=5.668627738952637, Class Loss=0.46246787905693054, Reg Loss=5.206160068511963
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=6.193608969449997
Loss made of: CE 0.5130609273910522, LKD 3.8539514541625977, LDE 2.001106023788452, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5281655192375183, Reg Loss=5.691746234893799
Clinet index 20, End of Epoch 1/6, Average Loss=6.219911575317383, Class Loss=0.5281655192375183, Reg Loss=5.691746234893799
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=5.963090842962265
Loss made of: CE 0.6390937566757202, LKD 3.604316234588623, LDE 1.6742331981658936, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5199651718139648, Reg Loss=5.40349817276001
Clinet index 20, End of Epoch 2/6, Average Loss=5.923463344573975, Class Loss=0.5199651718139648, Reg Loss=5.40349817276001
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=5.819559654593467
Loss made of: CE 0.38889607787132263, LKD 3.5606284141540527, LDE 1.3902466297149658, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4812871813774109, Reg Loss=5.3475260734558105
Clinet index 20, End of Epoch 3/6, Average Loss=5.828813076019287, Class Loss=0.4812871813774109, Reg Loss=5.3475260734558105
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=5.760648357868194
Loss made of: CE 0.5951585173606873, LKD 3.719127893447876, LDE 2.0555338859558105, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.48612040281295776, Reg Loss=5.268304347991943
Clinet index 20, End of Epoch 4/6, Average Loss=5.754424571990967, Class Loss=0.48612040281295776, Reg Loss=5.268304347991943
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=5.791505149006843
Loss made of: CE 0.5090370178222656, LKD 3.0034449100494385, LDE 1.7124589681625366, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.46887367963790894, Reg Loss=5.376902103424072
Clinet index 20, End of Epoch 5/6, Average Loss=5.845775604248047, Class Loss=0.46887367963790894, Reg Loss=5.376902103424072
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=5.599043488502502
Loss made of: CE 0.4013180434703827, LKD 3.9998698234558105, LDE 1.5050443410873413, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.45313259959220886, Reg Loss=5.1086649894714355
Clinet index 20, End of Epoch 6/6, Average Loss=5.561797618865967, Class Loss=0.45313259959220886, Reg Loss=5.1086649894714355
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=10.336395037174224
Loss made of: CE 0.4806322455406189, LKD 4.11248779296875, LDE 4.7594499588012695, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5591620206832886, Reg Loss=9.57198715209961
Clinet index 13, End of Epoch 1/6, Average Loss=10.131149291992188, Class Loss=0.5591620206832886, Reg Loss=9.57198715209961
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=8.374921816587449
Loss made of: CE 0.3607262969017029, LKD 4.0411152839660645, LDE 4.12293004989624, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35388463735580444, Reg Loss=7.9296369552612305
Clinet index 13, End of Epoch 2/6, Average Loss=8.28352165222168, Class Loss=0.35388463735580444, Reg Loss=7.9296369552612305
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=7.452350518107414
Loss made of: CE 0.35023897886276245, LKD 4.161107540130615, LDE 3.078803062438965, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2840099632740021, Reg Loss=7.240716457366943
Clinet index 13, End of Epoch 3/6, Average Loss=7.524726390838623, Class Loss=0.2840099632740021, Reg Loss=7.240716457366943
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=7.484881210327148
Loss made of: CE 0.20928935706615448, LKD 4.3454179763793945, LDE 3.434281826019287, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25605183839797974, Reg Loss=7.136474132537842
Clinet index 13, End of Epoch 4/6, Average Loss=7.392526149749756, Class Loss=0.25605183839797974, Reg Loss=7.136474132537842
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=7.100094552338123
Loss made of: CE 0.258119136095047, LKD 3.3189828395843506, LDE 3.1052052974700928, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2526417672634125, Reg Loss=6.906792640686035
Clinet index 13, End of Epoch 5/6, Average Loss=7.1594343185424805, Class Loss=0.2526417672634125, Reg Loss=6.906792640686035
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=7.211377796530724
Loss made of: CE 0.22291748225688934, LKD 3.4413933753967285, LDE 3.259269952774048, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2484574168920517, Reg Loss=6.93232536315918
Clinet index 13, End of Epoch 6/6, Average Loss=7.180782794952393, Class Loss=0.2484574168920517, Reg Loss=6.93232536315918
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Batch 10/12, Loss=11.136371898651124
Loss made of: CE 0.6916806101799011, LKD 4.806210994720459, LDE 4.572868347167969, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6031213998794556, Reg Loss=10.189252853393555
Clinet index 10, End of Epoch 1/6, Average Loss=10.792374610900879, Class Loss=0.6031213998794556, Reg Loss=10.189252853393555
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/12, Loss=8.559980347752571
Loss made of: CE 0.5816968679428101, LKD 4.7270965576171875, LDE 4.339778423309326, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3927239775657654, Reg Loss=8.089349746704102
Clinet index 10, End of Epoch 2/6, Average Loss=8.482073783874512, Class Loss=0.3927239775657654, Reg Loss=8.089349746704102
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=7.763364335894584
Loss made of: CE 0.3533446788787842, LKD 4.138947486877441, LDE 3.3051018714904785, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3112025856971741, Reg Loss=7.409820556640625
Clinet index 10, End of Epoch 3/6, Average Loss=7.721023082733154, Class Loss=0.3112025856971741, Reg Loss=7.409820556640625
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/12, Loss=7.552689860761165
Loss made of: CE 0.21657073497772217, LKD 3.7945170402526855, LDE 3.06294846534729, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2814912796020508, Reg Loss=7.259496212005615
Clinet index 10, End of Epoch 4/6, Average Loss=7.540987491607666, Class Loss=0.2814912796020508, Reg Loss=7.259496212005615
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/12, Loss=7.213631829619407
Loss made of: CE 0.23743204772472382, LKD 3.8117141723632812, LDE 2.886251211166382, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25726866722106934, Reg Loss=7.048778057098389
Clinet index 10, End of Epoch 5/6, Average Loss=7.306046485900879, Class Loss=0.25726866722106934, Reg Loss=7.048778057098389
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 6, Batch 10/12, Loss=7.491132931411267
Loss made of: CE 0.2795427739620209, LKD 3.2370097637176514, LDE 4.286067962646484, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26533353328704834, Reg Loss=7.130935192108154
Clinet index 10, End of Epoch 6/6, Average Loss=7.396268844604492, Class Loss=0.26533353328704834, Reg Loss=7.130935192108154
federated aggregation...
Validation, Class Loss=1.0629873275756836, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.719383
Mean Acc: 0.169837
FreqW Acc: 0.628526
Mean IoU: 0.104365
Class IoU:
	class 0: 0.84956235
	class 1: 0.05144373
	class 2: 2.8669006e-06
	class 3: 0.0
	class 4: 0.0863706
	class 5: 0.0
	class 6: 0.0037728283
	class 7: 0.012197164
	class 8: 0.0
	class 9: 2.3787481e-05
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.028778186
	class 14: 0.00042412584
	class 15: 0.6065349
	class 16: 0.018832225
	class 17: 0.16303489
	class 18: 0.115188934
	class 19: 0.08612578
	class 20: 0.16937542
Class Acc:
	class 0: 0.9522848
	class 1: 0.051449686
	class 2: 2.8669006e-06
	class 3: 0.0
	class 4: 0.086756594
	class 5: 0.0
	class 6: 0.003772831
	class 7: 0.012197164
	class 8: 0.0
	class 9: 2.3787481e-05
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.038761247
	class 14: 0.00042414584
	class 15: 0.6283858
	class 16: 0.018864606
	class 17: 0.24152704
	class 18: 0.36039585
	class 19: 0.70409817
	class 20: 0.46762305

federated global round: 34, step: 6
select part of clients to conduct local training
[19, 18, 27, 14]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=7.222285681962967
Loss made of: CE 0.47221994400024414, LKD 3.914499282836914, LDE 2.504877805709839, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5899236798286438, Reg Loss=6.476365566253662
Clinet index 19, End of Epoch 1/6, Average Loss=7.06628942489624, Class Loss=0.5899236798286438, Reg Loss=6.476365566253662
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=6.448239624500275
Loss made of: CE 0.5404505729675293, LKD 4.179355621337891, LDE 2.404895305633545, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5207415819168091, Reg Loss=5.819368839263916
Clinet index 19, End of Epoch 2/6, Average Loss=6.3401103019714355, Class Loss=0.5207415819168091, Reg Loss=5.819368839263916
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=5.957220986485481
Loss made of: CE 0.4780906140804291, LKD 3.427987575531006, LDE 1.6816612482070923, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.49602389335632324, Reg Loss=5.442745685577393
Clinet index 19, End of Epoch 3/6, Average Loss=5.938769340515137, Class Loss=0.49602389335632324, Reg Loss=5.442745685577393
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=5.98371419608593
Loss made of: CE 0.4894185960292816, LKD 3.742204189300537, LDE 1.9247092008590698, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.48202818632125854, Reg Loss=5.405831336975098
Clinet index 19, End of Epoch 4/6, Average Loss=5.887859344482422, Class Loss=0.48202818632125854, Reg Loss=5.405831336975098
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=5.843954446911812
Loss made of: CE 0.44500288367271423, LKD 3.982776403427124, LDE 1.833213448524475, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.47162601351737976, Reg Loss=5.395260334014893
Clinet index 19, End of Epoch 5/6, Average Loss=5.866886138916016, Class Loss=0.47162601351737976, Reg Loss=5.395260334014893
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=5.746366009116173
Loss made of: CE 0.49753880500793457, LKD 3.3763527870178223, LDE 1.602289080619812, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4744065999984741, Reg Loss=5.323297500610352
Clinet index 19, End of Epoch 6/6, Average Loss=5.797704219818115, Class Loss=0.4744065999984741, Reg Loss=5.323297500610352
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=6.995716470479965
Loss made of: CE 0.5819969177246094, LKD 3.633937358856201, LDE 2.7420735359191895, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5714144110679626, Reg Loss=6.2698540687561035
Clinet index 18, End of Epoch 1/6, Average Loss=6.841268539428711, Class Loss=0.5714144110679626, Reg Loss=6.2698540687561035
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=6.2211992055177685
Loss made of: CE 0.5401964783668518, LKD 3.268099308013916, LDE 2.015263557434082, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5105257034301758, Reg Loss=5.625511169433594
Clinet index 18, End of Epoch 2/6, Average Loss=6.1360368728637695, Class Loss=0.5105257034301758, Reg Loss=5.625511169433594
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=6.002082371711731
Loss made of: CE 0.4943077564239502, LKD 3.7633278369903564, LDE 1.4363559484481812, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5006026029586792, Reg Loss=5.409067630767822
Clinet index 18, End of Epoch 3/6, Average Loss=5.909670352935791, Class Loss=0.5006026029586792, Reg Loss=5.409067630767822
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=5.71310875415802
Loss made of: CE 0.4449304938316345, LKD 3.2434468269348145, LDE 1.5188331604003906, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4830704629421234, Reg Loss=5.357792377471924
Clinet index 18, End of Epoch 4/6, Average Loss=5.84086275100708, Class Loss=0.4830704629421234, Reg Loss=5.357792377471924
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=5.92744183242321
Loss made of: CE 0.5440170764923096, LKD 3.5639517307281494, LDE 2.2048962116241455, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4749905467033386, Reg Loss=5.316756725311279
Clinet index 18, End of Epoch 5/6, Average Loss=5.791747093200684, Class Loss=0.4749905467033386, Reg Loss=5.316756725311279
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=5.752963608503341
Loss made of: CE 0.42279142141342163, LKD 3.262728452682495, LDE 1.4845880270004272, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.47589871287345886, Reg Loss=5.354852199554443
Clinet index 18, End of Epoch 6/6, Average Loss=5.830750942230225, Class Loss=0.47589871287345886, Reg Loss=5.354852199554443
Current Client Index:  27
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/13, Loss=7.172755455970764
Loss made of: CE 0.514694094657898, LKD 3.844452381134033, LDE 2.317445755004883, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5855044722557068, Reg Loss=6.413295269012451
Clinet index 27, End of Epoch 1/6, Average Loss=6.998799800872803, Class Loss=0.5855044722557068, Reg Loss=6.413295269012451
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/13, Loss=6.3781820178031925
Loss made of: CE 0.5956968069076538, LKD 2.9669079780578613, LDE 2.595794677734375, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5648432374000549, Reg Loss=5.80375862121582
Clinet index 27, End of Epoch 2/6, Average Loss=6.3686017990112305, Class Loss=0.5648432374000549, Reg Loss=5.80375862121582
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/13, Loss=5.98978745341301
Loss made of: CE 0.5019516944885254, LKD 3.678830623626709, LDE 1.9176863431930542, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5074588656425476, Reg Loss=5.463352203369141
Clinet index 27, End of Epoch 3/6, Average Loss=5.970810890197754, Class Loss=0.5074588656425476, Reg Loss=5.463352203369141
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/13, Loss=5.914692071080208
Loss made of: CE 0.46766456961631775, LKD 3.6688613891601562, LDE 1.3984317779541016, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4863288700580597, Reg Loss=5.388746738433838
Clinet index 27, End of Epoch 4/6, Average Loss=5.875075817108154, Class Loss=0.4863288700580597, Reg Loss=5.388746738433838
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/13, Loss=6.186581480503082
Loss made of: CE 0.4944609999656677, LKD 3.751826763153076, LDE 1.426554799079895, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.515021800994873, Reg Loss=5.603414535522461
Clinet index 27, End of Epoch 5/6, Average Loss=6.118436336517334, Class Loss=0.515021800994873, Reg Loss=5.603414535522461
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/13, Loss=5.877700942754745
Loss made of: CE 0.5195910930633545, LKD 3.4706718921661377, LDE 1.6454319953918457, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5003669857978821, Reg Loss=5.430571556091309
Clinet index 27, End of Epoch 6/6, Average Loss=5.930938720703125, Class Loss=0.5003669857978821, Reg Loss=5.430571556091309
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/13, Loss=6.9352977752685545
Loss made of: CE 0.594688892364502, LKD 3.783909559249878, LDE 2.3901169300079346, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5716134309768677, Reg Loss=6.190533638000488
Clinet index 14, End of Epoch 1/6, Average Loss=6.762146949768066, Class Loss=0.5716134309768677, Reg Loss=6.190533638000488
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/13, Loss=6.2443216979503635
Loss made of: CE 0.43335795402526855, LKD 3.514216184616089, LDE 2.2306275367736816, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5121302604675293, Reg Loss=5.643022060394287
Clinet index 14, End of Epoch 2/6, Average Loss=6.155152320861816, Class Loss=0.5121302604675293, Reg Loss=5.643022060394287
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/13, Loss=5.949678263068199
Loss made of: CE 0.47206854820251465, LKD 3.858677387237549, LDE 1.6648021936416626, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.505705714225769, Reg Loss=5.364198684692383
Clinet index 14, End of Epoch 3/6, Average Loss=5.869904518127441, Class Loss=0.505705714225769, Reg Loss=5.364198684692383
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/13, Loss=5.604529544711113
Loss made of: CE 0.4540312886238098, LKD 3.382382869720459, LDE 1.705625295639038, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.49006137251853943, Reg Loss=5.233164310455322
Clinet index 14, End of Epoch 4/6, Average Loss=5.7232255935668945, Class Loss=0.49006137251853943, Reg Loss=5.233164310455322
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/13, Loss=5.607015940546989
Loss made of: CE 0.43631553649902344, LKD 3.2819252014160156, LDE 1.442563772201538, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4694247841835022, Reg Loss=5.175683498382568
Clinet index 14, End of Epoch 5/6, Average Loss=5.645108222961426, Class Loss=0.4694247841835022, Reg Loss=5.175683498382568
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/13, Loss=5.640522959828377
Loss made of: CE 0.5156735777854919, LKD 3.518709182739258, LDE 2.3234355449676514, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4829655885696411, Reg Loss=5.162814617156982
Clinet index 14, End of Epoch 6/6, Average Loss=5.645780086517334, Class Loss=0.4829655885696411, Reg Loss=5.162814617156982
federated aggregation...
Validation, Class Loss=1.091353178024292, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.715423
Mean Acc: 0.168980
FreqW Acc: 0.615586
Mean IoU: 0.103284
Class IoU:
	class 0: 0.8273893
	class 1: 0.083060585
	class 2: 0.002817016
	class 3: 0.0
	class 4: 0.11524282
	class 5: 9.4549205e-06
	class 6: 0.010286384
	class 7: 0.0031013272
	class 8: 0.0
	class 9: 3.278815e-05
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.08851037
	class 14: 0.0051478697
	class 15: 0.650125
	class 16: 0.0082681775
	class 17: 0.15880163
	class 18: 0.120988525
	class 19: 0.04611459
	class 20: 0.049057897
Class Acc:
	class 0: 0.95138913
	class 1: 0.08307474
	class 2: 0.0028246138
	class 3: 0.0
	class 4: 0.11587497
	class 5: 9.4549205e-06
	class 6: 0.010286465
	class 7: 0.0031013272
	class 8: 0.0
	class 9: 3.278815e-05
	class 10: 0.0
	class 11: 0.0
	class 12: 0.0
	class 13: 0.15278122
	class 14: 0.005188862
	class 15: 0.67891306
	class 16: 0.008279338
	class 17: 0.29989645
	class 18: 0.45049438
	class 19: 0.072643034
	class 20: 0.7137893

voc_8-2_ILT On GPUs 2
Run in 44118s
