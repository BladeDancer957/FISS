nohup: ignoring input
30
kvoc_15-1_OURS-APE On GPUs 0\Writing in results/seed_2023-ov/2023-03-15_voc_15-1_OURS-APE.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[1, 7, 2, 9]
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Current Client Index:  2
Current Client Index:  9
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[8, 6, 2, 7]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  6
Current Client Index:  2
Current Client Index:  7
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[9, 5, 0, 3]
Current Client Index:  9
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[7, 1, 6, 8]
Current Client Index:  7
Current Client Index:  1
Current Client Index:  6
Current Client Index:  8
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.1457791030406952, Reg Loss=0.0 (without scaling)

Total samples: 1240.000000
Overall Acc: 0.951776
Mean Acc: 0.881545
FreqW Acc: 0.912099
Mean IoU: 0.794359
Class IoU:
	class 0: 0.9435678441258032
	class 1: 0.9052423932314888
	class 2: 0.4213606004092534
	class 3: 0.8972771305496867
	class 4: 0.6901223685917613
	class 5: 0.8225643420979045
	class 6: 0.9389549813330007
	class 7: 0.9135277370452521
	class 8: 0.9198215099829363
	class 9: 0.43938349027396006
	class 10: 0.7777990824907851
	class 11: 0.6195788152128043
	class 12: 0.864871312975591
	class 13: 0.807772381198587
	class 14: 0.8770910277444374
	class 15: 0.8708080530270558
Class Acc:
	class 0: 0.973328795212368
	class 1: 0.9683061028854518
	class 2: 0.9023232645390187
	class 3: 0.9371807751986593
	class 4: 0.8242437144899553
	class 5: 0.9136934141450599
	class 6: 0.9610899155454063
	class 7: 0.9434665268341859
	class 8: 0.9562913760377284
	class 9: 0.5435478064083014
	class 10: 0.8131002178976983
	class 11: 0.6503240044823576
	class 12: 0.9597874531163153
	class 13: 0.8984842680642833
	class 14: 0.9376804242841374
	class 15: 0.9218656821409732

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[3, 6, 12, 0]
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.2130707502365112, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=1.2130707502365112, Class Loss=1.2130707502365112, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.0924623012542725, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=1.0924623012542725, Class Loss=1.0924623012542725, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 3, Class Loss=1.2903847694396973, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=1.2903847694396973, Class Loss=1.2903847694396973, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=1.02776300907135, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=1.02776300907135, Class Loss=1.02776300907135, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=1.02151358127594, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=1.02151358127594, Class Loss=1.02151358127594, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=1.0007444620132446, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=1.0007444620132446, Class Loss=1.0007444620132446, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.1565912961959839, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=1.1565912961959839, Class Loss=1.1565912961959839, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.1584481000900269, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=1.1584481000900269, Class Loss=1.1584481000900269, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.8777132630348206, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.8777132630348206, Class Loss=0.8777132630348206, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8367490768432617, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.8367490768432617, Class Loss=0.8367490768432617, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 5, Class Loss=1.4314379692077637, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=1.4314379692077637, Class Loss=1.4314379692077637, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=1.2625676393508911, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=1.2625676393508911, Class Loss=1.2625676393508911, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.3260470628738403, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=1.3260470628738403, Class Loss=1.3260470628738403, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.852841317653656, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.852841317653656, Class Loss=0.852841317653656, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.0610227584838867, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=1.0610227584838867, Class Loss=1.0610227584838867, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8148211240768433, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.8148211240768433, Class Loss=0.8148211240768433, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.8043584823608398, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.8043584823608398, Class Loss=0.8043584823608398, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=1.005785346031189, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=1.005785346031189, Class Loss=1.005785346031189, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.079532265663147, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=1.079532265663147, Class Loss=1.079532265663147, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=1.0486559867858887, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=1.0486559867858887, Class Loss=1.0486559867858887, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.0313777923583984, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=1.0313777923583984, Class Loss=1.0313777923583984, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=1.2818268537521362, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=1.2818268537521362, Class Loss=1.2818268537521362, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=1.2342398166656494, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=1.2342398166656494, Class Loss=1.2342398166656494, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.9624184370040894, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.9624184370040894, Class Loss=0.9624184370040894, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.29581838846206665, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.935906
Mean Acc: 0.858529
FreqW Acc: 0.886588
Mean IoU: 0.723660
Class IoU:
	class 0: 0.92435086
	class 1: 0.8464908
	class 2: 0.3969734
	class 3: 0.8990867
	class 4: 0.6424233
	class 5: 0.7794585
	class 6: 0.9192392
	class 7: 0.89601254
	class 8: 0.8985117
	class 9: 0.44612184
	class 10: 0.7428682
	class 11: 0.6135643
	class 12: 0.8405988
	class 13: 0.75961185
	class 14: 0.8379435
	class 15: 0.8589615
	class 16: 0.0
Class Acc:
	class 0: 0.9495513
	class 1: 0.98419774
	class 2: 0.92549926
	class 3: 0.94098806
	class 4: 0.87054855
	class 5: 0.9432855
	class 6: 0.98888534
	class 7: 0.9586274
	class 8: 0.96285474
	class 9: 0.7066628
	class 10: 0.8095226
	class 11: 0.7334953
	class 12: 0.9760493
	class 13: 0.95484465
	class 14: 0.9656836
	class 15: 0.92430395
	class 16: 0.0

federated global round: 6, step: 1
select part of clients to conduct local training
[0, 2, 8, 4]
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.7070060968399048, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.7070060968399048, Class Loss=0.7070060968399048, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000787
Epoch 2, Class Loss=0.7127659320831299, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.7127659320831299, Class Loss=0.7127659320831299, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000756
Epoch 3, Class Loss=0.9390491843223572, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.9390491843223572, Class Loss=0.9390491843223572, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000725
Epoch 4, Class Loss=0.7985563278198242, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.7985563278198242, Class Loss=0.7985563278198242, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.7432318329811096, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.7432318329811096, Class Loss=0.7432318329811096, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000663
Epoch 6, Class Loss=0.59555584192276, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.59555584192276, Class Loss=0.59555584192276, Reg Loss=0.0
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.6771363615989685, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.6771363615989685, Class Loss=0.6771363615989685, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6430838108062744, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.6430838108062744, Class Loss=0.6430838108062744, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7301856875419617, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.7301856875419617, Class Loss=0.7301856875419617, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=0.6437795758247375, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.6437795758247375, Class Loss=0.6437795758247375, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.67488694190979, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.67488694190979, Class Loss=0.67488694190979, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.5557689666748047, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.5557689666748047, Class Loss=0.5557689666748047, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6645002961158752, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.6645002961158752, Class Loss=0.6645002961158752, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6551163792610168, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.6551163792610168, Class Loss=0.6551163792610168, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6183085441589355, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.6183085441589355, Class Loss=0.6183085441589355, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6066329479217529, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.6066329479217529, Class Loss=0.6066329479217529, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.6182602047920227, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.6182602047920227, Class Loss=0.6182602047920227, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.589389443397522, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.589389443397522, Class Loss=0.589389443397522, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.7189258337020874, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.7189258337020874, Class Loss=0.7189258337020874, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.7919368743896484, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.7919368743896484, Class Loss=0.7919368743896484, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 3, Class Loss=0.6516866683959961, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.6516866683959961, Class Loss=0.6516866683959961, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6078406572341919, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.6078406572341919, Class Loss=0.6078406572341919, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.6713011860847473, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.6713011860847473, Class Loss=0.6713011860847473, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.8162850737571716, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.8162850737571716, Class Loss=0.8162850737571716, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.27896997332572937, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.934203
Mean Acc: 0.859410
FreqW Acc: 0.883556
Mean IoU: 0.719523
Class IoU:
	class 0: 0.9216076
	class 1: 0.81079865
	class 2: 0.40113673
	class 3: 0.88370264
	class 4: 0.64182633
	class 5: 0.7664792
	class 6: 0.91687506
	class 7: 0.8939023
	class 8: 0.8959291
	class 9: 0.44846234
	class 10: 0.73300046
	class 11: 0.6058873
	class 12: 0.84337664
	class 13: 0.7644522
	class 14: 0.8461798
	class 15: 0.8554022
	class 16: 0.0028660693
Class Acc:
	class 0: 0.9458561
	class 1: 0.99104834
	class 2: 0.93373734
	class 3: 0.9204991
	class 4: 0.86531323
	class 5: 0.9535125
	class 6: 0.99142903
	class 7: 0.95849884
	class 8: 0.97206247
	class 9: 0.68918765
	class 10: 0.8230029
	class 11: 0.7354715
	class 12: 0.9761346
	class 13: 0.9553002
	class 14: 0.96410257
	class 15: 0.93194854
	class 16: 0.0028660693

federated global round: 7, step: 1
select part of clients to conduct local training
[9, 13, 1, 11]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5733761191368103, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.5733761191368103, Class Loss=0.5733761191368103, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.5714258551597595, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.5714258551597595, Class Loss=0.5714258551597595, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.5472832918167114, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.5472832918167114, Class Loss=0.5472832918167114, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.558778703212738, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.558778703212738, Class Loss=0.558778703212738, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.5333102941513062, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.5333102941513062, Class Loss=0.5333102941513062, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.5153523087501526, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.5153523087501526, Class Loss=0.5153523087501526, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6181653738021851, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.6181653738021851, Class Loss=0.6181653738021851, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.5886659622192383, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.5886659622192383, Class Loss=0.5886659622192383, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.590792715549469, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.590792715549469, Class Loss=0.590792715549469, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.582930862903595, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.582930862903595, Class Loss=0.582930862903595, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.6562660932540894, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.6562660932540894, Class Loss=0.6562660932540894, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.5701791644096375, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.5701791644096375, Class Loss=0.5701791644096375, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6058409810066223, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.6058409810066223, Class Loss=0.6058409810066223, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6088188886642456, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.6088188886642456, Class Loss=0.6088188886642456, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.5770474672317505, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.5770474672317505, Class Loss=0.5770474672317505, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.636471152305603, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.636471152305603, Class Loss=0.636471152305603, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.569322407245636, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.569322407245636, Class Loss=0.569322407245636, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Class Loss=0.5702096819877625, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.5702096819877625, Class Loss=0.5702096819877625, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5589098930358887, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.5589098930358887, Class Loss=0.5589098930358887, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.5499895811080933, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.5499895811080933, Class Loss=0.5499895811080933, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.5661195516586304, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.5661195516586304, Class Loss=0.5661195516586304, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.577389657497406, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.577389657497406, Class Loss=0.577389657497406, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.4947863519191742, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.4947863519191742, Class Loss=0.4947863519191742, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.5333632826805115, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.5333632826805115, Class Loss=0.5333632826805115, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.25568291544914246, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.938019
Mean Acc: 0.859251
FreqW Acc: 0.889651
Mean IoU: 0.732497
Class IoU:
	class 0: 0.9269232
	class 1: 0.8251439
	class 2: 0.4096534
	class 3: 0.89306104
	class 4: 0.65219736
	class 5: 0.77770513
	class 6: 0.9228963
	class 7: 0.899431
	class 8: 0.89883524
	class 9: 0.44808662
	class 10: 0.74184847
	class 11: 0.6065318
	class 12: 0.8435375
	class 13: 0.76847816
	class 14: 0.8532655
	class 15: 0.86044353
	class 16: 0.124407664
Class Acc:
	class 0: 0.95269245
	class 1: 0.9904591
	class 2: 0.9247288
	class 3: 0.92711675
	class 4: 0.8504448
	class 5: 0.9409892
	class 6: 0.98692787
	class 7: 0.9576095
	class 8: 0.9664845
	class 9: 0.6285093
	class 10: 0.8232424
	class 11: 0.7204886
	class 12: 0.97495586
	class 13: 0.94539523
	class 14: 0.95616996
	class 15: 0.92845243
	class 16: 0.13259827

federated global round: 8, step: 1
select part of clients to conduct local training
[8, 5, 2, 9]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Epoch 1, Class Loss=0.5384037494659424, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.5384037494659424, Class Loss=0.5384037494659424, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000714
Epoch 2, Class Loss=0.5462033748626709, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.5462033748626709, Class Loss=0.5462033748626709, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000655
Epoch 3, Class Loss=0.5033820271492004, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.5033820271492004, Class Loss=0.5033820271492004, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000596
Epoch 4, Class Loss=0.5292409658432007, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.5292409658432007, Class Loss=0.5292409658432007, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000536
Epoch 5, Class Loss=0.5224806070327759, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.5224806070327759, Class Loss=0.5224806070327759, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000475
Epoch 6, Class Loss=0.4965074360370636, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.4965074360370636, Class Loss=0.4965074360370636, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5144842267036438, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.5144842267036438, Class Loss=0.5144842267036438, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5617173314094543, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.5617173314094543, Class Loss=0.5617173314094543, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.5343526005744934, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.5343526005744934, Class Loss=0.5343526005744934, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.5469930171966553, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.5469930171966553, Class Loss=0.5469930171966553, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.5345119833946228, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.5345119833946228, Class Loss=0.5345119833946228, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.5864067077636719, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.5864067077636719, Class Loss=0.5864067077636719, Reg Loss=0.0
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Epoch 1, Class Loss=0.5333172082901001, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.5333172082901001, Class Loss=0.5333172082901001, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000714
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.5228779911994934, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.5228779911994934, Class Loss=0.5228779911994934, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000655
Epoch 3, Class Loss=0.5176094770431519, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.5176094770431519, Class Loss=0.5176094770431519, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000596
Epoch 4, Class Loss=0.5117959976196289, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.5117959976196289, Class Loss=0.5117959976196289, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000536
Epoch 5, Class Loss=0.5256568193435669, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.5256568193435669, Class Loss=0.5256568193435669, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000475
Epoch 6, Class Loss=0.5477978587150574, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.5477978587150574, Class Loss=0.5477978587150574, Reg Loss=0.0
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000694
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.5328831672668457, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.5328831672668457, Class Loss=0.5328831672668457, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000642
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 2, Class Loss=0.503354549407959, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.503354549407959, Class Loss=0.503354549407959, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.5093203783035278, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.5093203783035278, Class Loss=0.5093203783035278, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5358474254608154, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.5358474254608154, Class Loss=0.5358474254608154, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.5481559634208679, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.5481559634208679, Class Loss=0.5481559634208679, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.5177894830703735, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.5177894830703735, Class Loss=0.5177894830703735, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.24312570691108704, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.938344
Mean Acc: 0.856766
FreqW Acc: 0.890335
Mean IoU: 0.734990
Class IoU:
	class 0: 0.92741305
	class 1: 0.849156
	class 2: 0.41126922
	class 3: 0.8338879
	class 4: 0.66268426
	class 5: 0.77344084
	class 6: 0.92555076
	class 7: 0.90339357
	class 8: 0.90387774
	class 9: 0.44423977
	class 10: 0.7465115
	class 11: 0.6032078
	class 12: 0.83638144
	class 13: 0.7796984
	class 14: 0.86027944
	class 15: 0.86141956
	class 16: 0.17242536
Class Acc:
	class 0: 0.9545018
	class 1: 0.987966
	class 2: 0.92012817
	class 3: 0.85166067
	class 4: 0.85481596
	class 5: 0.94455814
	class 6: 0.9880733
	class 7: 0.95581377
	class 8: 0.96342164
	class 9: 0.6098779
	class 10: 0.81293863
	class 11: 0.72258675
	class 12: 0.97335213
	class 13: 0.9360136
	class 14: 0.95898056
	class 15: 0.9296514
	class 16: 0.20068128

federated global round: 9, step: 1
select part of clients to conduct local training
[8, 9, 12, 4]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000414
Epoch 1, Class Loss=0.5129426717758179, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.5129426717758179, Class Loss=0.5129426717758179, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000351
Epoch 2, Class Loss=0.5013537406921387, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.5013537406921387, Class Loss=0.5013537406921387, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000287
Epoch 3, Class Loss=0.4878225028514862, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.4878225028514862, Class Loss=0.4878225028514862, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000222
Epoch 4, Class Loss=0.49510657787323, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.49510657787323, Class Loss=0.49510657787323, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000154
Epoch 5, Class Loss=0.49572184681892395, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.49572184681892395, Class Loss=0.49572184681892395, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000082
Epoch 6, Class Loss=0.495532751083374, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.495532751083374, Class Loss=0.495532751083374, Reg Loss=0.0
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000372
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.48797807097435, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.48797807097435, Class Loss=0.48797807097435, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000316
Epoch 2, Class Loss=0.46723639965057373, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.46723639965057373, Class Loss=0.46723639965057373, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000258
Epoch 3, Class Loss=0.5106349587440491, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.5106349587440491, Class Loss=0.5106349587440491, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000199
Epoch 4, Class Loss=0.4995468854904175, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.4995468854904175, Class Loss=0.4995468854904175, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000138
Epoch 5, Class Loss=0.49434545636177063, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.49434545636177063, Class Loss=0.49434545636177063, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000074
Epoch 6, Class Loss=0.48420843482017517, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.48420843482017517, Class Loss=0.48420843482017517, Reg Loss=0.0
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.542600691318512, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.542600691318512, Class Loss=0.542600691318512, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000694
Epoch 2, Class Loss=0.5169109106063843, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.5169109106063843, Class Loss=0.5169109106063843, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000568
Epoch 3, Class Loss=0.5123401880264282, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.5123401880264282, Class Loss=0.5123401880264282, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000438
Epoch 4, Class Loss=0.511236846446991, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.511236846446991, Class Loss=0.511236846446991, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000304
Epoch 5, Class Loss=0.5036104917526245, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.5036104917526245, Class Loss=0.5036104917526245, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000163
Epoch 6, Class Loss=0.48882514238357544, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.48882514238357544, Class Loss=0.48882514238357544, Reg Loss=0.0
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Epoch 1, Class Loss=0.49098631739616394, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.49098631739616394, Class Loss=0.49098631739616394, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000655
Epoch 2, Class Loss=0.47635143995285034, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.47635143995285034, Class Loss=0.47635143995285034, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000536
Epoch 3, Class Loss=0.511817216873169, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.511817216873169, Class Loss=0.511817216873169, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000414
Epoch 4, Class Loss=0.5089960098266602, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.5089960098266602, Class Loss=0.5089960098266602, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000287
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 5, Class Loss=0.5082612633705139, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.5082612633705139, Class Loss=0.5082612633705139, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000154
Epoch 6, Class Loss=0.4881817698478699, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.4881817698478699, Class Loss=0.4881817698478699, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.23256312310695648, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.939685
Mean Acc: 0.856164
FreqW Acc: 0.892370
Mean IoU: 0.738579
Class IoU:
	class 0: 0.9289398
	class 1: 0.8585484
	class 2: 0.41461343
	class 3: 0.8633807
	class 4: 0.6631517
	class 5: 0.7742103
	class 6: 0.9279644
	class 7: 0.9058389
	class 8: 0.90461475
	class 9: 0.444324
	class 10: 0.7469274
	class 11: 0.59986794
	class 12: 0.84601426
	class 13: 0.7825058
	class 14: 0.86067826
	class 15: 0.8619702
	class 16: 0.17229624
Class Acc:
	class 0: 0.9566671
	class 1: 0.98586524
	class 2: 0.91505873
	class 3: 0.8842662
	class 4: 0.8450351
	class 5: 0.943256
	class 6: 0.98735946
	class 7: 0.9548561
	class 8: 0.9634444
	class 9: 0.60852265
	class 10: 0.80396515
	class 11: 0.7125044
	class 12: 0.97129273
	class 13: 0.9424567
	class 14: 0.9564629
	class 15: 0.9284918
	class 16: 0.19527978

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[14, 6, 0, 16]
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.399638056755066, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=1.399638056755066, Class Loss=1.399638056755066, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=1.4138638973236084, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=1.4138638973236084, Class Loss=1.4138638973236084, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.219781517982483, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=1.219781517982483, Class Loss=1.219781517982483, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=1.1385853290557861, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=1.1385853290557861, Class Loss=1.1385853290557861, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 5, Class Loss=1.215675950050354, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=1.215675950050354, Class Loss=1.215675950050354, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.9746344685554504, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.9746344685554504, Class Loss=0.9746344685554504, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.7464277744293213, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=1.7464277744293213, Class Loss=1.7464277744293213, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.506500482559204, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=1.506500482559204, Class Loss=1.506500482559204, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.1618610620498657, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=1.1618610620498657, Class Loss=1.1618610620498657, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 4, Class Loss=1.4291459321975708, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=1.4291459321975708, Class Loss=1.4291459321975708, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=1.3256951570510864, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=1.3256951570510864, Class Loss=1.3256951570510864, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=1.1003962755203247, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=1.1003962755203247, Class Loss=1.1003962755203247, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=2.2368297576904297, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=2.2368297576904297, Class Loss=2.2368297576904297, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.7482879161834717, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=1.7482879161834717, Class Loss=1.7482879161834717, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.5707415342330933, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=1.5707415342330933, Class Loss=1.5707415342330933, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=1.201745629310608, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=1.201745629310608, Class Loss=1.201745629310608, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=1.0271952152252197, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=1.0271952152252197, Class Loss=1.0271952152252197, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.9755352139472961, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.9755352139472961, Class Loss=0.9755352139472961, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.7439630031585693, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=1.7439630031585693, Class Loss=1.7439630031585693, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.3457748889923096, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=1.3457748889923096, Class Loss=1.3457748889923096, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=1.205461859703064, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=1.205461859703064, Class Loss=1.205461859703064, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=1.1440389156341553, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=1.1440389156341553, Class Loss=1.1440389156341553, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 5, Class Loss=0.984164834022522, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.984164834022522, Class Loss=0.984164834022522, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.9099342823028564, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.9099342823028564, Class Loss=0.9099342823028564, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.5342851281166077, Reg Loss=0.0 (without scaling)

Total samples: 1329.000000
Overall Acc: 0.904364
Mean Acc: 0.726950
FreqW Acc: 0.834142
Mean IoU: 0.621045
Class IoU:
	class 0: 0.8912697
	class 1: 0.87807673
	class 2: 0.40917698
	class 3: 0.6709828
	class 4: 0.60313654
	class 5: 0.746908
	class 6: 0.9084702
	class 7: 0.8641914
	class 8: 0.82179004
	class 9: 0.3413325
	class 10: 0.5250456
	class 11: 0.525273
	class 12: 0.7144552
	class 13: 0.52840555
	class 14: 0.8188255
	class 15: 0.81125975
	class 16: 0.11986238
	class 17: 0.00034286035
Class Acc:
	class 0: 0.9532711
	class 1: 0.9382803
	class 2: 0.8725383
	class 3: 0.6835897
	class 4: 0.8093468
	class 5: 0.8961805
	class 6: 0.9734686
	class 7: 0.95373267
	class 8: 0.8458534
	class 9: 0.44453532
	class 10: 0.6861087
	class 11: 0.5542452
	class 12: 0.82232463
	class 13: 0.5527604
	class 14: 0.9152526
	class 15: 0.9190606
	class 16: 0.26421311
	class 17: 0.00034467396

federated global round: 11, step: 2
select part of clients to conduct local training
[0, 12, 10, 17]
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=1.0216481685638428, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=1.0216481685638428, Class Loss=1.0216481685638428, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000787
Epoch 2, Class Loss=0.8728170394897461, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.8728170394897461, Class Loss=0.8728170394897461, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000756
Epoch 3, Class Loss=0.8163854479789734, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.8163854479789734, Class Loss=0.8163854479789734, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000725
Epoch 4, Class Loss=0.7195358276367188, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.7195358276367188, Class Loss=0.7195358276367188, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.6880679130554199, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.6880679130554199, Class Loss=0.6880679130554199, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000663
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Class Loss=0.6923905611038208, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.6923905611038208, Class Loss=0.6923905611038208, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.8723785281181335, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.8723785281181335, Class Loss=0.8723785281181335, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9051935076713562, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.9051935076713562, Class Loss=0.9051935076713562, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.8252710103988647, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.8252710103988647, Class Loss=0.8252710103988647, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.8075119853019714, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.8075119853019714, Class Loss=0.8075119853019714, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.7732163667678833, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.7732163667678833, Class Loss=0.7732163667678833, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.7339264154434204, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.7339264154434204, Class Loss=0.7339264154434204, Reg Loss=0.0
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.8743305802345276, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=0.8743305802345276, Class Loss=0.8743305802345276, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.8703547120094299, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=0.8703547120094299, Class Loss=0.8703547120094299, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.866934061050415, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.866934061050415, Class Loss=0.866934061050415, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.833604097366333, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.833604097366333, Class Loss=0.833604097366333, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.7533572316169739, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.7533572316169739, Class Loss=0.7533572316169739, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.7858210802078247, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.7858210802078247, Class Loss=0.7858210802078247, Reg Loss=0.0
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9118605852127075, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.9118605852127075, Class Loss=0.9118605852127075, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7952442169189453, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.7952442169189453, Class Loss=0.7952442169189453, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7852871417999268, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.7852871417999268, Class Loss=0.7852871417999268, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.7370150685310364, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.7370150685310364, Class Loss=0.7370150685310364, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.7141036987304688, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.7141036987304688, Class Loss=0.7141036987304688, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.6635259389877319, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.6635259389877319, Class Loss=0.6635259389877319, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4317800998687744, Reg Loss=0.0 (without scaling)

Total samples: 1329.000000
Overall Acc: 0.920095
Mean Acc: 0.767751
FreqW Acc: 0.860274
Mean IoU: 0.658658
Class IoU:
	class 0: 0.9138193
	class 1: 0.85499847
	class 2: 0.40939593
	class 3: 0.72018796
	class 4: 0.5754887
	class 5: 0.75759906
	class 6: 0.9154225
	class 7: 0.8771454
	class 8: 0.8607866
	class 9: 0.38614425
	class 10: 0.46276703
	class 11: 0.5395524
	class 12: 0.7560516
	class 13: 0.69522077
	class 14: 0.8159609
	class 15: 0.82931674
	class 16: 0.0413597
	class 17: 0.44463187
Class Acc:
	class 0: 0.9622547
	class 1: 0.9099356
	class 2: 0.90040314
	class 3: 0.7309331
	class 4: 0.78341424
	class 5: 0.9152886
	class 6: 0.98118716
	class 7: 0.9453706
	class 8: 0.9050148
	class 9: 0.5235628
	class 10: 0.46851122
	class 11: 0.57852256
	class 12: 0.8119876
	class 13: 0.75126535
	class 14: 0.88699174
	class 15: 0.93055975
	class 16: 0.055652726
	class 17: 0.7786528

federated global round: 12, step: 2
select part of clients to conduct local training
[14, 8, 16, 3]
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.6476008296012878, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.6476008296012878, Class Loss=0.6476008296012878, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000777
Epoch 2, Class Loss=0.6784538626670837, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.6784538626670837, Class Loss=0.6784538626670837, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000736
Epoch 3, Class Loss=0.7220269441604614, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.7220269441604614, Class Loss=0.7220269441604614, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000694
Epoch 4, Class Loss=0.6433790922164917, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.6433790922164917, Class Loss=0.6433790922164917, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000652
Epoch 5, Class Loss=0.6351751089096069, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.6351751089096069, Class Loss=0.6351751089096069, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000610
Epoch 6, Class Loss=0.6431746482849121, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.6431746482849121, Class Loss=0.6431746482849121, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6483651399612427, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.6483651399612427, Class Loss=0.6483651399612427, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6285860538482666, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.6285860538482666, Class Loss=0.6285860538482666, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6553499698638916, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.6553499698638916, Class Loss=0.6553499698638916, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.6039746999740601, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.6039746999740601, Class Loss=0.6039746999740601, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.6185005307197571, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.6185005307197571, Class Loss=0.6185005307197571, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.5921785235404968, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.5921785235404968, Class Loss=0.5921785235404968, Reg Loss=0.0
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.6068872213363647, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.6068872213363647, Class Loss=0.6068872213363647, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000777
Epoch 2, Class Loss=0.5962023138999939, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.5962023138999939, Class Loss=0.5962023138999939, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000736
Epoch 3, Class Loss=0.6390225887298584, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.6390225887298584, Class Loss=0.6390225887298584, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000694
Epoch 4, Class Loss=0.6459274291992188, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.6459274291992188, Class Loss=0.6459274291992188, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000652
Epoch 5, Class Loss=0.7363003492355347, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.7363003492355347, Class Loss=0.7363003492355347, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000610
Epoch 6, Class Loss=0.6104047298431396, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.6104047298431396, Class Loss=0.6104047298431396, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6601403951644897, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.6601403951644897, Class Loss=0.6601403951644897, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6449385285377502, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.6449385285377502, Class Loss=0.6449385285377502, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6572032570838928, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.6572032570838928, Class Loss=0.6572032570838928, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.63321453332901, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.63321453332901, Class Loss=0.63321453332901, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.5731582045555115, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.5731582045555115, Class Loss=0.5731582045555115, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.7082120180130005, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.7082120180130005, Class Loss=0.7082120180130005, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.3528633713722229, Reg Loss=0.0 (without scaling)

Total samples: 1329.000000
Overall Acc: 0.927520
Mean Acc: 0.787838
FreqW Acc: 0.871562
Mean IoU: 0.678261
Class IoU:
	class 0: 0.9215798
	class 1: 0.8635869
	class 2: 0.41606635
	class 3: 0.7782787
	class 4: 0.58619237
	class 5: 0.7726676
	class 6: 0.90732026
	class 7: 0.87926984
	class 8: 0.86823636
	class 9: 0.39141265
	class 10: 0.57707703
	class 11: 0.55750024
	class 12: 0.79391074
	class 13: 0.7457137
	class 14: 0.8174203
	class 15: 0.83872926
	class 16: 0.014865761
	class 17: 0.4788644
Class Acc:
	class 0: 0.9637757
	class 1: 0.92504126
	class 2: 0.89636725
	class 3: 0.7930806
	class 4: 0.8321077
	class 5: 0.9095138
	class 6: 0.9782828
	class 7: 0.9456168
	class 8: 0.90077525
	class 9: 0.51974523
	class 10: 0.61488503
	class 11: 0.60525805
	class 12: 0.883867
	class 13: 0.8268413
	class 14: 0.88483965
	class 15: 0.93343073
	class 16: 0.015880488
	class 17: 0.75177

federated global round: 13, step: 2
select part of clients to conduct local training
[17, 13, 11, 7]
Current Client Index:  17
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.5878403186798096, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.5878403186798096, Class Loss=0.5878403186798096, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000714
Epoch 2, Class Loss=0.5860902070999146, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.5860902070999146, Class Loss=0.5860902070999146, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000655
Epoch 3, Class Loss=0.5546711087226868, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.5546711087226868, Class Loss=0.5546711087226868, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000596
Epoch 4, Class Loss=0.5589051842689514, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.5589051842689514, Class Loss=0.5589051842689514, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000536
Epoch 5, Class Loss=0.5393904447555542, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.5393904447555542, Class Loss=0.5393904447555542, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000475
Epoch 6, Class Loss=0.5510218143463135, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.5510218143463135, Class Loss=0.5510218143463135, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5828425884246826, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.5828425884246826, Class Loss=0.5828425884246826, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5674510598182678, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.5674510598182678, Class Loss=0.5674510598182678, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.5272992253303528, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.5272992253303528, Class Loss=0.5272992253303528, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.5368818640708923, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.5368818640708923, Class Loss=0.5368818640708923, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.5199859142303467, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.5199859142303467, Class Loss=0.5199859142303467, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.5202343463897705, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.5202343463897705, Class Loss=0.5202343463897705, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5467066168785095, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.5467066168785095, Class Loss=0.5467066168785095, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5820657014846802, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.5820657014846802, Class Loss=0.5820657014846802, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.5764583349227905, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.5764583349227905, Class Loss=0.5764583349227905, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.5704329609870911, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.5704329609870911, Class Loss=0.5704329609870911, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.6948497891426086, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.6948497891426086, Class Loss=0.6948497891426086, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.6562593579292297, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.6562593579292297, Class Loss=0.6562593579292297, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6356955766677856, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.6356955766677856, Class Loss=0.6356955766677856, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.6348650455474854, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.6348650455474854, Class Loss=0.6348650455474854, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.5999822616577148, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.5999822616577148, Class Loss=0.5999822616577148, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.6662115454673767, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.6662115454673767, Class Loss=0.6662115454673767, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.5898154377937317, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.5898154377937317, Class Loss=0.5898154377937317, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.5884443521499634, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.5884443521499634, Class Loss=0.5884443521499634, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.32244792580604553, Reg Loss=0.0 (without scaling)

Total samples: 1329.000000
Overall Acc: 0.925670
Mean Acc: 0.778777
FreqW Acc: 0.869472
Mean IoU: 0.666888
Class IoU:
	class 0: 0.92230624
	class 1: 0.86708665
	class 2: 0.4224398
	class 3: 0.77105105
	class 4: 0.58203256
	class 5: 0.7749464
	class 6: 0.9200735
	class 7: 0.88250643
	class 8: 0.8614282
	class 9: 0.38136247
	class 10: 0.46220407
	class 11: 0.56288844
	class 12: 0.8002713
	class 13: 0.7215455
	class 14: 0.80656475
	class 15: 0.8396593
	class 16: 0.0017101595
	class 17: 0.42390844
Class Acc:
	class 0: 0.9650032
	class 1: 0.9427206
	class 2: 0.87786645
	class 3: 0.78767943
	class 4: 0.8303544
	class 5: 0.9060982
	class 6: 0.9810207
	class 7: 0.9431665
	class 8: 0.8941342
	class 9: 0.51329494
	class 10: 0.47394875
	class 11: 0.6238813
	class 12: 0.87828535
	class 13: 0.78838044
	class 14: 0.8638215
	class 15: 0.9328357
	class 16: 0.0017236862
	class 17: 0.8137638

federated global round: 14, step: 2
select part of clients to conduct local training
[17, 4, 5, 2]
Current Client Index:  17
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000414
Epoch 1, Class Loss=0.5445223450660706, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=0.5445223450660706, Class Loss=0.5445223450660706, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000351
Epoch 2, Class Loss=0.6468364000320435, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=0.6468364000320435, Class Loss=0.6468364000320435, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000287
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Class Loss=0.5260030627250671, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.5260030627250671, Class Loss=0.5260030627250671, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000222
Epoch 4, Class Loss=0.5539501905441284, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.5539501905441284, Class Loss=0.5539501905441284, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000154
Epoch 5, Class Loss=0.5365907549858093, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.5365907549858093, Class Loss=0.5365907549858093, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000082
Epoch 6, Class Loss=0.5387057662010193, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.5387057662010193, Class Loss=0.5387057662010193, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.48759716749191284, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.48759716749191284, Class Loss=0.48759716749191284, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5139928460121155, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.5139928460121155, Class Loss=0.5139928460121155, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5299239754676819, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.5299239754676819, Class Loss=0.5299239754676819, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.49940481781959534, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.49940481781959534, Class Loss=0.49940481781959534, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.53542160987854, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.53542160987854, Class Loss=0.53542160987854, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.46593403816223145, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.46593403816223145, Class Loss=0.46593403816223145, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5550857782363892, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.5550857782363892, Class Loss=0.5550857782363892, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5911489725112915, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.5911489725112915, Class Loss=0.5911489725112915, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.6308120489120483, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.6308120489120483, Class Loss=0.6308120489120483, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5876544117927551, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.5876544117927551, Class Loss=0.5876544117927551, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 5, Class Loss=0.5397517085075378, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.5397517085075378, Class Loss=0.5397517085075378, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5219014286994934, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.5219014286994934, Class Loss=0.5219014286994934, Reg Loss=0.0
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5231033563613892, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.5231033563613892, Class Loss=0.5231033563613892, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5382758975028992, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.5382758975028992, Class Loss=0.5382758975028992, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Class Loss=0.5347267389297485, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.5347267389297485, Class Loss=0.5347267389297485, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5748031735420227, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.5748031735420227, Class Loss=0.5748031735420227, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.6268695592880249, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.6268695592880249, Class Loss=0.6268695592880249, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5452163815498352, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.5452163815498352, Class Loss=0.5452163815498352, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.31092679500579834, Reg Loss=0.0 (without scaling)

Total samples: 1329.000000
Overall Acc: 0.925158
Mean Acc: 0.773547
FreqW Acc: 0.868926
Mean IoU: 0.665830
Class IoU:
	class 0: 0.92252725
	class 1: 0.87136495
	class 2: 0.42503607
	class 3: 0.78602487
	class 4: 0.5960368
	class 5: 0.7724256
	class 6: 0.9232595
	class 7: 0.8848918
	class 8: 0.825851
	class 9: 0.38495657
	class 10: 0.47591394
	class 11: 0.563995
	class 12: 0.7781374
	class 13: 0.7215985
	class 14: 0.8040402
	class 15: 0.8483501
	class 16: 0.0006966049
	class 17: 0.3998323
Class Acc:
	class 0: 0.96913314
	class 1: 0.93522716
	class 2: 0.8789365
	class 3: 0.8043007
	class 4: 0.8335532
	class 5: 0.89355296
	class 6: 0.9790922
	class 7: 0.93581134
	class 8: 0.8432028
	class 9: 0.50901127
	class 10: 0.48726076
	class 11: 0.6130002
	class 12: 0.8315848
	class 13: 0.7884575
	class 14: 0.860258
	class 15: 0.92379147
	class 16: 0.000699351
	class 17: 0.83697164

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[17, 21, 10, 5]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.4674979448318481, Reg Loss=0.0
Clinet index 17, End of Epoch 1/6, Average Loss=1.4674979448318481, Class Loss=1.4674979448318481, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.0377109050750732, Reg Loss=0.0
Clinet index 17, End of Epoch 2/6, Average Loss=1.0377109050750732, Class Loss=1.0377109050750732, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.920384407043457, Reg Loss=0.0
Clinet index 17, End of Epoch 3/6, Average Loss=0.920384407043457, Class Loss=0.920384407043457, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8594756722450256, Reg Loss=0.0
Clinet index 17, End of Epoch 4/6, Average Loss=0.8594756722450256, Class Loss=0.8594756722450256, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.8099668622016907, Reg Loss=0.0
Clinet index 17, End of Epoch 5/6, Average Loss=0.8099668622016907, Class Loss=0.8099668622016907, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.7846593260765076, Reg Loss=0.0
Clinet index 17, End of Epoch 6/6, Average Loss=0.7846593260765076, Class Loss=0.7846593260765076, Reg Loss=0.0
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.668959617614746, Reg Loss=0.0
Clinet index 21, End of Epoch 1/6, Average Loss=1.668959617614746, Class Loss=1.668959617614746, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.0337821245193481, Reg Loss=0.0
Clinet index 21, End of Epoch 2/6, Average Loss=1.0337821245193481, Class Loss=1.0337821245193481, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.9444838166236877, Reg Loss=0.0
Clinet index 21, End of Epoch 3/6, Average Loss=0.9444838166236877, Class Loss=0.9444838166236877, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8925651907920837, Reg Loss=0.0
Clinet index 21, End of Epoch 4/6, Average Loss=0.8925651907920837, Class Loss=0.8925651907920837, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.8042892217636108, Reg Loss=0.0
Clinet index 21, End of Epoch 5/6, Average Loss=0.8042892217636108, Class Loss=0.8042892217636108, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.7767031192779541, Reg Loss=0.0
Clinet index 21, End of Epoch 6/6, Average Loss=0.7767031192779541, Class Loss=0.7767031192779541, Reg Loss=0.0
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.4891705513000488, Reg Loss=0.0
Clinet index 10, End of Epoch 1/6, Average Loss=1.4891705513000488, Class Loss=1.4891705513000488, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.0116136074066162, Reg Loss=0.0
Clinet index 10, End of Epoch 2/6, Average Loss=1.0116136074066162, Class Loss=1.0116136074066162, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.8956774473190308, Reg Loss=0.0
Clinet index 10, End of Epoch 3/6, Average Loss=0.8956774473190308, Class Loss=0.8956774473190308, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.8184554576873779, Reg Loss=0.0
Clinet index 10, End of Epoch 4/6, Average Loss=0.8184554576873779, Class Loss=0.8184554576873779, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.9312868714332581, Reg Loss=0.0
Clinet index 10, End of Epoch 5/6, Average Loss=0.9312868714332581, Class Loss=0.9312868714332581, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.783872663974762, Reg Loss=0.0
Clinet index 10, End of Epoch 6/6, Average Loss=0.783872663974762, Class Loss=0.783872663974762, Reg Loss=0.0
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.6326637268066406, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=1.6326637268066406, Class Loss=1.6326637268066406, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.066072940826416, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=1.066072940826416, Class Loss=1.066072940826416, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.9043688774108887, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.9043688774108887, Class Loss=0.9043688774108887, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.862703263759613, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.862703263759613, Class Loss=0.862703263759613, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.7948898077011108, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.7948898077011108, Class Loss=0.7948898077011108, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.7881537675857544, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.7881537675857544, Class Loss=0.7881537675857544, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4668741524219513, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.910442
Mean Acc: 0.725803
FreqW Acc: 0.840401
Mean IoU: 0.623237
Class IoU:
	class 0: 0.9012893
	class 1: 0.8489482
	class 2: 0.42102963
	class 3: 0.78528833
	class 4: 0.59258574
	class 5: 0.7505925
	class 6: 0.9139787
	class 7: 0.87311506
	class 8: 0.85597765
	class 9: 0.39769453
	class 10: 0.6086664
	class 11: 0.5620018
	class 12: 0.7976404
	class 13: 0.67644805
	class 14: 0.79755837
	class 15: 0.84712785
	class 16: 0.0239004
	class 17: 0.1647882
	class 18: 0.022867857
Class Acc:
	class 0: 0.96379775
	class 1: 0.8930955
	class 2: 0.8992858
	class 3: 0.80566967
	class 4: 0.8105104
	class 5: 0.88207525
	class 6: 0.9869551
	class 7: 0.9239527
	class 8: 0.91606414
	class 9: 0.5601923
	class 10: 0.73865354
	class 11: 0.6719052
	class 12: 0.9203139
	class 13: 0.7391473
	class 14: 0.91463244
	class 15: 0.9330963
	class 16: 0.024225669
	class 17: 0.18176208
	class 18: 0.024926944

federated global round: 16, step: 3
select part of clients to conduct local training
[19, 11, 9, 1]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.8052193522453308, Reg Loss=0.0
Clinet index 19, End of Epoch 1/6, Average Loss=0.8052193522453308, Class Loss=0.8052193522453308, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7398248910903931, Reg Loss=0.0
Clinet index 19, End of Epoch 2/6, Average Loss=0.7398248910903931, Class Loss=0.7398248910903931, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7270905375480652, Reg Loss=0.0
Clinet index 19, End of Epoch 3/6, Average Loss=0.7270905375480652, Class Loss=0.7270905375480652, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6863860487937927, Reg Loss=0.0
Clinet index 19, End of Epoch 4/6, Average Loss=0.6863860487937927, Class Loss=0.6863860487937927, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.6958450078964233, Reg Loss=0.0
Clinet index 19, End of Epoch 5/6, Average Loss=0.6958450078964233, Class Loss=0.6958450078964233, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.6550010442733765, Reg Loss=0.0
Clinet index 19, End of Epoch 6/6, Average Loss=0.6550010442733765, Class Loss=0.6550010442733765, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.7772293090820312, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.7772293090820312, Class Loss=0.7772293090820312, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7526041269302368, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.7526041269302368, Class Loss=0.7526041269302368, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7185782194137573, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.7185782194137573, Class Loss=0.7185782194137573, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.717491626739502, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.717491626739502, Class Loss=0.717491626739502, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.734889805316925, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.734889805316925, Class Loss=0.734889805316925, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.6568980813026428, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.6568980813026428, Class Loss=0.6568980813026428, Reg Loss=0.0
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.7781399488449097, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.7781399488449097, Class Loss=0.7781399488449097, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.7560685276985168, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.7560685276985168, Class Loss=0.7560685276985168, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7436457872390747, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.7436457872390747, Class Loss=0.7436457872390747, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.7287786602973938, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.7287786602973938, Class Loss=0.7287786602973938, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.7467707991600037, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.7467707991600037, Class Loss=0.7467707991600037, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.6846062541007996, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.6846062541007996, Class Loss=0.6846062541007996, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.777051568031311, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.777051568031311, Class Loss=0.777051568031311, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.74956214427948, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.74956214427948, Class Loss=0.74956214427948, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7226828336715698, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.7226828336715698, Class Loss=0.7226828336715698, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.7026054859161377, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.7026054859161377, Class Loss=0.7026054859161377, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.7045810222625732, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.7045810222625732, Class Loss=0.7045810222625732, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Class Loss=0.679246187210083, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.679246187210083, Class Loss=0.679246187210083, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4239054024219513, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.902764
Mean Acc: 0.745947
FreqW Acc: 0.838542
Mean IoU: 0.632753
Class IoU:
	class 0: 0.89327806
	class 1: 0.85895866
	class 2: 0.41890103
	class 3: 0.79245967
	class 4: 0.6052013
	class 5: 0.74937177
	class 6: 0.9229632
	class 7: 0.8721647
	class 8: 0.8643615
	class 9: 0.39253837
	class 10: 0.6135438
	class 11: 0.5510154
	class 12: 0.81869143
	class 13: 0.6957841
	class 14: 0.8145203
	class 15: 0.84713984
	class 16: 0.007048566
	class 17: 0.12180645
	class 18: 0.18256575
Class Acc:
	class 0: 0.9425341
	class 1: 0.9083402
	class 2: 0.9004483
	class 3: 0.81550616
	class 4: 0.81793183
	class 5: 0.89622307
	class 6: 0.9817676
	class 7: 0.9199553
	class 8: 0.93006
	class 9: 0.54091287
	class 10: 0.77811426
	class 11: 0.6728571
	class 12: 0.92074245
	class 13: 0.75087416
	class 14: 0.9167475
	class 15: 0.936908
	class 16: 0.007049007
	class 17: 0.12996225
	class 18: 0.40605515

federated global round: 17, step: 3
select part of clients to conduct local training
[8, 5, 21, 7]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6720609664916992, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.6720609664916992, Class Loss=0.6720609664916992, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6562252640724182, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.6562252640724182, Class Loss=0.6562252640724182, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6346950531005859, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.6346950531005859, Class Loss=0.6346950531005859, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.6768568754196167, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.6768568754196167, Class Loss=0.6768568754196167, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.6269064545631409, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.6269064545631409, Class Loss=0.6269064545631409, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.6533095240592957, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.6533095240592957, Class Loss=0.6533095240592957, Reg Loss=0.0
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.676861047744751, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.676861047744751, Class Loss=0.676861047744751, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000777
Epoch 2, Class Loss=0.6812819242477417, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.6812819242477417, Class Loss=0.6812819242477417, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000736
Epoch 3, Class Loss=0.6473119854927063, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.6473119854927063, Class Loss=0.6473119854927063, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000694
Epoch 4, Class Loss=0.631072461605072, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.631072461605072, Class Loss=0.631072461605072, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000652
Epoch 5, Class Loss=0.6378532648086548, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.6378532648086548, Class Loss=0.6378532648086548, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000610
Epoch 6, Class Loss=0.6497788429260254, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.6497788429260254, Class Loss=0.6497788429260254, Reg Loss=0.0
Current Client Index:  21
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.6643726825714111, Reg Loss=0.0
Clinet index 21, End of Epoch 1/6, Average Loss=0.6643726825714111, Class Loss=0.6643726825714111, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000777
Epoch 2, Class Loss=0.6477807760238647, Reg Loss=0.0
Clinet index 21, End of Epoch 2/6, Average Loss=0.6477807760238647, Class Loss=0.6477807760238647, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000736
Epoch 3, Class Loss=0.6446747779846191, Reg Loss=0.0
Clinet index 21, End of Epoch 3/6, Average Loss=0.6446747779846191, Class Loss=0.6446747779846191, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000694
Epoch 4, Class Loss=0.6635443568229675, Reg Loss=0.0
Clinet index 21, End of Epoch 4/6, Average Loss=0.6635443568229675, Class Loss=0.6635443568229675, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000652
Epoch 5, Class Loss=0.6195846796035767, Reg Loss=0.0
Clinet index 21, End of Epoch 5/6, Average Loss=0.6195846796035767, Class Loss=0.6195846796035767, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000610
Epoch 6, Class Loss=0.6049101948738098, Reg Loss=0.0
Clinet index 21, End of Epoch 6/6, Average Loss=0.6049101948738098, Class Loss=0.6049101948738098, Reg Loss=0.0
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.680457592010498, Reg Loss=0.0
Clinet index 7, End of Epoch 1/6, Average Loss=0.680457592010498, Class Loss=0.680457592010498, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6596486568450928, Reg Loss=0.0
Clinet index 7, End of Epoch 2/6, Average Loss=0.6596486568450928, Class Loss=0.6596486568450928, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.637892484664917, Reg Loss=0.0
Clinet index 7, End of Epoch 3/6, Average Loss=0.637892484664917, Class Loss=0.637892484664917, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.6241170763969421, Reg Loss=0.0
Clinet index 7, End of Epoch 4/6, Average Loss=0.6241170763969421, Class Loss=0.6241170763969421, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.6244868040084839, Reg Loss=0.0
Clinet index 7, End of Epoch 5/6, Average Loss=0.6244868040084839, Class Loss=0.6244868040084839, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.6353827714920044, Reg Loss=0.0
Clinet index 7, End of Epoch 6/6, Average Loss=0.6353827714920044, Class Loss=0.6353827714920044, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.39658528566360474, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.902319
Mean Acc: 0.748082
FreqW Acc: 0.839533
Mean IoU: 0.631222
Class IoU:
	class 0: 0.8946379
	class 1: 0.87202424
	class 2: 0.42646357
	class 3: 0.8011043
	class 4: 0.603541
	class 5: 0.73824596
	class 6: 0.9212428
	class 7: 0.87000996
	class 8: 0.86068255
	class 9: 0.38723916
	class 10: 0.6133544
	class 11: 0.5490354
	class 12: 0.806258
	class 13: 0.700452
	class 14: 0.81370705
	class 15: 0.85540086
	class 16: 6.208092e-05
	class 17: 0.06427304
	class 18: 0.21548904
Class Acc:
	class 0: 0.9410847
	class 1: 0.925509
	class 2: 0.8954456
	class 3: 0.8279816
	class 4: 0.83984077
	class 5: 0.8799494
	class 6: 0.9805323
	class 7: 0.9254275
	class 8: 0.9126369
	class 9: 0.53550345
	class 10: 0.7817307
	class 11: 0.6521771
	class 12: 0.9210038
	class 13: 0.75539714
	class 14: 0.9038282
	class 15: 0.9313807
	class 16: 6.208092e-05
	class 17: 0.06612683
	class 18: 0.53793496

federated global round: 18, step: 3
select part of clients to conduct local training
[14, 4, 11, 21]
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.632279634475708, Reg Loss=0.0
Clinet index 14, End of Epoch 1/6, Average Loss=0.632279634475708, Class Loss=0.632279634475708, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.6370015740394592, Reg Loss=0.0
Clinet index 14, End of Epoch 2/6, Average Loss=0.6370015740394592, Class Loss=0.6370015740394592, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.6333907842636108, Reg Loss=0.0
Clinet index 14, End of Epoch 3/6, Average Loss=0.6333907842636108, Class Loss=0.6333907842636108, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.6084819436073303, Reg Loss=0.0
Clinet index 14, End of Epoch 4/6, Average Loss=0.6084819436073303, Class Loss=0.6084819436073303, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.598206639289856, Reg Loss=0.0
Clinet index 14, End of Epoch 5/6, Average Loss=0.598206639289856, Class Loss=0.598206639289856, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.5906299352645874, Reg Loss=0.0
Clinet index 14, End of Epoch 6/6, Average Loss=0.5906299352645874, Class Loss=0.5906299352645874, Reg Loss=0.0
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6139828562736511, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.6139828562736511, Class Loss=0.6139828562736511, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.6466475129127502, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.6466475129127502, Class Loss=0.6466475129127502, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.6209129691123962, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.6209129691123962, Class Loss=0.6209129691123962, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.6065952181816101, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.6065952181816101, Class Loss=0.6065952181816101, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.6225712895393372, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.6225712895393372, Class Loss=0.6225712895393372, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.6167899370193481, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.6167899370193481, Class Loss=0.6167899370193481, Reg Loss=0.0
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Epoch 1, Class Loss=0.6214584708213806, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.6214584708213806, Class Loss=0.6214584708213806, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000714
Epoch 2, Class Loss=0.6180177927017212, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.6180177927017212, Class Loss=0.6180177927017212, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000655
Epoch 3, Class Loss=0.6178848147392273, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.6178848147392273, Class Loss=0.6178848147392273, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000596
Epoch 4, Class Loss=0.5976536870002747, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.5976536870002747, Class Loss=0.5976536870002747, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000536
Epoch 5, Class Loss=0.5900347232818604, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.5900347232818604, Class Loss=0.5900347232818604, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000475
Epoch 6, Class Loss=0.5707592964172363, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.5707592964172363, Class Loss=0.5707592964172363, Reg Loss=0.0
Current Client Index:  21
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000568
Epoch 1, Class Loss=0.6183823347091675, Reg Loss=0.0
Clinet index 21, End of Epoch 1/6, Average Loss=0.6183823347091675, Class Loss=0.6183823347091675, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000525
Epoch 2, Class Loss=0.6095175743103027, Reg Loss=0.0
Clinet index 21, End of Epoch 2/6, Average Loss=0.6095175743103027, Class Loss=0.6095175743103027, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000482
Epoch 3, Class Loss=0.5877299904823303, Reg Loss=0.0
Clinet index 21, End of Epoch 3/6, Average Loss=0.5877299904823303, Class Loss=0.5877299904823303, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000438
Epoch 4, Class Loss=0.645751953125, Reg Loss=0.0
Clinet index 21, End of Epoch 4/6, Average Loss=0.645751953125, Class Loss=0.645751953125, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000394
Epoch 5, Class Loss=0.5922031402587891, Reg Loss=0.0
Clinet index 21, End of Epoch 5/6, Average Loss=0.5922031402587891, Class Loss=0.5922031402587891, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000350
Epoch 6, Class Loss=0.5709121227264404, Reg Loss=0.0
Clinet index 21, End of Epoch 6/6, Average Loss=0.5709121227264404, Class Loss=0.5709121227264404, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.3775498867034912, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.901375
Mean Acc: 0.743682
FreqW Acc: 0.838605
Mean IoU: 0.628670
Class IoU:
	class 0: 0.8941374
	class 1: 0.8683262
	class 2: 0.42952898
	class 3: 0.7912675
	class 4: 0.61043197
	class 5: 0.7388792
	class 6: 0.92485714
	class 7: 0.85959756
	class 8: 0.8595074
	class 9: 0.39331123
	class 10: 0.6086308
	class 11: 0.55007046
	class 12: 0.8069347
	class 13: 0.70461625
	class 14: 0.8141674
	class 15: 0.85520965
	class 16: 0.0
	class 17: 0.015158197
	class 18: 0.2200953
Class Acc:
	class 0: 0.94077516
	class 1: 0.91808736
	class 2: 0.88266206
	class 3: 0.8151915
	class 4: 0.8310751
	class 5: 0.8786981
	class 6: 0.9786985
	class 7: 0.9217986
	class 8: 0.91233844
	class 9: 0.5384152
	class 10: 0.7659743
	class 11: 0.64067847
	class 12: 0.9144703
	class 13: 0.7601295
	class 14: 0.90203184
	class 15: 0.93231785
	class 16: 0.0
	class 17: 0.015272217
	class 18: 0.58134097

federated global round: 19, step: 3
select part of clients to conduct local training
[15, 12, 21, 16]
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.593347430229187, Reg Loss=0.0
Clinet index 15, End of Epoch 1/6, Average Loss=0.593347430229187, Class Loss=0.593347430229187, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5461036562919617, Reg Loss=0.0
Clinet index 15, End of Epoch 2/6, Average Loss=0.5461036562919617, Class Loss=0.5461036562919617, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5520930886268616, Reg Loss=0.0
Clinet index 15, End of Epoch 3/6, Average Loss=0.5520930886268616, Class Loss=0.5520930886268616, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5424939393997192, Reg Loss=0.0
Clinet index 15, End of Epoch 4/6, Average Loss=0.5424939393997192, Class Loss=0.5424939393997192, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.5433694124221802, Reg Loss=0.0
Clinet index 15, End of Epoch 5/6, Average Loss=0.5433694124221802, Class Loss=0.5433694124221802, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5588967800140381, Reg Loss=0.0
Clinet index 15, End of Epoch 6/6, Average Loss=0.5588967800140381, Class Loss=0.5588967800140381, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5704353451728821, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.5704353451728821, Class Loss=0.5704353451728821, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.5681885480880737, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.5681885480880737, Class Loss=0.5681885480880737, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.563818633556366, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.563818633556366, Class Loss=0.563818633556366, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5554155707359314, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.5554155707359314, Class Loss=0.5554155707359314, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.5382921099662781, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.5382921099662781, Class Loss=0.5382921099662781, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5517427325248718, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.5517427325248718, Class Loss=0.5517427325248718, Reg Loss=0.0
Current Client Index:  21
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000304
Epoch 1, Class Loss=0.6122652292251587, Reg Loss=0.0
Clinet index 21, End of Epoch 1/6, Average Loss=0.6122652292251587, Class Loss=0.6122652292251587, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000258
Epoch 2, Class Loss=0.5773158073425293, Reg Loss=0.0
Clinet index 21, End of Epoch 2/6, Average Loss=0.5773158073425293, Class Loss=0.5773158073425293, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000211
Epoch 3, Class Loss=0.5655131340026855, Reg Loss=0.0
Clinet index 21, End of Epoch 3/6, Average Loss=0.5655131340026855, Class Loss=0.5655131340026855, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000163
Epoch 4, Class Loss=0.5968340635299683, Reg Loss=0.0
Clinet index 21, End of Epoch 4/6, Average Loss=0.5968340635299683, Class Loss=0.5968340635299683, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000113
Epoch 5, Class Loss=0.5710115432739258, Reg Loss=0.0
Clinet index 21, End of Epoch 5/6, Average Loss=0.5710115432739258, Class Loss=0.5710115432739258, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000061
Epoch 6, Class Loss=0.5606359839439392, Reg Loss=0.0
Clinet index 21, End of Epoch 6/6, Average Loss=0.5606359839439392, Class Loss=0.5606359839439392, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6210302710533142, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.6210302710533142, Class Loss=0.6210302710533142, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5940550565719604, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.5940550565719604, Class Loss=0.5940550565719604, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5679711103439331, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.5679711103439331, Class Loss=0.5679711103439331, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5601834058761597, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.5601834058761597, Class Loss=0.5601834058761597, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.5777181386947632, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.5777181386947632, Class Loss=0.5777181386947632, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5714423656463623, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.5714423656463623, Class Loss=0.5714423656463623, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.36908501386642456, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.901852
Mean Acc: 0.740163
FreqW Acc: 0.838229
Mean IoU: 0.627477
Class IoU:
	class 0: 0.8943223
	class 1: 0.8693861
	class 2: 0.42897576
	class 3: 0.77680457
	class 4: 0.61207825
	class 5: 0.73949105
	class 6: 0.9253394
	class 7: 0.8610837
	class 8: 0.85835004
	class 9: 0.3874183
	class 10: 0.6103677
	class 11: 0.55116475
	class 12: 0.80108815
	class 13: 0.7048364
	class 14: 0.8148598
	class 15: 0.8512155
	class 16: 0.0
	class 17: 0.005524305
	class 18: 0.22974826
Class Acc:
	class 0: 0.9424836
	class 1: 0.9189392
	class 2: 0.88045096
	class 3: 0.7975808
	class 4: 0.8261501
	class 5: 0.8794858
	class 6: 0.97747105
	class 7: 0.9159393
	class 8: 0.9116754
	class 9: 0.5228083
	class 10: 0.75812614
	class 11: 0.63466954
	class 12: 0.9119742
	class 13: 0.7587962
	class 14: 0.896891
	class 15: 0.9346333
	class 16: 0.0
	class 17: 0.005542779
	class 18: 0.58947617

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[9, 12, 24, 8]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.5728424787521362, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=1.5728424787521362, Class Loss=1.5728424787521362, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.1122342348098755, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=1.1122342348098755, Class Loss=1.1122342348098755, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.9448824524879456, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.9448824524879456, Class Loss=0.9448824524879456, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7638868689537048, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.7638868689537048, Class Loss=0.7638868689537048, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.6873440742492676, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.6873440742492676, Class Loss=0.6873440742492676, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.6319798827171326, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.6319798827171326, Class Loss=0.6319798827171326, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.4833797216415405, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=1.4833797216415405, Class Loss=1.4833797216415405, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.0955332517623901, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=1.0955332517623901, Class Loss=1.0955332517623901, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.8916653990745544, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.8916653990745544, Class Loss=0.8916653990745544, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7754420042037964, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.7754420042037964, Class Loss=0.7754420042037964, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.6981909275054932, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.6981909275054932, Class Loss=0.6981909275054932, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.6440863609313965, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.6440863609313965, Class Loss=0.6440863609313965, Reg Loss=0.0
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.4656685590744019, Reg Loss=0.0
Clinet index 24, End of Epoch 1/6, Average Loss=1.4656685590744019, Class Loss=1.4656685590744019, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.0847727060317993, Reg Loss=0.0
Clinet index 24, End of Epoch 2/6, Average Loss=1.0847727060317993, Class Loss=1.0847727060317993, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.8883954286575317, Reg Loss=0.0
Clinet index 24, End of Epoch 3/6, Average Loss=0.8883954286575317, Class Loss=0.8883954286575317, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7994534969329834, Reg Loss=0.0
Clinet index 24, End of Epoch 4/6, Average Loss=0.7994534969329834, Class Loss=0.7994534969329834, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.7538287043571472, Reg Loss=0.0
Clinet index 24, End of Epoch 5/6, Average Loss=0.7538287043571472, Class Loss=0.7538287043571472, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Class Loss=0.6453593969345093, Reg Loss=0.0
Clinet index 24, End of Epoch 6/6, Average Loss=0.6453593969345093, Class Loss=0.6453593969345093, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.5662678480148315, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=1.5662678480148315, Class Loss=1.5662678480148315, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.1498616933822632, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=1.1498616933822632, Class Loss=1.1498616933822632, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.8823452591896057, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.8823452591896057, Class Loss=0.8823452591896057, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7663483023643494, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.7663483023643494, Class Loss=0.7663483023643494, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.7105557918548584, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.7105557918548584, Class Loss=0.7105557918548584, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.6759189367294312, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.6759189367294312, Class Loss=0.6759189367294312, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.5685680508613586, Reg Loss=0.0 (without scaling)

Total samples: 1421.000000
Overall Acc: 0.878429
Mean Acc: 0.600370
FreqW Acc: 0.787825
Mean IoU: 0.524093
Class IoU:
	class 0: 0.8741898
	class 1: 0.6634444
	class 2: 0.43579203
	class 3: 0.5693474
	class 4: 0.55804473
	class 5: 0.670441
	class 6: 0.6696915
	class 7: 0.8200331
	class 8: 0.696496
	class 9: 0.27078786
	class 10: 0.5278931
	class 11: 0.45057467
	class 12: 0.7096804
	class 13: 0.6015445
	class 14: 0.75271666
	class 15: 0.8354464
	class 16: 0.0
	class 17: 0.0012874787
	class 18: 0.0039587626
	class 19: 0.37049308
Class Acc:
	class 0: 0.9744535
	class 1: 0.6849105
	class 2: 0.8227223
	class 3: 0.5777078
	class 4: 0.6393762
	class 5: 0.76359624
	class 6: 0.6821287
	class 7: 0.8765741
	class 8: 0.70963544
	class 9: 0.31451583
	class 10: 0.5813691
	class 11: 0.4938591
	class 12: 0.78823555
	class 13: 0.63994104
	class 14: 0.8073311
	class 15: 0.9023245
	class 16: 0.0
	class 17: 0.0012880872
	class 18: 0.0040032845
	class 19: 0.7434303

federated global round: 21, step: 4
select part of clients to conduct local training
[5, 8, 0, 6]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6185910701751709, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.6185910701751709, Class Loss=0.6185910701751709, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6059409379959106, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.6059409379959106, Class Loss=0.6059409379959106, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.5985708832740784, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.5985708832740784, Class Loss=0.5985708832740784, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6002286076545715, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.6002286076545715, Class Loss=0.6002286076545715, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 5, Class Loss=0.531311571598053, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.531311571598053, Class Loss=0.531311571598053, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.5388455986976624, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.5388455986976624, Class Loss=0.5388455986976624, Reg Loss=0.0
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.6179057359695435, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.6179057359695435, Class Loss=0.6179057359695435, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000787
Epoch 2, Class Loss=0.5988113284111023, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.5988113284111023, Class Loss=0.5988113284111023, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000756
Epoch 3, Class Loss=0.5670378804206848, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.5670378804206848, Class Loss=0.5670378804206848, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000725
Epoch 4, Class Loss=0.5458650588989258, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.5458650588989258, Class Loss=0.5458650588989258, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.5251343250274658, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.5251343250274658, Class Loss=0.5251343250274658, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000663
Epoch 6, Class Loss=0.5198596715927124, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.5198596715927124, Class Loss=0.5198596715927124, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6186954379081726, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.6186954379081726, Class Loss=0.6186954379081726, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.6346769332885742, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.6346769332885742, Class Loss=0.6346769332885742, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6055033206939697, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.6055033206939697, Class Loss=0.6055033206939697, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.5587018728256226, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.5587018728256226, Class Loss=0.5587018728256226, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.5494967699050903, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.5494967699050903, Class Loss=0.5494967699050903, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.5223445892333984, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.5223445892333984, Class Loss=0.5223445892333984, Reg Loss=0.0
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6344798803329468, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.6344798803329468, Class Loss=0.6344798803329468, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6295403242111206, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.6295403242111206, Class Loss=0.6295403242111206, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.60017329454422, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.60017329454422, Class Loss=0.60017329454422, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.546599268913269, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.546599268913269, Class Loss=0.546599268913269, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.5250920653343201, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.5250920653343201, Class Loss=0.5250920653343201, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.5300434231758118, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.5300434231758118, Class Loss=0.5300434231758118, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4642942547798157, Reg Loss=0.0 (without scaling)

Total samples: 1421.000000
Overall Acc: 0.882346
Mean Acc: 0.610540
FreqW Acc: 0.795939
Mean IoU: 0.533266
Class IoU:
	class 0: 0.88160324
	class 1: 0.6585653
	class 2: 0.4379166
	class 3: 0.5934663
	class 4: 0.5797176
	class 5: 0.6827699
	class 6: 0.7192948
	class 7: 0.83801067
	class 8: 0.7018202
	class 9: 0.28017798
	class 10: 0.533414
	class 11: 0.45588106
	class 12: 0.7264033
	class 13: 0.60667515
	class 14: 0.7654723
	class 15: 0.8395885
	class 16: 0.0
	class 17: 2.1974754e-05
	class 18: 0.00048516356
	class 19: 0.36403003
Class Acc:
	class 0: 0.9742401
	class 1: 0.6706061
	class 2: 0.8136357
	class 3: 0.6003136
	class 4: 0.6685506
	class 5: 0.77546185
	class 6: 0.73550665
	class 7: 0.8928065
	class 8: 0.7131286
	class 9: 0.32390097
	class 10: 0.59186214
	class 11: 0.4861073
	class 12: 0.81533813
	class 13: 0.64192045
	class 14: 0.8072683
	class 15: 0.9081838
	class 16: 0.0
	class 17: 2.1974847e-05
	class 18: 0.00048719606
	class 19: 0.7914532

federated global round: 22, step: 4
select part of clients to conduct local training
[8, 25, 22, 5]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000631
Epoch 1, Class Loss=0.4967472553253174, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=0.4967472553253174, Class Loss=0.4967472553253174, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000600
Epoch 2, Class Loss=0.48320508003234863, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.48320508003234863, Class Loss=0.48320508003234863, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000568
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Class Loss=0.4659123420715332, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.4659123420715332, Class Loss=0.4659123420715332, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.4882725477218628, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.4882725477218628, Class Loss=0.4882725477218628, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000504
Epoch 5, Class Loss=0.46258628368377686, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.46258628368377686, Class Loss=0.46258628368377686, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000471
Epoch 6, Class Loss=0.4777856171131134, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.4777856171131134, Class Loss=0.4777856171131134, Reg Loss=0.0
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5024102926254272, Reg Loss=0.0
Clinet index 25, End of Epoch 1/6, Average Loss=0.5024102926254272, Class Loss=0.5024102926254272, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.46592485904693604, Reg Loss=0.0
Clinet index 25, End of Epoch 2/6, Average Loss=0.46592485904693604, Class Loss=0.46592485904693604, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.44998666644096375, Reg Loss=0.0
Clinet index 25, End of Epoch 3/6, Average Loss=0.44998666644096375, Class Loss=0.44998666644096375, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.4650789797306061, Reg Loss=0.0
Clinet index 25, End of Epoch 4/6, Average Loss=0.4650789797306061, Class Loss=0.4650789797306061, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.4625678062438965, Reg Loss=0.0
Clinet index 25, End of Epoch 5/6, Average Loss=0.4625678062438965, Class Loss=0.4625678062438965, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.4387529194355011, Reg Loss=0.0
Clinet index 25, End of Epoch 6/6, Average Loss=0.4387529194355011, Class Loss=0.4387529194355011, Reg Loss=0.0
Current Client Index:  22
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5054149031639099, Reg Loss=0.0
Clinet index 22, End of Epoch 1/6, Average Loss=0.5054149031639099, Class Loss=0.5054149031639099, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.4894455373287201, Reg Loss=0.0
Clinet index 22, End of Epoch 2/6, Average Loss=0.4894455373287201, Class Loss=0.4894455373287201, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.4730435311794281, Reg Loss=0.0
Clinet index 22, End of Epoch 3/6, Average Loss=0.4730435311794281, Class Loss=0.4730435311794281, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.4570584297180176, Reg Loss=0.0
Clinet index 22, End of Epoch 4/6, Average Loss=0.4570584297180176, Class Loss=0.4570584297180176, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.43084952235221863, Reg Loss=0.0
Clinet index 22, End of Epoch 5/6, Average Loss=0.43084952235221863, Class Loss=0.43084952235221863, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.4754409193992615, Reg Loss=0.0
Clinet index 22, End of Epoch 6/6, Average Loss=0.4754409193992615, Class Loss=0.4754409193992615, Reg Loss=0.0
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Epoch 1, Class Loss=0.5232867002487183, Reg Loss=0.0
Clinet index 5, End of Epoch 1/6, Average Loss=0.5232867002487183, Class Loss=0.5232867002487183, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000733
Epoch 2, Class Loss=0.5063920617103577, Reg Loss=0.0
Clinet index 5, End of Epoch 2/6, Average Loss=0.5063920617103577, Class Loss=0.5063920617103577, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5276017189025879, Reg Loss=0.0
Clinet index 5, End of Epoch 3/6, Average Loss=0.5276017189025879, Class Loss=0.5276017189025879, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000655
Epoch 4, Class Loss=0.529530942440033, Reg Loss=0.0
Clinet index 5, End of Epoch 4/6, Average Loss=0.529530942440033, Class Loss=0.529530942440033, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000616
Epoch 5, Class Loss=0.5002048015594482, Reg Loss=0.0
Clinet index 5, End of Epoch 5/6, Average Loss=0.5002048015594482, Class Loss=0.5002048015594482, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000576
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Class Loss=0.48741641640663147, Reg Loss=0.0
Clinet index 5, End of Epoch 6/6, Average Loss=0.48741641640663147, Class Loss=0.48741641640663147, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4345375895500183, Reg Loss=0.0 (without scaling)

Total samples: 1421.000000
Overall Acc: 0.880233
Mean Acc: 0.601885
FreqW Acc: 0.793015
Mean IoU: 0.527816
Class IoU:
	class 0: 0.8802565
	class 1: 0.6798345
	class 2: 0.43351632
	class 3: 0.5802486
	class 4: 0.6004668
	class 5: 0.6764806
	class 6: 0.7174998
	class 7: 0.84013444
	class 8: 0.66156906
	class 9: 0.27537128
	class 10: 0.53674763
	class 11: 0.4534264
	class 12: 0.73799145
	class 13: 0.59497744
	class 14: 0.69477934
	class 15: 0.84027195
	class 16: 0.0
	class 17: 9.030759e-07
	class 18: 1.5387792e-05
	class 19: 0.35273886
Class Acc:
	class 0: 0.9748576
	class 1: 0.69134146
	class 2: 0.7712737
	class 3: 0.5863924
	class 4: 0.70518583
	class 5: 0.7559688
	class 6: 0.7365958
	class 7: 0.8905007
	class 8: 0.6693681
	class 9: 0.3114241
	class 10: 0.59638304
	class 11: 0.47955766
	class 12: 0.80605996
	class 13: 0.6273554
	class 14: 0.7174282
	class 15: 0.91167843
	class 16: 0.0
	class 17: 9.030759e-07
	class 18: 1.542474e-05
	class 19: 0.8063047

federated global round: 23, step: 4
select part of clients to conduct local training
[3, 19, 1, 11]
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.44990524649620056, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=0.44990524649620056, Class Loss=0.44990524649620056, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.4540541172027588, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.4540541172027588, Class Loss=0.4540541172027588, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 3, Class Loss=0.4399868845939636, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.4399868845939636, Class Loss=0.4399868845939636, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.45963552594184875, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.45963552594184875, Class Loss=0.45963552594184875, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.4145236015319824, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.4145236015319824, Class Loss=0.4145236015319824, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.4021326005458832, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.4021326005458832, Class Loss=0.4021326005458832, Reg Loss=0.0
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.46330106258392334, Reg Loss=0.0
Clinet index 19, End of Epoch 1/6, Average Loss=0.46330106258392334, Class Loss=0.46330106258392334, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.4777897894382477, Reg Loss=0.0
Clinet index 19, End of Epoch 2/6, Average Loss=0.4777897894382477, Class Loss=0.4777897894382477, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.447748601436615, Reg Loss=0.0
Clinet index 19, End of Epoch 3/6, Average Loss=0.447748601436615, Class Loss=0.447748601436615, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.465621680021286, Reg Loss=0.0
Clinet index 19, End of Epoch 4/6, Average Loss=0.465621680021286, Class Loss=0.465621680021286, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.4830295741558075, Reg Loss=0.0
Clinet index 19, End of Epoch 5/6, Average Loss=0.4830295741558075, Class Loss=0.4830295741558075, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.4371527135372162, Reg Loss=0.0
Clinet index 19, End of Epoch 6/6, Average Loss=0.4371527135372162, Class Loss=0.4371527135372162, Reg Loss=0.0
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.45601874589920044, Reg Loss=0.0
Clinet index 1, End of Epoch 1/6, Average Loss=0.45601874589920044, Class Loss=0.45601874589920044, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.4642626643180847, Reg Loss=0.0
Clinet index 1, End of Epoch 2/6, Average Loss=0.4642626643180847, Class Loss=0.4642626643180847, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.4619981050491333, Reg Loss=0.0
Clinet index 1, End of Epoch 3/6, Average Loss=0.4619981050491333, Class Loss=0.4619981050491333, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.46826425194740295, Reg Loss=0.0
Clinet index 1, End of Epoch 4/6, Average Loss=0.46826425194740295, Class Loss=0.46826425194740295, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.46048012375831604, Reg Loss=0.0
Clinet index 1, End of Epoch 5/6, Average Loss=0.46048012375831604, Class Loss=0.46048012375831604, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.4199241101741791, Reg Loss=0.0
Clinet index 1, End of Epoch 6/6, Average Loss=0.4199241101741791, Class Loss=0.4199241101741791, Reg Loss=0.0
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.4712832570075989, Reg Loss=0.0
Clinet index 11, End of Epoch 1/6, Average Loss=0.4712832570075989, Class Loss=0.4712832570075989, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.4528164863586426, Reg Loss=0.0
Clinet index 11, End of Epoch 2/6, Average Loss=0.4528164863586426, Class Loss=0.4528164863586426, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.46638554334640503, Reg Loss=0.0
Clinet index 11, End of Epoch 3/6, Average Loss=0.46638554334640503, Class Loss=0.46638554334640503, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.4535094201564789, Reg Loss=0.0
Clinet index 11, End of Epoch 4/6, Average Loss=0.4535094201564789, Class Loss=0.4535094201564789, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.48435136675834656, Reg Loss=0.0
Clinet index 11, End of Epoch 5/6, Average Loss=0.48435136675834656, Class Loss=0.48435136675834656, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.47827643156051636, Reg Loss=0.0
Clinet index 11, End of Epoch 6/6, Average Loss=0.47827643156051636, Class Loss=0.47827643156051636, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.41612544655799866, Reg Loss=0.0 (without scaling)

Total samples: 1421.000000
Overall Acc: 0.880550
Mean Acc: 0.602166
FreqW Acc: 0.794691
Mean IoU: 0.529658
Class IoU:
	class 0: 0.88245183
	class 1: 0.75476074
	class 2: 0.42485672
	class 3: 0.61220473
	class 4: 0.6116913
	class 5: 0.67716193
	class 6: 0.72359014
	class 7: 0.83980286
	class 8: 0.6542773
	class 9: 0.24999572
	class 10: 0.53168595
	class 11: 0.43802166
	class 12: 0.7397079
	class 13: 0.60954475
	class 14: 0.6625549
	class 15: 0.8394416
	class 16: 0.0
	class 17: 0.0
	class 18: 5.073637e-06
	class 19: 0.34139863
Class Acc:
	class 0: 0.97464305
	class 1: 0.7708102
	class 2: 0.74521786
	class 3: 0.62083423
	class 4: 0.70079
	class 5: 0.7573232
	class 6: 0.7331764
	class 7: 0.8827272
	class 8: 0.660845
	class 9: 0.2724483
	class 10: 0.58856356
	class 11: 0.45822626
	class 12: 0.8078837
	class 13: 0.6458065
	class 14: 0.68378997
	class 15: 0.91734934
	class 16: 0.0
	class 17: 0.0
	class 18: 5.0788776e-06
	class 19: 0.8228761

federated global round: 24, step: 4
select part of clients to conduct local training
[4, 13, 18, 9]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.4327690601348877, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.4327690601348877, Class Loss=0.4327690601348877, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.43633177876472473, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.43633177876472473, Class Loss=0.43633177876472473, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.45275795459747314, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.45275795459747314, Class Loss=0.45275795459747314, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.4108426868915558, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.4108426868915558, Class Loss=0.4108426868915558, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.4137897789478302, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.4137897789478302, Class Loss=0.4137897789478302, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.42595329880714417, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.42595329880714417, Class Loss=0.42595329880714417, Reg Loss=0.0
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.4237530827522278, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.4237530827522278, Class Loss=0.4237530827522278, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.42816221714019775, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.42816221714019775, Class Loss=0.42816221714019775, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.42361608147621155, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.42361608147621155, Class Loss=0.42361608147621155, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.427212119102478, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.427212119102478, Class Loss=0.427212119102478, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.42679017782211304, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.42679017782211304, Class Loss=0.42679017782211304, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.40454137325286865, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.40454137325286865, Class Loss=0.40454137325286865, Reg Loss=0.0
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.44545984268188477, Reg Loss=0.0
Clinet index 18, End of Epoch 1/6, Average Loss=0.44545984268188477, Class Loss=0.44545984268188477, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.43980640172958374, Reg Loss=0.0
Clinet index 18, End of Epoch 2/6, Average Loss=0.43980640172958374, Class Loss=0.43980640172958374, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.47417977452278137, Reg Loss=0.0
Clinet index 18, End of Epoch 3/6, Average Loss=0.47417977452278137, Class Loss=0.47417977452278137, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.43930283188819885, Reg Loss=0.0
Clinet index 18, End of Epoch 4/6, Average Loss=0.43930283188819885, Class Loss=0.43930283188819885, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.4332874119281769, Reg Loss=0.0
Clinet index 18, End of Epoch 5/6, Average Loss=0.4332874119281769, Class Loss=0.4332874119281769, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.40748751163482666, Reg Loss=0.0
Clinet index 18, End of Epoch 6/6, Average Loss=0.40748751163482666, Class Loss=0.40748751163482666, Reg Loss=0.0
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=0.4242261052131653, Reg Loss=0.0
Clinet index 9, End of Epoch 1/6, Average Loss=0.4242261052131653, Class Loss=0.4242261052131653, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000694
Epoch 2, Class Loss=0.42676907777786255, Reg Loss=0.0
Clinet index 9, End of Epoch 2/6, Average Loss=0.42676907777786255, Class Loss=0.42676907777786255, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000568
Epoch 3, Class Loss=0.4083609879016876, Reg Loss=0.0
Clinet index 9, End of Epoch 3/6, Average Loss=0.4083609879016876, Class Loss=0.4083609879016876, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000438
Epoch 4, Class Loss=0.4363662302494049, Reg Loss=0.0
Clinet index 9, End of Epoch 4/6, Average Loss=0.4363662302494049, Class Loss=0.4363662302494049, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000304
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 5, Class Loss=0.3990396559238434, Reg Loss=0.0
Clinet index 9, End of Epoch 5/6, Average Loss=0.3990396559238434, Class Loss=0.3990396559238434, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000163
Epoch 6, Class Loss=0.426341712474823, Reg Loss=0.0
Clinet index 9, End of Epoch 6/6, Average Loss=0.426341712474823, Class Loss=0.426341712474823, Reg Loss=0.0
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=0.40851128101348877, Reg Loss=0.0 (without scaling)

Total samples: 1421.000000
Overall Acc: 0.880318
Mean Acc: 0.592422
FreqW Acc: 0.790780
Mean IoU: 0.525074
Class IoU:
	class 0: 0.87769926
	class 1: 0.72250307
	class 2: 0.4269573
	class 3: 0.54801214
	class 4: 0.60154283
	class 5: 0.6720387
	class 6: 0.7701258
	class 7: 0.8416615
	class 8: 0.6100372
	class 9: 0.212452
	class 10: 0.53850806
	class 11: 0.4243534
	class 12: 0.73502094
	class 13: 0.6172783
	class 14: 0.68909526
	class 15: 0.84229255
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.3719026
Class Acc:
	class 0: 0.97791207
	class 1: 0.73355293
	class 2: 0.74216676
	class 3: 0.55296934
	class 4: 0.6782357
	class 5: 0.7322254
	class 6: 0.7955206
	class 7: 0.87979597
	class 8: 0.6151471
	class 9: 0.22407325
	class 10: 0.5961363
	class 11: 0.43861
	class 12: 0.7975472
	class 13: 0.6572082
	class 14: 0.71170247
	class 15: 0.91377604
	class 16: 0.0
	class 17: 0.0
	class 18: 0.0
	class 19: 0.80185103

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 25, step: 5
select part of clients to conduct local training
[29, 3, 8, 19]
Current Client Index:  29
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.3270682096481323, Reg Loss=0.0
Clinet index 29, End of Epoch 1/6, Average Loss=1.3270682096481323, Class Loss=1.3270682096481323, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.8582637310028076, Reg Loss=0.0
Clinet index 29, End of Epoch 2/6, Average Loss=0.8582637310028076, Class Loss=0.8582637310028076, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.7683225274085999, Reg Loss=0.0
Clinet index 29, End of Epoch 3/6, Average Loss=0.7683225274085999, Class Loss=0.7683225274085999, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7106047868728638, Reg Loss=0.0
Clinet index 29, End of Epoch 4/6, Average Loss=0.7106047868728638, Class Loss=0.7106047868728638, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.6952283978462219, Reg Loss=0.0
Clinet index 29, End of Epoch 5/6, Average Loss=0.6952283978462219, Class Loss=0.6952283978462219, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.6702168583869934, Reg Loss=0.0
Clinet index 29, End of Epoch 6/6, Average Loss=0.6702168583869934, Class Loss=0.6702168583869934, Reg Loss=0.0
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch 1, Class Loss=1.363370656967163, Reg Loss=0.0
Clinet index 3, End of Epoch 1/6, Average Loss=1.363370656967163, Class Loss=1.363370656967163, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.8854629993438721, Reg Loss=0.0
Clinet index 3, End of Epoch 2/6, Average Loss=0.8854629993438721, Class Loss=0.8854629993438721, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.7687705159187317, Reg Loss=0.0
Clinet index 3, End of Epoch 3/6, Average Loss=0.7687705159187317, Class Loss=0.7687705159187317, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7117549180984497, Reg Loss=0.0
Clinet index 3, End of Epoch 4/6, Average Loss=0.7117549180984497, Class Loss=0.7117549180984497, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.7055452466011047, Reg Loss=0.0
Clinet index 3, End of Epoch 5/6, Average Loss=0.7055452466011047, Class Loss=0.7055452466011047, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.7030494809150696, Reg Loss=0.0
Clinet index 3, End of Epoch 6/6, Average Loss=0.7030494809150696, Class Loss=0.7030494809150696, Reg Loss=0.0
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.405495285987854, Reg Loss=0.0
Clinet index 8, End of Epoch 1/6, Average Loss=1.405495285987854, Class Loss=1.405495285987854, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.8858689069747925, Reg Loss=0.0
Clinet index 8, End of Epoch 2/6, Average Loss=0.8858689069747925, Class Loss=0.8858689069747925, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.7635576128959656, Reg Loss=0.0
Clinet index 8, End of Epoch 3/6, Average Loss=0.7635576128959656, Class Loss=0.7635576128959656, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.742660641670227, Reg Loss=0.0
Clinet index 8, End of Epoch 4/6, Average Loss=0.742660641670227, Class Loss=0.742660641670227, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.7118522524833679, Reg Loss=0.0
Clinet index 8, End of Epoch 5/6, Average Loss=0.7118522524833679, Class Loss=0.7118522524833679, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.6829020977020264, Reg Loss=0.0
Clinet index 8, End of Epoch 6/6, Average Loss=0.6829020977020264, Class Loss=0.6829020977020264, Reg Loss=0.0
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 1, Class Loss=1.3581507205963135, Reg Loss=0.0
Clinet index 19, End of Epoch 1/6, Average Loss=1.3581507205963135, Class Loss=1.3581507205963135, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.8704891800880432, Reg Loss=0.0
Clinet index 19, End of Epoch 2/6, Average Loss=0.8704891800880432, Class Loss=0.8704891800880432, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.7724708318710327, Reg Loss=0.0
Clinet index 19, End of Epoch 3/6, Average Loss=0.7724708318710327, Class Loss=0.7724708318710327, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.7216782569885254, Reg Loss=0.0
Clinet index 19, End of Epoch 4/6, Average Loss=0.7216782569885254, Class Loss=0.7216782569885254, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.724640429019928, Reg Loss=0.0
Clinet index 19, End of Epoch 5/6, Average Loss=0.724640429019928, Class Loss=0.724640429019928, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.6935328841209412, Reg Loss=0.0
Clinet index 19, End of Epoch 6/6, Average Loss=0.6935328841209412, Class Loss=0.6935328841209412, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.5045602917671204, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.870082
Mean Acc: 0.539133
FreqW Acc: 0.764959
Mean IoU: 0.488474
Class IoU:
	class 0: 0.85179067
	class 1: 0.7656696
	class 2: 0.41249964
	class 3: 0.48793134
	class 4: 0.56157726
	class 5: 0.6818584
	class 6: 0.82132256
	class 7: 0.74444884
	class 8: 0.63921285
	class 9: 0.18644461
	class 10: 0.55465275
	class 11: 0.37757528
	class 12: 0.75558716
	class 13: 0.6346172
	class 14: 0.687257
	class 15: 0.835276
	class 16: 0.0
	class 17: 0.0007916392
	class 18: 0.0006178625
	class 19: 0.25881487
	class 20: 0.0
Class Acc:
	class 0: 0.98433906
	class 1: 0.78719383
	class 2: 0.70744425
	class 3: 0.4917995
	class 4: 0.66679853
	class 5: 0.7502004
	class 6: 0.8522813
	class 7: 0.76671314
	class 8: 0.6449903
	class 9: 0.19410424
	class 10: 0.620714
	class 11: 0.38631293
	class 12: 0.8453082
	class 13: 0.69207865
	class 14: 0.714346
	class 15: 0.9128515
	class 16: 0.0
	class 17: 0.0007925996
	class 18: 0.00061793014
	class 19: 0.30291632
	class 20: 0.0

federated global round: 26, step: 5
select part of clients to conduct local training
[4, 0, 29, 20]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6848390698432922, Reg Loss=0.0
Clinet index 4, End of Epoch 1/6, Average Loss=0.6848390698432922, Class Loss=0.6848390698432922, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6851252317428589, Reg Loss=0.0
Clinet index 4, End of Epoch 2/6, Average Loss=0.6851252317428589, Class Loss=0.6851252317428589, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6925505995750427, Reg Loss=0.0
Clinet index 4, End of Epoch 3/6, Average Loss=0.6925505995750427, Class Loss=0.6925505995750427, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6311433911323547, Reg Loss=0.0
Clinet index 4, End of Epoch 4/6, Average Loss=0.6311433911323547, Class Loss=0.6311433911323547, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.6357372403144836, Reg Loss=0.0
Clinet index 4, End of Epoch 5/6, Average Loss=0.6357372403144836, Class Loss=0.6357372403144836, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.6182603240013123, Reg Loss=0.0
Clinet index 4, End of Epoch 6/6, Average Loss=0.6182603240013123, Class Loss=0.6182603240013123, Reg Loss=0.0
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6309693455696106, Reg Loss=0.0
Clinet index 0, End of Epoch 1/6, Average Loss=0.6309693455696106, Class Loss=0.6309693455696106, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6279744505882263, Reg Loss=0.0
Clinet index 0, End of Epoch 2/6, Average Loss=0.6279744505882263, Class Loss=0.6279744505882263, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6046894192695618, Reg Loss=0.0
Clinet index 0, End of Epoch 3/6, Average Loss=0.6046894192695618, Class Loss=0.6046894192695618, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6004148721694946, Reg Loss=0.0
Clinet index 0, End of Epoch 4/6, Average Loss=0.6004148721694946, Class Loss=0.6004148721694946, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.6053318381309509, Reg Loss=0.0
Clinet index 0, End of Epoch 5/6, Average Loss=0.6053318381309509, Class Loss=0.6053318381309509, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.5834611654281616, Reg Loss=0.0
Clinet index 0, End of Epoch 6/6, Average Loss=0.5834611654281616, Class Loss=0.5834611654281616, Reg Loss=0.0
Current Client Index:  29
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000818
Epoch 1, Class Loss=0.6683392524719238, Reg Loss=0.0
Clinet index 29, End of Epoch 1/6, Average Loss=0.6683392524719238, Class Loss=0.6683392524719238, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000787
Epoch 2, Class Loss=0.6713438034057617, Reg Loss=0.0
Clinet index 29, End of Epoch 2/6, Average Loss=0.6713438034057617, Class Loss=0.6713438034057617, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000756
Epoch 3, Class Loss=0.6492898464202881, Reg Loss=0.0
Clinet index 29, End of Epoch 3/6, Average Loss=0.6492898464202881, Class Loss=0.6492898464202881, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000725
Epoch 4, Class Loss=0.6341598629951477, Reg Loss=0.0
Clinet index 29, End of Epoch 4/6, Average Loss=0.6341598629951477, Class Loss=0.6341598629951477, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.6209014058113098, Reg Loss=0.0
Clinet index 29, End of Epoch 5/6, Average Loss=0.6209014058113098, Class Loss=0.6209014058113098, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000663
Epoch 6, Class Loss=0.6031106114387512, Reg Loss=0.0
Clinet index 29, End of Epoch 6/6, Average Loss=0.6031106114387512, Class Loss=0.6031106114387512, Reg Loss=0.0
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6818113327026367, Reg Loss=0.0
Clinet index 20, End of Epoch 1/6, Average Loss=0.6818113327026367, Class Loss=0.6818113327026367, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.6556341648101807, Reg Loss=0.0
Clinet index 20, End of Epoch 2/6, Average Loss=0.6556341648101807, Class Loss=0.6556341648101807, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.6503627896308899, Reg Loss=0.0
Clinet index 20, End of Epoch 3/6, Average Loss=0.6503627896308899, Class Loss=0.6503627896308899, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6326188445091248, Reg Loss=0.0
Clinet index 20, End of Epoch 4/6, Average Loss=0.6326188445091248, Class Loss=0.6326188445091248, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.609237790107727, Reg Loss=0.0
Clinet index 20, End of Epoch 5/6, Average Loss=0.609237790107727, Class Loss=0.609237790107727, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.6097679138183594, Reg Loss=0.0
Clinet index 20, End of Epoch 6/6, Average Loss=0.6097679138183594, Class Loss=0.6097679138183594, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.46761560440063477, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.875804
Mean Acc: 0.557888
FreqW Acc: 0.774426
Mean IoU: 0.504259
Class IoU:
	class 0: 0.8586366
	class 1: 0.78707576
	class 2: 0.41175887
	class 3: 0.5877233
	class 4: 0.5637836
	class 5: 0.6974658
	class 6: 0.84151167
	class 7: 0.7923608
	class 8: 0.68383044
	class 9: 0.17681609
	class 10: 0.5576702
	class 11: 0.39558458
	class 12: 0.7586368
	class 13: 0.6385959
	class 14: 0.692443
	class 15: 0.8334028
	class 16: 0.0
	class 17: 0.001268004
	class 18: 7.5430056e-05
	class 19: 0.27050328
	class 20: 0.04030039
Class Acc:
	class 0: 0.98376423
	class 1: 0.8137188
	class 2: 0.72505134
	class 3: 0.5944864
	class 4: 0.65793747
	class 5: 0.7716737
	class 6: 0.8960034
	class 7: 0.8254692
	class 8: 0.6931504
	class 9: 0.18268336
	class 10: 0.6408286
	class 11: 0.40606362
	class 12: 0.8566247
	class 13: 0.69108063
	class 14: 0.7151997
	class 15: 0.91552234
	class 16: 0.0
	class 17: 0.0012688217
	class 18: 7.543074e-05
	class 19: 0.30474624
	class 20: 0.04030039

federated global round: 27, step: 5
select part of clients to conduct local training
[13, 12, 20, 15]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6338978409767151, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.6338978409767151, Class Loss=0.6338978409767151, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6409603953361511, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.6409603953361511, Class Loss=0.6409603953361511, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6446356177330017, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.6446356177330017, Class Loss=0.6446356177330017, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.6098268032073975, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.6098268032073975, Class Loss=0.6098268032073975, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.6303611397743225, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.6303611397743225, Class Loss=0.6303611397743225, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.5918302536010742, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.5918302536010742, Class Loss=0.5918302536010742, Reg Loss=0.0
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6358866095542908, Reg Loss=0.0
Clinet index 12, End of Epoch 1/6, Average Loss=0.6358866095542908, Class Loss=0.6358866095542908, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6137479543685913, Reg Loss=0.0
Clinet index 12, End of Epoch 2/6, Average Loss=0.6137479543685913, Class Loss=0.6137479543685913, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.5974150896072388, Reg Loss=0.0
Clinet index 12, End of Epoch 3/6, Average Loss=0.5974150896072388, Class Loss=0.5974150896072388, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.5834428668022156, Reg Loss=0.0
Clinet index 12, End of Epoch 4/6, Average Loss=0.5834428668022156, Class Loss=0.5834428668022156, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.5851070880889893, Reg Loss=0.0
Clinet index 12, End of Epoch 5/6, Average Loss=0.5851070880889893, Class Loss=0.5851070880889893, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 6, Class Loss=0.5975540280342102, Reg Loss=0.0
Clinet index 12, End of Epoch 6/6, Average Loss=0.5975540280342102, Class Loss=0.5975540280342102, Reg Loss=0.0
Current Client Index:  20
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000772
Epoch 1, Class Loss=0.6126958131790161, Reg Loss=0.0
Clinet index 20, End of Epoch 1/6, Average Loss=0.6126958131790161, Class Loss=0.6126958131790161, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000733
Epoch 2, Class Loss=0.5944960117340088, Reg Loss=0.0
Clinet index 20, End of Epoch 2/6, Average Loss=0.5944960117340088, Class Loss=0.5944960117340088, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5784398317337036, Reg Loss=0.0
Clinet index 20, End of Epoch 3/6, Average Loss=0.5784398317337036, Class Loss=0.5784398317337036, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000655
Epoch 4, Class Loss=0.5770390629768372, Reg Loss=0.0
Clinet index 20, End of Epoch 4/6, Average Loss=0.5770390629768372, Class Loss=0.5770390629768372, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000616
Epoch 5, Class Loss=0.5662984848022461, Reg Loss=0.0
Clinet index 20, End of Epoch 5/6, Average Loss=0.5662984848022461, Class Loss=0.5662984848022461, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000576
Epoch 6, Class Loss=0.5627654790878296, Reg Loss=0.0
Clinet index 20, End of Epoch 6/6, Average Loss=0.5627654790878296, Class Loss=0.5627654790878296, Reg Loss=0.0
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.6063357591629028, Reg Loss=0.0
Clinet index 15, End of Epoch 1/6, Average Loss=0.6063357591629028, Class Loss=0.6063357591629028, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000950
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 2, Class Loss=0.6029446721076965, Reg Loss=0.0
Clinet index 15, End of Epoch 2/6, Average Loss=0.6029446721076965, Class Loss=0.6029446721076965, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.5870426297187805, Reg Loss=0.0
Clinet index 15, End of Epoch 3/6, Average Loss=0.5870426297187805, Class Loss=0.5870426297187805, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.5726349353790283, Reg Loss=0.0
Clinet index 15, End of Epoch 4/6, Average Loss=0.5726349353790283, Class Loss=0.5726349353790283, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.5669168829917908, Reg Loss=0.0
Clinet index 15, End of Epoch 5/6, Average Loss=0.5669168829917908, Class Loss=0.5669168829917908, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.5563680529594421, Reg Loss=0.0
Clinet index 15, End of Epoch 6/6, Average Loss=0.5563680529594421, Class Loss=0.5563680529594421, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4535403847694397, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.880572
Mean Acc: 0.579731
FreqW Acc: 0.783060
Mean IoU: 0.523323
Class IoU:
	class 0: 0.86493534
	class 1: 0.7922218
	class 2: 0.41192117
	class 3: 0.6493366
	class 4: 0.559848
	class 5: 0.7157714
	class 6: 0.8470338
	class 7: 0.7997641
	class 8: 0.7092927
	class 9: 0.18501227
	class 10: 0.5582307
	class 11: 0.3908575
	class 12: 0.7529132
	class 13: 0.6415189
	class 14: 0.7020765
	class 15: 0.83196807
	class 16: 0.0
	class 17: 0.0011981658
	class 18: 6.546109e-05
	class 19: 0.30595213
	class 20: 0.2698563
Class Acc:
	class 0: 0.98264503
	class 1: 0.8179275
	class 2: 0.72980607
	class 3: 0.6590674
	class 4: 0.6479905
	class 5: 0.7992685
	class 6: 0.9038502
	class 7: 0.8265442
	class 8: 0.720849
	class 9: 0.19249344
	class 10: 0.6519838
	class 11: 0.400577
	class 12: 0.8703069
	class 13: 0.690295
	class 14: 0.7273978
	class 15: 0.9189561
	class 16: 0.0
	class 17: 0.0011986827
	class 18: 6.546109e-05
	class 19: 0.34147683
	class 20: 0.29165864

federated global round: 28, step: 5
select part of clients to conduct local training
[6, 29, 13, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5809000134468079, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.5809000134468079, Class Loss=0.5809000134468079, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5730751156806946, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.5730751156806946, Class Loss=0.5730751156806946, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.57319575548172, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.57319575548172, Class Loss=0.57319575548172, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.5511182546615601, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.5511182546615601, Class Loss=0.5511182546615601, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.5508009195327759, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.5508009195327759, Class Loss=0.5508009195327759, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.5555863976478577, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.5555863976478577, Class Loss=0.5555863976478577, Reg Loss=0.0
Current Client Index:  29
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000631
Epoch 1, Class Loss=0.5545535087585449, Reg Loss=0.0
Clinet index 29, End of Epoch 1/6, Average Loss=0.5545535087585449, Class Loss=0.5545535087585449, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000584
Epoch 2, Class Loss=0.5735312700271606, Reg Loss=0.0
Clinet index 29, End of Epoch 2/6, Average Loss=0.5735312700271606, Class Loss=0.5735312700271606, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000536
Epoch 3, Class Loss=0.5722101330757141, Reg Loss=0.0
Clinet index 29, End of Epoch 3/6, Average Loss=0.5722101330757141, Class Loss=0.5722101330757141, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000487
Epoch 4, Class Loss=0.536981463432312, Reg Loss=0.0
Clinet index 29, End of Epoch 4/6, Average Loss=0.536981463432312, Class Loss=0.536981463432312, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000438
Epoch 5, Class Loss=0.5306932330131531, Reg Loss=0.0
Clinet index 29, End of Epoch 5/6, Average Loss=0.5306932330131531, Class Loss=0.5306932330131531, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000389
Epoch 6, Class Loss=0.5354827046394348, Reg Loss=0.0
Clinet index 29, End of Epoch 6/6, Average Loss=0.5354827046394348, Class Loss=0.5354827046394348, Reg Loss=0.0
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.5992114543914795, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.5992114543914795, Class Loss=0.5992114543914795, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.5903599858283997, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.5903599858283997, Class Loss=0.5903599858283997, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.5911837816238403, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.5911837816238403, Class Loss=0.5911837816238403, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5802629590034485, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.5802629590034485, Class Loss=0.5802629590034485, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.569024920463562, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.569024920463562, Class Loss=0.569024920463562, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.5732824206352234, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.5732824206352234, Class Loss=0.5732824206352234, Reg Loss=0.0
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5765354633331299, Reg Loss=0.0
Clinet index 2, End of Epoch 1/6, Average Loss=0.5765354633331299, Class Loss=0.5765354633331299, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.5906263589859009, Reg Loss=0.0
Clinet index 2, End of Epoch 2/6, Average Loss=0.5906263589859009, Class Loss=0.5906263589859009, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.5492904782295227, Reg Loss=0.0
Clinet index 2, End of Epoch 3/6, Average Loss=0.5492904782295227, Class Loss=0.5492904782295227, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.5345717668533325, Reg Loss=0.0
Clinet index 2, End of Epoch 4/6, Average Loss=0.5345717668533325, Class Loss=0.5345717668533325, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.5493404865264893, Reg Loss=0.0
Clinet index 2, End of Epoch 5/6, Average Loss=0.5493404865264893, Class Loss=0.5493404865264893, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.5230391621589661, Reg Loss=0.0
Clinet index 2, End of Epoch 6/6, Average Loss=0.5230391621589661, Class Loss=0.5230391621589661, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4476909637451172, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.878227
Mean Acc: 0.574466
FreqW Acc: 0.778659
Mean IoU: 0.519762
Class IoU:
	class 0: 0.86128986
	class 1: 0.77522904
	class 2: 0.41792122
	class 3: 0.6281528
	class 4: 0.552993
	class 5: 0.7059419
	class 6: 0.8431686
	class 7: 0.798146
	class 8: 0.68161446
	class 9: 0.18221495
	class 10: 0.55371416
	class 11: 0.3767338
	class 12: 0.74723
	class 13: 0.63320756
	class 14: 0.69097096
	class 15: 0.8271765
	class 16: 0.0
	class 17: 0.00019955532
	class 18: 1.0910182e-05
	class 19: 0.3014178
	class 20: 0.33767608
Class Acc:
	class 0: 0.98325795
	class 1: 0.7959163
	class 2: 0.7524367
	class 3: 0.63788503
	class 4: 0.62980825
	class 5: 0.779032
	class 6: 0.89938176
	class 7: 0.8240237
	class 8: 0.6943856
	class 9: 0.18951647
	class 10: 0.6344126
	class 11: 0.38537088
	class 12: 0.8376729
	class 13: 0.6800084
	class 14: 0.7117154
	class 15: 0.91958404
	class 16: 0.0
	class 17: 0.00019957976
	class 18: 1.0910182e-05
	class 19: 0.3225637
	class 20: 0.38660684

federated global round: 29, step: 5
select part of clients to conduct local training
[6, 16, 13, 22]
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000536
Epoch 1, Class Loss=0.5542727112770081, Reg Loss=0.0
Clinet index 6, End of Epoch 1/6, Average Loss=0.5542727112770081, Class Loss=0.5542727112770081, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000455
Epoch 2, Class Loss=0.5512062907218933, Reg Loss=0.0
Clinet index 6, End of Epoch 2/6, Average Loss=0.5512062907218933, Class Loss=0.5512062907218933, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000372
Epoch 3, Class Loss=0.5543609261512756, Reg Loss=0.0
Clinet index 6, End of Epoch 3/6, Average Loss=0.5543609261512756, Class Loss=0.5543609261512756, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000287
Epoch 4, Class Loss=0.5352048873901367, Reg Loss=0.0
Clinet index 6, End of Epoch 4/6, Average Loss=0.5352048873901367, Class Loss=0.5352048873901367, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000199
Epoch 5, Class Loss=0.5349777340888977, Reg Loss=0.0
Clinet index 6, End of Epoch 5/6, Average Loss=0.5349777340888977, Class Loss=0.5349777340888977, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000107
Epoch 6, Class Loss=0.5362147092819214, Reg Loss=0.0
Clinet index 6, End of Epoch 6/6, Average Loss=0.5362147092819214, Class Loss=0.5362147092819214, Reg Loss=0.0
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5378512740135193, Reg Loss=0.0
Clinet index 16, End of Epoch 1/6, Average Loss=0.5378512740135193, Class Loss=0.5378512740135193, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5486030578613281, Reg Loss=0.0
Clinet index 16, End of Epoch 2/6, Average Loss=0.5486030578613281, Class Loss=0.5486030578613281, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5226165056228638, Reg Loss=0.0
Clinet index 16, End of Epoch 3/6, Average Loss=0.5226165056228638, Class Loss=0.5226165056228638, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5339183211326599, Reg Loss=0.0
Clinet index 16, End of Epoch 4/6, Average Loss=0.5339183211326599, Class Loss=0.5339183211326599, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.5520815253257751, Reg Loss=0.0
Clinet index 16, End of Epoch 5/6, Average Loss=0.5520815253257751, Class Loss=0.5520815253257751, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5632084608078003, Reg Loss=0.0
Clinet index 16, End of Epoch 6/6, Average Loss=0.5632084608078003, Class Loss=0.5632084608078003, Reg Loss=0.0
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.000372
Epoch 1, Class Loss=0.5796318054199219, Reg Loss=0.0
Clinet index 13, End of Epoch 1/6, Average Loss=0.5796318054199219, Class Loss=0.5796318054199219, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000316
Epoch 2, Class Loss=0.5632136464118958, Reg Loss=0.0
Clinet index 13, End of Epoch 2/6, Average Loss=0.5632136464118958, Class Loss=0.5632136464118958, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000258
Epoch 3, Class Loss=0.5631244778633118, Reg Loss=0.0
Clinet index 13, End of Epoch 3/6, Average Loss=0.5631244778633118, Class Loss=0.5631244778633118, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000199
Epoch 4, Class Loss=0.560605525970459, Reg Loss=0.0
Clinet index 13, End of Epoch 4/6, Average Loss=0.560605525970459, Class Loss=0.560605525970459, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000138
Epoch 5, Class Loss=0.5981208086013794, Reg Loss=0.0
Clinet index 13, End of Epoch 5/6, Average Loss=0.5981208086013794, Class Loss=0.5981208086013794, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000074
Epoch 6, Class Loss=0.5638068914413452, Reg Loss=0.0
Clinet index 13, End of Epoch 6/6, Average Loss=0.5638068914413452, Class Loss=0.5638068914413452, Reg Loss=0.0
Current Client Index:  22
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: entropy
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5439474582672119, Reg Loss=0.0
Clinet index 22, End of Epoch 1/6, Average Loss=0.5439474582672119, Class Loss=0.5439474582672119, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.5440956354141235, Reg Loss=0.0
Clinet index 22, End of Epoch 2/6, Average Loss=0.5440956354141235, Class Loss=0.5440956354141235, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.5327105522155762, Reg Loss=0.0
Clinet index 22, End of Epoch 3/6, Average Loss=0.5327105522155762, Class Loss=0.5327105522155762, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 4, lr = 0.000536
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch 4, Class Loss=0.5133537650108337, Reg Loss=0.0
Clinet index 22, End of Epoch 4/6, Average Loss=0.5133537650108337, Class Loss=0.5133537650108337, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.5167236924171448, Reg Loss=0.0
Clinet index 22, End of Epoch 5/6, Average Loss=0.5167236924171448, Class Loss=0.5167236924171448, Reg Loss=0.0
Pseudo labeling is: entropy
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.5249640941619873, Reg Loss=0.0
Clinet index 22, End of Epoch 6/6, Average Loss=0.5249640941619873, Class Loss=0.5249640941619873, Reg Loss=0.0
federated aggregation...
Validation, Class Loss=0.4450080394744873, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.878748
Mean Acc: 0.576559
FreqW Acc: 0.779632
Mean IoU: 0.520555
Class IoU:
	class 0: 0.8626639
	class 1: 0.7701117
	class 2: 0.41816494
	class 3: 0.6483048
	class 4: 0.54969466
	class 5: 0.7092672
	class 6: 0.83960414
	class 7: 0.8033451
	class 8: 0.6765476
	class 9: 0.17516264
	class 10: 0.5553125
	class 11: 0.38174063
	class 12: 0.7456919
	class 13: 0.6304188
	class 14: 0.6821165
	class 15: 0.8278422
	class 16: 0.0
	class 17: 0.00016854783
	class 18: 5.455091e-06
	class 19: 0.29930782
	class 20: 0.3561793
Class Acc:
	class 0: 0.9832593
	class 1: 0.78981286
	class 2: 0.7466964
	class 3: 0.658145
	class 4: 0.6235064
	class 5: 0.78209424
	class 6: 0.89424556
	class 7: 0.83941525
	class 8: 0.68689936
	class 9: 0.18187426
	class 10: 0.63790023
	class 11: 0.39085606
	class 12: 0.8527092
	class 13: 0.6747822
	class 14: 0.700191
	class 15: 0.9194152
	class 16: 0.0
	class 17: 0.00016857416
	class 18: 5.455091e-06
	class 19: 0.31779763
	class 20: 0.4279578

voc_15-1_OURS-APE On GPUs 0
Run in 30798s
