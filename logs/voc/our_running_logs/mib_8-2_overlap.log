nohup: ignoring input
35
kvoc_8-2_MiB On GPUs 0\Writing in results/seed_2023-ov/2023-03-14_voc_8-2_MiB.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[4, 3, 1, 2]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[0, 4, 7, 2]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  4
Current Client Index:  7
Current Client Index:  2
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[1, 9, 3, 8]
Current Client Index:  1
Current Client Index:  9
Current Client Index:  3
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[5, 9, 0, 4]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Current Client Index:  0
Current Client Index:  4
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.11884414404630661, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.959771
Mean Acc: 0.898867
FreqW Acc: 0.927997
Mean IoU: 0.803600
Class IoU:
	class 0: 0.9505860659032771
	class 1: 0.9002121543757099
	class 2: 0.3911996045853578
	class 3: 0.7886755539422873
	class 4: 0.7227948650191602
	class 5: 0.777020491034379
	class 6: 0.9452273228283382
	class 7: 0.8680230685934628
	class 8: 0.8886579855388657
Class Acc:
	class 0: 0.9742031520387592
	class 1: 0.9505188705401268
	class 2: 0.8333169681087177
	class 3: 0.7954920085182839
	class 4: 0.8649138231019398
	class 5: 0.839701567241524
	class 6: 0.9766569231687022
	class 7: 0.9440467027150332
	class 8: 0.910953836504121

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[5, 11, 7, 1]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: None
Epoch 1, lr = 0.001000
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Epoch 1, Batch 10/27, Loss=1.1236410588026047
Loss made of: CE 0.6151294708251953, LKD 0.22319558262825012, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.6513350866734982
Loss made of: CE 0.39729344844818115, LKD 0.16350796818733215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6449981331825256, Reg Loss=0.15740297734737396
Clinet index 5, End of Epoch 1/6, Average Loss=0.8024011254310608, Class Loss=0.6449981331825256, Reg Loss=0.15740297734737396
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=0.49835522249341013
Loss made of: CE 0.3755483031272888, LKD 0.10320823639631271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.49364458695054053
Loss made of: CE 0.34118303656578064, LKD 0.08220870792865753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.41927412152290344, Reg Loss=0.07871542870998383
Clinet index 5, End of Epoch 2/6, Average Loss=0.4979895353317261, Class Loss=0.41927412152290344, Reg Loss=0.07871542870998383
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=0.4675164517015219
Loss made of: CE 0.4176788330078125, LKD 0.05648338794708252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.429274358227849
Loss made of: CE 0.32849061489105225, LKD 0.08789881318807602, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.376295268535614, Reg Loss=0.07182052731513977
Clinet index 5, End of Epoch 3/6, Average Loss=0.4481157958507538, Class Loss=0.376295268535614, Reg Loss=0.07182052731513977
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=0.4229252029210329
Loss made of: CE 0.34092509746551514, LKD 0.05538734048604965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.4327162317931652
Loss made of: CE 0.3543938100337982, LKD 0.05730458348989487, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.35816916823387146, Reg Loss=0.06903281807899475
Clinet index 5, End of Epoch 4/6, Average Loss=0.4272019863128662, Class Loss=0.35816916823387146, Reg Loss=0.06903281807899475
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.42408719211816787
Loss made of: CE 0.30344870686531067, LKD 0.07162808626890182, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.3791218053549528
Loss made of: CE 0.3418067693710327, LKD 0.06147494912147522, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34264442324638367, Reg Loss=0.06814975291490555
Clinet index 5, End of Epoch 5/6, Average Loss=0.4107941687107086, Class Loss=0.34264442324638367, Reg Loss=0.06814975291490555
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.40540984496474264
Loss made of: CE 0.3616366386413574, LKD 0.12337730824947357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.3993312831968069
Loss made of: CE 0.32651573419570923, LKD 0.04095868393778801, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3252028524875641, Reg Loss=0.0697234570980072
Clinet index 5, End of Epoch 6/6, Average Loss=0.3949263095855713, Class Loss=0.3252028524875641, Reg Loss=0.0697234570980072
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.1429362297058105, Reg Loss=0.27134883403778076
Clinet index 11, End of Epoch 1/6, Average Loss=1.4142850637435913, Class Loss=1.1429362297058105, Reg Loss=0.27134883403778076
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=0.8200156688690186, Reg Loss=0.16183552145957947
Clinet index 11, End of Epoch 2/6, Average Loss=0.9818512201309204, Class Loss=0.8200156688690186, Reg Loss=0.16183552145957947
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.6633222699165344, Reg Loss=0.12337469309568405
Clinet index 11, End of Epoch 3/6, Average Loss=0.7866969704627991, Class Loss=0.6633222699165344, Reg Loss=0.12337469309568405
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.5935333967208862, Reg Loss=0.10418357700109482
Clinet index 11, End of Epoch 4/6, Average Loss=0.6977169513702393, Class Loss=0.5935333967208862, Reg Loss=0.10418357700109482
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.5321547985076904, Reg Loss=0.09337121248245239
Clinet index 11, End of Epoch 5/6, Average Loss=0.6255260109901428, Class Loss=0.5321547985076904, Reg Loss=0.09337121248245239
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.506140947341919, Reg Loss=0.08314841985702515
Clinet index 11, End of Epoch 6/6, Average Loss=0.5892893671989441, Class Loss=0.506140947341919, Reg Loss=0.08314841985702515
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=1.1112159863114357
Loss made of: CE 0.6725335121154785, LKD 0.13763457536697388, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.6793772041797638
Loss made of: CE 0.5074228048324585, LKD 0.09398192167282104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.640671968460083, Reg Loss=0.1553853303194046
Clinet index 7, End of Epoch 1/6, Average Loss=0.7960572838783264, Class Loss=0.640671968460083, Reg Loss=0.1553853303194046
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=0.5520238742232323
Loss made of: CE 0.6406094431877136, LKD 0.09375716745853424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.48590923137962816
Loss made of: CE 0.447528600692749, LKD 0.0741257295012474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4256771206855774, Reg Loss=0.08404863625764847
Clinet index 7, End of Epoch 2/6, Average Loss=0.5097257494926453, Class Loss=0.4256771206855774, Reg Loss=0.08404863625764847
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=0.4525653626769781
Loss made of: CE 0.4193999171257019, LKD 0.0662829652428627, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.46451014280319214
Loss made of: CE 0.38065677881240845, LKD 0.06442975997924805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38837501406669617, Reg Loss=0.07680913060903549
Clinet index 7, End of Epoch 3/6, Average Loss=0.46518415212631226, Class Loss=0.38837501406669617, Reg Loss=0.07680913060903549
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=0.43059494718909264
Loss made of: CE 0.3385901153087616, LKD 0.0561823770403862, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.457309215888381
Loss made of: CE 0.4944450855255127, LKD 0.10070431232452393, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3668624460697174, Reg Loss=0.0768505185842514
Clinet index 7, End of Epoch 4/6, Average Loss=0.4437129497528076, Class Loss=0.3668624460697174, Reg Loss=0.0768505185842514
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.4321653965860605
Loss made of: CE 0.36541780829429626, LKD 0.05496464669704437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.40992236211895944
Loss made of: CE 0.24593393504619598, LKD 0.07896672934293747, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3499736189842224, Reg Loss=0.07367633283138275
Clinet index 7, End of Epoch 5/6, Average Loss=0.42364996671676636, Class Loss=0.3499736189842224, Reg Loss=0.07367633283138275
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.4240500271320343
Loss made of: CE 0.38124021887779236, LKD 0.07354527711868286, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.3976319473236799
Loss made of: CE 0.25730153918266296, LKD 0.06392545253038406, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.33447250723838806, Reg Loss=0.07298830151557922
Clinet index 7, End of Epoch 6/6, Average Loss=0.4074608087539673, Class Loss=0.33447250723838806, Reg Loss=0.07298830151557922
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=1.1106162719428538
Loss made of: CE 0.6281968951225281, LKD 0.11313103884458542, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.651926438510418
Loss made of: CE 0.45696306228637695, LKD 0.09481525421142578, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6386005282402039, Reg Loss=0.1549863964319229
Clinet index 1, End of Epoch 1/6, Average Loss=0.7935869097709656, Class Loss=0.6386005282402039, Reg Loss=0.1549863964319229
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/27, Loss=0.5082898147404193
Loss made of: CE 0.35740017890930176, LKD 0.07634550333023071, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.512949151173234
Loss made of: CE 0.4358057975769043, LKD 0.03948602080345154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.42049917578697205, Reg Loss=0.08158710598945618
Clinet index 1, End of Epoch 2/6, Average Loss=0.5020862817764282, Class Loss=0.42049917578697205, Reg Loss=0.08158710598945618
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/27, Loss=0.4568303972482681
Loss made of: CE 0.3662719130516052, LKD 0.04199637100100517, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.4605085734277964
Loss made of: CE 0.3995448052883148, LKD 0.06639593094587326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3804852068424225, Reg Loss=0.070754773914814
Clinet index 1, End of Epoch 3/6, Average Loss=0.4512399733066559, Class Loss=0.3804852068424225, Reg Loss=0.070754773914814
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/27, Loss=0.4584844298660755
Loss made of: CE 0.38172513246536255, LKD 0.05558910220861435, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.40314554460346697
Loss made of: CE 0.3216506838798523, LKD 0.03657987341284752, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3598145544528961, Reg Loss=0.07099185138940811
Clinet index 1, End of Epoch 4/6, Average Loss=0.43080639839172363, Class Loss=0.3598145544528961, Reg Loss=0.07099185138940811
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/27, Loss=0.4114467229694128
Loss made of: CE 0.3338007926940918, LKD 0.04193240404129028, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.4127788681536913
Loss made of: CE 0.28078192472457886, LKD 0.04574720188975334, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3392027020454407, Reg Loss=0.06582388281822205
Clinet index 1, End of Epoch 5/6, Average Loss=0.4050265848636627, Class Loss=0.3392027020454407, Reg Loss=0.06582388281822205
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/27, Loss=0.3913810633122921
Loss made of: CE 0.31764042377471924, LKD 0.03979163616895676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.39554012902081015
Loss made of: CE 0.39391860365867615, LKD 0.1795799732208252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32907962799072266, Reg Loss=0.06751072406768799
Clinet index 1, End of Epoch 6/6, Average Loss=0.39659035205841064, Class Loss=0.32907962799072266, Reg Loss=0.06751072406768799
federated aggregation...
Validation, Class Loss=0.323192298412323, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.914752
Mean Acc: 0.650115
FreqW Acc: 0.842322
Mean IoU: 0.590658
Class IoU:
	class 0: 0.9015901
	class 1: 0.8579944
	class 2: 0.3640731
	class 3: 0.52586025
	class 4: 0.6628483
	class 5: 0.69595873
	class 6: 0.8634816
	class 7: 0.78757656
	class 8: 0.8378512
	class 9: 0.0
	class 10: 0.0
Class Acc:
	class 0: 0.9855613
	class 1: 0.8740046
	class 2: 0.7540615
	class 3: 0.5283851
	class 4: 0.7216311
	class 5: 0.71934426
	class 6: 0.8784542
	class 7: 0.8244617
	class 8: 0.86535937
	class 9: 0.0
	class 10: 0.0

federated global round: 6, step: 1
select part of clients to conduct local training
[1, 6, 7, 3]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.4560514837503433
Loss made of: CE 0.2936933636665344, LKD 0.0454234704375267, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.3962073758244514
Loss made of: CE 0.3553802967071533, LKD 0.06896138191223145, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3505890369415283, Reg Loss=0.07113347202539444
Clinet index 1, End of Epoch 1/6, Average Loss=0.42172250151634216, Class Loss=0.3505890369415283, Reg Loss=0.07113347202539444
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=0.3989713419228792
Loss made of: CE 0.30453211069107056, LKD 0.06115567684173584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.39710923507809637
Loss made of: CE 0.32078802585601807, LKD 0.045309048146009445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32846564054489136, Reg Loss=0.0685882419347763
Clinet index 1, End of Epoch 2/6, Average Loss=0.39705389738082886, Class Loss=0.32846564054489136, Reg Loss=0.0685882419347763
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=0.3872182507067919
Loss made of: CE 0.2942175269126892, LKD 0.04721992462873459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.39512407332658767
Loss made of: CE 0.3247920870780945, LKD 0.055927716195583344, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3192816972732544, Reg Loss=0.06780429184436798
Clinet index 1, End of Epoch 3/6, Average Loss=0.3870859742164612, Class Loss=0.3192816972732544, Reg Loss=0.06780429184436798
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=0.39413823634386064
Loss made of: CE 0.3051180839538574, LKD 0.05946388840675354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.3503238007426262
Loss made of: CE 0.2820349335670471, LKD 0.02787851169705391, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3031121790409088, Reg Loss=0.06772145628929138
Clinet index 1, End of Epoch 4/6, Average Loss=0.3708336353302002, Class Loss=0.3031121790409088, Reg Loss=0.06772145628929138
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.3688572525978088
Loss made of: CE 0.2934640645980835, LKD 0.042775958776474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.3572827883064747
Loss made of: CE 0.2335222363471985, LKD 0.04344029352068901, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29216620326042175, Reg Loss=0.06804891675710678
Clinet index 1, End of Epoch 5/6, Average Loss=0.36021512746810913, Class Loss=0.29216620326042175, Reg Loss=0.06804891675710678
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=0.3371512331068516
Loss made of: CE 0.28337031602859497, LKD 0.03756118193268776, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.3549018159508705
Loss made of: CE 0.3241015672683716, LKD 0.19559931755065918, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2816392481327057, Reg Loss=0.06870076805353165
Clinet index 1, End of Epoch 6/6, Average Loss=0.35034000873565674, Class Loss=0.2816392481327057, Reg Loss=0.06870076805353165
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.47619329765439034
Loss made of: CE 0.3237418830394745, LKD 0.09415208548307419, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.418082720041275
Loss made of: CE 0.29911112785339355, LKD 0.08253302425146103, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.36408308148384094, Reg Loss=0.07740850001573563
Clinet index 6, End of Epoch 1/6, Average Loss=0.44149157404899597, Class Loss=0.36408308148384094, Reg Loss=0.07740850001573563
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/27, Loss=0.42017906010150907
Loss made of: CE 0.32905709743499756, LKD 0.05884484574198723, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.42134883999824524
Loss made of: CE 0.35787826776504517, LKD 0.05405507609248161, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3423989415168762, Reg Loss=0.07483299821615219
Clinet index 6, End of Epoch 2/6, Average Loss=0.417231947183609, Class Loss=0.3423989415168762, Reg Loss=0.07483299821615219
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/27, Loss=0.394605777785182
Loss made of: CE 0.32041630148887634, LKD 0.04641593620181084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.3853456243872643
Loss made of: CE 0.3241291642189026, LKD 0.06863898038864136, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31757551431655884, Reg Loss=0.07145597040653229
Clinet index 6, End of Epoch 3/6, Average Loss=0.38903146982192993, Class Loss=0.31757551431655884, Reg Loss=0.07145597040653229
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/27, Loss=0.3658057115972042
Loss made of: CE 0.362807959318161, LKD 0.12292329967021942, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.37974276915192606
Loss made of: CE 0.2708733379840851, LKD 0.06779410690069199, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3062187135219574, Reg Loss=0.07035819441080093
Clinet index 6, End of Epoch 4/6, Average Loss=0.37657690048217773, Class Loss=0.3062187135219574, Reg Loss=0.07035819441080093
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/27, Loss=0.37013054490089414
Loss made of: CE 0.27106407284736633, LKD 0.08834899961948395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.34105290435254576
Loss made of: CE 0.20927321910858154, LKD 0.06302309036254883, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2912498712539673, Reg Loss=0.07294917106628418
Clinet index 6, End of Epoch 5/6, Average Loss=0.36419904232025146, Class Loss=0.2912498712539673, Reg Loss=0.07294917106628418
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/27, Loss=0.36212899945676325
Loss made of: CE 0.25580450892448425, LKD 0.07085128128528595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.352116122469306
Loss made of: CE 0.24346807599067688, LKD 0.0651715099811554, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.28528910875320435, Reg Loss=0.07166119664907455
Clinet index 6, End of Epoch 6/6, Average Loss=0.3569503128528595, Class Loss=0.28528910875320435, Reg Loss=0.07166119664907455
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.45090342648327353
Loss made of: CE 0.3336644172668457, LKD 0.05970783159136772, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.44312541410326955
Loss made of: CE 0.3802914619445801, LKD 0.04922095686197281, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3552981913089752, Reg Loss=0.0748269185423851
Clinet index 7, End of Epoch 1/6, Average Loss=0.4301251173019409, Class Loss=0.3552981913089752, Reg Loss=0.0748269185423851
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/27, Loss=0.4269934292882681
Loss made of: CE 0.457265704870224, LKD 0.10345916450023651, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.394207201525569
Loss made of: CE 0.3379308581352234, LKD 0.060494713485240936, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.33839479088783264, Reg Loss=0.07024633884429932
Clinet index 7, End of Epoch 2/6, Average Loss=0.40864112973213196, Class Loss=0.33839479088783264, Reg Loss=0.07024633884429932
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/27, Loss=0.3838756997138262
Loss made of: CE 0.34880781173706055, LKD 0.050016455352306366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.39946090802550316
Loss made of: CE 0.33043426275253296, LKD 0.06104864180088043, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.32580897212028503, Reg Loss=0.07236715406179428
Clinet index 7, End of Epoch 3/6, Average Loss=0.3981761336326599, Class Loss=0.32580897212028503, Reg Loss=0.07236715406179428
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/27, Loss=0.37065350338816644
Loss made of: CE 0.27847084403038025, LKD 0.05670174956321716, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.38911855667829515
Loss made of: CE 0.4027456045150757, LKD 0.11404122412204742, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.30792996287345886, Reg Loss=0.0710718184709549
Clinet index 7, End of Epoch 4/6, Average Loss=0.37900179624557495, Class Loss=0.30792996287345886, Reg Loss=0.0710718184709549
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.3745202012360096
Loss made of: CE 0.3026806116104126, LKD 0.06504999101161957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.37281193658709527
Loss made of: CE 0.23686572909355164, LKD 0.08791756629943848, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.30064287781715393, Reg Loss=0.07286088913679123
Clinet index 7, End of Epoch 5/6, Average Loss=0.37350377440452576, Class Loss=0.30064287781715393, Reg Loss=0.07286088913679123
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/27, Loss=0.3749766644090414
Loss made of: CE 0.3231939971446991, LKD 0.0731775313615799, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.3546443972736597
Loss made of: CE 0.24186383187770844, LKD 0.07810740917921066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2879333794116974, Reg Loss=0.07160502672195435
Clinet index 7, End of Epoch 6/6, Average Loss=0.35953840613365173, Class Loss=0.2879333794116974, Reg Loss=0.07160502672195435
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9695865511894226, Reg Loss=0.10402746498584747
Clinet index 3, End of Epoch 1/6, Average Loss=1.0736140012741089, Class Loss=0.9695865511894226, Reg Loss=0.10402746498584747
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.8392187356948853, Reg Loss=0.08744680881500244
Clinet index 3, End of Epoch 2/6, Average Loss=0.9266655445098877, Class Loss=0.8392187356948853, Reg Loss=0.08744680881500244
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7258596420288086, Reg Loss=0.08446382731199265
Clinet index 3, End of Epoch 3/6, Average Loss=0.8103234767913818, Class Loss=0.7258596420288086, Reg Loss=0.08446382731199265
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6163185834884644, Reg Loss=0.08155452460050583
Clinet index 3, End of Epoch 4/6, Average Loss=0.6978731155395508, Class Loss=0.6163185834884644, Reg Loss=0.08155452460050583
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.5427717566490173, Reg Loss=0.09326233714818954
Clinet index 3, End of Epoch 5/6, Average Loss=0.6360340714454651, Class Loss=0.5427717566490173, Reg Loss=0.09326233714818954
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.45521044731140137, Reg Loss=0.08353131264448166
Clinet index 3, End of Epoch 6/6, Average Loss=0.5387417674064636, Class Loss=0.45521044731140137, Reg Loss=0.08353131264448166
federated aggregation...
Validation, Class Loss=0.3159167766571045, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.917029
Mean Acc: 0.679859
FreqW Acc: 0.850535
Mean IoU: 0.613022
Class IoU:
	class 0: 0.9051609
	class 1: 0.86962754
	class 2: 0.3644977
	class 3: 0.58967155
	class 4: 0.66804063
	class 5: 0.7295804
	class 6: 0.8808037
	class 7: 0.8181592
	class 8: 0.86310416
	class 9: 0.05459998
	class 10: 0.0
Class Acc:
	class 0: 0.9793689
	class 1: 0.88640904
	class 2: 0.7760879
	class 3: 0.5926679
	class 4: 0.74038017
	class 5: 0.7629063
	class 6: 0.89772856
	class 7: 0.8707181
	class 8: 0.9003891
	class 9: 0.07179769
	class 10: 0.0

federated global round: 7, step: 1
select part of clients to conduct local training
[13, 8, 0, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9115008115768433, Reg Loss=0.09910043329000473
Clinet index 13, End of Epoch 1/6, Average Loss=1.010601282119751, Class Loss=0.9115008115768433, Reg Loss=0.09910043329000473
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.8255206346511841, Reg Loss=0.09319943189620972
Clinet index 13, End of Epoch 2/6, Average Loss=0.9187200665473938, Class Loss=0.8255206346511841, Reg Loss=0.09319943189620972
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.6773609519004822, Reg Loss=0.08669921010732651
Clinet index 13, End of Epoch 3/6, Average Loss=0.7640601396560669, Class Loss=0.6773609519004822, Reg Loss=0.08669921010732651
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.5590724945068359, Reg Loss=0.08198264241218567
Clinet index 13, End of Epoch 4/6, Average Loss=0.6410551071166992, Class Loss=0.5590724945068359, Reg Loss=0.08198264241218567
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.47861120104789734, Reg Loss=0.08239790797233582
Clinet index 13, End of Epoch 5/6, Average Loss=0.5610091090202332, Class Loss=0.47861120104789734, Reg Loss=0.08239790797233582
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.44588977098464966, Reg Loss=0.08057873696088791
Clinet index 13, End of Epoch 6/6, Average Loss=0.5264685153961182, Class Loss=0.44588977098464966, Reg Loss=0.08057873696088791
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.0074392557144165, Reg Loss=0.09643318504095078
Clinet index 8, End of Epoch 1/6, Average Loss=1.1038724184036255, Class Loss=1.0074392557144165, Reg Loss=0.09643318504095078
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.8770275115966797, Reg Loss=0.08588012307882309
Clinet index 8, End of Epoch 2/6, Average Loss=0.962907612323761, Class Loss=0.8770275115966797, Reg Loss=0.08588012307882309
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.7293775081634521, Reg Loss=0.08665861934423447
Clinet index 8, End of Epoch 3/6, Average Loss=0.8160361051559448, Class Loss=0.7293775081634521, Reg Loss=0.08665861934423447
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.6152752041816711, Reg Loss=0.08784930408000946
Clinet index 8, End of Epoch 4/6, Average Loss=0.7031245231628418, Class Loss=0.6152752041816711, Reg Loss=0.08784930408000946
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.4931655526161194, Reg Loss=0.0904957503080368
Clinet index 8, End of Epoch 5/6, Average Loss=0.5836613178253174, Class Loss=0.4931655526161194, Reg Loss=0.0904957503080368
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.4282435178756714, Reg Loss=0.08122836798429489
Clinet index 8, End of Epoch 6/6, Average Loss=0.5094718933105469, Class Loss=0.4282435178756714, Reg Loss=0.08122836798429489
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9708041548728943, Reg Loss=0.082215815782547
Clinet index 0, End of Epoch 1/6, Average Loss=1.0530200004577637, Class Loss=0.9708041548728943, Reg Loss=0.082215815782547
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.8612036108970642, Reg Loss=0.09460614621639252
Clinet index 0, End of Epoch 2/6, Average Loss=0.9558097720146179, Class Loss=0.8612036108970642, Reg Loss=0.09460614621639252
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.705291748046875, Reg Loss=0.09317706525325775
Clinet index 0, End of Epoch 3/6, Average Loss=0.798468828201294, Class Loss=0.705291748046875, Reg Loss=0.09317706525325775
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.576357364654541, Reg Loss=0.08960482478141785
Clinet index 0, End of Epoch 4/6, Average Loss=0.6659622192382812, Class Loss=0.576357364654541, Reg Loss=0.08960482478141785
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.47495877742767334, Reg Loss=0.0846899002790451
Clinet index 0, End of Epoch 5/6, Average Loss=0.5596486926078796, Class Loss=0.47495877742767334, Reg Loss=0.0846899002790451
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.43200528621673584, Reg Loss=0.08074948191642761
Clinet index 0, End of Epoch 6/6, Average Loss=0.5127547979354858, Class Loss=0.43200528621673584, Reg Loss=0.08074948191642761
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/27, Loss=0.3741467796266079
Loss made of: CE 0.23683449625968933, LKD 0.04714279621839523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.370458772405982
Loss made of: CE 0.28636157512664795, LKD 0.12873636186122894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2966971695423126, Reg Loss=0.06991960108280182
Clinet index 5, End of Epoch 1/6, Average Loss=0.36661678552627563, Class Loss=0.2966971695423126, Reg Loss=0.06991960108280182
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/27, Loss=0.34984193220734594
Loss made of: CE 0.28046631813049316, LKD 0.08558638393878937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.3597027599811554
Loss made of: CE 0.25542205572128296, LKD 0.04970704764127731, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2843863368034363, Reg Loss=0.06756247580051422
Clinet index 5, End of Epoch 2/6, Average Loss=0.3519487977027893, Class Loss=0.2843863368034363, Reg Loss=0.06756247580051422
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/27, Loss=0.340335251390934
Loss made of: CE 0.3168097138404846, LKD 0.06739112734794617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.327717525139451
Loss made of: CE 0.22200749814510345, LKD 0.07790839672088623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26797109842300415, Reg Loss=0.07098381221294403
Clinet index 5, End of Epoch 3/6, Average Loss=0.3389549255371094, Class Loss=0.26797109842300415, Reg Loss=0.07098381221294403
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/27, Loss=0.32214292846620085
Loss made of: CE 0.27255529165267944, LKD 0.04572945833206177, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.3330940630286932
Loss made of: CE 0.26242050528526306, LKD 0.06038320064544678, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2581073045730591, Reg Loss=0.06849446892738342
Clinet index 5, End of Epoch 4/6, Average Loss=0.3266017735004425, Class Loss=0.2581073045730591, Reg Loss=0.06849446892738342
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/27, Loss=0.33144267797470095
Loss made of: CE 0.2484099119901657, LKD 0.06764712184667587, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.29331322722136977
Loss made of: CE 0.25261038541793823, LKD 0.07291316986083984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24749429523944855, Reg Loss=0.06909633427858353
Clinet index 5, End of Epoch 5/6, Average Loss=0.31659063696861267, Class Loss=0.24749429523944855, Reg Loss=0.06909633427858353
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/27, Loss=0.3182691100984812
Loss made of: CE 0.2745330333709717, LKD 0.09492646157741547, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.30926255136728287
Loss made of: CE 0.2638396918773651, LKD 0.03862025588750839, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24186182022094727, Reg Loss=0.06802240759134293
Clinet index 5, End of Epoch 6/6, Average Loss=0.3098842203617096, Class Loss=0.24186182022094727, Reg Loss=0.06802240759134293
federated aggregation...
Validation, Class Loss=0.30859920382499695, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.913245
Mean Acc: 0.667448
FreqW Acc: 0.844127
Mean IoU: 0.593772
Class IoU:
	class 0: 0.903851
	class 1: 0.80122447
	class 2: 0.37802693
	class 3: 0.60542595
	class 4: 0.63300776
	class 5: 0.7034079
	class 6: 0.8515799
	class 7: 0.8208704
	class 8: 0.8113852
	class 9: 0.02013092
	class 10: 0.0025827643
Class Acc:
	class 0: 0.9812692
	class 1: 0.81489295
	class 2: 0.8404247
	class 3: 0.61326945
	class 4: 0.7461588
	class 5: 0.7478863
	class 6: 0.86266327
	class 7: 0.8616962
	class 8: 0.8448632
	class 9: 0.02621284
	class 10: 0.0025881138

federated global round: 8, step: 1
select part of clients to conduct local training
[12, 9, 4, 13]
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.45294605270028115
Loss made of: CE 0.4163167476654053, LKD 0.08553637564182281, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.38172192573547364
Loss made of: CE 0.3027488887310028, LKD 0.04831477999687195, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3341905474662781, Reg Loss=0.07429324835538864
Clinet index 12, End of Epoch 1/6, Average Loss=0.4084838032722473, Class Loss=0.3341905474662781, Reg Loss=0.07429324835538864
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=0.3455692660063505
Loss made of: CE 0.28691646456718445, LKD 0.053500618785619736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.36777655854821206
Loss made of: CE 0.33762383460998535, LKD 0.08719071745872498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2816719114780426, Reg Loss=0.06959199160337448
Clinet index 12, End of Epoch 2/6, Average Loss=0.3512639105319977, Class Loss=0.2816719114780426, Reg Loss=0.06959199160337448
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=0.30696067921817305
Loss made of: CE 0.24313294887542725, LKD 0.08605098724365234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.3348246790468693
Loss made of: CE 0.23919767141342163, LKD 0.058573514223098755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2564050555229187, Reg Loss=0.0694810077548027
Clinet index 12, End of Epoch 3/6, Average Loss=0.325886070728302, Class Loss=0.2564050555229187, Reg Loss=0.0694810077548027
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=0.30649632811546323
Loss made of: CE 0.21341775357723236, LKD 0.08474801480770111, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.3197939392179251
Loss made of: CE 0.23236331343650818, LKD 0.07798343896865845, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2429906129837036, Reg Loss=0.0723731592297554
Clinet index 12, End of Epoch 4/6, Average Loss=0.3153637647628784, Class Loss=0.2429906129837036, Reg Loss=0.0723731592297554
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.29431985281407835
Loss made of: CE 0.22567051649093628, LKD 0.052592407912015915, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.30805591568350793
Loss made of: CE 0.23729658126831055, LKD 0.04683336615562439, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23657208681106567, Reg Loss=0.07038147747516632
Clinet index 12, End of Epoch 5/6, Average Loss=0.3069535493850708, Class Loss=0.23657208681106567, Reg Loss=0.07038147747516632
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=0.29753272999078034
Loss made of: CE 0.26040273904800415, LKD 0.08110411465167999, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.3069076403975487
Loss made of: CE 0.25261756777763367, LKD 0.07032639533281326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2301260232925415, Reg Loss=0.06828173995018005
Clinet index 12, End of Epoch 6/6, Average Loss=0.29840776324272156, Class Loss=0.2301260232925415, Reg Loss=0.06828173995018005
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.5167869925498962, Reg Loss=0.08995559811592102
Clinet index 9, End of Epoch 1/6, Average Loss=0.6067426204681396, Class Loss=0.5167869925498962, Reg Loss=0.08995559811592102
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.4435673952102661, Reg Loss=0.08641058206558228
Clinet index 9, End of Epoch 2/6, Average Loss=0.5299779772758484, Class Loss=0.4435673952102661, Reg Loss=0.08641058206558228
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.3860411047935486, Reg Loss=0.09435348212718964
Clinet index 9, End of Epoch 3/6, Average Loss=0.4803946018218994, Class Loss=0.3860411047935486, Reg Loss=0.09435348212718964
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.34902048110961914, Reg Loss=0.08377023041248322
Clinet index 9, End of Epoch 4/6, Average Loss=0.43279069662094116, Class Loss=0.34902048110961914, Reg Loss=0.08377023041248322
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.32498639822006226, Reg Loss=0.093863844871521
Clinet index 9, End of Epoch 5/6, Average Loss=0.41885024309158325, Class Loss=0.32498639822006226, Reg Loss=0.093863844871521
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.28909799456596375, Reg Loss=0.08647530525922775
Clinet index 9, End of Epoch 6/6, Average Loss=0.3755733072757721, Class Loss=0.28909799456596375, Reg Loss=0.08647530525922775
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/27, Loss=0.41922973170876504
Loss made of: CE 0.3550145626068115, LKD 0.06799473613500595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.4402893718332052
Loss made of: CE 0.33891576528549194, LKD 0.07323373109102249, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.34364813566207886, Reg Loss=0.0714036077260971
Clinet index 4, End of Epoch 1/6, Average Loss=0.41505175828933716, Class Loss=0.34364813566207886, Reg Loss=0.0714036077260971
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/27, Loss=0.3662752233445644
Loss made of: CE 0.2790318429470062, LKD 0.07761897891759872, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.36880652979016304
Loss made of: CE 0.31508341431617737, LKD 0.07859616726636887, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2930126488208771, Reg Loss=0.07213882356882095
Clinet index 4, End of Epoch 2/6, Average Loss=0.36515146493911743, Class Loss=0.2930126488208771, Reg Loss=0.07213882356882095
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/27, Loss=0.34589709863066675
Loss made of: CE 0.24823932349681854, LKD 0.07274498045444489, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.3368909440934658
Loss made of: CE 0.3017576336860657, LKD 0.06408518552780151, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2670377492904663, Reg Loss=0.06698662042617798
Clinet index 4, End of Epoch 3/6, Average Loss=0.3340243697166443, Class Loss=0.2670377492904663, Reg Loss=0.06698662042617798
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/27, Loss=0.3275896545499563
Loss made of: CE 0.32739880681037903, LKD 0.10831596702337265, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.3134946282953024
Loss made of: CE 0.2234797477722168, LKD 0.0722552090883255, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25009119510650635, Reg Loss=0.07086151093244553
Clinet index 4, End of Epoch 4/6, Average Loss=0.32095271348953247, Class Loss=0.25009119510650635, Reg Loss=0.07086151093244553
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/27, Loss=0.32834824062883855
Loss made of: CE 0.2390727996826172, LKD 0.09503769874572754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.2910524524748325
Loss made of: CE 0.24232465028762817, LKD 0.049264274537563324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24545694887638092, Reg Loss=0.07034323364496231
Clinet index 4, End of Epoch 5/6, Average Loss=0.31580018997192383, Class Loss=0.24545694887638092, Reg Loss=0.07034323364496231
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/27, Loss=0.2899684298783541
Loss made of: CE 0.25995051860809326, LKD 0.03646451607346535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.32180336527526376
Loss made of: CE 0.2501016855239868, LKD 0.07069399952888489, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.235784113407135, Reg Loss=0.07049596309661865
Clinet index 4, End of Epoch 6/6, Average Loss=0.30628007650375366, Class Loss=0.235784113407135, Reg Loss=0.07049596309661865
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.4817521274089813, Reg Loss=0.09102733433246613
Clinet index 13, End of Epoch 1/6, Average Loss=0.5727794766426086, Class Loss=0.4817521274089813, Reg Loss=0.09102733433246613
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.4602416455745697, Reg Loss=0.08363570272922516
Clinet index 13, End of Epoch 2/6, Average Loss=0.543877363204956, Class Loss=0.4602416455745697, Reg Loss=0.08363570272922516
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.4092034101486206, Reg Loss=0.0830458402633667
Clinet index 13, End of Epoch 3/6, Average Loss=0.4922492504119873, Class Loss=0.4092034101486206, Reg Loss=0.0830458402633667
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.3898915946483612, Reg Loss=0.08648388087749481
Clinet index 13, End of Epoch 4/6, Average Loss=0.4763754606246948, Class Loss=0.3898915946483612, Reg Loss=0.08648388087749481
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.3606380820274353, Reg Loss=0.07669377326965332
Clinet index 13, End of Epoch 5/6, Average Loss=0.4373318552970886, Class Loss=0.3606380820274353, Reg Loss=0.07669377326965332
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.3465180993080139, Reg Loss=0.08260594308376312
Clinet index 13, End of Epoch 6/6, Average Loss=0.42912405729293823, Class Loss=0.3465180993080139, Reg Loss=0.08260594308376312
federated aggregation...
Validation, Class Loss=0.2719401717185974, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.917041
Mean Acc: 0.691059
FreqW Acc: 0.852669
Mean IoU: 0.617448
Class IoU:
	class 0: 0.90688974
	class 1: 0.84904706
	class 2: 0.37462026
	class 3: 0.63215154
	class 4: 0.65231127
	class 5: 0.73488826
	class 6: 0.86201787
	class 7: 0.8352809
	class 8: 0.86828476
	class 9: 0.07643258
	class 10: 0.0
Class Acc:
	class 0: 0.97757757
	class 1: 0.86273116
	class 2: 0.8335341
	class 3: 0.6359727
	class 4: 0.7390288
	class 5: 0.77617663
	class 6: 0.8746935
	class 7: 0.87884474
	class 8: 0.9099491
	class 9: 0.11314355
	class 10: 0.0

federated global round: 9, step: 1
select part of clients to conduct local training
[4, 6, 13, 12]
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=0.35437404811382295
Loss made of: CE 0.2868744730949402, LKD 0.05545217916369438, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.39229066520929334
Loss made of: CE 0.29621249437332153, LKD 0.08151854574680328, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.29488328099250793, Reg Loss=0.06966426223516464
Clinet index 4, End of Epoch 1/6, Average Loss=0.3645475506782532, Class Loss=0.29488328099250793, Reg Loss=0.06966426223516464
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=0.34592247307300567
Loss made of: CE 0.26451584696769714, LKD 0.05507798492908478, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.36710502244532106
Loss made of: CE 0.283997118473053, LKD 0.07495475560426712, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28354039788246155, Reg Loss=0.07014769315719604
Clinet index 4, End of Epoch 2/6, Average Loss=0.3536880910396576, Class Loss=0.28354039788246155, Reg Loss=0.07014769315719604
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=0.3415112361311913
Loss made of: CE 0.26047948002815247, LKD 0.07407841086387634, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.33694390654563905
Loss made of: CE 0.30962270498275757, LKD 0.06221497803926468, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2643198072910309, Reg Loss=0.06833285838365555
Clinet index 4, End of Epoch 3/6, Average Loss=0.33265265822410583, Class Loss=0.2643198072910309, Reg Loss=0.06833285838365555
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=0.33059678599238396
Loss made of: CE 0.3764175772666931, LKD 0.1021350622177124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.31356871239840983
Loss made of: CE 0.22811612486839294, LKD 0.06422516703605652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25516393780708313, Reg Loss=0.0670834630727768
Clinet index 4, End of Epoch 4/6, Average Loss=0.32224738597869873, Class Loss=0.25516393780708313, Reg Loss=0.0670834630727768
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=0.33346038199961187
Loss made of: CE 0.25176677107810974, LKD 0.08528425544500351, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.2970571257174015
Loss made of: CE 0.25475144386291504, LKD 0.0500432550907135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2566055357456207, Reg Loss=0.06759608536958694
Clinet index 4, End of Epoch 5/6, Average Loss=0.3242016136646271, Class Loss=0.2566055357456207, Reg Loss=0.06759608536958694
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=0.3060206174850464
Loss made of: CE 0.29551205039024353, LKD 0.036248527467250824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.33693076893687246
Loss made of: CE 0.26971635222435, LKD 0.08056262135505676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25129786133766174, Reg Loss=0.07276227325201035
Clinet index 4, End of Epoch 6/6, Average Loss=0.3240601420402527, Class Loss=0.25129786133766174, Reg Loss=0.07276227325201035
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/27, Loss=0.40453755147755144
Loss made of: CE 0.291085422039032, LKD 0.08566614240407944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.3589854914695024
Loss made of: CE 0.26588913798332214, LKD 0.07670824974775314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3081434667110443, Reg Loss=0.06960456818342209
Clinet index 6, End of Epoch 1/6, Average Loss=0.377748042345047, Class Loss=0.3081434667110443, Reg Loss=0.06960456818342209
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/27, Loss=0.3495687011629343
Loss made of: CE 0.2726864516735077, LKD 0.053564250469207764, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.3553423400968313
Loss made of: CE 0.3414090573787689, LKD 0.0543719157576561, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27951526641845703, Reg Loss=0.06972890347242355
Clinet index 6, End of Epoch 2/6, Average Loss=0.3492441773414612, Class Loss=0.27951526641845703, Reg Loss=0.06972890347242355
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/27, Loss=0.328053355589509
Loss made of: CE 0.2632308304309845, LKD 0.05033590644598007, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.3260787382721901
Loss made of: CE 0.24741578102111816, LKD 0.06668578088283539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2574084401130676, Reg Loss=0.07107359915971756
Clinet index 6, End of Epoch 3/6, Average Loss=0.3284820318222046, Class Loss=0.2574084401130676, Reg Loss=0.07107359915971756
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/27, Loss=0.3242090575397015
Loss made of: CE 0.2887965738773346, LKD 0.14360812306404114, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.325644551217556
Loss made of: CE 0.23133492469787598, LKD 0.05855598673224449, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2574102580547333, Reg Loss=0.07297597825527191
Clinet index 6, End of Epoch 4/6, Average Loss=0.330386221408844, Class Loss=0.2574102580547333, Reg Loss=0.07297597825527191
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/27, Loss=0.3266210056841373
Loss made of: CE 0.22707413136959076, LKD 0.0788317546248436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.30264876410365105
Loss made of: CE 0.17841491103172302, LKD 0.07041911780834198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25125840306282043, Reg Loss=0.07014290243387222
Clinet index 6, End of Epoch 5/6, Average Loss=0.32140129804611206, Class Loss=0.25125840306282043, Reg Loss=0.07014290243387222
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/27, Loss=0.31873466446995735
Loss made of: CE 0.21227416396141052, LKD 0.08142738044261932, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.31712078787386416
Loss made of: CE 0.23279695212841034, LKD 0.07107048481702805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24920326471328735, Reg Loss=0.06994293630123138
Clinet index 6, End of Epoch 6/6, Average Loss=0.31914621591567993, Class Loss=0.24920326471328735, Reg Loss=0.06994293630123138
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000372
Epoch 1, Class Loss=0.5353432297706604, Reg Loss=0.08452653139829636
Clinet index 13, End of Epoch 1/6, Average Loss=0.6198697686195374, Class Loss=0.5353432297706604, Reg Loss=0.08452653139829636
Pseudo labeling is: None
Epoch 2, lr = 0.000316
Epoch 2, Class Loss=0.5063698291778564, Reg Loss=0.08532547950744629
Clinet index 13, End of Epoch 2/6, Average Loss=0.5916953086853027, Class Loss=0.5063698291778564, Reg Loss=0.08532547950744629
Pseudo labeling is: None
Epoch 3, lr = 0.000258
Epoch 3, Class Loss=0.47441190481185913, Reg Loss=0.0783551037311554
Clinet index 13, End of Epoch 3/6, Average Loss=0.5527670383453369, Class Loss=0.47441190481185913, Reg Loss=0.0783551037311554
Pseudo labeling is: None
Epoch 4, lr = 0.000199
Epoch 4, Class Loss=0.4536624550819397, Reg Loss=0.07854234427213669
Clinet index 13, End of Epoch 4/6, Average Loss=0.532204806804657, Class Loss=0.4536624550819397, Reg Loss=0.07854234427213669
Pseudo labeling is: None
Epoch 5, lr = 0.000138
Epoch 5, Class Loss=0.4482642412185669, Reg Loss=0.07937915623188019
Clinet index 13, End of Epoch 5/6, Average Loss=0.5276433825492859, Class Loss=0.4482642412185669, Reg Loss=0.07937915623188019
Pseudo labeling is: None
Epoch 6, lr = 0.000074
Epoch 6, Class Loss=0.4588243365287781, Reg Loss=0.07415023446083069
Clinet index 13, End of Epoch 6/6, Average Loss=0.5329746007919312, Class Loss=0.4588243365287781, Reg Loss=0.07415023446083069
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/27, Loss=0.39328642301261424
Loss made of: CE 0.36646395921707153, LKD 0.10103263705968857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/27, Loss=0.35610955357551577
Loss made of: CE 0.2707827687263489, LKD 0.05091507360339165, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.29715415835380554, Reg Loss=0.07451996207237244
Clinet index 12, End of Epoch 1/6, Average Loss=0.371674120426178, Class Loss=0.29715415835380554, Reg Loss=0.07451996207237244
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/27, Loss=0.3247593831270933
Loss made of: CE 0.2743019759654999, LKD 0.050376035273075104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/27, Loss=0.35266071408987043
Loss made of: CE 0.31720393896102905, LKD 0.08431693911552429, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2662505507469177, Reg Loss=0.06985102593898773
Clinet index 12, End of Epoch 2/6, Average Loss=0.33610159158706665, Class Loss=0.2662505507469177, Reg Loss=0.06985102593898773
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/27, Loss=0.31519810259342196
Loss made of: CE 0.2528105676174164, LKD 0.0924733430147171, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/27, Loss=0.32503308951854704
Loss made of: CE 0.22881506383419037, LKD 0.057666342705488205, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2551684081554413, Reg Loss=0.06863453984260559
Clinet index 12, End of Epoch 3/6, Average Loss=0.3238029479980469, Class Loss=0.2551684081554413, Reg Loss=0.06863453984260559
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/27, Loss=0.30924930311739446
Loss made of: CE 0.21691641211509705, LKD 0.05683574825525284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/27, Loss=0.31635237522423265
Loss made of: CE 0.22050879895687103, LKD 0.06223606690764427, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24522191286087036, Reg Loss=0.06881430745124817
Clinet index 12, End of Epoch 4/6, Average Loss=0.31403622031211853, Class Loss=0.24522191286087036, Reg Loss=0.06881430745124817
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/27, Loss=0.2976618938148022
Loss made of: CE 0.236980602145195, LKD 0.04793175309896469, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/27, Loss=0.3176021631807089
Loss made of: CE 0.23559068143367767, LKD 0.06132778152823448, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24460190534591675, Reg Loss=0.07071853429079056
Clinet index 12, End of Epoch 5/6, Average Loss=0.3153204321861267, Class Loss=0.24460190534591675, Reg Loss=0.07071853429079056
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/27, Loss=0.3099735386669636
Loss made of: CE 0.28318914771080017, LKD 0.07799631357192993, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/27, Loss=0.32631372921168805
Loss made of: CE 0.2463982105255127, LKD 0.062438663095235825, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2438240647315979, Reg Loss=0.07261974364519119
Clinet index 12, End of Epoch 6/6, Average Loss=0.3164438009262085, Class Loss=0.2438240647315979, Reg Loss=0.07261974364519119
federated aggregation...
Validation, Class Loss=0.28753191232681274, Reg Loss=0.0 (without scaling)

Total samples: 869.000000
Overall Acc: 0.912367
Mean Acc: 0.693752
FreqW Acc: 0.850729
Mean IoU: 0.616689
Class IoU:
	class 0: 0.904015
	class 1: 0.8572946
	class 2: 0.3577978
	class 3: 0.5769943
	class 4: 0.64805275
	class 5: 0.7263678
	class 6: 0.8651891
	class 7: 0.8392228
	class 8: 0.8779707
	class 9: 0.13067429
	class 10: 0.0
Class Acc:
	class 0: 0.96955913
	class 1: 0.87037647
	class 2: 0.75857973
	class 3: 0.5792675
	class 4: 0.71904296
	class 5: 0.7673865
	class 6: 0.8801605
	class 7: 0.88468194
	class 8: 0.9219306
	class 9: 0.28028274
	class 10: 0.0

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[10, 14, 16, 7]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.662942010164261
Loss made of: CE 0.804168701171875, LKD 0.49233371019363403, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=1.3372927129268646
Loss made of: CE 0.677781343460083, LKD 0.6095967292785645, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8044493198394775, Reg Loss=0.6188442707061768
Clinet index 10, End of Epoch 1/6, Average Loss=1.4232935905456543, Class Loss=0.8044493198394775, Reg Loss=0.6188442707061768
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=1.0939055562019349
Loss made of: CE 0.4526149034500122, LKD 0.6249768733978271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=1.0859065115451814
Loss made of: CE 0.41031694412231445, LKD 0.5899990200996399, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4576584994792938, Reg Loss=0.6021024584770203
Clinet index 10, End of Epoch 2/6, Average Loss=1.0597609281539917, Class Loss=0.4576584994792938, Reg Loss=0.6021024584770203
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=0.96756392121315
Loss made of: CE 0.3444804549217224, LKD 0.5493800640106201, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.9349602133035659
Loss made of: CE 0.3039243221282959, LKD 0.5543906092643738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3474710285663605, Reg Loss=0.5989232659339905
Clinet index 10, End of Epoch 3/6, Average Loss=0.9463943243026733, Class Loss=0.3474710285663605, Reg Loss=0.5989232659339905
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=0.8914559006690979
Loss made of: CE 0.34888753294944763, LKD 0.673689603805542, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8623639941215515
Loss made of: CE 0.3318302035331726, LKD 0.6322888135910034, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2880537509918213, Reg Loss=0.5999878644943237
Clinet index 10, End of Epoch 4/6, Average Loss=0.888041615486145, Class Loss=0.2880537509918213, Reg Loss=0.5999878644943237
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=0.885252122581005
Loss made of: CE 0.24611234664916992, LKD 0.5474275350570679, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.8246184095740319
Loss made of: CE 0.2544609606266022, LKD 0.5564929246902466, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2602854073047638, Reg Loss=0.5945516228675842
Clinet index 10, End of Epoch 5/6, Average Loss=0.8548370599746704, Class Loss=0.2602854073047638, Reg Loss=0.5945516228675842
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=0.8322392389178276
Loss made of: CE 0.23549386858940125, LKD 0.6232147812843323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.8059144437313079
Loss made of: CE 0.22282998263835907, LKD 0.6269673109054565, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23762623965740204, Reg Loss=0.5925955772399902
Clinet index 10, End of Epoch 6/6, Average Loss=0.8302218317985535, Class Loss=0.23762623965740204, Reg Loss=0.5925955772399902
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.1926378041505814
Loss made of: CE 0.7663323879241943, LKD 0.33618780970573425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8501535654067993, Reg Loss=0.3001321852207184
Clinet index 14, End of Epoch 1/6, Average Loss=1.1502857208251953, Class Loss=0.8501535654067993, Reg Loss=0.3001321852207184
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=0.8871708810329437
Loss made of: CE 0.5632491111755371, LKD 0.27115708589553833, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6114782094955444, Reg Loss=0.28008580207824707
Clinet index 14, End of Epoch 2/6, Average Loss=0.8915640115737915, Class Loss=0.6114782094955444, Reg Loss=0.28008580207824707
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=0.8051159620285034
Loss made of: CE 0.4934719502925873, LKD 0.2600153386592865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5312917828559875, Reg Loss=0.2763805389404297
Clinet index 14, End of Epoch 3/6, Average Loss=0.8076723217964172, Class Loss=0.5312917828559875, Reg Loss=0.2763805389404297
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=0.7698672622442245
Loss made of: CE 0.46309512853622437, LKD 0.2277776002883911, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.48733827471733093, Reg Loss=0.27288034558296204
Clinet index 14, End of Epoch 4/6, Average Loss=0.760218620300293, Class Loss=0.48733827471733093, Reg Loss=0.27288034558296204
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=0.7219958230853081
Loss made of: CE 0.4764484763145447, LKD 0.3119845390319824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.44835397601127625, Reg Loss=0.2763035297393799
Clinet index 14, End of Epoch 5/6, Average Loss=0.7246575355529785, Class Loss=0.44835397601127625, Reg Loss=0.2763035297393799
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=0.6966857150197029
Loss made of: CE 0.4038187265396118, LKD 0.2181689590215683, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.42160314321517944, Reg Loss=0.27473631501197815
Clinet index 14, End of Epoch 6/6, Average Loss=0.69633948802948, Class Loss=0.42160314321517944, Reg Loss=0.27473631501197815
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.690606674551964
Loss made of: CE 0.9222947359085083, LKD 0.597489595413208, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=1.329524850845337
Loss made of: CE 0.6583413481712341, LKD 0.7617315053939819, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.804990828037262, Reg Loss=0.6236783862113953
Clinet index 16, End of Epoch 1/6, Average Loss=1.4286692142486572, Class Loss=0.804990828037262, Reg Loss=0.6236783862113953
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/29, Loss=1.1259092897176743
Loss made of: CE 0.43459591269493103, LKD 0.6325686573982239, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=1.0574511408805847
Loss made of: CE 0.41417407989501953, LKD 0.584037184715271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.45302614569664, Reg Loss=0.606691837310791
Clinet index 16, End of Epoch 2/6, Average Loss=1.0597180128097534, Class Loss=0.45302614569664, Reg Loss=0.606691837310791
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/29, Loss=0.9872171342372894
Loss made of: CE 0.37718915939331055, LKD 0.6304404139518738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.9080514788627625
Loss made of: CE 0.30465346574783325, LKD 0.46726399660110474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3397918939590454, Reg Loss=0.6009954214096069
Clinet index 16, End of Epoch 3/6, Average Loss=0.9407873153686523, Class Loss=0.3397918939590454, Reg Loss=0.6009954214096069
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/29, Loss=0.8918446749448776
Loss made of: CE 0.26509416103363037, LKD 0.5154803991317749, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8859734088182449
Loss made of: CE 0.253552109003067, LKD 0.6130338907241821, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2828129529953003, Reg Loss=0.5992218255996704
Clinet index 16, End of Epoch 4/6, Average Loss=0.8820347785949707, Class Loss=0.2828129529953003, Reg Loss=0.5992218255996704
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/29, Loss=0.8927727237343788
Loss made of: CE 0.26968687772750854, LKD 0.6621335744857788, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.7840899169445038
Loss made of: CE 0.19897393882274628, LKD 0.40240049362182617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25904756784439087, Reg Loss=0.5947717428207397
Clinet index 16, End of Epoch 5/6, Average Loss=0.8538193106651306, Class Loss=0.25904756784439087, Reg Loss=0.5947717428207397
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/29, Loss=0.8468415901064873
Loss made of: CE 0.270255446434021, LKD 0.5934360027313232, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.8214509218931199
Loss made of: CE 0.20645391941070557, LKD 0.5640280842781067, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24009689688682556, Reg Loss=0.5988755822181702
Clinet index 16, End of Epoch 6/6, Average Loss=0.8389724493026733, Class Loss=0.24009689688682556, Reg Loss=0.5988755822181702
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.1877834498882294
Loss made of: CE 0.7388638257980347, LKD 0.26996493339538574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8480749726295471, Reg Loss=0.2957727611064911
Clinet index 7, End of Epoch 1/6, Average Loss=1.1438477039337158, Class Loss=0.8480749726295471, Reg Loss=0.2957727611064911
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=0.8783421725034714
Loss made of: CE 0.616378664970398, LKD 0.2866389751434326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6181979179382324, Reg Loss=0.27564793825149536
Clinet index 7, End of Epoch 2/6, Average Loss=0.8938458561897278, Class Loss=0.6181979179382324, Reg Loss=0.27564793825149536
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=0.8277341887354851
Loss made of: CE 0.49789783358573914, LKD 0.3229979872703552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5377392768859863, Reg Loss=0.2759673595428467
Clinet index 7, End of Epoch 3/6, Average Loss=0.813706636428833, Class Loss=0.5377392768859863, Reg Loss=0.2759673595428467
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=0.7719777032732964
Loss made of: CE 0.4659695029258728, LKD 0.31104764342308044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.48573291301727295, Reg Loss=0.2771841287612915
Clinet index 7, End of Epoch 4/6, Average Loss=0.7629170417785645, Class Loss=0.48573291301727295, Reg Loss=0.2771841287612915
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=0.7429633542895318
Loss made of: CE 0.4256150424480438, LKD 0.23041987419128418, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.46125319600105286, Reg Loss=0.27627602219581604
Clinet index 7, End of Epoch 5/6, Average Loss=0.7375292181968689, Class Loss=0.46125319600105286, Reg Loss=0.27627602219581604
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=0.721131817996502
Loss made of: CE 0.4272381067276001, LKD 0.21550123393535614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4349329471588135, Reg Loss=0.27644142508506775
Clinet index 7, End of Epoch 6/6, Average Loss=0.7113744020462036, Class Loss=0.4349329471588135, Reg Loss=0.27644142508506775
federated aggregation...
Validation, Class Loss=0.44393977522850037, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.859826
Mean Acc: 0.572733
FreqW Acc: 0.775390
Mean IoU: 0.494196
Class IoU:
	class 0: 0.8671231
	class 1: 0.77776986
	class 2: 0.35662973
	class 3: 0.5339512
	class 4: 0.5516796
	class 5: 0.7195063
	class 6: 0.81987077
	class 7: 0.8504555
	class 8: 0.8084017
	class 9: 0.09053836
	class 10: 0.0
	class 11: 0.0
	class 12: 0.048615776
Class Acc:
	class 0: 0.9618196
	class 1: 0.78424674
	class 2: 0.7298247
	class 3: 0.53623134
	class 4: 0.59297687
	class 5: 0.759733
	class 6: 0.8299951
	class 7: 0.87954825
	class 8: 0.9248803
	class 9: 0.3972895
	class 10: 0.0
	class 11: 0.0
	class 12: 0.048979796

federated global round: 11, step: 2
select part of clients to conduct local training
[10, 13, 6, 1]
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/29, Loss=1.1756707638502122
Loss made of: CE 0.430351585149765, LKD 0.5011448860168457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.9959130078554154
Loss made of: CE 0.4043368697166443, LKD 0.5647454261779785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.46539026498794556, Reg Loss=0.5861760377883911
Clinet index 10, End of Epoch 1/6, Average Loss=1.0515663623809814, Class Loss=0.46539026498794556, Reg Loss=0.5861760377883911
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/29, Loss=0.9136723697185516
Loss made of: CE 0.28579285740852356, LKD 0.6409107446670532, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.916494956612587
Loss made of: CE 0.26318544149398804, LKD 0.557700514793396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2995108366012573, Reg Loss=0.6017513275146484
Clinet index 10, End of Epoch 2/6, Average Loss=0.9012621641159058, Class Loss=0.2995108366012573, Reg Loss=0.6017513275146484
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/29, Loss=0.871529158949852
Loss made of: CE 0.2723241150379181, LKD 0.5541243553161621, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.8564488559961319
Loss made of: CE 0.24302661418914795, LKD 0.528486430644989, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27196580171585083, Reg Loss=0.5897037386894226
Clinet index 10, End of Epoch 3/6, Average Loss=0.8616695404052734, Class Loss=0.27196580171585083, Reg Loss=0.5897037386894226
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/29, Loss=0.845349469780922
Loss made of: CE 0.27629849314689636, LKD 0.6399564743041992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8177340015769005
Loss made of: CE 0.28795361518859863, LKD 0.599040150642395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2451971173286438, Reg Loss=0.5976170301437378
Clinet index 10, End of Epoch 4/6, Average Loss=0.8428141474723816, Class Loss=0.2451971173286438, Reg Loss=0.5976170301437378
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=0.8398819446563721
Loss made of: CE 0.2084510177373886, LKD 0.5154303908348083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.7859088227152824
Loss made of: CE 0.23606464266777039, LKD 0.5811735391616821, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23295262455940247, Reg Loss=0.5902525782585144
Clinet index 10, End of Epoch 5/6, Average Loss=0.8232052326202393, Class Loss=0.23295262455940247, Reg Loss=0.5902525782585144
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/29, Loss=0.810079836845398
Loss made of: CE 0.23955003917217255, LKD 0.6319412589073181, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.7917859360575676
Loss made of: CE 0.21867001056671143, LKD 0.5922280550003052, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2232455015182495, Reg Loss=0.5897162556648254
Clinet index 10, End of Epoch 6/6, Average Loss=0.812961757183075, Class Loss=0.2232455015182495, Reg Loss=0.5897162556648254
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.2529221504926682
Loss made of: CE 0.38064154982566833, LKD 0.4760514497756958, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=1.0171330571174622
Loss made of: CE 0.3251376748085022, LKD 0.6377469301223755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4646031856536865, Reg Loss=0.6022480130195618
Clinet index 13, End of Epoch 1/6, Average Loss=1.0668511390686035, Class Loss=0.4646031856536865, Reg Loss=0.6022480130195618
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/29, Loss=0.9360445290803909
Loss made of: CE 0.31238025426864624, LKD 0.7116897106170654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.9094164967536926
Loss made of: CE 0.2895139157772064, LKD 0.7131175994873047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29076990485191345, Reg Loss=0.6171383261680603
Clinet index 13, End of Epoch 2/6, Average Loss=0.9079082012176514, Class Loss=0.29076990485191345, Reg Loss=0.6171383261680603
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/29, Loss=0.8768443435430526
Loss made of: CE 0.27813002467155457, LKD 0.6842719912528992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.8741473451256752
Loss made of: CE 0.2616521716117859, LKD 0.624859094619751, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2600131928920746, Reg Loss=0.6010844111442566
Clinet index 13, End of Epoch 3/6, Average Loss=0.8610975742340088, Class Loss=0.2600131928920746, Reg Loss=0.6010844111442566
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/29, Loss=0.8812546223402024
Loss made of: CE 0.24806563556194305, LKD 0.6402464509010315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8409511253237725
Loss made of: CE 0.23684261739253998, LKD 0.6344698667526245, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24140629172325134, Reg Loss=0.6013985872268677
Clinet index 13, End of Epoch 4/6, Average Loss=0.8428049087524414, Class Loss=0.24140629172325134, Reg Loss=0.6013985872268677
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/29, Loss=0.8057586640119553
Loss made of: CE 0.22651676833629608, LKD 0.7055193185806274, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.8043809935450554
Loss made of: CE 0.237186461687088, LKD 0.5923653841018677, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22342683374881744, Reg Loss=0.5999681353569031
Clinet index 13, End of Epoch 5/6, Average Loss=0.8233949542045593, Class Loss=0.22342683374881744, Reg Loss=0.5999681353569031
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/29, Loss=0.7959369882941246
Loss made of: CE 0.18204770982265472, LKD 0.5433698892593384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.8226850047707558
Loss made of: CE 0.22368454933166504, LKD 0.6935648918151855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2132181078195572, Reg Loss=0.5966205596923828
Clinet index 13, End of Epoch 6/6, Average Loss=0.8098386526107788, Class Loss=0.2132181078195572, Reg Loss=0.5966205596923828
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.9204825788736344
Loss made of: CE 0.7454017996788025, LKD 0.2817140817642212, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6212595701217651, Reg Loss=0.29712656140327454
Clinet index 6, End of Epoch 1/6, Average Loss=0.9183861017227173, Class Loss=0.6212595701217651, Reg Loss=0.29712656140327454
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.8376496821641922
Loss made of: CE 0.47039127349853516, LKD 0.2831472158432007, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5145719647407532, Reg Loss=0.2930762469768524
Clinet index 6, End of Epoch 2/6, Average Loss=0.8076481819152832, Class Loss=0.5145719647407532, Reg Loss=0.2930762469768524
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.7207911342382431
Loss made of: CE 0.3894691467285156, LKD 0.275031179189682, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4346292316913605, Reg Loss=0.2864646911621094
Clinet index 6, End of Epoch 3/6, Average Loss=0.7210938930511475, Class Loss=0.4346292316913605, Reg Loss=0.2864646911621094
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.6880438759922981
Loss made of: CE 0.38939768075942993, LKD 0.2296374887228012, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4055316150188446, Reg Loss=0.28304651379585266
Clinet index 6, End of Epoch 4/6, Average Loss=0.6885781288146973, Class Loss=0.4055316150188446, Reg Loss=0.28304651379585266
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.6609824955463409
Loss made of: CE 0.4376048445701599, LKD 0.32168781757354736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3770979046821594, Reg Loss=0.2878047823905945
Clinet index 6, End of Epoch 5/6, Average Loss=0.6649026870727539, Class Loss=0.3770979046821594, Reg Loss=0.2878047823905945
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.6281121328473092
Loss made of: CE 0.3350452780723572, LKD 0.2970290780067444, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34588924050331116, Reg Loss=0.28479987382888794
Clinet index 6, End of Epoch 6/6, Average Loss=0.6306891441345215, Class Loss=0.34588924050331116, Reg Loss=0.28479987382888794
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.9228099018335343
Loss made of: CE 0.6197360754013062, LKD 0.3164898753166199, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6146252751350403, Reg Loss=0.29153138399124146
Clinet index 1, End of Epoch 1/6, Average Loss=0.9061566591262817, Class Loss=0.6146252751350403, Reg Loss=0.29153138399124146
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.788773512840271
Loss made of: CE 0.4093255400657654, LKD 0.2878272235393524, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5006143450737, Reg Loss=0.2791595160961151
Clinet index 1, End of Epoch 2/6, Average Loss=0.7797738313674927, Class Loss=0.5006143450737, Reg Loss=0.2791595160961151
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.703292042016983
Loss made of: CE 0.4740745425224304, LKD 0.28626763820648193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4245316982269287, Reg Loss=0.27109307050704956
Clinet index 1, End of Epoch 3/6, Average Loss=0.6956247687339783, Class Loss=0.4245316982269287, Reg Loss=0.27109307050704956
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.6716590285301208
Loss made of: CE 0.39164233207702637, LKD 0.31033897399902344, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.395251989364624, Reg Loss=0.26654085516929626
Clinet index 1, End of Epoch 4/6, Average Loss=0.6617928743362427, Class Loss=0.395251989364624, Reg Loss=0.26654085516929626
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.6381175339221954
Loss made of: CE 0.32723039388656616, LKD 0.299146831035614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.36413317918777466, Reg Loss=0.27988874912261963
Clinet index 1, End of Epoch 5/6, Average Loss=0.6440219283103943, Class Loss=0.36413317918777466, Reg Loss=0.27988874912261963
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.6049167007207871
Loss made of: CE 0.35552582144737244, LKD 0.25188982486724854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34137582778930664, Reg Loss=0.27066299319267273
Clinet index 1, End of Epoch 6/6, Average Loss=0.6120388507843018, Class Loss=0.34137582778930664, Reg Loss=0.27066299319267273
federated aggregation...
Validation, Class Loss=0.4139789938926697, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.879468
Mean Acc: 0.618811
FreqW Acc: 0.807247
Mean IoU: 0.532665
Class IoU:
	class 0: 0.8856915
	class 1: 0.77433926
	class 2: 0.3510136
	class 3: 0.5096834
	class 4: 0.5528964
	class 5: 0.73974836
	class 6: 0.8128915
	class 7: 0.8566505
	class 8: 0.8318052
	class 9: 0.10644249
	class 10: 0.0
	class 11: 0.0
	class 12: 0.5034869
Class Acc:
	class 0: 0.9573009
	class 1: 0.7800446
	class 2: 0.71452624
	class 3: 0.5117489
	class 4: 0.58867806
	class 5: 0.79023576
	class 6: 0.8237125
	class 7: 0.8900264
	class 8: 0.9298943
	class 9: 0.38890636
	class 10: 0.0
	class 11: 0.0
	class 12: 0.6694619

federated global round: 12, step: 2
select part of clients to conduct local training
[11, 0, 8, 14]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.8852231651544571
Loss made of: CE 0.5704070329666138, LKD 0.2785450220108032, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5671634674072266, Reg Loss=0.30518868565559387
Clinet index 11, End of Epoch 1/6, Average Loss=0.872352123260498, Class Loss=0.5671634674072266, Reg Loss=0.30518868565559387
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.7563976377248764
Loss made of: CE 0.40436333417892456, LKD 0.2697349786758423, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4469244182109833, Reg Loss=0.28809279203414917
Clinet index 11, End of Epoch 2/6, Average Loss=0.7350171804428101, Class Loss=0.4469244182109833, Reg Loss=0.28809279203414917
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.6590824857354164
Loss made of: CE 0.4108709692955017, LKD 0.3154758810997009, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37783947587013245, Reg Loss=0.28082597255706787
Clinet index 11, End of Epoch 3/6, Average Loss=0.6586654186248779, Class Loss=0.37783947587013245, Reg Loss=0.28082597255706787
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.6441292449831962
Loss made of: CE 0.32873833179473877, LKD 0.25707387924194336, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3485432267189026, Reg Loss=0.2824244201183319
Clinet index 11, End of Epoch 4/6, Average Loss=0.6309676170349121, Class Loss=0.3485432267189026, Reg Loss=0.2824244201183319
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.6082158058881759
Loss made of: CE 0.301973432302475, LKD 0.2458202838897705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.32607197761535645, Reg Loss=0.28124377131462097
Clinet index 11, End of Epoch 5/6, Average Loss=0.6073157787322998, Class Loss=0.32607197761535645, Reg Loss=0.28124377131462097
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.596401198208332
Loss made of: CE 0.2817855477333069, LKD 0.3020114302635193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.31332457065582275, Reg Loss=0.2793585956096649
Clinet index 11, End of Epoch 6/6, Average Loss=0.5926831960678101, Class Loss=0.31332457065582275, Reg Loss=0.2793585956096649
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.0170652359724044
Loss made of: CE 0.48168396949768066, LKD 0.5199609994888306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.9058054149150848
Loss made of: CE 0.27405834197998047, LKD 0.571982741355896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3441750109195709, Reg Loss=0.5901164412498474
Clinet index 0, End of Epoch 1/6, Average Loss=0.9342914819717407, Class Loss=0.3441750109195709, Reg Loss=0.5901164412498474
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=0.8802321359515191
Loss made of: CE 0.20539617538452148, LKD 0.619897723197937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.8468842014670372
Loss made of: CE 0.2670547366142273, LKD 0.5762219429016113, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24457868933677673, Reg Loss=0.6077058911323547
Clinet index 0, End of Epoch 2/6, Average Loss=0.8522845506668091, Class Loss=0.24457868933677673, Reg Loss=0.6077058911323547
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=0.8370410621166229
Loss made of: CE 0.20997145771980286, LKD 0.5117921829223633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.808427345752716
Loss made of: CE 0.22286877036094666, LKD 0.5239683985710144, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23027914762496948, Reg Loss=0.5876443982124329
Clinet index 0, End of Epoch 3/6, Average Loss=0.8179235458374023, Class Loss=0.23027914762496948, Reg Loss=0.5876443982124329
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=0.812742717564106
Loss made of: CE 0.32797548174858093, LKD 0.8087197542190552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8117779895663262
Loss made of: CE 0.20605896413326263, LKD 0.607074499130249, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2207154780626297, Reg Loss=0.5865581631660461
Clinet index 0, End of Epoch 4/6, Average Loss=0.8072736263275146, Class Loss=0.2207154780626297, Reg Loss=0.5865581631660461
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=0.7776314228773117
Loss made of: CE 0.1967581957578659, LKD 0.49677175283432007, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.8034372523427009
Loss made of: CE 0.20943257212638855, LKD 0.5641849040985107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20943467319011688, Reg Loss=0.5918803811073303
Clinet index 0, End of Epoch 5/6, Average Loss=0.8013150691986084, Class Loss=0.20943467319011688, Reg Loss=0.5918803811073303
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=0.7410536199808121
Loss made of: CE 0.1736474335193634, LKD 0.5947619676589966, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.8224116310477256
Loss made of: CE 0.2422487735748291, LKD 0.727820873260498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1992938071489334, Reg Loss=0.5872454643249512
Clinet index 0, End of Epoch 6/6, Average Loss=0.7865392565727234, Class Loss=0.1992938071489334, Reg Loss=0.5872454643249512
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=1.0437044292688369
Loss made of: CE 0.4839359521865845, LKD 0.5709764957427979, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.8766612932085991
Loss made of: CE 0.23729746043682098, LKD 0.5097267031669617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3499683439731598, Reg Loss=0.5814336538314819
Clinet index 8, End of Epoch 1/6, Average Loss=0.9314019680023193, Class Loss=0.3499683439731598, Reg Loss=0.5814336538314819
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/29, Loss=0.8358510509133339
Loss made of: CE 0.26249566674232483, LKD 0.656104564666748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.84351906478405
Loss made of: CE 0.2664068341255188, LKD 0.6503115892410278, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24050740897655487, Reg Loss=0.5947755575180054
Clinet index 8, End of Epoch 2/6, Average Loss=0.8352829813957214, Class Loss=0.24050740897655487, Reg Loss=0.5947755575180054
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/29, Loss=0.8495186150074006
Loss made of: CE 0.2174803465604782, LKD 0.6867107152938843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.8137181609869003
Loss made of: CE 0.2628060579299927, LKD 0.6633416414260864, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2331915646791458, Reg Loss=0.5900680422782898
Clinet index 8, End of Epoch 3/6, Average Loss=0.8232595920562744, Class Loss=0.2331915646791458, Reg Loss=0.5900680422782898
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/29, Loss=0.8159498825669289
Loss made of: CE 0.19705617427825928, LKD 0.5291576385498047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8647660315036774
Loss made of: CE 0.2285730540752411, LKD 0.6990013122558594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2218351811170578, Reg Loss=0.5943667888641357
Clinet index 8, End of Epoch 4/6, Average Loss=0.8162019848823547, Class Loss=0.2218351811170578, Reg Loss=0.5943667888641357
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/29, Loss=0.8246005803346634
Loss made of: CE 0.2512584626674652, LKD 0.6023735404014587, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.7657539874315262
Loss made of: CE 0.19701263308525085, LKD 0.6094395518302917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20874141156673431, Reg Loss=0.5838293433189392
Clinet index 8, End of Epoch 5/6, Average Loss=0.7925707697868347, Class Loss=0.20874141156673431, Reg Loss=0.5838293433189392
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/29, Loss=0.7969870924949646
Loss made of: CE 0.20014595985412598, LKD 0.5671305656433105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.7840879887342453
Loss made of: CE 0.20028898119926453, LKD 0.5824447870254517, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1981280893087387, Reg Loss=0.5796536803245544
Clinet index 8, End of Epoch 6/6, Average Loss=0.7777817845344543, Class Loss=0.1981280893087387, Reg Loss=0.5796536803245544
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=0.8965763747692108
Loss made of: CE 0.5640785694122314, LKD 0.31013423204421997, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5852802395820618, Reg Loss=0.2974585294723511
Clinet index 14, End of Epoch 1/6, Average Loss=0.8827387690544128, Class Loss=0.5852802395820618, Reg Loss=0.2974585294723511
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/13, Loss=0.7561312973499298
Loss made of: CE 0.4281163811683655, LKD 0.2823035717010498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4594677984714508, Reg Loss=0.2927095293998718
Clinet index 14, End of Epoch 2/6, Average Loss=0.752177357673645, Class Loss=0.4594677984714508, Reg Loss=0.2927095293998718
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/13, Loss=0.6626154690980911
Loss made of: CE 0.3743698000907898, LKD 0.2817760705947876, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3811253607273102, Reg Loss=0.2770644724369049
Clinet index 14, End of Epoch 3/6, Average Loss=0.6581898331642151, Class Loss=0.3811253607273102, Reg Loss=0.2770644724369049
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/13, Loss=0.6290748625993728
Loss made of: CE 0.3247377574443817, LKD 0.22437748312950134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3415593206882477, Reg Loss=0.2825110852718353
Clinet index 14, End of Epoch 4/6, Average Loss=0.624070405960083, Class Loss=0.3415593206882477, Reg Loss=0.2825110852718353
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/13, Loss=0.6094310700893402
Loss made of: CE 0.339800089597702, LKD 0.3207203149795532, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3313330113887787, Reg Loss=0.2791922688484192
Clinet index 14, End of Epoch 5/6, Average Loss=0.6105252504348755, Class Loss=0.3313330113887787, Reg Loss=0.2791922688484192
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/13, Loss=0.6000740215182304
Loss made of: CE 0.3082156181335449, LKD 0.2263501137495041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.31486865878105164, Reg Loss=0.28363263607025146
Clinet index 14, End of Epoch 6/6, Average Loss=0.5985013246536255, Class Loss=0.31486865878105164, Reg Loss=0.28363263607025146
federated aggregation...
Validation, Class Loss=0.4027158319950104, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.881456
Mean Acc: 0.633521
FreqW Acc: 0.813839
Mean IoU: 0.537990
Class IoU:
	class 0: 0.89261574
	class 1: 0.7859161
	class 2: 0.34859905
	class 3: 0.47545376
	class 4: 0.5759451
	class 5: 0.74440134
	class 6: 0.8293512
	class 7: 0.8622985
	class 8: 0.83822477
	class 9: 0.10878602
	class 10: 0.0
	class 11: 0.028088063
	class 12: 0.5041934
Class Acc:
	class 0: 0.95162743
	class 1: 0.7922671
	class 2: 0.7047128
	class 3: 0.47697675
	class 4: 0.61395144
	class 5: 0.8016727
	class 6: 0.8412912
	class 7: 0.9012171
	class 8: 0.92103696
	class 9: 0.38973665
	class 10: 0.0
	class 11: 0.028209316
	class 12: 0.81307733

federated global round: 13, step: 2
select part of clients to conduct local training
[13, 5, 15, 7]
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/29, Loss=1.0262359812855721
Loss made of: CE 0.2328048199415207, LKD 0.48398715257644653, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.8838126882910728
Loss made of: CE 0.2314169853925705, LKD 0.6862024068832397, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.32444438338279724, Reg Loss=0.5930734276771545
Clinet index 13, End of Epoch 1/6, Average Loss=0.9175177812576294, Class Loss=0.32444438338279724, Reg Loss=0.5930734276771545
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/29, Loss=0.8702755928039551
Loss made of: CE 0.24360895156860352, LKD 0.7449411749839783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.8551324635744095
Loss made of: CE 0.20004288852214813, LKD 0.6715916395187378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.23328636586666107, Reg Loss=0.6179907917976379
Clinet index 13, End of Epoch 2/6, Average Loss=0.8512771725654602, Class Loss=0.23328636586666107, Reg Loss=0.6179907917976379
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/29, Loss=0.8281176283955574
Loss made of: CE 0.23168525099754333, LKD 0.6302487254142761, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.8478153362870217
Loss made of: CE 0.1964847296476364, LKD 0.6135807037353516, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22741387784481049, Reg Loss=0.6009746789932251
Clinet index 13, End of Epoch 3/6, Average Loss=0.8283885717391968, Class Loss=0.22741387784481049, Reg Loss=0.6009746789932251
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/29, Loss=0.8482889726758003
Loss made of: CE 0.22483667731285095, LKD 0.6143449544906616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8145476892590523
Loss made of: CE 0.21419337391853333, LKD 0.6079697012901306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.21735906600952148, Reg Loss=0.6026310324668884
Clinet index 13, End of Epoch 4/6, Average Loss=0.8199900984764099, Class Loss=0.21735906600952148, Reg Loss=0.6026310324668884
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/29, Loss=0.7990674763917923
Loss made of: CE 0.1968369483947754, LKD 0.691100537776947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.781498895585537
Loss made of: CE 0.23120960593223572, LKD 0.5597993731498718, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2082180678844452, Reg Loss=0.6009736061096191
Clinet index 13, End of Epoch 5/6, Average Loss=0.8091917037963867, Class Loss=0.2082180678844452, Reg Loss=0.6009736061096191
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/29, Loss=0.7771572828292846
Loss made of: CE 0.17301802337169647, LKD 0.5455812811851501, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.8046671360731125
Loss made of: CE 0.18942207098007202, LKD 0.7234388589859009, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2007816582918167, Reg Loss=0.5959172248840332
Clinet index 13, End of Epoch 6/6, Average Loss=0.7966988682746887, Class Loss=0.2007816582918167, Reg Loss=0.5959172248840332
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.8792847216129303
Loss made of: CE 0.2698005437850952, LKD 0.4606981873512268, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.8623472332954407
Loss made of: CE 0.2414056956768036, LKD 0.5847583413124084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2926827073097229, Reg Loss=0.5881085395812988
Clinet index 5, End of Epoch 1/6, Average Loss=0.8807912468910217, Class Loss=0.2926827073097229, Reg Loss=0.5881085395812988
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/29, Loss=0.8335513964295387
Loss made of: CE 0.20943674445152283, LKD 0.6320960521697998, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.7980175316333771
Loss made of: CE 0.22139036655426025, LKD 0.5814775228500366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21659187972545624, Reg Loss=0.5956847071647644
Clinet index 5, End of Epoch 2/6, Average Loss=0.8122766017913818, Class Loss=0.21659187972545624, Reg Loss=0.5956847071647644
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/29, Loss=0.8339908644556999
Loss made of: CE 0.20864653587341309, LKD 0.5550443530082703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.765263232588768
Loss made of: CE 0.18153594434261322, LKD 0.4452987611293793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21279585361480713, Reg Loss=0.5840498208999634
Clinet index 5, End of Epoch 3/6, Average Loss=0.7968456745147705, Class Loss=0.21279585361480713, Reg Loss=0.5840498208999634
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/29, Loss=0.7788797870278359
Loss made of: CE 0.19400298595428467, LKD 0.581376850605011, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.7855269864201546
Loss made of: CE 0.2660876512527466, LKD 0.5452978610992432, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.20280176401138306, Reg Loss=0.5844552516937256
Clinet index 5, End of Epoch 4/6, Average Loss=0.7872570157051086, Class Loss=0.20280176401138306, Reg Loss=0.5844552516937256
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/29, Loss=0.731711995601654
Loss made of: CE 0.19534306228160858, LKD 0.5923664569854736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.8371162682771682
Loss made of: CE 0.2101357877254486, LKD 0.5642225742340088, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1954541951417923, Reg Loss=0.5838896632194519
Clinet index 5, End of Epoch 5/6, Average Loss=0.779343843460083, Class Loss=0.1954541951417923, Reg Loss=0.5838896632194519
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/29, Loss=0.7881948247551918
Loss made of: CE 0.1988552212715149, LKD 0.6620802879333496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.7358717501163483
Loss made of: CE 0.17486631870269775, LKD 0.44921940565109253, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18830916285514832, Reg Loss=0.5802447199821472
Clinet index 5, End of Epoch 6/6, Average Loss=0.7685538530349731, Class Loss=0.18830916285514832, Reg Loss=0.5802447199821472
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.7889674693346024
Loss made of: CE 0.42518895864486694, LKD 0.258698046207428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.48236340284347534, Reg Loss=0.29774338006973267
Clinet index 15, End of Epoch 1/6, Average Loss=0.780106782913208, Class Loss=0.48236340284347534, Reg Loss=0.29774338006973267
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=0.6892836838960648
Loss made of: CE 0.3505569398403168, LKD 0.2532350420951843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3803679645061493, Reg Loss=0.28688159584999084
Clinet index 15, End of Epoch 2/6, Average Loss=0.6672495603561401, Class Loss=0.3803679645061493, Reg Loss=0.28688159584999084
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=0.6120122894644737
Loss made of: CE 0.2980584502220154, LKD 0.30012768507003784, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3270573318004608, Reg Loss=0.2783527374267578
Clinet index 15, End of Epoch 3/6, Average Loss=0.605410099029541, Class Loss=0.3270573318004608, Reg Loss=0.2783527374267578
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=0.571437893807888
Loss made of: CE 0.3080233037471771, LKD 0.33188575506210327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2949509918689728, Reg Loss=0.27902257442474365
Clinet index 15, End of Epoch 4/6, Average Loss=0.573973536491394, Class Loss=0.2949509918689728, Reg Loss=0.27902257442474365
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=0.5529871478676796
Loss made of: CE 0.25369226932525635, LKD 0.2948548495769501, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27839887142181396, Reg Loss=0.2763567566871643
Clinet index 15, End of Epoch 5/6, Average Loss=0.5547556281089783, Class Loss=0.27839887142181396, Reg Loss=0.2763567566871643
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=0.5521489828824997
Loss made of: CE 0.2532700002193451, LKD 0.24217939376831055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2703872621059418, Reg Loss=0.2774718105792999
Clinet index 15, End of Epoch 6/6, Average Loss=0.5478590726852417, Class Loss=0.2703872621059418, Reg Loss=0.2774718105792999
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/13, Loss=0.844389694929123
Loss made of: CE 0.44476574659347534, LKD 0.2673431634902954, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5271187424659729, Reg Loss=0.3046271800994873
Clinet index 7, End of Epoch 1/6, Average Loss=0.8317459225654602, Class Loss=0.5271187424659729, Reg Loss=0.3046271800994873
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/13, Loss=0.6942183464765549
Loss made of: CE 0.3745572566986084, LKD 0.3188292384147644, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4157056212425232, Reg Loss=0.2943168580532074
Clinet index 7, End of Epoch 2/6, Average Loss=0.7100224494934082, Class Loss=0.4157056212425232, Reg Loss=0.2943168580532074
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.6404386639595032
Loss made of: CE 0.3253990411758423, LKD 0.2977091670036316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3543318510055542, Reg Loss=0.28104549646377563
Clinet index 7, End of Epoch 3/6, Average Loss=0.6353773474693298, Class Loss=0.3543318510055542, Reg Loss=0.28104549646377563
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/13, Loss=0.6091538310050965
Loss made of: CE 0.32982686161994934, LKD 0.3229021430015564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3283320963382721, Reg Loss=0.28196319937705994
Clinet index 7, End of Epoch 4/6, Average Loss=0.610295295715332, Class Loss=0.3283320963382721, Reg Loss=0.28196319937705994
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/13, Loss=0.5874964892864227
Loss made of: CE 0.2701737880706787, LKD 0.2555428147315979, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3052098751068115, Reg Loss=0.2845344841480255
Clinet index 7, End of Epoch 5/6, Average Loss=0.5897443294525146, Class Loss=0.3052098751068115, Reg Loss=0.2845344841480255
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/13, Loss=0.5848507359623909
Loss made of: CE 0.31566208600997925, LKD 0.22697047889232635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29500219225883484, Reg Loss=0.28052783012390137
Clinet index 7, End of Epoch 6/6, Average Loss=0.5755300521850586, Class Loss=0.29500219225883484, Reg Loss=0.28052783012390137
federated aggregation...
Validation, Class Loss=0.4028834104537964, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.880946
Mean Acc: 0.640072
FreqW Acc: 0.815537
Mean IoU: 0.540671
Class IoU:
	class 0: 0.8943123
	class 1: 0.78727186
	class 2: 0.34650257
	class 3: 0.4335359
	class 4: 0.5698749
	class 5: 0.7487935
	class 6: 0.82942176
	class 7: 0.8611146
	class 8: 0.8390758
	class 9: 0.10888193
	class 10: 0.0
	class 11: 0.11982856
	class 12: 0.4901098
Class Acc:
	class 0: 0.9478754
	class 1: 0.7937207
	class 2: 0.7001774
	class 3: 0.43458867
	class 4: 0.60623217
	class 5: 0.81157434
	class 6: 0.8419298
	class 7: 0.9037524
	class 8: 0.91313154
	class 9: 0.3874788
	class 10: 0.0
	class 11: 0.12708725
	class 12: 0.8533917

federated global round: 14, step: 2
select part of clients to conduct local training
[17, 3, 12, 16]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.9381245464086533
Loss made of: CE 0.23141047358512878, LKD 0.466535747051239, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.9638626664876938
Loss made of: CE 0.23053500056266785, LKD 0.599318265914917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.30195119976997375, Reg Loss=0.6129477620124817
Clinet index 17, End of Epoch 1/6, Average Loss=0.9148989915847778, Class Loss=0.30195119976997375, Reg Loss=0.6129477620124817
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=0.8001185059547424
Loss made of: CE 0.21088695526123047, LKD 0.7378524541854858, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.8565950691699982
Loss made of: CE 0.26184237003326416, LKD 0.6436206102371216, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21487343311309814, Reg Loss=0.6140186786651611
Clinet index 17, End of Epoch 2/6, Average Loss=0.8288921117782593, Class Loss=0.21487343311309814, Reg Loss=0.6140186786651611
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=0.7976170241832733
Loss made of: CE 0.186036616563797, LKD 0.5679256916046143, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.8515102595090867
Loss made of: CE 0.23181816935539246, LKD 0.5901139974594116, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21876993775367737, Reg Loss=0.6057606339454651
Clinet index 17, End of Epoch 3/6, Average Loss=0.8245306015014648, Class Loss=0.21876993775367737, Reg Loss=0.6057606339454651
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=0.801378358900547
Loss made of: CE 0.2528887391090393, LKD 0.6747661828994751, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.7882242634892463
Loss made of: CE 0.23186716437339783, LKD 0.629858672618866, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.20411734282970428, Reg Loss=0.6042417883872986
Clinet index 17, End of Epoch 4/6, Average Loss=0.8083591461181641, Class Loss=0.20411734282970428, Reg Loss=0.6042417883872986
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=0.8147674024105072
Loss made of: CE 0.17018982768058777, LKD 0.5458487272262573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.8090454429388046
Loss made of: CE 0.20063887536525726, LKD 0.6153473854064941, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2036212533712387, Reg Loss=0.6081329584121704
Clinet index 17, End of Epoch 5/6, Average Loss=0.8117542266845703, Class Loss=0.2036212533712387, Reg Loss=0.6081329584121704
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=0.812906165421009
Loss made of: CE 0.1956508457660675, LKD 0.5873646140098572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.7720814809203148
Loss made of: CE 0.1814378947019577, LKD 0.5844897031784058, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20448696613311768, Reg Loss=0.6044064164161682
Clinet index 17, End of Epoch 6/6, Average Loss=0.8088933825492859, Class Loss=0.20448696613311768, Reg Loss=0.6044064164161682
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/29, Loss=0.9201404958963394
Loss made of: CE 0.2893974483013153, LKD 0.49931061267852783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.842539319396019
Loss made of: CE 0.25100964307785034, LKD 0.6216156482696533, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2834309935569763, Reg Loss=0.5922157764434814
Clinet index 3, End of Epoch 1/6, Average Loss=0.8756467700004578, Class Loss=0.2834309935569763, Reg Loss=0.5922157764434814
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/29, Loss=0.8309014081954956
Loss made of: CE 0.19725458323955536, LKD 0.5765160918235779, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.7766948491334915
Loss made of: CE 0.295016884803772, LKD 0.5370982885360718, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21195285022258759, Reg Loss=0.6067607402801514
Clinet index 3, End of Epoch 2/6, Average Loss=0.8187136054039001, Class Loss=0.21195285022258759, Reg Loss=0.6067607402801514
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/29, Loss=0.8814533740282059
Loss made of: CE 0.1761714518070221, LKD 0.6364819407463074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.7548029735684395
Loss made of: CE 0.21007053554058075, LKD 0.5029053092002869, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21431265771389008, Reg Loss=0.6076340675354004
Clinet index 3, End of Epoch 3/6, Average Loss=0.8219467401504517, Class Loss=0.21431265771389008, Reg Loss=0.6076340675354004
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/29, Loss=0.8203171223402024
Loss made of: CE 0.22451584041118622, LKD 0.5604853630065918, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.7998514235019684
Loss made of: CE 0.20633834600448608, LKD 0.5777122974395752, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.20591561496257782, Reg Loss=0.5959180593490601
Clinet index 3, End of Epoch 4/6, Average Loss=0.8018336892127991, Class Loss=0.20591561496257782, Reg Loss=0.5959180593490601
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/29, Loss=0.7870062425732612
Loss made of: CE 0.18269914388656616, LKD 0.5452990531921387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.7760136544704437
Loss made of: CE 0.19083285331726074, LKD 0.5245844125747681, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19967558979988098, Reg Loss=0.5898400545120239
Clinet index 3, End of Epoch 5/6, Average Loss=0.7895156145095825, Class Loss=0.19967558979988098, Reg Loss=0.5898400545120239
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/29, Loss=0.8264115884900093
Loss made of: CE 0.21023134887218475, LKD 0.6414877772331238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.7650431722402573
Loss made of: CE 0.21505120396614075, LKD 0.4953588843345642, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19968834519386292, Reg Loss=0.595922589302063
Clinet index 3, End of Epoch 6/6, Average Loss=0.7956109046936035, Class Loss=0.19968834519386292, Reg Loss=0.595922589302063
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.800965890288353
Loss made of: CE 0.37592214345932007, LKD 0.28415340185165405, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.47484833002090454, Reg Loss=0.299285888671875
Clinet index 12, End of Epoch 1/6, Average Loss=0.7741342186927795, Class Loss=0.47484833002090454, Reg Loss=0.299285888671875
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=0.652913099527359
Loss made of: CE 0.3412001132965088, LKD 0.25715529918670654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35610926151275635, Reg Loss=0.28686925768852234
Clinet index 12, End of Epoch 2/6, Average Loss=0.6429785490036011, Class Loss=0.35610926151275635, Reg Loss=0.28686925768852234
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.6052493244409561
Loss made of: CE 0.29069551825523376, LKD 0.24792061746120453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3179325461387634, Reg Loss=0.2869319021701813
Clinet index 12, End of Epoch 3/6, Average Loss=0.6048644781112671, Class Loss=0.3179325461387634, Reg Loss=0.2869319021701813
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=0.574595895409584
Loss made of: CE 0.2671332061290741, LKD 0.2605839967727661, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2942958474159241, Reg Loss=0.28082504868507385
Clinet index 12, End of Epoch 4/6, Average Loss=0.5751209259033203, Class Loss=0.2942958474159241, Reg Loss=0.28082504868507385
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=0.5776781603693962
Loss made of: CE 0.30196911096572876, LKD 0.24324563145637512, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.28624972701072693, Reg Loss=0.27915969491004944
Clinet index 12, End of Epoch 5/6, Average Loss=0.5654094219207764, Class Loss=0.28624972701072693, Reg Loss=0.27915969491004944
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=0.5482966512441635
Loss made of: CE 0.2523193955421448, LKD 0.2542014718055725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.27366265654563904, Reg Loss=0.2811957895755768
Clinet index 12, End of Epoch 6/6, Average Loss=0.5548584461212158, Class Loss=0.27366265654563904, Reg Loss=0.2811957895755768
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/29, Loss=0.9692649975419044
Loss made of: CE 0.30700135231018066, LKD 0.5757920145988464, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/29, Loss=0.8511305123567581
Loss made of: CE 0.28559190034866333, LKD 0.727624773979187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3019852042198181, Reg Loss=0.5984230637550354
Clinet index 16, End of Epoch 1/6, Average Loss=0.9004082679748535, Class Loss=0.3019852042198181, Reg Loss=0.5984230637550354
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/29, Loss=0.843446284532547
Loss made of: CE 0.2008558213710785, LKD 0.617048978805542, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/29, Loss=0.8249278426170349
Loss made of: CE 0.21483337879180908, LKD 0.6062352061271667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22274713218212128, Reg Loss=0.6011480093002319
Clinet index 16, End of Epoch 2/6, Average Loss=0.8238951563835144, Class Loss=0.22274713218212128, Reg Loss=0.6011480093002319
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/29, Loss=0.8249012112617493
Loss made of: CE 0.2338714301586151, LKD 0.6187275648117065, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/29, Loss=0.7885903686285018
Loss made of: CE 0.1802559792995453, LKD 0.48101067543029785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21338315308094025, Reg Loss=0.5955657958984375
Clinet index 16, End of Epoch 3/6, Average Loss=0.8089489340782166, Class Loss=0.21338315308094025, Reg Loss=0.5955657958984375
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/29, Loss=0.7912525981664658
Loss made of: CE 0.18596208095550537, LKD 0.5156575441360474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/29, Loss=0.8134741097688675
Loss made of: CE 0.19060444831848145, LKD 0.5932008624076843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2037973552942276, Reg Loss=0.5968736410140991
Clinet index 16, End of Epoch 4/6, Average Loss=0.8006709814071655, Class Loss=0.2037973552942276, Reg Loss=0.5968736410140991
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/29, Loss=0.8253853723406792
Loss made of: CE 0.18935136497020721, LKD 0.657602071762085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/29, Loss=0.7398826703429222
Loss made of: CE 0.14190441370010376, LKD 0.408606618642807, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20492389798164368, Reg Loss=0.5913736820220947
Clinet index 16, End of Epoch 5/6, Average Loss=0.796297550201416, Class Loss=0.20492389798164368, Reg Loss=0.5913736820220947
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/29, Loss=0.8217577129602432
Loss made of: CE 0.21504753828048706, LKD 0.5901219248771667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/29, Loss=0.7793876886367798
Loss made of: CE 0.16916291415691376, LKD 0.5419374108314514, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2036820948123932, Reg Loss=0.597699761390686
Clinet index 16, End of Epoch 6/6, Average Loss=0.8013818264007568, Class Loss=0.2036820948123932, Reg Loss=0.597699761390686
federated aggregation...
Validation, Class Loss=0.41262441873550415, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.873248
Mean Acc: 0.601525
FreqW Acc: 0.806000
Mean IoU: 0.501830
Class IoU:
	class 0: 0.8948418
	class 1: 0.71362805
	class 2: 0.3495034
	class 3: 0.25478014
	class 4: 0.54212624
	class 5: 0.71996576
	class 6: 0.80810386
	class 7: 0.8589467
	class 8: 0.81046385
	class 9: 0.10380971
	class 10: 0.0
	class 11: 0.02881662
	class 12: 0.4387989
Class Acc:
	class 0: 0.9482444
	class 1: 0.7172198
	class 2: 0.6813813
	class 3: 0.25503305
	class 4: 0.5810048
	class 5: 0.7690822
	class 6: 0.8152442
	class 7: 0.9009293
	class 8: 0.8500196
	class 9: 0.35400304
	class 10: 0.0
	class 11: 0.028918725
	class 12: 0.9187422

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[13, 9, 6, 5]
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=2.0159064888954163
Loss made of: CE 1.1498188972473145, LKD 0.516265869140625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.4617109298706055, Reg Loss=0.5039070844650269
Clinet index 13, End of Epoch 1/6, Average Loss=1.9656180143356323, Class Loss=1.4617109298706055, Reg Loss=0.5039070844650269
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=1.4036005318164826
Loss made of: CE 0.665669322013855, LKD 0.5462524890899658, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8317290544509888, Reg Loss=0.5439077615737915
Clinet index 13, End of Epoch 2/6, Average Loss=1.3756368160247803, Class Loss=0.8317290544509888, Reg Loss=0.5439077615737915
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=1.1912208259105683
Loss made of: CE 0.5854094624519348, LKD 0.5988265872001648, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.575169026851654, Reg Loss=0.6090465784072876
Clinet index 13, End of Epoch 3/6, Average Loss=1.1842155456542969, Class Loss=0.575169026851654, Reg Loss=0.6090465784072876
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=1.0593556970357896
Loss made of: CE 0.498612642288208, LKD 0.601507306098938, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4760948121547699, Reg Loss=0.570309579372406
Clinet index 13, End of Epoch 4/6, Average Loss=1.0464043617248535, Class Loss=0.4760948121547699, Reg Loss=0.570309579372406
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=0.9822486460208892
Loss made of: CE 0.41642341017723083, LKD 0.5328047275543213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.42501387000083923, Reg Loss=0.5446428656578064
Clinet index 13, End of Epoch 5/6, Average Loss=0.9696567058563232, Class Loss=0.42501387000083923, Reg Loss=0.5446428656578064
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=0.9264335781335831
Loss made of: CE 0.3444724977016449, LKD 0.5516974329948425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3764895498752594, Reg Loss=0.5471550822257996
Clinet index 13, End of Epoch 6/6, Average Loss=0.9236446619033813, Class Loss=0.3764895498752594, Reg Loss=0.5471550822257996
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.1103364706039427
Loss made of: CE 1.2391529083251953, LKD 0.6388649344444275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.351083517074585, Reg Loss=0.6558502912521362
Clinet index 9, End of Epoch 1/6, Average Loss=2.0069336891174316, Class Loss=1.351083517074585, Reg Loss=0.6558502912521362
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.4191076576709747
Loss made of: CE 0.6289079189300537, LKD 0.5619357824325562, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7750616073608398, Reg Loss=0.631767749786377
Clinet index 9, End of Epoch 2/6, Average Loss=1.4068293571472168, Class Loss=0.7750616073608398, Reg Loss=0.631767749786377
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.209229052066803
Loss made of: CE 0.5770187377929688, LKD 0.611541748046875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5816255807876587, Reg Loss=0.6148766875267029
Clinet index 9, End of Epoch 3/6, Average Loss=1.1965022087097168, Class Loss=0.5816255807876587, Reg Loss=0.6148766875267029
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.110431107878685
Loss made of: CE 0.44989001750946045, LKD 0.542745053768158, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5038235187530518, Reg Loss=0.5919371843338013
Clinet index 9, End of Epoch 4/6, Average Loss=1.095760703086853, Class Loss=0.5038235187530518, Reg Loss=0.5919371843338013
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0193814158439636
Loss made of: CE 0.44636017084121704, LKD 0.5412640571594238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.44379955530166626, Reg Loss=0.5759546756744385
Clinet index 9, End of Epoch 5/6, Average Loss=1.01975417137146, Class Loss=0.44379955530166626, Reg Loss=0.5759546756744385
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.9961672306060791
Loss made of: CE 0.3363603949546814, LKD 0.5183656215667725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3951488137245178, Reg Loss=0.5880848169326782
Clinet index 9, End of Epoch 6/6, Average Loss=0.983233630657196, Class Loss=0.3951488137245178, Reg Loss=0.5880848169326782
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=1.9718053758144378
Loss made of: CE 1.2621243000030518, LKD 0.5027147531509399, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.442503809928894, Reg Loss=0.5025696754455566
Clinet index 6, End of Epoch 1/6, Average Loss=1.9450734853744507, Class Loss=1.442503809928894, Reg Loss=0.5025696754455566
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/11, Loss=1.371276792883873
Loss made of: CE 0.779658317565918, LKD 0.6559590101242065, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8220252990722656, Reg Loss=0.543286144733429
Clinet index 6, End of Epoch 2/6, Average Loss=1.3653113842010498, Class Loss=0.8220252990722656, Reg Loss=0.543286144733429
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/11, Loss=1.1651400864124297
Loss made of: CE 0.5334843993186951, LKD 0.5660501718521118, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5670720338821411, Reg Loss=0.5791619420051575
Clinet index 6, End of Epoch 3/6, Average Loss=1.1462340354919434, Class Loss=0.5670720338821411, Reg Loss=0.5791619420051575
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/11, Loss=1.0252936840057374
Loss made of: CE 0.47876283526420593, LKD 0.5397948622703552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4718490540981293, Reg Loss=0.5503526926040649
Clinet index 6, End of Epoch 4/6, Average Loss=1.0222017765045166, Class Loss=0.4718490540981293, Reg Loss=0.5503526926040649
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/11, Loss=0.946396866440773
Loss made of: CE 0.3537641763687134, LKD 0.46473655104637146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4171849191188812, Reg Loss=0.53299880027771
Clinet index 6, End of Epoch 5/6, Average Loss=0.9501837491989136, Class Loss=0.4171849191188812, Reg Loss=0.53299880027771
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/11, Loss=0.8924683779478073
Loss made of: CE 0.31920963525772095, LKD 0.5167829394340515, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3725162446498871, Reg Loss=0.525347888469696
Clinet index 6, End of Epoch 6/6, Average Loss=0.8978641033172607, Class Loss=0.3725162446498871, Reg Loss=0.525347888469696
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=2.0138277292251585
Loss made of: CE 1.1746797561645508, LKD 0.5953523516654968, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.333470106124878, Reg Loss=0.6428384184837341
Clinet index 5, End of Epoch 1/6, Average Loss=1.9763085842132568, Class Loss=1.333470106124878, Reg Loss=0.6428384184837341
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.418935340642929
Loss made of: CE 0.6746788024902344, LKD 0.6908395290374756, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7802016735076904, Reg Loss=0.625741720199585
Clinet index 5, End of Epoch 2/6, Average Loss=1.4059433937072754, Class Loss=0.7802016735076904, Reg Loss=0.625741720199585
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.202042704820633
Loss made of: CE 0.5969963073730469, LKD 0.6439619064331055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5854917168617249, Reg Loss=0.6139906644821167
Clinet index 5, End of Epoch 3/6, Average Loss=1.1994824409484863, Class Loss=0.5854917168617249, Reg Loss=0.6139906644821167
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.1014184296131133
Loss made of: CE 0.4562353789806366, LKD 0.5353926420211792, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5018442869186401, Reg Loss=0.5814993977546692
Clinet index 5, End of Epoch 4/6, Average Loss=1.083343744277954, Class Loss=0.5018442869186401, Reg Loss=0.5814993977546692
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0183090776205064
Loss made of: CE 0.3682782053947449, LKD 0.46146997809410095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.44156667590141296, Reg Loss=0.5725192427635193
Clinet index 5, End of Epoch 5/6, Average Loss=1.0140858888626099, Class Loss=0.44156667590141296, Reg Loss=0.5725192427635193
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.9739362537860871
Loss made of: CE 0.4345579147338867, LKD 0.6846567988395691, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.40395498275756836, Reg Loss=0.5756023526191711
Clinet index 5, End of Epoch 6/6, Average Loss=0.9795573353767395, Class Loss=0.40395498275756836, Reg Loss=0.5756023526191711
federated aggregation...
Validation, Class Loss=0.5781068205833435, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.840417
Mean Acc: 0.428064
FreqW Acc: 0.751132
Mean IoU: 0.359187
Class IoU:
	class 0: 0.880094
	class 1: 0.60205704
	class 2: 0.3018629
	class 3: 0.14400661
	class 4: 0.41098464
	class 5: 0.6228695
	class 6: 0.71564984
	class 7: 0.81411433
	class 8: 0.5442167
	class 9: 0.06406368
	class 10: 0.0
	class 11: 0.00086974085
	class 12: 0.2870172
	class 13: 0.0
	class 14: 0.0
Class Acc:
	class 0: 0.9749591
	class 1: 0.6044605
	class 2: 0.5879619
	class 3: 0.14404821
	class 4: 0.43464708
	class 5: 0.6482905
	class 6: 0.72237337
	class 7: 0.8578486
	class 8: 0.5504548
	class 9: 0.21317248
	class 10: 0.0
	class 11: 0.0008701371
	class 12: 0.68187225
	class 13: 0.0
	class 14: 0.0

federated global round: 16, step: 3
select part of clients to conduct local training
[18, 5, 20, 0]
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.2517837584018707
Loss made of: CE 0.571365475654602, LKD 0.48543688654899597, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7249752879142761, Reg Loss=0.5470749139785767
Clinet index 18, End of Epoch 1/6, Average Loss=1.272050142288208, Class Loss=0.7249752879142761, Reg Loss=0.5470749139785767
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=1.0848055154085159
Loss made of: CE 0.4593658447265625, LKD 0.596630871295929, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4941360354423523, Reg Loss=0.5689307451248169
Clinet index 18, End of Epoch 2/6, Average Loss=1.0630667209625244, Class Loss=0.4941360354423523, Reg Loss=0.5689307451248169
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.9755903601646423
Loss made of: CE 0.3453976511955261, LKD 0.4757881760597229, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3854977488517761, Reg Loss=0.5920501947402954
Clinet index 18, End of Epoch 3/6, Average Loss=0.9775479435920715, Class Loss=0.3854977488517761, Reg Loss=0.5920501947402954
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.9478922426700592
Loss made of: CE 0.3103477656841278, LKD 0.5534870624542236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3543550670146942, Reg Loss=0.5803264379501343
Clinet index 18, End of Epoch 4/6, Average Loss=0.9346815347671509, Class Loss=0.3543550670146942, Reg Loss=0.5803264379501343
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.877016031742096
Loss made of: CE 0.28289148211479187, LKD 0.4771251380443573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34087735414505005, Reg Loss=0.5691040754318237
Clinet index 18, End of Epoch 5/6, Average Loss=0.9099814295768738, Class Loss=0.34087735414505005, Reg Loss=0.5691040754318237
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.8865166366100311
Loss made of: CE 0.31393224000930786, LKD 0.5375766158103943, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32273322343826294, Reg Loss=0.5669959783554077
Clinet index 18, End of Epoch 6/6, Average Loss=0.8897292017936707, Class Loss=0.32273322343826294, Reg Loss=0.5669959783554077
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=1.242062297463417
Loss made of: CE 0.748210608959198, LKD 0.5299800038337708, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.725723147392273, Reg Loss=0.5335383415222168
Clinet index 5, End of Epoch 1/6, Average Loss=1.2592614889144897, Class Loss=0.725723147392273, Reg Loss=0.5335383415222168
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=1.0710337519645692
Loss made of: CE 0.48331284523010254, LKD 0.5326980948448181, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5226261615753174, Reg Loss=0.5438350439071655
Clinet index 5, End of Epoch 2/6, Average Loss=1.066461205482483, Class Loss=0.5226261615753174, Reg Loss=0.5438350439071655
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=0.9932996034622192
Loss made of: CE 0.42834481596946716, LKD 0.6594647765159607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.41351598501205444, Reg Loss=0.5862231254577637
Clinet index 5, End of Epoch 3/6, Average Loss=0.9997391104698181, Class Loss=0.41351598501205444, Reg Loss=0.5862231254577637
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=0.96605786383152
Loss made of: CE 0.36153334379196167, LKD 0.5486792325973511, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3702687919139862, Reg Loss=0.5807209014892578
Clinet index 5, End of Epoch 4/6, Average Loss=0.9509897232055664, Class Loss=0.3702687919139862, Reg Loss=0.5807209014892578
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.9324044734239578
Loss made of: CE 0.31602510809898376, LKD 0.496886670589447, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3518582284450531, Reg Loss=0.5786607265472412
Clinet index 5, End of Epoch 5/6, Average Loss=0.9305189847946167, Class Loss=0.3518582284450531, Reg Loss=0.5786607265472412
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=0.9005817383527756
Loss made of: CE 0.3802119195461273, LKD 0.6468600034713745, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34457141160964966, Reg Loss=0.5674837827682495
Clinet index 5, End of Epoch 6/6, Average Loss=0.9120551943778992, Class Loss=0.34457141160964966, Reg Loss=0.5674837827682495
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.307846063375473
Loss made of: CE 0.810413122177124, LKD 0.6712357997894287, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7281152009963989, Reg Loss=0.5538225769996643
Clinet index 20, End of Epoch 1/6, Average Loss=1.281937837600708, Class Loss=0.7281152009963989, Reg Loss=0.5538225769996643
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=1.1075874835252761
Loss made of: CE 0.4778668284416199, LKD 0.6312365531921387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.49346670508384705, Reg Loss=0.5873264074325562
Clinet index 20, End of Epoch 2/6, Average Loss=1.0807931423187256, Class Loss=0.49346670508384705, Reg Loss=0.5873264074325562
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.995766481757164
Loss made of: CE 0.43936464190483093, LKD 0.727670431137085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.39399707317352295, Reg Loss=0.6069291830062866
Clinet index 20, End of Epoch 3/6, Average Loss=1.0009262561798096, Class Loss=0.39399707317352295, Reg Loss=0.6069291830062866
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.9670754194259643
Loss made of: CE 0.3476569354534149, LKD 0.5930020809173584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36034315824508667, Reg Loss=0.5950289964675903
Clinet index 20, End of Epoch 4/6, Average Loss=0.955372154712677, Class Loss=0.36034315824508667, Reg Loss=0.5950289964675903
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.937214833498001
Loss made of: CE 0.32321834564208984, LKD 0.6037330031394958, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34414002299308777, Reg Loss=0.5807958841323853
Clinet index 20, End of Epoch 5/6, Average Loss=0.9249359369277954, Class Loss=0.34414002299308777, Reg Loss=0.5807958841323853
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.8861571669578552
Loss made of: CE 0.3304223418235779, LKD 0.5804328918457031, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32258936762809753, Reg Loss=0.5768331289291382
Clinet index 20, End of Epoch 6/6, Average Loss=0.8994225263595581, Class Loss=0.32258936762809753, Reg Loss=0.5768331289291382
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=1.1669939041137696
Loss made of: CE 0.6558901071548462, LKD 0.4894159734249115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6763458251953125, Reg Loss=0.47068706154823303
Clinet index 0, End of Epoch 1/6, Average Loss=1.1470328569412231, Class Loss=0.6763458251953125, Reg Loss=0.47068706154823303
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/11, Loss=1.0008739948272705
Loss made of: CE 0.38278698921203613, LKD 0.42615506052970886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.48515573143959045, Reg Loss=0.4958931803703308
Clinet index 0, End of Epoch 2/6, Average Loss=0.9810489416122437, Class Loss=0.48515573143959045, Reg Loss=0.4958931803703308
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/11, Loss=0.9046114623546601
Loss made of: CE 0.35717886686325073, LKD 0.46704012155532837, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37589311599731445, Reg Loss=0.5264445543289185
Clinet index 0, End of Epoch 3/6, Average Loss=0.9023376703262329, Class Loss=0.37589311599731445, Reg Loss=0.5264445543289185
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/11, Loss=0.87626733481884
Loss made of: CE 0.3662184178829193, LKD 0.6000120639801025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.34151318669319153, Reg Loss=0.5368178486824036
Clinet index 0, End of Epoch 4/6, Average Loss=0.8783310651779175, Class Loss=0.34151318669319153, Reg Loss=0.5368178486824036
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/11, Loss=0.848514786362648
Loss made of: CE 0.34573066234588623, LKD 0.4658893048763275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3353123962879181, Reg Loss=0.5228433609008789
Clinet index 0, End of Epoch 5/6, Average Loss=0.8581557273864746, Class Loss=0.3353123962879181, Reg Loss=0.5228433609008789
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/11, Loss=0.8086090356111526
Loss made of: CE 0.30375945568084717, LKD 0.47868531942367554, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.30854395031929016, Reg Loss=0.5064302682876587
Clinet index 0, End of Epoch 6/6, Average Loss=0.8149741888046265, Class Loss=0.30854395031929016, Reg Loss=0.5064302682876587
federated aggregation...
Validation, Class Loss=0.5893269777297974, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.841326
Mean Acc: 0.456443
FreqW Acc: 0.761260
Mean IoU: 0.370016
Class IoU:
	class 0: 0.8905567
	class 1: 0.62624395
	class 2: 0.292465
	class 3: 0.12333581
	class 4: 0.4154356
	class 5: 0.51692325
	class 6: 0.73735166
	class 7: 0.8385614
	class 8: 0.5122681
	class 9: 0.082315624
	class 10: 0.0
	class 11: 0.0
	class 12: 0.26002598
	class 13: 0.0
	class 14: 0.25475198
Class Acc:
	class 0: 0.9688514
	class 1: 0.6293554
	class 2: 0.56040525
	class 3: 0.123370774
	class 4: 0.4388593
	class 5: 0.5273656
	class 6: 0.74481124
	class 7: 0.8779302
	class 8: 0.5181227
	class 9: 0.24518079
	class 10: 0.0
	class 11: 0.0
	class 12: 0.5600115
	class 13: 0.0
	class 14: 0.65238523

federated global round: 17, step: 3
select part of clients to conduct local training
[1, 16, 6, 21]
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=1.2465554237365724
Loss made of: CE 0.6502425670623779, LKD 0.4588966965675354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7670760750770569, Reg Loss=0.4949478805065155
Clinet index 1, End of Epoch 1/6, Average Loss=1.26202392578125, Class Loss=0.7670760750770569, Reg Loss=0.4949478805065155
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=0.9799234390258789
Loss made of: CE 0.3844212293624878, LKD 0.49715447425842285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.48792028427124023, Reg Loss=0.4902481436729431
Clinet index 1, End of Epoch 2/6, Average Loss=0.9781684279441833, Class Loss=0.48792028427124023, Reg Loss=0.4902481436729431
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=0.8822389841079712
Loss made of: CE 0.2952124774456024, LKD 0.5068973898887634, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3412393033504486, Reg Loss=0.5262733101844788
Clinet index 1, End of Epoch 3/6, Average Loss=0.867512583732605, Class Loss=0.3412393033504486, Reg Loss=0.5262733101844788
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=0.8305529057979584
Loss made of: CE 0.2997833490371704, LKD 0.5889819860458374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2962053716182709, Reg Loss=0.5442692041397095
Clinet index 1, End of Epoch 4/6, Average Loss=0.8404746055603027, Class Loss=0.2962053716182709, Reg Loss=0.5442692041397095
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=0.8075547069311142
Loss made of: CE 0.287635862827301, LKD 0.4990273416042328, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2904367446899414, Reg Loss=0.5287646055221558
Clinet index 1, End of Epoch 5/6, Average Loss=0.8192013502120972, Class Loss=0.2904367446899414, Reg Loss=0.5287646055221558
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=0.791842344403267
Loss made of: CE 0.28462857007980347, LKD 0.48299726843833923, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29100996255874634, Reg Loss=0.511303722858429
Clinet index 1, End of Epoch 6/6, Average Loss=0.8023136854171753, Class Loss=0.29100996255874634, Reg Loss=0.511303722858429
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=1.2974313616752624
Loss made of: CE 0.6803483963012695, LKD 0.51286780834198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7822001576423645, Reg Loss=0.5025094747543335
Clinet index 16, End of Epoch 1/6, Average Loss=1.2847096920013428, Class Loss=0.7822001576423645, Reg Loss=0.5025094747543335
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/11, Loss=1.0133302539587021
Loss made of: CE 0.4282906949520111, LKD 0.5032538175582886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.48909348249435425, Reg Loss=0.500734806060791
Clinet index 16, End of Epoch 2/6, Average Loss=0.9898282885551453, Class Loss=0.48909348249435425, Reg Loss=0.500734806060791
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/11, Loss=0.8572457551956176
Loss made of: CE 0.3012942373752594, LKD 0.5576324462890625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.33065953850746155, Reg Loss=0.5305845737457275
Clinet index 16, End of Epoch 3/6, Average Loss=0.8612440824508667, Class Loss=0.33065953850746155, Reg Loss=0.5305845737457275
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/11, Loss=0.8418671727180481
Loss made of: CE 0.24336841702461243, LKD 0.4208366870880127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3013451099395752, Reg Loss=0.5470647215843201
Clinet index 16, End of Epoch 4/6, Average Loss=0.8484098315238953, Class Loss=0.3013451099395752, Reg Loss=0.5470647215843201
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/11, Loss=0.8253324329853058
Loss made of: CE 0.3231812119483948, LKD 0.5379566550254822, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29443302750587463, Reg Loss=0.5303549766540527
Clinet index 16, End of Epoch 5/6, Average Loss=0.824787974357605, Class Loss=0.29443302750587463, Reg Loss=0.5303549766540527
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/11, Loss=0.8071288257837296
Loss made of: CE 0.2940933406352997, LKD 0.5491503477096558, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2866939902305603, Reg Loss=0.5138704180717468
Clinet index 16, End of Epoch 6/6, Average Loss=0.8005644083023071, Class Loss=0.2866939902305603, Reg Loss=0.5138704180717468
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/11, Loss=1.3327849239110947
Loss made of: CE 0.8084947466850281, LKD 0.5466816425323486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8070050477981567, Reg Loss=0.5126684904098511
Clinet index 6, End of Epoch 1/6, Average Loss=1.3196735382080078, Class Loss=0.8070050477981567, Reg Loss=0.5126684904098511
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/11, Loss=1.0603973597288132
Loss made of: CE 0.5978243350982666, LKD 0.6266297101974487, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5502725839614868, Reg Loss=0.513431191444397
Clinet index 6, End of Epoch 2/6, Average Loss=1.0637037754058838, Class Loss=0.5502725839614868, Reg Loss=0.513431191444397
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/11, Loss=0.9348777920007706
Loss made of: CE 0.3659200072288513, LKD 0.5671343803405762, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37581947445869446, Reg Loss=0.5422844886779785
Clinet index 6, End of Epoch 3/6, Average Loss=0.9181039333343506, Class Loss=0.37581947445869446, Reg Loss=0.5422844886779785
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/11, Loss=0.8647655576467514
Loss made of: CE 0.3365970849990845, LKD 0.5805308818817139, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3160310387611389, Reg Loss=0.552299439907074
Clinet index 6, End of Epoch 4/6, Average Loss=0.8683304786682129, Class Loss=0.3160310387611389, Reg Loss=0.552299439907074
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/11, Loss=0.8477134972810745
Loss made of: CE 0.2613823413848877, LKD 0.4688502252101898, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.30445271730422974, Reg Loss=0.5490249991416931
Clinet index 6, End of Epoch 5/6, Average Loss=0.8534777164459229, Class Loss=0.30445271730422974, Reg Loss=0.5490249991416931
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/11, Loss=0.8263133615255356
Loss made of: CE 0.2685549259185791, LKD 0.5136734247207642, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3000181317329407, Reg Loss=0.5319104194641113
Clinet index 6, End of Epoch 6/6, Average Loss=0.831928551197052, Class Loss=0.3000181317329407, Reg Loss=0.5319104194641113
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9584762722253799
Loss made of: CE 0.35384875535964966, LKD 0.5206515789031982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.41505318880081177, Reg Loss=0.5588101148605347
Clinet index 21, End of Epoch 1/6, Average Loss=0.9738633036613464, Class Loss=0.41505318880081177, Reg Loss=0.5588101148605347
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=0.9233977764844894
Loss made of: CE 0.3250964879989624, LKD 0.6051003932952881, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3316725492477417, Reg Loss=0.6026637554168701
Clinet index 21, End of Epoch 2/6, Average Loss=0.9343363046646118, Class Loss=0.3316725492477417, Reg Loss=0.6026637554168701
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=0.9266571938991547
Loss made of: CE 0.32837826013565063, LKD 0.6724613904953003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31043320894241333, Reg Loss=0.6098155975341797
Clinet index 21, End of Epoch 3/6, Average Loss=0.920248806476593, Class Loss=0.31043320894241333, Reg Loss=0.6098155975341797
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.8957792490720748
Loss made of: CE 0.2994152009487152, LKD 0.5597138404846191, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.30665433406829834, Reg Loss=0.587315559387207
Clinet index 21, End of Epoch 4/6, Average Loss=0.8939698934555054, Class Loss=0.30665433406829834, Reg Loss=0.587315559387207
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.8547366052865982
Loss made of: CE 0.3050433397293091, LKD 0.5769860148429871, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29567086696624756, Reg Loss=0.5851430892944336
Clinet index 21, End of Epoch 5/6, Average Loss=0.8808139562606812, Class Loss=0.29567086696624756, Reg Loss=0.5851430892944336
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.8836691349744796
Loss made of: CE 0.2567650079727173, LKD 0.5233806371688843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.28771349787712097, Reg Loss=0.5850600004196167
Clinet index 21, End of Epoch 6/6, Average Loss=0.8727735280990601, Class Loss=0.28771349787712097, Reg Loss=0.5850600004196167
federated aggregation...
Validation, Class Loss=0.548606276512146, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.839085
Mean Acc: 0.460866
FreqW Acc: 0.770511
Mean IoU: 0.375927
Class IoU:
	class 0: 0.90023416
	class 1: 0.580779
	class 2: 0.3381632
	class 3: 0.17052974
	class 4: 0.38121274
	class 5: 0.6433254
	class 6: 0.7172161
	class 7: 0.8277179
	class 8: 0.5992063
	class 9: 0.07106972
	class 10: 0.0
	class 11: 0.0
	class 12: 0.2578961
	class 13: 0.121823385
	class 14: 0.029731365
Class Acc:
	class 0: 0.96488965
	class 1: 0.5826725
	class 2: 0.7083624
	class 3: 0.17059703
	class 4: 0.40046743
	class 5: 0.6753402
	class 6: 0.7225245
	class 7: 0.89371926
	class 8: 0.6084327
	class 9: 0.22322012
	class 10: 0.0
	class 11: 0.0
	class 12: 0.5399693
	class 13: 0.3929739
	class 14: 0.029824162

federated global round: 18, step: 3
select part of clients to conduct local training
[8, 2, 17, 14]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.8449848860502243
Loss made of: CE 0.313495934009552, LKD 0.4525395333766937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3676740527153015, Reg Loss=0.47801071405410767
Clinet index 8, End of Epoch 1/6, Average Loss=0.8456847667694092, Class Loss=0.3676740527153015, Reg Loss=0.47801071405410767
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=0.8133899241685867
Loss made of: CE 0.3068661093711853, LKD 0.5811709761619568, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3016205430030823, Reg Loss=0.5105201005935669
Clinet index 8, End of Epoch 2/6, Average Loss=0.8121406435966492, Class Loss=0.3016205430030823, Reg Loss=0.5105201005935669
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=0.7829025089740753
Loss made of: CE 0.24575039744377136, LKD 0.4869174659252167, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2742689847946167, Reg Loss=0.5231369733810425
Clinet index 8, End of Epoch 3/6, Average Loss=0.7974059581756592, Class Loss=0.2742689847946167, Reg Loss=0.5231369733810425
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=0.7678332135081292
Loss made of: CE 0.21995097398757935, LKD 0.46089738607406616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2575940191745758, Reg Loss=0.5097952485084534
Clinet index 8, End of Epoch 4/6, Average Loss=0.7673892974853516, Class Loss=0.2575940191745758, Reg Loss=0.5097952485084534
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=0.7483049809932709
Loss made of: CE 0.25507885217666626, LKD 0.4826357066631317, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2583332359790802, Reg Loss=0.4972512125968933
Clinet index 8, End of Epoch 5/6, Average Loss=0.7555844783782959, Class Loss=0.2583332359790802, Reg Loss=0.4972512125968933
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=0.7724951401352882
Loss made of: CE 0.2874661684036255, LKD 0.5368320345878601, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25865235924720764, Reg Loss=0.5024053454399109
Clinet index 8, End of Epoch 6/6, Average Loss=0.7610577344894409, Class Loss=0.25865235924720764, Reg Loss=0.5024053454399109
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.851664936542511
Loss made of: CE 0.2919188141822815, LKD 0.45166724920272827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.37558531761169434, Reg Loss=0.4818662405014038
Clinet index 2, End of Epoch 1/6, Average Loss=0.8574515581130981, Class Loss=0.37558531761169434, Reg Loss=0.4818662405014038
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=0.8282558143138885
Loss made of: CE 0.28587624430656433, LKD 0.4999092221260071, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3065375089645386, Reg Loss=0.5151646733283997
Clinet index 2, End of Epoch 2/6, Average Loss=0.8217021822929382, Class Loss=0.3065375089645386, Reg Loss=0.5151646733283997
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=0.8230124622583389
Loss made of: CE 0.263322651386261, LKD 0.5003489255905151, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2748979330062866, Reg Loss=0.533869743347168
Clinet index 2, End of Epoch 3/6, Average Loss=0.8087676763534546, Class Loss=0.2748979330062866, Reg Loss=0.533869743347168
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=0.7940340235829353
Loss made of: CE 0.25061559677124023, LKD 0.517763078212738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26830556988716125, Reg Loss=0.5225602388381958
Clinet index 2, End of Epoch 4/6, Average Loss=0.7908657789230347, Class Loss=0.26830556988716125, Reg Loss=0.5225602388381958
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=0.7843847185373306
Loss made of: CE 0.239061638712883, LKD 0.4761340618133545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26754599809646606, Reg Loss=0.5129399299621582
Clinet index 2, End of Epoch 5/6, Average Loss=0.7804859280586243, Class Loss=0.26754599809646606, Reg Loss=0.5129399299621582
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=0.7760927274823188
Loss made of: CE 0.2641461491584778, LKD 0.4701795279979706, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26464515924453735, Reg Loss=0.5129631757736206
Clinet index 2, End of Epoch 6/6, Average Loss=0.777608335018158, Class Loss=0.26464515924453735, Reg Loss=0.5129631757736206
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.2652524054050445
Loss made of: CE 0.6864097118377686, LKD 0.6836671829223633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.680601954460144, Reg Loss=0.551192045211792
Clinet index 17, End of Epoch 1/6, Average Loss=1.231793999671936, Class Loss=0.680601954460144, Reg Loss=0.551192045211792
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.99688118994236
Loss made of: CE 0.30920907855033875, LKD 0.6086227297782898, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3868425786495209, Reg Loss=0.5902585387229919
Clinet index 17, End of Epoch 2/6, Average Loss=0.9771010875701904, Class Loss=0.3868425786495209, Reg Loss=0.5902585387229919
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.9267719253897667
Loss made of: CE 0.26312941312789917, LKD 0.6110708117485046, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.29286015033721924, Reg Loss=0.6284263134002686
Clinet index 17, End of Epoch 3/6, Average Loss=0.9212864637374878, Class Loss=0.29286015033721924, Reg Loss=0.6284263134002686
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.9329313665628434
Loss made of: CE 0.2570779025554657, LKD 0.5166201591491699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.29658907651901245, Reg Loss=0.6150756478309631
Clinet index 17, End of Epoch 4/6, Average Loss=0.9116647243499756, Class Loss=0.29658907651901245, Reg Loss=0.6150756478309631
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.8468988731503486
Loss made of: CE 0.24872861802577972, LKD 0.5550985336303711, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.30599355697631836, Reg Loss=0.5979117751121521
Clinet index 17, End of Epoch 5/6, Average Loss=0.9039053320884705, Class Loss=0.30599355697631836, Reg Loss=0.5979117751121521
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.8884664177894592
Loss made of: CE 0.25187161564826965, LKD 0.495347261428833, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2942346930503845, Reg Loss=0.5946964621543884
Clinet index 17, End of Epoch 6/6, Average Loss=0.888931155204773, Class Loss=0.2942346930503845, Reg Loss=0.5946964621543884
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/11, Loss=0.8735732108354568
Loss made of: CE 0.3278845548629761, LKD 0.4530255198478699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3816128671169281, Reg Loss=0.4948221743106842
Clinet index 14, End of Epoch 1/6, Average Loss=0.8764350414276123, Class Loss=0.3816128671169281, Reg Loss=0.4948221743106842
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/11, Loss=0.8338650971651077
Loss made of: CE 0.279452919960022, LKD 0.5543559789657593, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3086399734020233, Reg Loss=0.5344832539558411
Clinet index 14, End of Epoch 2/6, Average Loss=0.843123197555542, Class Loss=0.3086399734020233, Reg Loss=0.5344832539558411
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/11, Loss=0.8238764002919197
Loss made of: CE 0.2662908434867859, LKD 0.5178841352462769, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27796870470046997, Reg Loss=0.5475780963897705
Clinet index 14, End of Epoch 3/6, Average Loss=0.8255468010902405, Class Loss=0.27796870470046997, Reg Loss=0.5475780963897705
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/11, Loss=0.8336107343435287
Loss made of: CE 0.278787225484848, LKD 0.5531831383705139, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2818770408630371, Reg Loss=0.5505977869033813
Clinet index 14, End of Epoch 4/6, Average Loss=0.8324748277664185, Class Loss=0.2818770408630371, Reg Loss=0.5505977869033813
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/11, Loss=0.8024217858910561
Loss made of: CE 0.24880677461624146, LKD 0.47473570704460144, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2726893424987793, Reg Loss=0.5369115471839905
Clinet index 14, End of Epoch 5/6, Average Loss=0.8096008896827698, Class Loss=0.2726893424987793, Reg Loss=0.5369115471839905
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/11, Loss=0.7991656988859177
Loss made of: CE 0.2348405122756958, LKD 0.4827896058559418, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.27257412672042847, Reg Loss=0.5311406254768372
Clinet index 14, End of Epoch 6/6, Average Loss=0.8037147521972656, Class Loss=0.27257412672042847, Reg Loss=0.5311406254768372
federated aggregation...
Validation, Class Loss=0.5491639375686646, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.833778
Mean Acc: 0.461629
FreqW Acc: 0.768725
Mean IoU: 0.372147
Class IoU:
	class 0: 0.9002018
	class 1: 0.59556746
	class 2: 0.33761573
	class 3: 0.15743266
	class 4: 0.3663288
	class 5: 0.6324185
	class 6: 0.71573126
	class 7: 0.83347255
	class 8: 0.5844712
	class 9: 0.0757834
	class 10: 0.0
	class 11: 0.0
	class 12: 0.21383256
	class 13: 0.14271368
	class 14: 0.026642228
Class Acc:
	class 0: 0.96056956
	class 1: 0.59741753
	class 2: 0.6905138
	class 3: 0.1574928
	class 4: 0.38302836
	class 5: 0.6622179
	class 6: 0.72057194
	class 7: 0.8993448
	class 8: 0.59252405
	class 9: 0.25658914
	class 10: 0.0
	class 11: 0.0
	class 12: 0.39427003
	class 13: 0.583187
	class 14: 0.026708852

federated global round: 19, step: 3
select part of clients to conduct local training
[1, 9, 8, 0]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/11, Loss=0.7949532836675643
Loss made of: CE 0.3056069016456604, LKD 0.4531455934047699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3378206789493561, Reg Loss=0.4764578640460968
Clinet index 1, End of Epoch 1/6, Average Loss=0.8142785429954529, Class Loss=0.3378206789493561, Reg Loss=0.4764578640460968
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/11, Loss=0.7891768932342529
Loss made of: CE 0.2751910090446472, LKD 0.5130974054336548, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29286518692970276, Reg Loss=0.500281810760498
Clinet index 1, End of Epoch 2/6, Average Loss=0.7931469678878784, Class Loss=0.29286518692970276, Reg Loss=0.500281810760498
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/11, Loss=0.8073875501751899
Loss made of: CE 0.2416207492351532, LKD 0.4663425087928772, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2762465476989746, Reg Loss=0.5193654298782349
Clinet index 1, End of Epoch 3/6, Average Loss=0.7956119775772095, Class Loss=0.2762465476989746, Reg Loss=0.5193654298782349
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/11, Loss=0.7749386861920357
Loss made of: CE 0.26865190267562866, LKD 0.5566321015357971, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2667166292667389, Reg Loss=0.5225765109062195
Clinet index 1, End of Epoch 4/6, Average Loss=0.7892931699752808, Class Loss=0.2667166292667389, Reg Loss=0.5225765109062195
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/11, Loss=0.7694715857505798
Loss made of: CE 0.26689600944519043, LKD 0.47294068336486816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26275864243507385, Reg Loss=0.5200773477554321
Clinet index 1, End of Epoch 5/6, Average Loss=0.7828359603881836, Class Loss=0.26275864243507385, Reg Loss=0.5200773477554321
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/11, Loss=0.7827155739068985
Loss made of: CE 0.25958767533302307, LKD 0.5001506805419922, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2683711349964142, Reg Loss=0.5247671008110046
Clinet index 1, End of Epoch 6/6, Average Loss=0.7931382656097412, Class Loss=0.2683711349964142, Reg Loss=0.5247671008110046
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=1.3203371107578277
Loss made of: CE 0.6721362471580505, LKD 0.5945832133293152, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7063450217247009, Reg Loss=0.5466391444206238
Clinet index 9, End of Epoch 1/6, Average Loss=1.2529841661453247, Class Loss=0.7063450217247009, Reg Loss=0.5466391444206238
Pseudo labeling is: None
Epoch 2, lr = 0.000694
Epoch 2, Batch 10/12, Loss=0.9882834613323211
Loss made of: CE 0.32575133442878723, LKD 0.4888150095939636, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.43419134616851807, Reg Loss=0.5560168027877808
Clinet index 9, End of Epoch 2/6, Average Loss=0.9902081489562988, Class Loss=0.43419134616851807, Reg Loss=0.5560168027877808
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/12, Loss=0.9109781056642532
Loss made of: CE 0.3439015746116638, LKD 0.6165450811386108, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31158190965652466, Reg Loss=0.5894314646720886
Clinet index 9, End of Epoch 3/6, Average Loss=0.9010133743286133, Class Loss=0.31158190965652466, Reg Loss=0.5894314646720886
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/12, Loss=0.8964057803153992
Loss made of: CE 0.24798402190208435, LKD 0.5442067980766296, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28835606575012207, Reg Loss=0.5988688468933105
Clinet index 9, End of Epoch 4/6, Average Loss=0.8872249126434326, Class Loss=0.28835606575012207, Reg Loss=0.5988688468933105
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/12, Loss=0.8739133566617966
Loss made of: CE 0.3081026077270508, LKD 0.5685997605323792, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2830841839313507, Reg Loss=0.5922554135322571
Clinet index 9, End of Epoch 5/6, Average Loss=0.8753396272659302, Class Loss=0.2830841839313507, Reg Loss=0.5922554135322571
Pseudo labeling is: None
Epoch 6, lr = 0.000163
Epoch 6, Batch 10/12, Loss=0.8898893296718597
Loss made of: CE 0.23660653829574585, LKD 0.522803008556366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2843460440635681, Reg Loss=0.601259708404541
Clinet index 9, End of Epoch 6/6, Average Loss=0.8856057524681091, Class Loss=0.2843460440635681, Reg Loss=0.601259708404541
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/11, Loss=0.8001015514135361
Loss made of: CE 0.2965134382247925, LKD 0.4474698305130005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33114010095596313, Reg Loss=0.47164052724838257
Clinet index 8, End of Epoch 1/6, Average Loss=0.8027806282043457, Class Loss=0.33114010095596313, Reg Loss=0.47164052724838257
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/11, Loss=0.795261350274086
Loss made of: CE 0.30281051993370056, LKD 0.5506573915481567, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.30048710107803345, Reg Loss=0.4927331805229187
Clinet index 8, End of Epoch 2/6, Average Loss=0.7932202816009521, Class Loss=0.30048710107803345, Reg Loss=0.4927331805229187
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/11, Loss=0.769035916030407
Loss made of: CE 0.22962836921215057, LKD 0.44536638259887695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2787259519100189, Reg Loss=0.5026276707649231
Clinet index 8, End of Epoch 3/6, Average Loss=0.7813535928726196, Class Loss=0.2787259519100189, Reg Loss=0.5026276707649231
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/11, Loss=0.7890103831887245
Loss made of: CE 0.22427813708782196, LKD 0.47604870796203613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26900529861450195, Reg Loss=0.517280101776123
Clinet index 8, End of Epoch 4/6, Average Loss=0.786285400390625, Class Loss=0.26900529861450195, Reg Loss=0.517280101776123
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/11, Loss=0.76480173766613
Loss made of: CE 0.25667354464530945, LKD 0.497617244720459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2629530429840088, Reg Loss=0.508952796459198
Clinet index 8, End of Epoch 5/6, Average Loss=0.7719058394432068, Class Loss=0.2629530429840088, Reg Loss=0.508952796459198
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/11, Loss=0.7762625485658645
Loss made of: CE 0.27631115913391113, LKD 0.5559184551239014, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25829797983169556, Reg Loss=0.508094072341919
Clinet index 8, End of Epoch 6/6, Average Loss=0.7663920521736145, Class Loss=0.25829797983169556, Reg Loss=0.508094072341919
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/11, Loss=0.8428720831871033
Loss made of: CE 0.37001463770866394, LKD 0.5134785175323486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.34404119849205017, Reg Loss=0.4883851408958435
Clinet index 0, End of Epoch 1/6, Average Loss=0.8324263095855713, Class Loss=0.34404119849205017, Reg Loss=0.4883851408958435
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/11, Loss=0.824089452624321
Loss made of: CE 0.23694786429405212, LKD 0.4350516200065613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29678967595100403, Reg Loss=0.5110557079315186
Clinet index 0, End of Epoch 2/6, Average Loss=0.8078453540802002, Class Loss=0.29678967595100403, Reg Loss=0.5110557079315186
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/11, Loss=0.7978629827499389
Loss made of: CE 0.2629356384277344, LKD 0.47535061836242676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2709934711456299, Reg Loss=0.5230353474617004
Clinet index 0, End of Epoch 3/6, Average Loss=0.7940288186073303, Class Loss=0.2709934711456299, Reg Loss=0.5230353474617004
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/11, Loss=0.775841823220253
Loss made of: CE 0.2882286012172699, LKD 0.5810847282409668, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26364850997924805, Reg Loss=0.5186725854873657
Clinet index 0, End of Epoch 4/6, Average Loss=0.7823210954666138, Class Loss=0.26364850997924805, Reg Loss=0.5186725854873657
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/11, Loss=0.7607818841934204
Loss made of: CE 0.26053544878959656, LKD 0.4495212435722351, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26475024223327637, Reg Loss=0.5076872110366821
Clinet index 0, End of Epoch 5/6, Average Loss=0.7724374532699585, Class Loss=0.26475024223327637, Reg Loss=0.5076872110366821
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/11, Loss=0.7825071752071381
Loss made of: CE 0.26021623611450195, LKD 0.49300169944763184, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.26185861229896545, Reg Loss=0.5210774540901184
Clinet index 0, End of Epoch 6/6, Average Loss=0.7829360961914062, Class Loss=0.26185861229896545, Reg Loss=0.5210774540901184
federated aggregation...
Validation, Class Loss=0.5559015274047852, Reg Loss=0.0 (without scaling)

Total samples: 1140.000000
Overall Acc: 0.831567
Mean Acc: 0.469240
FreqW Acc: 0.768174
Mean IoU: 0.374686
Class IoU:
	class 0: 0.9005893
	class 1: 0.5854175
	class 2: 0.34124187
	class 3: 0.13978294
	class 4: 0.3722002
	class 5: 0.61768514
	class 6: 0.7203115
	class 7: 0.8324308
	class 8: 0.5726219
	class 9: 0.081842385
	class 10: 0.0
	class 11: 0.0
	class 12: 0.13281067
	class 13: 0.15246508
	class 14: 0.17088601
Class Acc:
	class 0: 0.9593718
	class 1: 0.5871636
	class 2: 0.7059707
	class 3: 0.1398355
	class 4: 0.3897865
	class 5: 0.64581776
	class 6: 0.7253488
	class 7: 0.89875287
	class 8: 0.58019596
	class 9: 0.24682276
	class 10: 0.0
	class 11: 0.0
	class 12: 0.20146167
	class 13: 0.7755887
	class 14: 0.1824814

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[11, 2, 15, 6]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.4975742518901825
Loss made of: CE 0.951744019985199, LKD 0.5319963693618774, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9434530735015869, Reg Loss=0.5212773084640503
Clinet index 11, End of Epoch 1/6, Average Loss=1.4647303819656372, Class Loss=0.9434530735015869, Reg Loss=0.5212773084640503
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.1830868035554887
Loss made of: CE 0.6331539154052734, LKD 0.5023583173751831, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.699607253074646, Reg Loss=0.5011255741119385
Clinet index 11, End of Epoch 2/6, Average Loss=1.2007328271865845, Class Loss=0.699607253074646, Reg Loss=0.5011255741119385
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.064301896095276
Loss made of: CE 0.5947846174240112, LKD 0.43426650762557983, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6053227186203003, Reg Loss=0.486857533454895
Clinet index 11, End of Epoch 3/6, Average Loss=1.0921802520751953, Class Loss=0.6053227186203003, Reg Loss=0.486857533454895
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.0762719690799714
Loss made of: CE 0.6189537048339844, LKD 0.48484134674072266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5880427360534668, Reg Loss=0.46676892042160034
Clinet index 11, End of Epoch 4/6, Average Loss=1.054811716079712, Class Loss=0.5880427360534668, Reg Loss=0.46676892042160034
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0374136477708817
Loss made of: CE 0.5006933212280273, LKD 0.4665970504283905, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5665735006332397, Reg Loss=0.4510548710823059
Clinet index 11, End of Epoch 5/6, Average Loss=1.0176284313201904, Class Loss=0.5665735006332397, Reg Loss=0.4510548710823059
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.9909693866968154
Loss made of: CE 0.6375458240509033, LKD 0.4947158992290497, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5457618832588196, Reg Loss=0.44580143690109253
Clinet index 11, End of Epoch 6/6, Average Loss=0.9915633201599121, Class Loss=0.5457618832588196, Reg Loss=0.44580143690109253
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.5084662437438965
Loss made of: CE 0.9344199895858765, LKD 0.5353845953941345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9610641002655029, Reg Loss=0.5298252701759338
Clinet index 2, End of Epoch 1/6, Average Loss=1.490889310836792, Class Loss=0.9610641002655029, Reg Loss=0.5298252701759338
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2179349899291991
Loss made of: CE 0.5980846285820007, LKD 0.46251267194747925, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6835295557975769, Reg Loss=0.5047563314437866
Clinet index 2, End of Epoch 2/6, Average Loss=1.1882858276367188, Class Loss=0.6835295557975769, Reg Loss=0.5047563314437866
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.0946344971656798
Loss made of: CE 0.5258747339248657, LKD 0.41998252272605896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6048815250396729, Reg Loss=0.4975733160972595
Clinet index 2, End of Epoch 3/6, Average Loss=1.1024549007415771, Class Loss=0.6048815250396729, Reg Loss=0.4975733160972595
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.047962662577629
Loss made of: CE 0.6158524751663208, LKD 0.5462391376495361, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.575661838054657, Reg Loss=0.4699241816997528
Clinet index 2, End of Epoch 4/6, Average Loss=1.0455859899520874, Class Loss=0.575661838054657, Reg Loss=0.4699241816997528
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0354468733072282
Loss made of: CE 0.6183764338493347, LKD 0.5486719012260437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5588545203208923, Reg Loss=0.465990275144577
Clinet index 2, End of Epoch 5/6, Average Loss=1.024844765663147, Class Loss=0.5588545203208923, Reg Loss=0.465990275144577
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=1.0046439528465272
Loss made of: CE 0.5852770209312439, LKD 0.45852383971214294, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5483952760696411, Reg Loss=0.45590949058532715
Clinet index 2, End of Epoch 6/6, Average Loss=1.0043047666549683, Class Loss=0.5483952760696411, Reg Loss=0.45590949058532715
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.499642199277878
Loss made of: CE 0.9850783348083496, LKD 0.5433310270309448, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9313560724258423, Reg Loss=0.5292510986328125
Clinet index 15, End of Epoch 1/6, Average Loss=1.4606071710586548, Class Loss=0.9313560724258423, Reg Loss=0.5292510986328125
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2165316939353943
Loss made of: CE 0.6886751651763916, LKD 0.5266727209091187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6793825626373291, Reg Loss=0.499869704246521
Clinet index 15, End of Epoch 2/6, Average Loss=1.17925226688385, Class Loss=0.6793825626373291, Reg Loss=0.499869704246521
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.054606282711029
Loss made of: CE 0.6125949025154114, LKD 0.4079853296279907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5969827175140381, Reg Loss=0.4890139102935791
Clinet index 15, End of Epoch 3/6, Average Loss=1.0859966278076172, Class Loss=0.5969827175140381, Reg Loss=0.4890139102935791
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.0193301290273666
Loss made of: CE 0.4544242322444916, LKD 0.39963898062705994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5755596160888672, Reg Loss=0.4563739001750946
Clinet index 15, End of Epoch 4/6, Average Loss=1.0319335460662842, Class Loss=0.5755596160888672, Reg Loss=0.4563739001750946
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0164496093988418
Loss made of: CE 0.6895546913146973, LKD 0.40807637572288513, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5638672113418579, Reg Loss=0.4427003562450409
Clinet index 15, End of Epoch 5/6, Average Loss=1.0065675973892212, Class Loss=0.5638672113418579, Reg Loss=0.4427003562450409
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.9459953993558884
Loss made of: CE 0.4903661608695984, LKD 0.37177368998527527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5244290232658386, Reg Loss=0.4315057396888733
Clinet index 15, End of Epoch 6/6, Average Loss=0.9559347629547119, Class Loss=0.5244290232658386, Reg Loss=0.4315057396888733
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=1.5324553966522216
Loss made of: CE 0.8637611269950867, LKD 0.45704174041748047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=1.229588383436203
Loss made of: CE 0.7094734907150269, LKD 0.42231255769729614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=1.0292912662029265
Loss made of: CE 0.6015512347221375, LKD 0.465828001499176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.9356799840927124
Loss made of: CE 0.47039347887039185, LKD 0.36404484510421753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.8473633736371994
Loss made of: CE 0.47228679060935974, LKD 0.34799131751060486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.8584726721048355
Loss made of: CE 0.5414330959320068, LKD 0.505818784236908, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.8824821174144745
Loss made of: CE 0.5192208886146545, LKD 0.40477728843688965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.8109007030725479
Loss made of: CE 0.42337292432785034, LKD 0.35808834433555603, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.8199904680252075
Loss made of: CE 0.3964788615703583, LKD 0.3963375985622406, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5642629861831665, Reg Loss=0.41733258962631226
Clinet index 6, End of Epoch 1/6, Average Loss=0.9815955758094788, Class Loss=0.5642629861831665, Reg Loss=0.41733258962631226
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/97, Loss=0.7763193160295486
Loss made of: CE 0.36912667751312256, LKD 0.36715635657310486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.7221840292215347
Loss made of: CE 0.46315306425094604, LKD 0.36095690727233887, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.7566955506801605
Loss made of: CE 0.2987522482872009, LKD 0.3835523724555969, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.7278592735528946
Loss made of: CE 0.31361517310142517, LKD 0.4043557643890381, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.7101633489131928
Loss made of: CE 0.2697038948535919, LKD 0.33722084760665894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.7158244729042054
Loss made of: CE 0.3572043180465698, LKD 0.3609747290611267, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.6572876304388047
Loss made of: CE 0.2276453673839569, LKD 0.34693312644958496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.7127616554498672
Loss made of: CE 0.3037681579589844, LKD 0.38530394434928894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.7408278197050094
Loss made of: CE 0.2754446268081665, LKD 0.4068639874458313, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3212137520313263, Reg Loss=0.3976776897907257
Clinet index 6, End of Epoch 2/6, Average Loss=0.718891441822052, Class Loss=0.3212137520313263, Reg Loss=0.3976776897907257
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/97, Loss=0.6383509650826454
Loss made of: CE 0.24675379693508148, LKD 0.4415346086025238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.6301774397492409
Loss made of: CE 0.2705053687095642, LKD 0.37541836500167847, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.642780776321888
Loss made of: CE 0.23735547065734863, LKD 0.4345453679561615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.6266131773591042
Loss made of: CE 0.25338590145111084, LKD 0.3511675298213959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.6720956206321717
Loss made of: CE 0.2708556652069092, LKD 0.408829927444458, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.6494450628757477
Loss made of: CE 0.31706154346466064, LKD 0.47590646147727966, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.6195217505097389
Loss made of: CE 0.1737486571073532, LKD 0.3851388394832611, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.6497931510210038
Loss made of: CE 0.20893704891204834, LKD 0.3735911548137665, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.6669179260730743
Loss made of: CE 0.2343806028366089, LKD 0.386507123708725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2456573098897934, Reg Loss=0.39980241656303406
Clinet index 6, End of Epoch 3/6, Average Loss=0.6454597115516663, Class Loss=0.2456573098897934, Reg Loss=0.39980241656303406
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/97, Loss=0.6351864010095596
Loss made of: CE 0.23666176199913025, LKD 0.3952476382255554, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.6412478536367416
Loss made of: CE 0.22049283981323242, LKD 0.3632829189300537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.5931600168347358
Loss made of: CE 0.1846790313720703, LKD 0.4220162332057953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.6002976968884468
Loss made of: CE 0.24148941040039062, LKD 0.3790789246559143, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.6023130878806114
Loss made of: CE 0.20181804895401, LKD 0.3445601165294647, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.6019213527441025
Loss made of: CE 0.2179471254348755, LKD 0.4297703504562378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5881681323051453
Loss made of: CE 0.17894655466079712, LKD 0.35860010981559753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.641769340634346
Loss made of: CE 0.16366487741470337, LKD 0.3393058776855469, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.6581734329462051
Loss made of: CE 0.3011277914047241, LKD 0.5167049169540405, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2139369398355484, Reg Loss=0.39850175380706787
Clinet index 6, End of Epoch 4/6, Average Loss=0.6124386787414551, Class Loss=0.2139369398355484, Reg Loss=0.39850175380706787
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/97, Loss=0.6046856880187989
Loss made of: CE 0.17526847124099731, LKD 0.39970001578330994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.6171040326356888
Loss made of: CE 0.17464026808738708, LKD 0.37808316946029663, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5857877120375633
Loss made of: CE 0.19070589542388916, LKD 0.46992796659469604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.5859675943851471
Loss made of: CE 0.2536771893501282, LKD 0.41153156757354736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5928356289863587
Loss made of: CE 0.1614677757024765, LKD 0.3332366645336151, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5761410802602768
Loss made of: CE 0.1481168270111084, LKD 0.36249399185180664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.619709487259388
Loss made of: CE 0.16309261322021484, LKD 0.4269596040248871, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.583804976940155
Loss made of: CE 0.16418252885341644, LKD 0.42170655727386475, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5964297324419021
Loss made of: CE 0.1630406379699707, LKD 0.3776865005493164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20005349814891815, Reg Loss=0.3955446183681488
Clinet index 6, End of Epoch 5/6, Average Loss=0.5955981016159058, Class Loss=0.20005349814891815, Reg Loss=0.3955446183681488
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/97, Loss=0.5478762000799179
Loss made of: CE 0.1809549629688263, LKD 0.3831000328063965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5683581620454788
Loss made of: CE 0.13239970803260803, LKD 0.3789535164833069, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5841799005866051
Loss made of: CE 0.14978276193141937, LKD 0.43412625789642334, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5918994173407555
Loss made of: CE 0.20154142379760742, LKD 0.3582790791988373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5763293266296386
Loss made of: CE 0.15994973480701447, LKD 0.3804956376552582, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.6398651286959648
Loss made of: CE 0.24855929613113403, LKD 0.4628044366836548, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5721138462424278
Loss made of: CE 0.2412935197353363, LKD 0.43889355659484863, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5792173072695732
Loss made of: CE 0.18534527719020844, LKD 0.34232282638549805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5768206015229225
Loss made of: CE 0.18063990771770477, LKD 0.34650033712387085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18538573384284973, Reg Loss=0.39696410298347473
Clinet index 6, End of Epoch 6/6, Average Loss=0.5823498368263245, Class Loss=0.18538573384284973, Reg Loss=0.39696410298347473
federated aggregation...
Validation, Class Loss=0.7450470924377441, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.771667
Mean Acc: 0.406739
FreqW Acc: 0.652877
Mean IoU: 0.312583
Class IoU:
	class 0: 0.8199107
	class 1: 0.55878043
	class 2: 0.33270377
	class 3: 0.045837793
	class 4: 0.25993696
	class 5: 0.6291635
	class 6: 0.628307
	class 7: 0.8339306
	class 8: 0.5384453
	class 9: 0.09832532
	class 10: 0.0
	class 11: 0.0
	class 12: 0.12535414
	class 13: 0.16931017
	class 14: 0.27390373
	class 15: 0.0
	class 16: 0.0
Class Acc:
	class 0: 0.9633427
	class 1: 0.56134504
	class 2: 0.7086548
	class 3: 0.04584292
	class 4: 0.26373377
	class 5: 0.6595546
	class 6: 0.6347948
	class 7: 0.8766185
	class 8: 0.54396665
	class 9: 0.2933498
	class 10: 0.0
	class 11: 0.0
	class 12: 0.17922918
	class 13: 0.8781442
	class 14: 0.30597794
	class 15: 0.0
	class 16: 0.0

federated global round: 21, step: 4
select part of clients to conduct local training
[20, 2, 24, 4]
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=1.074135395884514
Loss made of: CE 0.47275301814079285, LKD 0.37296080589294434, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.8624993830919265
Loss made of: CE 0.4171605706214905, LKD 0.40183746814727783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.8603183269500733
Loss made of: CE 0.33452457189559937, LKD 0.3719748854637146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.7986432760953903
Loss made of: CE 0.3443388342857361, LKD 0.3936083912849426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.7141123920679092
Loss made of: CE 0.3506617546081543, LKD 0.45420873165130615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.7385666966438293
Loss made of: CE 0.2843160927295685, LKD 0.392223596572876, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.7342599600553512
Loss made of: CE 0.31629428267478943, LKD 0.3899783790111542, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.6428148552775383
Loss made of: CE 0.24904978275299072, LKD 0.420579731464386, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.6788336753845214
Loss made of: CE 0.27019837498664856, LKD 0.49106544256210327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3755192160606384, Reg Loss=0.4074680209159851
Clinet index 20, End of Epoch 1/6, Average Loss=0.7829872369766235, Class Loss=0.3755192160606384, Reg Loss=0.4074680209159851
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/97, Loss=0.6676428496837616
Loss made of: CE 0.3098755478858948, LKD 0.45544275641441345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.6527277633547783
Loss made of: CE 0.2830025553703308, LKD 0.48489436507225037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.6369720369577407
Loss made of: CE 0.21917252242565155, LKD 0.5650317668914795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.6630582809448242
Loss made of: CE 0.24263159930706024, LKD 0.4883069396018982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.6430021092295647
Loss made of: CE 0.21560141444206238, LKD 0.42681121826171875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.6480008527636528
Loss made of: CE 0.2697645425796509, LKD 0.32456856966018677, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.6867904588580132
Loss made of: CE 0.3121333122253418, LKD 0.3567299246788025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.6467689633369446
Loss made of: CE 0.20634159445762634, LKD 0.3505510091781616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.5964647024869919
Loss made of: CE 0.21225020289421082, LKD 0.4249638020992279, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2380797117948532, Reg Loss=0.4091724753379822
Clinet index 20, End of Epoch 2/6, Average Loss=0.6472522020339966, Class Loss=0.2380797117948532, Reg Loss=0.4091724753379822
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/97, Loss=0.633460296690464
Loss made of: CE 0.21213583648204803, LKD 0.388107031583786, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.6181164085865021
Loss made of: CE 0.20466530323028564, LKD 0.33608078956604004, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.6218680992722512
Loss made of: CE 0.17485356330871582, LKD 0.4057987928390503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5904451549053192
Loss made of: CE 0.26494064927101135, LKD 0.3055574893951416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.6042380347847939
Loss made of: CE 0.18969522416591644, LKD 0.40745222568511963, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.6399614229798317
Loss made of: CE 0.2002730369567871, LKD 0.4517204165458679, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.6172521695494652
Loss made of: CE 0.17659786343574524, LKD 0.3816843628883362, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.6136916488409042
Loss made of: CE 0.15045560896396637, LKD 0.3739447593688965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.6070164769887925
Loss made of: CE 0.21845710277557373, LKD 0.3710212707519531, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2095932811498642, Reg Loss=0.405382364988327
Clinet index 20, End of Epoch 3/6, Average Loss=0.61497563123703, Class Loss=0.2095932811498642, Reg Loss=0.405382364988327
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/97, Loss=0.603578120470047
Loss made of: CE 0.1449052393436432, LKD 0.48514413833618164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.5970710620284081
Loss made of: CE 0.18744179606437683, LKD 0.46521374583244324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.5999168798327446
Loss made of: CE 0.1519608497619629, LKD 0.3533002734184265, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.6179615750908851
Loss made of: CE 0.22365576028823853, LKD 0.3892413079738617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5933534577488899
Loss made of: CE 0.15879186987876892, LKD 0.3662378191947937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5921701237559318
Loss made of: CE 0.19630393385887146, LKD 0.4034542739391327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5868248164653778
Loss made of: CE 0.2016110122203827, LKD 0.4479402005672455, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.6167736604809761
Loss made of: CE 0.17987984418869019, LKD 0.33668053150177, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.588132506608963
Loss made of: CE 0.2254350483417511, LKD 0.49354466795921326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.19159115850925446, Reg Loss=0.4045340418815613
Clinet index 20, End of Epoch 4/6, Average Loss=0.5961251854896545, Class Loss=0.19159115850925446, Reg Loss=0.4045340418815613
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/97, Loss=0.6289133682847023
Loss made of: CE 0.20293256640434265, LKD 0.5139917135238647, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.6119260489940643
Loss made of: CE 0.1471915990114212, LKD 0.4369540214538574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5788555428385734
Loss made of: CE 0.17704415321350098, LKD 0.3420632779598236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.608396552503109
Loss made of: CE 0.16760924458503723, LKD 0.4502647817134857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.6057873278856277
Loss made of: CE 0.1767088621854782, LKD 0.47929924726486206, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5725224316120148
Loss made of: CE 0.1860521286725998, LKD 0.3459162414073944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5855839759111404
Loss made of: CE 0.16211055219173431, LKD 0.38457736372947693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.5811859130859375
Loss made of: CE 0.17794984579086304, LKD 0.3595035970211029, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5823809891939163
Loss made of: CE 0.16151034832000732, LKD 0.36983436346054077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1858270764350891, Reg Loss=0.4072493612766266
Clinet index 20, End of Epoch 5/6, Average Loss=0.5930764675140381, Class Loss=0.1858270764350891, Reg Loss=0.4072493612766266
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/97, Loss=0.5840978130698204
Loss made of: CE 0.16932055354118347, LKD 0.36633962392807007, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5794889077544212
Loss made of: CE 0.21448390185832977, LKD 0.4586615562438965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5713403135538101
Loss made of: CE 0.12764285504817963, LKD 0.3563520908355713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5800165981054306
Loss made of: CE 0.20979976654052734, LKD 0.3602980077266693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5695420488715172
Loss made of: CE 0.13807623088359833, LKD 0.336770236492157, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.6118238210678101
Loss made of: CE 0.1420966386795044, LKD 0.3974510133266449, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5902735769748688
Loss made of: CE 0.23372209072113037, LKD 0.36270415782928467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.6064969569444656
Loss made of: CE 0.21915805339813232, LKD 0.504720151424408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5702327445149422
Loss made of: CE 0.1629813313484192, LKD 0.3708420395851135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1762823462486267, Reg Loss=0.4043271839618683
Clinet index 20, End of Epoch 6/6, Average Loss=0.5806095600128174, Class Loss=0.1762823462486267, Reg Loss=0.4043271839618683
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=1.0079901933670044
Loss made of: CE 0.6656915545463562, LKD 0.45927566289901733, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5620490908622742, Reg Loss=0.44616979360580444
Clinet index 2, End of Epoch 1/6, Average Loss=1.0082188844680786, Class Loss=0.5620490908622742, Reg Loss=0.44616979360580444
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=0.9894181519746781
Loss made of: CE 0.4744524359703064, LKD 0.43825802206993103, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5196038484573364, Reg Loss=0.45013782382011414
Clinet index 2, End of Epoch 2/6, Average Loss=0.969741702079773, Class Loss=0.5196038484573364, Reg Loss=0.45013782382011414
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=0.9274419069290161
Loss made of: CE 0.42226848006248474, LKD 0.4009997248649597, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.48359793424606323, Reg Loss=0.453037828207016
Clinet index 2, End of Epoch 3/6, Average Loss=0.9366357326507568, Class Loss=0.48359793424606323, Reg Loss=0.453037828207016
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=0.923461788892746
Loss made of: CE 0.4733967185020447, LKD 0.5872134566307068, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4592241048812866, Reg Loss=0.46658360958099365
Clinet index 2, End of Epoch 4/6, Average Loss=0.9258077144622803, Class Loss=0.4592241048812866, Reg Loss=0.46658360958099365
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.9124263107776642
Loss made of: CE 0.4905939996242523, LKD 0.5197390913963318, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4483710527420044, Reg Loss=0.4538569152355194
Clinet index 2, End of Epoch 5/6, Average Loss=0.9022279977798462, Class Loss=0.4483710527420044, Reg Loss=0.4538569152355194
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=0.9000159233808518
Loss made of: CE 0.4300384521484375, LKD 0.4963642954826355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4391970634460449, Reg Loss=0.4583373963832855
Clinet index 2, End of Epoch 6/6, Average Loss=0.8975344896316528, Class Loss=0.4391970634460449, Reg Loss=0.4583373963832855
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9508723109960556
Loss made of: CE 0.49607211351394653, LKD 0.41568562388420105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5146811008453369, Reg Loss=0.43480372428894043
Clinet index 24, End of Epoch 1/6, Average Loss=0.9494848251342773, Class Loss=0.5146811008453369, Reg Loss=0.43480372428894043
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.9083406805992127
Loss made of: CE 0.5606509447097778, LKD 0.4671592116355896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.461174339056015, Reg Loss=0.4351864457130432
Clinet index 24, End of Epoch 2/6, Average Loss=0.8963607549667358, Class Loss=0.461174339056015, Reg Loss=0.4351864457130432
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.8642321169376374
Loss made of: CE 0.3949872851371765, LKD 0.46311911940574646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.43389517068862915, Reg Loss=0.42670831084251404
Clinet index 24, End of Epoch 3/6, Average Loss=0.8606034517288208, Class Loss=0.43389517068862915, Reg Loss=0.42670831084251404
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.8437601059675217
Loss made of: CE 0.33450421690940857, LKD 0.37317460775375366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4248238205909729, Reg Loss=0.42290040850639343
Clinet index 24, End of Epoch 4/6, Average Loss=0.847724199295044, Class Loss=0.4248238205909729, Reg Loss=0.42290040850639343
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.8270476430654525
Loss made of: CE 0.3577955663204193, LKD 0.40220189094543457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39833325147628784, Reg Loss=0.4333401322364807
Clinet index 24, End of Epoch 5/6, Average Loss=0.8316733837127686, Class Loss=0.39833325147628784, Reg Loss=0.4333401322364807
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.8380798786878586
Loss made of: CE 0.3669811189174652, LKD 0.40675604343414307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3923272490501404, Reg Loss=0.4332271218299866
Clinet index 24, End of Epoch 6/6, Average Loss=0.825554370880127, Class Loss=0.3923272490501404, Reg Loss=0.4332271218299866
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9502577692270279
Loss made of: CE 0.38429969549179077, LKD 0.3822447657585144, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.52904212474823, Reg Loss=0.4208061397075653
Clinet index 4, End of Epoch 1/6, Average Loss=0.9498482942581177, Class Loss=0.52904212474823, Reg Loss=0.4208061397075653
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.9195383995771408
Loss made of: CE 0.545345664024353, LKD 0.5361158847808838, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4904381036758423, Reg Loss=0.43038129806518555
Clinet index 4, End of Epoch 2/6, Average Loss=0.9208194017410278, Class Loss=0.4904381036758423, Reg Loss=0.43038129806518555
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.8554722100496293
Loss made of: CE 0.5815839767456055, LKD 0.42473429441452026, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4521125555038452, Reg Loss=0.41991323232650757
Clinet index 4, End of Epoch 3/6, Average Loss=0.8720257878303528, Class Loss=0.4521125555038452, Reg Loss=0.41991323232650757
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.8408946335315705
Loss made of: CE 0.5450206995010376, LKD 0.3727375864982605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.44404906034469604, Reg Loss=0.4191057085990906
Clinet index 4, End of Epoch 4/6, Average Loss=0.8631547689437866, Class Loss=0.44404906034469604, Reg Loss=0.4191057085990906
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.8249324500560761
Loss made of: CE 0.4145948886871338, LKD 0.45503219962120056, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.42400380969047546, Reg Loss=0.4262000024318695
Clinet index 4, End of Epoch 5/6, Average Loss=0.850203812122345, Class Loss=0.42400380969047546, Reg Loss=0.4262000024318695
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.8314855426549912
Loss made of: CE 0.38267502188682556, LKD 0.3618868291378021, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4058628976345062, Reg Loss=0.42555293440818787
Clinet index 4, End of Epoch 6/6, Average Loss=0.8314158320426941, Class Loss=0.4058628976345062, Reg Loss=0.42555293440818787
federated aggregation...
Validation, Class Loss=0.6685352325439453, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.815203
Mean Acc: 0.445342
FreqW Acc: 0.730657
Mean IoU: 0.353606
Class IoU:
	class 0: 0.8651252
	class 1: 0.55144066
	class 2: 0.3290631
	class 3: 0.05677275
	class 4: 0.25469005
	class 5: 0.5998868
	class 6: 0.642994
	class 7: 0.8317397
	class 8: 0.6267596
	class 9: 0.08521795
	class 10: 0.0
	class 11: 0.0
	class 12: 0.12983046
	class 13: 0.16342528
	class 14: 0.22695701
	class 15: 0.62984896
	class 16: 0.017559083
Class Acc:
	class 0: 0.9563043
	class 1: 0.55415434
	class 2: 0.6958878
	class 3: 0.056778952
	class 4: 0.25956377
	class 5: 0.62885004
	class 6: 0.6484043
	class 7: 0.8757797
	class 8: 0.6381691
	class 9: 0.2645319
	class 10: 0.0
	class 11: 0.0
	class 12: 0.16838379
	class 13: 0.8792438
	class 14: 0.25648034
	class 15: 0.67043686
	class 16: 0.017844973

federated global round: 22, step: 4
select part of clients to conduct local training
[21, 0, 25, 23]
Current Client Index:  21
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.8570138305425644
Loss made of: CE 0.440012663602829, LKD 0.3840350806713104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.7702515721321106
Loss made of: CE 0.36281728744506836, LKD 0.5022545456886292, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.6953632652759552
Loss made of: CE 0.26359742879867554, LKD 0.3125419020652771, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.652619118988514
Loss made of: CE 0.2182648628950119, LKD 0.36265450716018677, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.6514421015977859
Loss made of: CE 0.229339599609375, LKD 0.4840623140335083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.6600187107920646
Loss made of: CE 0.2544757127761841, LKD 0.4726456105709076, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.6487524539232254
Loss made of: CE 0.2468324899673462, LKD 0.31514376401901245, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.6369049176573753
Loss made of: CE 0.2135588377714157, LKD 0.4513089656829834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.6202839061617851
Loss made of: CE 0.21118411421775818, LKD 0.41500329971313477, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.28364798426628113, Reg Loss=0.39976322650909424
Clinet index 21, End of Epoch 1/6, Average Loss=0.6834112405776978, Class Loss=0.28364798426628113, Reg Loss=0.39976322650909424
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.6177391350269318
Loss made of: CE 0.22883948683738708, LKD 0.3755974769592285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.6273916095495224
Loss made of: CE 0.1813800185918808, LKD 0.44942575693130493, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.599775642156601
Loss made of: CE 0.21591071784496307, LKD 0.40028366446495056, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.6640949591994285
Loss made of: CE 0.2005874365568161, LKD 0.37278589606285095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.6104654490947723
Loss made of: CE 0.2271735966205597, LKD 0.46501362323760986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.5943705767393113
Loss made of: CE 0.18159978091716766, LKD 0.3894822597503662, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.605385085940361
Loss made of: CE 0.16649150848388672, LKD 0.45615845918655396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.5655385196208954
Loss made of: CE 0.21628491580486298, LKD 0.42988747358322144, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.6092290088534356
Loss made of: CE 0.22209203243255615, LKD 0.4317421317100525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20725594460964203, Reg Loss=0.40380534529685974
Clinet index 21, End of Epoch 2/6, Average Loss=0.6110612750053406, Class Loss=0.20725594460964203, Reg Loss=0.40380534529685974
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.6123006388545036
Loss made of: CE 0.2723099887371063, LKD 0.42110371589660645, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.6098428800702095
Loss made of: CE 0.1955280601978302, LKD 0.43579304218292236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.5954784169793129
Loss made of: CE 0.21521759033203125, LKD 0.3433241546154022, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5920350462198257
Loss made of: CE 0.2141624391078949, LKD 0.4465721547603607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.5944061324000358
Loss made of: CE 0.23550504446029663, LKD 0.4148746430873871, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.5744753018021583
Loss made of: CE 0.18494395911693573, LKD 0.40642186999320984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5932088777422905
Loss made of: CE 0.24332909286022186, LKD 0.4378228783607483, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.5968150228261948
Loss made of: CE 0.2162855863571167, LKD 0.3664640188217163, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.5578276574611664
Loss made of: CE 0.14164483547210693, LKD 0.3378671109676361, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19053609669208527, Reg Loss=0.40017277002334595
Clinet index 21, End of Epoch 3/6, Average Loss=0.59070885181427, Class Loss=0.19053609669208527, Reg Loss=0.40017277002334595
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.6385225415229797
Loss made of: CE 0.21802060306072235, LKD 0.4726489782333374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.5435783699154854
Loss made of: CE 0.1599484235048294, LKD 0.41219663619995117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.6001562252640724
Loss made of: CE 0.19086691737174988, LKD 0.32523149251937866, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5798603102564812
Loss made of: CE 0.2095700204372406, LKD 0.3661784827709198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5615037947893142
Loss made of: CE 0.14343680441379547, LKD 0.4205451011657715, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5543455690145492
Loss made of: CE 0.23607823252677917, LKD 0.3767814636230469, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5957701168954372
Loss made of: CE 0.1907307207584381, LKD 0.4283948540687561, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5796258643269538
Loss made of: CE 0.14473798871040344, LKD 0.3746895492076874, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.6049654826521873
Loss made of: CE 0.14720332622528076, LKD 0.4021027088165283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18400542438030243, Reg Loss=0.39954835176467896
Clinet index 21, End of Epoch 4/6, Average Loss=0.5835537910461426, Class Loss=0.18400542438030243, Reg Loss=0.39954835176467896
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.5714079022407532
Loss made of: CE 0.15795038640499115, LKD 0.4288884997367859, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5779657632112503
Loss made of: CE 0.2125832885503769, LKD 0.42154115438461304, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5618528500199318
Loss made of: CE 0.13923707604408264, LKD 0.3480300307273865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.5727123990654945
Loss made of: CE 0.21257436275482178, LKD 0.33125972747802734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5820071592926979
Loss made of: CE 0.15025851130485535, LKD 0.4132119119167328, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5696194887161254
Loss made of: CE 0.1747601330280304, LKD 0.395088791847229, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5852017670869827
Loss made of: CE 0.16291768848896027, LKD 0.36443549394607544, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.5679209426045417
Loss made of: CE 0.18614345788955688, LKD 0.4242277145385742, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5760304600000381
Loss made of: CE 0.23339498043060303, LKD 0.4391755759716034, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17469733953475952, Reg Loss=0.3982483744621277
Clinet index 21, End of Epoch 5/6, Average Loss=0.5729457139968872, Class Loss=0.17469733953475952, Reg Loss=0.3982483744621277
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.5800571694970131
Loss made of: CE 0.14575333893299103, LKD 0.37317436933517456, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5376909233629703
Loss made of: CE 0.14434859156608582, LKD 0.3847111165523529, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5701974332332611
Loss made of: CE 0.1540229320526123, LKD 0.38774293661117554, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5354675903916359
Loss made of: CE 0.16520927846431732, LKD 0.4367145001888275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5471982881426811
Loss made of: CE 0.17919431626796722, LKD 0.3723703622817993, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.5595697477459908
Loss made of: CE 0.17739693820476532, LKD 0.4676400125026703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5741650417447091
Loss made of: CE 0.17392365634441376, LKD 0.43806910514831543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5750766798853875
Loss made of: CE 0.2237943410873413, LKD 0.4010000228881836, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.592301820218563
Loss made of: CE 0.18854030966758728, LKD 0.45036524534225464, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.16660210490226746, Reg Loss=0.3976452350616455
Clinet index 21, End of Epoch 6/6, Average Loss=0.5642473697662354, Class Loss=0.16660210490226746, Reg Loss=0.3976452350616455
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.8258726119995117
Loss made of: CE 0.5224927067756653, LKD 0.3851885199546814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.7493451088666916
Loss made of: CE 0.2597323954105377, LKD 0.37028175592422485, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.7042343646287919
Loss made of: CE 0.2436167299747467, LKD 0.4075327515602112, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.6960542380809784
Loss made of: CE 0.3451247811317444, LKD 0.37281572818756104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.6408497378230095
Loss made of: CE 0.3493860960006714, LKD 0.40507107973098755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.638763478398323
Loss made of: CE 0.21854154765605927, LKD 0.4126611649990082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.6399648636579514
Loss made of: CE 0.3750590980052948, LKD 0.3943602740764618, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.6511983379721642
Loss made of: CE 0.23506073653697968, LKD 0.3172720670700073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.6419339537620544
Loss made of: CE 0.16290611028671265, LKD 0.3336218595504761, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2816196084022522, Reg Loss=0.3992653489112854
Clinet index 0, End of Epoch 1/6, Average Loss=0.6808849573135376, Class Loss=0.2816196084022522, Reg Loss=0.3992653489112854
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.6335996955633163
Loss made of: CE 0.19723069667816162, LKD 0.35677003860473633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.6059444412589073
Loss made of: CE 0.23024940490722656, LKD 0.38030874729156494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.605362132191658
Loss made of: CE 0.19265899062156677, LKD 0.4143165946006775, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.5906104952096939
Loss made of: CE 0.18909916281700134, LKD 0.38325703144073486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.6519654601812362
Loss made of: CE 0.17466577887535095, LKD 0.3839402198791504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.5929904028773307
Loss made of: CE 0.22253142297267914, LKD 0.4545165002346039, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.6015108451247215
Loss made of: CE 0.20083743333816528, LKD 0.39578506350517273, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.5874379798769951
Loss made of: CE 0.17754197120666504, LKD 0.31007450819015503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.6424544677138329
Loss made of: CE 0.18775205314159393, LKD 0.41948673129081726, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20845045149326324, Reg Loss=0.39986464381217957
Clinet index 0, End of Epoch 2/6, Average Loss=0.608315110206604, Class Loss=0.20845045149326324, Reg Loss=0.39986464381217957
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.5922406703233719
Loss made of: CE 0.15046453475952148, LKD 0.4154178500175476, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.5943847015500069
Loss made of: CE 0.1553110033273697, LKD 0.4566713273525238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.6114812761545181
Loss made of: CE 0.261808305978775, LKD 0.4177432060241699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5772511601448059
Loss made of: CE 0.20402322709560394, LKD 0.3527261018753052, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.5680321723222732
Loss made of: CE 0.16064433753490448, LKD 0.42891329526901245, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.6247754916548729
Loss made of: CE 0.16207420825958252, LKD 0.39202189445495605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5891340792179107
Loss made of: CE 0.15244919061660767, LKD 0.4078871011734009, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.5794022932648659
Loss made of: CE 0.18131056427955627, LKD 0.4300430417060852, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.5872493743896484
Loss made of: CE 0.206643745303154, LKD 0.4042477011680603, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1942366510629654, Reg Loss=0.40028756856918335
Clinet index 0, End of Epoch 3/6, Average Loss=0.5945242047309875, Class Loss=0.1942366510629654, Reg Loss=0.40028756856918335
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.5830007866024971
Loss made of: CE 0.13367843627929688, LKD 0.4088366627693176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.6091557160019875
Loss made of: CE 0.16666513681411743, LKD 0.3798940181732178, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.5865344852209091
Loss made of: CE 0.19973604381084442, LKD 0.42042988538742065, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5902602016925812
Loss made of: CE 0.16725394129753113, LKD 0.4752649664878845, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5811582639813423
Loss made of: CE 0.17953845858573914, LKD 0.3599368929862976, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5771428406238556
Loss made of: CE 0.16882404685020447, LKD 0.3865097165107727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5351375073194504
Loss made of: CE 0.1564955711364746, LKD 0.41838622093200684, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5575464710593223
Loss made of: CE 0.18967944383621216, LKD 0.4306967854499817, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.5556635908782482
Loss made of: CE 0.17857906222343445, LKD 0.4535219073295593, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1793883889913559, Reg Loss=0.3966534733772278
Clinet index 0, End of Epoch 4/6, Average Loss=0.5760418772697449, Class Loss=0.1793883889913559, Reg Loss=0.3966534733772278
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.5838325515389442
Loss made of: CE 0.20385238528251648, LKD 0.5095590353012085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5683981016278267
Loss made of: CE 0.15286588668823242, LKD 0.33396944403648376, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5875075682997704
Loss made of: CE 0.1506882756948471, LKD 0.3080763816833496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.5806381367146969
Loss made of: CE 0.1747048944234848, LKD 0.44324883818626404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5567317038774491
Loss made of: CE 0.21528267860412598, LKD 0.39278697967529297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5675992533564568
Loss made of: CE 0.22057005763053894, LKD 0.38053712248802185, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5530743628740311
Loss made of: CE 0.16658565402030945, LKD 0.41660043597221375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.5829312667250633
Loss made of: CE 0.15805433690547943, LKD 0.36990684270858765, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5635758563876152
Loss made of: CE 0.15787792205810547, LKD 0.40586936473846436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17569999396800995, Reg Loss=0.39896056056022644
Clinet index 0, End of Epoch 5/6, Average Loss=0.5746605396270752, Class Loss=0.17569999396800995, Reg Loss=0.39896056056022644
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.5357517808675766
Loss made of: CE 0.13198000192642212, LKD 0.4660780429840088, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5396856486797332
Loss made of: CE 0.11784711480140686, LKD 0.3256433606147766, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5569047048687935
Loss made of: CE 0.13784824311733246, LKD 0.3811212480068207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.6043289870023727
Loss made of: CE 0.18220435082912445, LKD 0.3922275900840759, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5712087944149971
Loss made of: CE 0.14354921877384186, LKD 0.3269484043121338, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.5776568681001664
Loss made of: CE 0.15632420778274536, LKD 0.35366007685661316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5423266112804412
Loss made of: CE 0.1817639172077179, LKD 0.39205536246299744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5902021050453186
Loss made of: CE 0.14142507314682007, LKD 0.38347357511520386, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5499484077095985
Loss made of: CE 0.18549585342407227, LKD 0.38965243101119995, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1707986444234848, Reg Loss=0.39681223034858704
Clinet index 0, End of Epoch 6/6, Average Loss=0.5676108598709106, Class Loss=0.1707986444234848, Reg Loss=0.39681223034858704
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.876476714015007
Loss made of: CE 0.4149191975593567, LKD 0.392743319272995, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.7479392170906067
Loss made of: CE 0.38437366485595703, LKD 0.44074687361717224, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.7164449006319046
Loss made of: CE 0.29256054759025574, LKD 0.4436109960079193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.6721974954009056
Loss made of: CE 0.27134400606155396, LKD 0.4688452482223511, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.6913379311561585
Loss made of: CE 0.25663334131240845, LKD 0.37852591276168823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.6681248858571053
Loss made of: CE 0.1989094465970993, LKD 0.359813392162323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.6253820091485978
Loss made of: CE 0.19892653822898865, LKD 0.3662201762199402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.6727336257696152
Loss made of: CE 0.30148154497146606, LKD 0.3790794312953949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.6335046797990799
Loss made of: CE 0.17890560626983643, LKD 0.36264166235923767, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.28849849104881287, Reg Loss=0.4061756730079651
Clinet index 25, End of Epoch 1/6, Average Loss=0.6946741342544556, Class Loss=0.28849849104881287, Reg Loss=0.4061756730079651
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.6339178755879402
Loss made of: CE 0.20112112164497375, LKD 0.3607495427131653, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.6285827204585075
Loss made of: CE 0.20459076762199402, LKD 0.41068440675735474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.6539884313941002
Loss made of: CE 0.20071522891521454, LKD 0.4705270230770111, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.6403608381748199
Loss made of: CE 0.16748997569084167, LKD 0.42021775245666504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.5844088539481163
Loss made of: CE 0.18239304423332214, LKD 0.38641875982284546, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.5925583019852638
Loss made of: CE 0.14614495635032654, LKD 0.3599270284175873, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.5928735747933388
Loss made of: CE 0.2059243619441986, LKD 0.44312405586242676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.6274717837572098
Loss made of: CE 0.2146049439907074, LKD 0.4287605881690979, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.6171024844050408
Loss made of: CE 0.19693467020988464, LKD 0.39018353819847107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21139797568321228, Reg Loss=0.40394967794418335
Clinet index 25, End of Epoch 2/6, Average Loss=0.6153476238250732, Class Loss=0.21139797568321228, Reg Loss=0.40394967794418335
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.6044074267148971
Loss made of: CE 0.20798389613628387, LKD 0.37703919410705566, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.6017983555793762
Loss made of: CE 0.18643546104431152, LKD 0.42548471689224243, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.5887299224734306
Loss made of: CE 0.2069011926651001, LKD 0.4086267352104187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.604224619269371
Loss made of: CE 0.2365395724773407, LKD 0.46631333231925964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.5873908162117004
Loss made of: CE 0.17937979102134705, LKD 0.4607353210449219, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.5764314234256744
Loss made of: CE 0.26000118255615234, LKD 0.4076550602912903, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5758804470300675
Loss made of: CE 0.198093444108963, LKD 0.34860095381736755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.6389961287379264
Loss made of: CE 0.1762845516204834, LKD 0.3584364354610443, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.5880469352006912
Loss made of: CE 0.1988823264837265, LKD 0.3808387219905853, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19231534004211426, Reg Loss=0.40145617723464966
Clinet index 25, End of Epoch 3/6, Average Loss=0.5937715172767639, Class Loss=0.19231534004211426, Reg Loss=0.40145617723464966
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.580527751147747
Loss made of: CE 0.16315162181854248, LKD 0.4223766028881073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.5998312473297119
Loss made of: CE 0.2249494045972824, LKD 0.3973056674003601, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.5928354397416115
Loss made of: CE 0.13602927327156067, LKD 0.3335847854614258, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5694975391030311
Loss made of: CE 0.21224430203437805, LKD 0.3273274898529053, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.614542493224144
Loss made of: CE 0.28962233662605286, LKD 0.30940723419189453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.6473290279507637
Loss made of: CE 0.19712404906749725, LKD 0.4126298427581787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5986323043704033
Loss made of: CE 0.2029157280921936, LKD 0.4814785122871399, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5672348901629448
Loss made of: CE 0.20385704934597015, LKD 0.4498443603515625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.5488727107644081
Loss made of: CE 0.15934208035469055, LKD 0.31881794333457947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1874445676803589, Reg Loss=0.4036962687969208
Clinet index 25, End of Epoch 4/6, Average Loss=0.591140866279602, Class Loss=0.1874445676803589, Reg Loss=0.4036962687969208
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.5854371815919877
Loss made of: CE 0.15044067800045013, LKD 0.37399566173553467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5641285046935082
Loss made of: CE 0.201407790184021, LKD 0.5030807256698608, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5543924026191235
Loss made of: CE 0.16371461749076843, LKD 0.4178907573223114, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.5675857305526734
Loss made of: CE 0.17982201278209686, LKD 0.3689866065979004, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5571688383817672
Loss made of: CE 0.14258763194084167, LKD 0.40819334983825684, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5803970783948899
Loss made of: CE 0.21496856212615967, LKD 0.4136875569820404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5679293781518936
Loss made of: CE 0.19471532106399536, LKD 0.44981616735458374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.595705783367157
Loss made of: CE 0.1271960437297821, LKD 0.3484128415584564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.6053986296057701
Loss made of: CE 0.1951512098312378, LKD 0.316100150346756, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.1785753071308136, Reg Loss=0.4016769826412201
Clinet index 25, End of Epoch 5/6, Average Loss=0.5802522897720337, Class Loss=0.1785753071308136, Reg Loss=0.4016769826412201
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.5683378115296364
Loss made of: CE 0.15069285035133362, LKD 0.46849507093429565, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5951387390494347
Loss made of: CE 0.172532320022583, LKD 0.4120090901851654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5773130699992179
Loss made of: CE 0.15121959149837494, LKD 0.36499667167663574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5598323807120323
Loss made of: CE 0.12131641805171967, LKD 0.37481802701950073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5826937586069107
Loss made of: CE 0.212330624461174, LKD 0.3472268581390381, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.5694732561707496
Loss made of: CE 0.17117170989513397, LKD 0.43036603927612305, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5662506744265556
Loss made of: CE 0.1665128767490387, LKD 0.3385598063468933, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.562091451883316
Loss made of: CE 0.15726906061172485, LKD 0.5429078340530396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5473414793610573
Loss made of: CE 0.15842309594154358, LKD 0.42786329984664917, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1718609482049942, Reg Loss=0.39937615394592285
Clinet index 25, End of Epoch 6/6, Average Loss=0.5712370872497559, Class Loss=0.1718609482049942, Reg Loss=0.39937615394592285
Current Client Index:  23
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.9017710477113724
Loss made of: CE 0.3057715892791748, LKD 0.42867517471313477, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.7336828708648682
Loss made of: CE 0.2844027876853943, LKD 0.3900887370109558, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.6513068228960037
Loss made of: CE 0.28777843713760376, LKD 0.40997838973999023, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.6280243948101998
Loss made of: CE 0.19394153356552124, LKD 0.3222910761833191, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.6441039875149727
Loss made of: CE 0.24932849407196045, LKD 0.34867650270462036, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.6698163270950317
Loss made of: CE 0.2275885045528412, LKD 0.34084606170654297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.6520034402608872
Loss made of: CE 0.239580899477005, LKD 0.39786624908447266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.6352799937129021
Loss made of: CE 0.231729656457901, LKD 0.3501235842704773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.649727363884449
Loss made of: CE 0.20937006175518036, LKD 0.4753640592098236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.284090518951416, Reg Loss=0.3979116976261139
Clinet index 23, End of Epoch 1/6, Average Loss=0.6820021867752075, Class Loss=0.284090518951416, Reg Loss=0.3979116976261139
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/97, Loss=0.6108340799808503
Loss made of: CE 0.16395747661590576, LKD 0.5475767850875854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.6095771446824074
Loss made of: CE 0.2111499011516571, LKD 0.4421578049659729, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.593806017935276
Loss made of: CE 0.1688300371170044, LKD 0.3731158673763275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.6047978878021241
Loss made of: CE 0.26893576979637146, LKD 0.44808048009872437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.5894033715128899
Loss made of: CE 0.18373891711235046, LKD 0.45132455229759216, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.5671873167157173
Loss made of: CE 0.21126389503479004, LKD 0.3876722455024719, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.6136905133724213
Loss made of: CE 0.25231248140335083, LKD 0.39622825384140015, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.6555461212992668
Loss made of: CE 0.18837133049964905, LKD 0.34695881605148315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.648454487323761
Loss made of: CE 0.24098464846611023, LKD 0.35340437293052673, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20687802135944366, Reg Loss=0.4001990556716919
Clinet index 23, End of Epoch 2/6, Average Loss=0.6070770621299744, Class Loss=0.20687802135944366, Reg Loss=0.4001990556716919
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/97, Loss=0.5702073395252227
Loss made of: CE 0.21847593784332275, LKD 0.396406888961792, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.6048276647925377
Loss made of: CE 0.2695940136909485, LKD 0.4762338101863861, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.6264522895216942
Loss made of: CE 0.17376844584941864, LKD 0.3840526044368744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5923510640859604
Loss made of: CE 0.22377929091453552, LKD 0.30220088362693787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.5579226821660995
Loss made of: CE 0.2155708521604538, LKD 0.3870907425880432, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.5995990082621574
Loss made of: CE 0.21048609912395477, LKD 0.4247826039791107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5613710656762123
Loss made of: CE 0.1700873225927353, LKD 0.4435732364654541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.5871152266860008
Loss made of: CE 0.20975981652736664, LKD 0.4542553126811981, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.6262907609343529
Loss made of: CE 0.16051042079925537, LKD 0.3477536141872406, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19207225739955902, Reg Loss=0.3993481397628784
Clinet index 23, End of Epoch 3/6, Average Loss=0.5914204120635986, Class Loss=0.19207225739955902, Reg Loss=0.3993481397628784
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/97, Loss=0.6025678545236588
Loss made of: CE 0.18918322026729584, LKD 0.4325745105743408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.5800015300512313
Loss made of: CE 0.17031654715538025, LKD 0.5220632553100586, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.5834246188402176
Loss made of: CE 0.14595632255077362, LKD 0.31530481576919556, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5852737292647362
Loss made of: CE 0.19101844727993011, LKD 0.3378092050552368, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5919462576508522
Loss made of: CE 0.17711904644966125, LKD 0.35077208280563354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5824733301997185
Loss made of: CE 0.18986275792121887, LKD 0.37727054953575134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5526149660348892
Loss made of: CE 0.15523481369018555, LKD 0.3635248839855194, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5990655660629273
Loss made of: CE 0.1533241868019104, LKD 0.4372189939022064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.5790254965424537
Loss made of: CE 0.17768189311027527, LKD 0.3526676297187805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18002735078334808, Reg Loss=0.40200042724609375
Clinet index 23, End of Epoch 4/6, Average Loss=0.582027792930603, Class Loss=0.18002735078334808, Reg Loss=0.40200042724609375
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/97, Loss=0.5953382298350334
Loss made of: CE 0.18019554018974304, LKD 0.39117395877838135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5722972378134727
Loss made of: CE 0.22423580288887024, LKD 0.4830014109611511, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.6094941034913063
Loss made of: CE 0.20078091323375702, LKD 0.4291934370994568, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.562443670630455
Loss made of: CE 0.1383654773235321, LKD 0.38592299818992615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5527655348181725
Loss made of: CE 0.17161236703395844, LKD 0.3381690979003906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.593423244357109
Loss made of: CE 0.16546818614006042, LKD 0.3669171929359436, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5816291570663452
Loss made of: CE 0.17025195062160492, LKD 0.46882960200309753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.564743323624134
Loss made of: CE 0.16710984706878662, LKD 0.3719136118888855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5729580670595169
Loss made of: CE 0.1610613614320755, LKD 0.3311942517757416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.17824576795101166, Reg Loss=0.3978527784347534
Clinet index 23, End of Epoch 5/6, Average Loss=0.5760985612869263, Class Loss=0.17824576795101166, Reg Loss=0.3978527784347534
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/97, Loss=0.5611629545688629
Loss made of: CE 0.16204503178596497, LKD 0.39195355772972107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.6124643057584762
Loss made of: CE 0.16027449071407318, LKD 0.3372141718864441, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5854947701096535
Loss made of: CE 0.18094909191131592, LKD 0.3417453169822693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5542306065559387
Loss made of: CE 0.12589077651500702, LKD 0.35848087072372437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.6024792850017547
Loss made of: CE 0.15785890817642212, LKD 0.38019776344299316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.5229402229189872
Loss made of: CE 0.1645483821630478, LKD 0.35520344972610474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.6060570850968361
Loss made of: CE 0.21854576468467712, LKD 0.48297905921936035, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5665929704904556
Loss made of: CE 0.20355533063411713, LKD 0.32825297117233276, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5784527778625488
Loss made of: CE 0.2567287087440491, LKD 0.46076568961143494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.17577946186065674, Reg Loss=0.39841288328170776
Clinet index 23, End of Epoch 6/6, Average Loss=0.5741923451423645, Class Loss=0.17577946186065674, Reg Loss=0.39841288328170776
federated aggregation...
Validation, Class Loss=0.5900394320487976, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.828088
Mean Acc: 0.466937
FreqW Acc: 0.754914
Mean IoU: 0.371548
Class IoU:
	class 0: 0.883687
	class 1: 0.61589724
	class 2: 0.32951558
	class 3: 0.050503172
	class 4: 0.3219202
	class 5: 0.55624074
	class 6: 0.76008266
	class 7: 0.8401293
	class 8: 0.6178672
	class 9: 0.091053136
	class 10: 0.0
	class 11: 0.0
	class 12: 0.11117204
	class 13: 0.14213909
	class 14: 0.24515444
	class 15: 0.75095314
	class 16: 0.0
Class Acc:
	class 0: 0.948121
	class 1: 0.6193042
	class 2: 0.72192496
	class 3: 0.050509885
	class 4: 0.33378825
	class 5: 0.57763714
	class 6: 0.7688187
	class 7: 0.91104084
	class 8: 0.6325794
	class 9: 0.23723833
	class 10: 0.0
	class 11: 0.0
	class 12: 0.13615434
	class 13: 0.8230278
	class 14: 0.27335963
	class 15: 0.90441716
	class 16: 0.0

federated global round: 23, step: 4
select part of clients to conduct local training
[17, 3, 5, 22]
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.5682322137057781
Loss made of: CE 0.21727794408798218, LKD 0.33852195739746094, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.5655535370111465
Loss made of: CE 0.19086526334285736, LKD 0.4262861907482147, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.5972112655639649
Loss made of: CE 0.15395887196063995, LKD 0.4882301688194275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.5926699966192246
Loss made of: CE 0.15117543935775757, LKD 0.3622870445251465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.5591527804732322
Loss made of: CE 0.16887173056602478, LKD 0.4024360775947571, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.5819294020533562
Loss made of: CE 0.16181138157844543, LKD 0.47306084632873535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.561152009665966
Loss made of: CE 0.12104088068008423, LKD 0.37991636991500854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.567173421382904
Loss made of: CE 0.19729922711849213, LKD 0.41592738032341003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.5607864111661911
Loss made of: CE 0.17448437213897705, LKD 0.43098291754722595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.1681450456380844, Reg Loss=0.4016592502593994
Clinet index 17, End of Epoch 1/6, Average Loss=0.569804310798645, Class Loss=0.1681450456380844, Reg Loss=0.4016592502593994
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=0.5469116494059563
Loss made of: CE 0.16636459529399872, LKD 0.43735742568969727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.5517457202076912
Loss made of: CE 0.15118905901908875, LKD 0.4268394410610199, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.551027937233448
Loss made of: CE 0.1573493778705597, LKD 0.5007668137550354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.5730255030095577
Loss made of: CE 0.14921313524246216, LKD 0.42880094051361084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.534819945693016
Loss made of: CE 0.14757148921489716, LKD 0.37537550926208496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.5919808477163315
Loss made of: CE 0.1562739908695221, LKD 0.3499906063079834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.6067270487546921
Loss made of: CE 0.1556156724691391, LKD 0.4829621911048889, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.5832346230745316
Loss made of: CE 0.16505858302116394, LKD 0.4970599412918091, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.5095329210162163
Loss made of: CE 0.1418396234512329, LKD 0.3546144962310791, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1622839868068695, Reg Loss=0.39680150151252747
Clinet index 17, End of Epoch 2/6, Average Loss=0.559085488319397, Class Loss=0.1622839868068695, Reg Loss=0.39680150151252747
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=0.5632007718086243
Loss made of: CE 0.17381177842617035, LKD 0.4428190588951111, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.5564846053719521
Loss made of: CE 0.2469109296798706, LKD 0.4399563670158386, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.5727067783474922
Loss made of: CE 0.12741748988628387, LKD 0.4082818925380707, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5708962395787239
Loss made of: CE 0.24147455394268036, LKD 0.46745583415031433, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.560223026573658
Loss made of: CE 0.1453520953655243, LKD 0.4109165668487549, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.548045689612627
Loss made of: CE 0.14977481961250305, LKD 0.3306772708892822, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5744222611188888
Loss made of: CE 0.1400141566991806, LKD 0.3672851324081421, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.5365912109613419
Loss made of: CE 0.13884365558624268, LKD 0.40086719393730164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.5518910378217697
Loss made of: CE 0.18569432199001312, LKD 0.4226006865501404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1592983603477478, Reg Loss=0.39990952610969543
Clinet index 17, End of Epoch 3/6, Average Loss=0.5592079162597656, Class Loss=0.1592983603477478, Reg Loss=0.39990952610969543
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=0.5547066688537597
Loss made of: CE 0.17563866078853607, LKD 0.45866894721984863, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.543271966278553
Loss made of: CE 0.12999415397644043, LKD 0.39701104164123535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.562020069360733
Loss made of: CE 0.14233481884002686, LKD 0.3758922219276428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5595085173845291
Loss made of: CE 0.1311732530593872, LKD 0.4804351329803467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5730964660644531
Loss made of: CE 0.13792702555656433, LKD 0.3245477080345154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5635074213147163
Loss made of: CE 0.1318022459745407, LKD 0.3809768557548523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5660868108272552
Loss made of: CE 0.13852611184120178, LKD 0.5117515921592712, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5213528126478195
Loss made of: CE 0.13530901074409485, LKD 0.3624520003795624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.5601793728768826
Loss made of: CE 0.14647060632705688, LKD 0.45588991045951843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1548779010772705, Reg Loss=0.39908039569854736
Clinet index 17, End of Epoch 4/6, Average Loss=0.5539582967758179, Class Loss=0.1548779010772705, Reg Loss=0.39908039569854736
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=0.5395363435149193
Loss made of: CE 0.17057470977306366, LKD 0.34463974833488464, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5924304723739624
Loss made of: CE 0.13190680742263794, LKD 0.4390752911567688, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5682871751487255
Loss made of: CE 0.16090407967567444, LKD 0.46276700496673584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.534579698741436
Loss made of: CE 0.14694884419441223, LKD 0.3921124339103699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5690308719873428
Loss made of: CE 0.14147821068763733, LKD 0.42080578207969666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5997778818011283
Loss made of: CE 0.19816109538078308, LKD 0.5055781006813049, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5589300394058228
Loss made of: CE 0.14706113934516907, LKD 0.35869789123535156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.5444398611783982
Loss made of: CE 0.15132151544094086, LKD 0.39533722400665283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5259847462177276
Loss made of: CE 0.14037756621837616, LKD 0.35058459639549255, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15825709700584412, Reg Loss=0.3987342417240143
Clinet index 17, End of Epoch 5/6, Average Loss=0.5569913387298584, Class Loss=0.15825709700584412, Reg Loss=0.3987342417240143
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=0.5448549881577491
Loss made of: CE 0.16317175328731537, LKD 0.4135301113128662, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5886461585760117
Loss made of: CE 0.1563951075077057, LKD 0.38674086332321167, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5496445804834366
Loss made of: CE 0.13459563255310059, LKD 0.4525560736656189, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.548688342422247
Loss made of: CE 0.1783429980278015, LKD 0.4666135311126709, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5114140324294567
Loss made of: CE 0.12538465857505798, LKD 0.3908848762512207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.5807890087366104
Loss made of: CE 0.11228983104228973, LKD 0.3251556158065796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5256397619843483
Loss made of: CE 0.15891869366168976, LKD 0.3459203839302063, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5416640870273113
Loss made of: CE 0.15064173936843872, LKD 0.4608459174633026, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5223153293132782
Loss made of: CE 0.13073652982711792, LKD 0.4147956967353821, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.151619553565979, Reg Loss=0.3982091546058655
Clinet index 17, End of Epoch 6/6, Average Loss=0.5498287081718445, Class Loss=0.151619553565979, Reg Loss=0.3982091546058655
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.3463201910257339
Loss made of: CE 0.568609893321991, LKD 0.42139074206352234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8346570730209351, Reg Loss=0.47066235542297363
Clinet index 3, End of Epoch 1/6, Average Loss=1.3053194284439087, Class Loss=0.8346570730209351, Reg Loss=0.47066235542297363
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=1.0980333715677262
Loss made of: CE 0.5033854842185974, LKD 0.4947189688682556, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6386789679527283, Reg Loss=0.4522477090358734
Clinet index 3, End of Epoch 2/6, Average Loss=1.0909266471862793, Class Loss=0.6386789679527283, Reg Loss=0.4522477090358734
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.9366870313882828
Loss made of: CE 0.26066142320632935, LKD 0.4097769260406494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5057515501976013, Reg Loss=0.4502405822277069
Clinet index 3, End of Epoch 3/6, Average Loss=0.9559921026229858, Class Loss=0.5057515501976013, Reg Loss=0.4502405822277069
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.8755699306726455
Loss made of: CE 0.26876765489578247, LKD 0.44582995772361755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4070621132850647, Reg Loss=0.4530418813228607
Clinet index 3, End of Epoch 4/6, Average Loss=0.860103964805603, Class Loss=0.4070621132850647, Reg Loss=0.4530418813228607
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.8162906229496002
Loss made of: CE 0.29693159461021423, LKD 0.4187352657318115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34774065017700195, Reg Loss=0.45502209663391113
Clinet index 3, End of Epoch 5/6, Average Loss=0.8027627468109131, Class Loss=0.34774065017700195, Reg Loss=0.45502209663391113
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.8243688911199569
Loss made of: CE 0.29851871728897095, LKD 0.5022128820419312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3384985327720642, Reg Loss=0.4612717628479004
Clinet index 3, End of Epoch 6/6, Average Loss=0.7997702956199646, Class Loss=0.3384985327720642, Reg Loss=0.4612717628479004
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.5890719622373581
Loss made of: CE 0.17322075366973877, LKD 0.43931064009666443, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.6277698636054992
Loss made of: CE 0.3324015140533447, LKD 0.4999346137046814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.5473709255456924
Loss made of: CE 0.16640058159828186, LKD 0.44505906105041504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.560496310889721
Loss made of: CE 0.16126219928264618, LKD 0.5095985531806946, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.5746456734836102
Loss made of: CE 0.12097962945699692, LKD 0.39606210589408875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.5333373099565506
Loss made of: CE 0.14184564352035522, LKD 0.465471088886261, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.581062550842762
Loss made of: CE 0.18471431732177734, LKD 0.3300665318965912, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.5749366417527199
Loss made of: CE 0.19132795929908752, LKD 0.3924741744995117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.5705188751220703
Loss made of: CE 0.17903165519237518, LKD 0.40519189834594727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.169345885515213, Reg Loss=0.40496203303337097
Clinet index 5, End of Epoch 1/6, Average Loss=0.574307918548584, Class Loss=0.169345885515213, Reg Loss=0.40496203303337097
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/97, Loss=0.5171417839825153
Loss made of: CE 0.15662029385566711, LKD 0.38682591915130615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.5546642199158669
Loss made of: CE 0.15569819509983063, LKD 0.3793885409832001, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.5773388743400574
Loss made of: CE 0.18405607342720032, LKD 0.4101736545562744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.5769735231995583
Loss made of: CE 0.19043773412704468, LKD 0.4289100170135498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.6079699575901032
Loss made of: CE 0.18271367251873016, LKD 0.36194929480552673, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.5841565728187561
Loss made of: CE 0.16309432685375214, LKD 0.3665224313735962, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.5608379393815994
Loss made of: CE 0.13060611486434937, LKD 0.3358305096626282, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.5592572301626205
Loss made of: CE 0.14259634912014008, LKD 0.3714779317378998, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.5729968905448913
Loss made of: CE 0.16310644149780273, LKD 0.42335909605026245, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1651192605495453, Reg Loss=0.4050474464893341
Clinet index 5, End of Epoch 2/6, Average Loss=0.5701667070388794, Class Loss=0.1651192605495453, Reg Loss=0.4050474464893341
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/97, Loss=0.5799057066440583
Loss made of: CE 0.1522994041442871, LKD 0.4570363163948059, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.5631617218255996
Loss made of: CE 0.1417594701051712, LKD 0.3569277226924896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.5477828823029995
Loss made of: CE 0.16085974872112274, LKD 0.3434990346431732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5931488573551178
Loss made of: CE 0.17414718866348267, LKD 0.4419584274291992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.5834557384252548
Loss made of: CE 0.17244510352611542, LKD 0.3551848828792572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.5912082582712174
Loss made of: CE 0.3960675597190857, LKD 0.4650954604148865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5437339320778847
Loss made of: CE 0.15390199422836304, LKD 0.3142746686935425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.5691000267863273
Loss made of: CE 0.15018072724342346, LKD 0.361571729183197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.5513485915958881
Loss made of: CE 0.16529148817062378, LKD 0.40424785017967224, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.16276335716247559, Reg Loss=0.4047990143299103
Clinet index 5, End of Epoch 3/6, Average Loss=0.5675623416900635, Class Loss=0.16276335716247559, Reg Loss=0.4047990143299103
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/97, Loss=0.5626730799674988
Loss made of: CE 0.1559017300605774, LKD 0.350189208984375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.5518603533506393
Loss made of: CE 0.14245271682739258, LKD 0.40353769063949585, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.551251994818449
Loss made of: CE 0.17557579278945923, LKD 0.35919392108917236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5402846038341522
Loss made of: CE 0.19218721985816956, LKD 0.45651480555534363, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5792948186397553
Loss made of: CE 0.139652281999588, LKD 0.5113346576690674, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5696753323078155
Loss made of: CE 0.18888112902641296, LKD 0.3636443018913269, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5664429873228073
Loss made of: CE 0.21816472709178925, LKD 0.41433995962142944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5512323766946793
Loss made of: CE 0.15325483679771423, LKD 0.3864549398422241, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.5774741441011428
Loss made of: CE 0.154913067817688, LKD 0.3841809630393982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15975970029830933, Reg Loss=0.40200603008270264
Clinet index 5, End of Epoch 4/6, Average Loss=0.561765730381012, Class Loss=0.15975970029830933, Reg Loss=0.40200603008270264
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/97, Loss=0.5675431221723557
Loss made of: CE 0.14646349847316742, LKD 0.3221285343170166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5483068287372589
Loss made of: CE 0.15903089940547943, LKD 0.3913862705230713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.5418979004025459
Loss made of: CE 0.14848193526268005, LKD 0.3729860782623291, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.5543566949665546
Loss made of: CE 0.18400834500789642, LKD 0.39017724990844727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.5704250529408454
Loss made of: CE 0.1542140543460846, LKD 0.352508008480072, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5676715269684791
Loss made of: CE 0.1866893768310547, LKD 0.4252689778804779, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5470580063760281
Loss made of: CE 0.1339944303035736, LKD 0.4455331563949585, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.5340017013251781
Loss made of: CE 0.14145156741142273, LKD 0.3446095883846283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5840477749705315
Loss made of: CE 0.16685637831687927, LKD 0.43114709854125977, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15199311077594757, Reg Loss=0.4020281136035919
Clinet index 5, End of Epoch 5/6, Average Loss=0.5540212392807007, Class Loss=0.15199311077594757, Reg Loss=0.4020281136035919
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/97, Loss=0.5569710820913315
Loss made of: CE 0.16377772390842438, LKD 0.43497365713119507, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.580032316595316
Loss made of: CE 0.14346943795681, LKD 0.37732023000717163, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.533947491645813
Loss made of: CE 0.16628102958202362, LKD 0.4538423418998718, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5267601706087589
Loss made of: CE 0.13960693776607513, LKD 0.38598963618278503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5682130552828312
Loss made of: CE 0.1297704428434372, LKD 0.35258209705352783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.5420206651091576
Loss made of: CE 0.15107262134552002, LKD 0.381291002035141, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5558860532939434
Loss made of: CE 0.14576324820518494, LKD 0.39064615964889526, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5621048107743263
Loss made of: CE 0.1720907986164093, LKD 0.46095865964889526, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5825725503265857
Loss made of: CE 0.14432233572006226, LKD 0.3972684144973755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15145938098430634, Reg Loss=0.4032394587993622
Clinet index 5, End of Epoch 6/6, Average Loss=0.5546988248825073, Class Loss=0.15145938098430634, Reg Loss=0.4032394587993622
Current Client Index:  22
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.387732782959938
Loss made of: CE 1.1196134090423584, LKD 0.5398707389831543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8750662803649902, Reg Loss=0.47072070837020874
Clinet index 22, End of Epoch 1/6, Average Loss=1.3457870483398438, Class Loss=0.8750662803649902, Reg Loss=0.47072070837020874
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=1.0988637894392013
Loss made of: CE 0.41772639751434326, LKD 0.4107471704483032, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6589223146438599, Reg Loss=0.44333624839782715
Clinet index 22, End of Epoch 2/6, Average Loss=1.102258563041687, Class Loss=0.6589223146438599, Reg Loss=0.44333624839782715
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.9323500990867615
Loss made of: CE 0.5940110683441162, LKD 0.45598506927490234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.486441969871521, Reg Loss=0.43743830919265747
Clinet index 22, End of Epoch 3/6, Average Loss=0.9238802790641785, Class Loss=0.486441969871521, Reg Loss=0.43743830919265747
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.8506397604942322
Loss made of: CE 0.34210216999053955, LKD 0.42113399505615234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3976784646511078, Reg Loss=0.44260305166244507
Clinet index 22, End of Epoch 4/6, Average Loss=0.8402814865112305, Class Loss=0.3976784646511078, Reg Loss=0.44260305166244507
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.7852225378155708
Loss made of: CE 0.24500630795955658, LKD 0.385328471660614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34746235609054565, Reg Loss=0.44452470541000366
Clinet index 22, End of Epoch 5/6, Average Loss=0.7919870615005493, Class Loss=0.34746235609054565, Reg Loss=0.44452470541000366
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.7641015976667405
Loss made of: CE 0.2975465655326843, LKD 0.4769825339317322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.33111774921417236, Reg Loss=0.454280823469162
Clinet index 22, End of Epoch 6/6, Average Loss=0.7853986024856567, Class Loss=0.33111774921417236, Reg Loss=0.454280823469162
federated aggregation...
Validation, Class Loss=0.5982182025909424, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.825757
Mean Acc: 0.468205
FreqW Acc: 0.753582
Mean IoU: 0.370633
Class IoU:
	class 0: 0.88076377
	class 1: 0.6126199
	class 2: 0.32483086
	class 3: 0.06941151
	class 4: 0.28802487
	class 5: 0.558251
	class 6: 0.7202644
	class 7: 0.8387436
	class 8: 0.61893266
	class 9: 0.0965497
	class 10: 0.0
	class 11: 0.0
	class 12: 0.16135688
	class 13: 0.143751
	class 14: 0.23032686
	class 15: 0.75683117
	class 16: 9.6883865e-05
Class Acc:
	class 0: 0.9425074
	class 1: 0.6165573
	class 2: 0.69865936
	class 3: 0.06942146
	class 4: 0.2983664
	class 5: 0.5820112
	class 6: 0.73266864
	class 7: 0.90446675
	class 8: 0.6344495
	class 9: 0.27497396
	class 10: 0.0
	class 11: 0.0
	class 12: 0.21796456
	class 13: 0.8154246
	class 14: 0.2654177
	class 15: 0.9065068
	class 16: 9.6883865e-05

federated global round: 24, step: 4
select part of clients to conduct local training
[16, 9, 12, 2]
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/97, Loss=0.6191621094942092
Loss made of: CE 0.26239946484565735, LKD 0.4752771854400635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/97, Loss=0.5895516589283943
Loss made of: CE 0.18803343176841736, LKD 0.4184940755367279, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/97, Loss=0.5901269547641277
Loss made of: CE 0.14851069450378418, LKD 0.46213310956954956, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/97, Loss=0.5336891040205956
Loss made of: CE 0.16689173877239227, LKD 0.3383236825466156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/97, Loss=0.5827674016356468
Loss made of: CE 0.2856718599796295, LKD 0.41703516244888306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/97, Loss=0.5828778430819511
Loss made of: CE 0.16477608680725098, LKD 0.3622126579284668, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/97, Loss=0.5346559651196003
Loss made of: CE 0.12149416655302048, LKD 0.3957921862602234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/97, Loss=0.5571553587913514
Loss made of: CE 0.18964436650276184, LKD 0.3549565076828003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/97, Loss=0.553435106575489
Loss made of: CE 0.15015116333961487, LKD 0.3465159833431244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.17810338735580444, Reg Loss=0.3918650150299072
Clinet index 16, End of Epoch 1/6, Average Loss=0.5699684023857117, Class Loss=0.17810338735580444, Reg Loss=0.3918650150299072
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/97, Loss=0.5625286683440208
Loss made of: CE 0.1333887279033661, LKD 0.40714216232299805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/97, Loss=0.5547630384564399
Loss made of: CE 0.1353801190853119, LKD 0.40901613235473633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/97, Loss=0.5740056455135345
Loss made of: CE 0.14688323438167572, LKD 0.37704166769981384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/97, Loss=0.5487650275230408
Loss made of: CE 0.20285680890083313, LKD 0.36421263217926025, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/97, Loss=0.5438974738121033
Loss made of: CE 0.13356135785579681, LKD 0.36081331968307495, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/97, Loss=0.528438238799572
Loss made of: CE 0.19537930190563202, LKD 0.4387918710708618, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/97, Loss=0.5668686300516128
Loss made of: CE 0.1550183892250061, LKD 0.46873053908348083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/97, Loss=0.5312057077884674
Loss made of: CE 0.15461158752441406, LKD 0.3869081437587738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/97, Loss=0.5441482461988926
Loss made of: CE 0.14684437215328217, LKD 0.3367115259170532, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.16021572053432465, Reg Loss=0.3897263705730438
Clinet index 16, End of Epoch 2/6, Average Loss=0.5499420762062073, Class Loss=0.16021572053432465, Reg Loss=0.3897263705730438
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/97, Loss=0.5330709591507912
Loss made of: CE 0.16229580342769623, LKD 0.35328322649002075, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/97, Loss=0.5406915917992592
Loss made of: CE 0.14308571815490723, LKD 0.36733925342559814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/97, Loss=0.5288881219923496
Loss made of: CE 0.1796134114265442, LKD 0.3823089599609375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/97, Loss=0.5685627475380898
Loss made of: CE 0.1510947197675705, LKD 0.4201917052268982, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/97, Loss=0.5340756312012672
Loss made of: CE 0.12355844676494598, LKD 0.40536102652549744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/97, Loss=0.5637204393744468
Loss made of: CE 0.15198278427124023, LKD 0.3508518636226654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/97, Loss=0.5671213023364544
Loss made of: CE 0.18068084120750427, LKD 0.4400331974029541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/97, Loss=0.5594774931669235
Loss made of: CE 0.1781235635280609, LKD 0.36714595556259155, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/97, Loss=0.5138004064559937
Loss made of: CE 0.10974662005901337, LKD 0.41149580478668213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.15568916499614716, Reg Loss=0.38916513323783875
Clinet index 16, End of Epoch 3/6, Average Loss=0.5448542833328247, Class Loss=0.15568916499614716, Reg Loss=0.38916513323783875
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/97, Loss=0.5307229101657868
Loss made of: CE 0.18016992509365082, LKD 0.33353638648986816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/97, Loss=0.5625307083129882
Loss made of: CE 0.12136659026145935, LKD 0.373285710811615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/97, Loss=0.558465938270092
Loss made of: CE 0.1653463989496231, LKD 0.449277400970459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/97, Loss=0.5244737409055233
Loss made of: CE 0.14441509544849396, LKD 0.338034987449646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/97, Loss=0.5183203861117363
Loss made of: CE 0.11638908088207245, LKD 0.41462552547454834, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/97, Loss=0.5418070510029793
Loss made of: CE 0.13453395664691925, LKD 0.38390645384788513, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/97, Loss=0.5414688840508461
Loss made of: CE 0.15542981028556824, LKD 0.4081815183162689, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/97, Loss=0.5639588184654712
Loss made of: CE 0.24042777717113495, LKD 0.33567485213279724, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/97, Loss=0.5362770229578018
Loss made of: CE 0.14381687343120575, LKD 0.3770688474178314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.15550972521305084, Reg Loss=0.391198992729187
Clinet index 16, End of Epoch 4/6, Average Loss=0.5467087030410767, Class Loss=0.15550972521305084, Reg Loss=0.391198992729187
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/97, Loss=0.5692925438284874
Loss made of: CE 0.1604519784450531, LKD 0.33737561106681824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/97, Loss=0.5494780838489532
Loss made of: CE 0.23520813882350922, LKD 0.44825372099876404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/97, Loss=0.613069087266922
Loss made of: CE 0.2241418957710266, LKD 0.45102620124816895, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/97, Loss=0.5309389159083366
Loss made of: CE 0.1544361114501953, LKD 0.38984259963035583, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/97, Loss=0.49591673985123635
Loss made of: CE 0.11754842102527618, LKD 0.2883244752883911, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/97, Loss=0.5108454167842865
Loss made of: CE 0.14026662707328796, LKD 0.3641970753669739, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/97, Loss=0.5197267346084118
Loss made of: CE 0.1257001906633377, LKD 0.3845052123069763, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/97, Loss=0.5810060888528824
Loss made of: CE 0.15098455548286438, LKD 0.4505555331707001, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/97, Loss=0.5242205344140529
Loss made of: CE 0.2052425742149353, LKD 0.40609920024871826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.15390664339065552, Reg Loss=0.39017972350120544
Clinet index 16, End of Epoch 5/6, Average Loss=0.5440863370895386, Class Loss=0.15390664339065552, Reg Loss=0.39017972350120544
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/97, Loss=0.5264871463179588
Loss made of: CE 0.14965936541557312, LKD 0.3499513566493988, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/97, Loss=0.5585956566035748
Loss made of: CE 0.17355571687221527, LKD 0.3104962110519409, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/97, Loss=0.5433944821357727
Loss made of: CE 0.11515602469444275, LKD 0.3906131386756897, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/97, Loss=0.5331880502402783
Loss made of: CE 0.15564817190170288, LKD 0.372314453125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/97, Loss=0.5142608471214771
Loss made of: CE 0.10473348945379257, LKD 0.38272160291671753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/97, Loss=0.562253239005804
Loss made of: CE 0.12796688079833984, LKD 0.46657678484916687, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/97, Loss=0.5415247537195682
Loss made of: CE 0.17632600665092468, LKD 0.35813766717910767, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/97, Loss=0.5589448258280754
Loss made of: CE 0.14231066405773163, LKD 0.33977338671684265, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/97, Loss=0.5426829151809216
Loss made of: CE 0.14370737969875336, LKD 0.3677828311920166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.15258952975273132, Reg Loss=0.3900398313999176
Clinet index 16, End of Epoch 6/6, Average Loss=0.5426293611526489, Class Loss=0.15258952975273132, Reg Loss=0.3900398313999176
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9323206692934036
Loss made of: CE 0.658627986907959, LKD 0.43602752685546875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.49689754843711853, Reg Loss=0.4434560239315033
Clinet index 9, End of Epoch 1/6, Average Loss=0.9403535723686218, Class Loss=0.49689754843711853, Reg Loss=0.4434560239315033
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.8522550314664841
Loss made of: CE 0.44904589653015137, LKD 0.46132755279541016, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.40711748600006104, Reg Loss=0.4441251754760742
Clinet index 9, End of Epoch 2/6, Average Loss=0.8512426614761353, Class Loss=0.40711748600006104, Reg Loss=0.4441251754760742
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.8015317916870117
Loss made of: CE 0.31193333864212036, LKD 0.4197997450828552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3550543785095215, Reg Loss=0.4472030997276306
Clinet index 9, End of Epoch 3/6, Average Loss=0.8022574782371521, Class Loss=0.3550543785095215, Reg Loss=0.4472030997276306
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.7623344853520393
Loss made of: CE 0.3040177524089813, LKD 0.49328315258026123, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.31896069645881653, Reg Loss=0.440430611371994
Clinet index 9, End of Epoch 4/6, Average Loss=0.7593913078308105, Class Loss=0.31896069645881653, Reg Loss=0.440430611371994
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.7726550653576851
Loss made of: CE 0.2749338150024414, LKD 0.4906364381313324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3118440806865692, Reg Loss=0.4516967535018921
Clinet index 9, End of Epoch 5/6, Average Loss=0.7635408639907837, Class Loss=0.3118440806865692, Reg Loss=0.4516967535018921
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.754415924847126
Loss made of: CE 0.22101855278015137, LKD 0.4695907533168793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3112542927265167, Reg Loss=0.4495631456375122
Clinet index 9, End of Epoch 6/6, Average Loss=0.7608174085617065, Class Loss=0.3112542927265167, Reg Loss=0.4495631456375122
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9426144331693649
Loss made of: CE 0.426153302192688, LKD 0.41898247599601746, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4928022027015686, Reg Loss=0.4502236247062683
Clinet index 12, End of Epoch 1/6, Average Loss=0.9430258274078369, Class Loss=0.4928022027015686, Reg Loss=0.4502236247062683
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.8359661251306534
Loss made of: CE 0.34921035170555115, LKD 0.41357284784317017, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4071831703186035, Reg Loss=0.43658292293548584
Clinet index 12, End of Epoch 2/6, Average Loss=0.8437660932540894, Class Loss=0.4071831703186035, Reg Loss=0.43658292293548584
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.7946345120668411
Loss made of: CE 0.37809205055236816, LKD 0.5052582025527954, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.341044545173645, Reg Loss=0.44193214178085327
Clinet index 12, End of Epoch 3/6, Average Loss=0.7829766869544983, Class Loss=0.341044545173645, Reg Loss=0.44193214178085327
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.7516532018780708
Loss made of: CE 0.29265522956848145, LKD 0.3927714228630066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.31595587730407715, Reg Loss=0.44241905212402344
Clinet index 12, End of Epoch 4/6, Average Loss=0.7583749294281006, Class Loss=0.31595587730407715, Reg Loss=0.44241905212402344
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.7562255740165711
Loss made of: CE 0.3317981958389282, LKD 0.44137996435165405, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3082467317581177, Reg Loss=0.44329380989074707
Clinet index 12, End of Epoch 5/6, Average Loss=0.7515405416488647, Class Loss=0.3082467317581177, Reg Loss=0.44329380989074707
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.7486893817782402
Loss made of: CE 0.2514268159866333, LKD 0.4333338439464569, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.30798250436782837, Reg Loss=0.4401988983154297
Clinet index 12, End of Epoch 6/6, Average Loss=0.7481814026832581, Class Loss=0.30798250436782837, Reg Loss=0.4401988983154297
Current Client Index:  2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/12, Loss=0.9616954058408738
Loss made of: CE 0.5907599329948425, LKD 0.4727869927883148, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5191012024879456, Reg Loss=0.45666274428367615
Clinet index 2, End of Epoch 1/6, Average Loss=0.9757639169692993, Class Loss=0.5191012024879456, Reg Loss=0.45666274428367615
Pseudo labeling is: None
Epoch 2, lr = 0.000536
Epoch 2, Batch 10/12, Loss=0.9518618762493134
Loss made of: CE 0.3825666606426239, LKD 0.42263421416282654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.47705695033073425, Reg Loss=0.4494141936302185
Clinet index 2, End of Epoch 2/6, Average Loss=0.9264711141586304, Class Loss=0.47705695033073425, Reg Loss=0.4494141936302185
Pseudo labeling is: None
Epoch 3, lr = 0.000438
Epoch 3, Batch 10/12, Loss=0.8625386148691178
Loss made of: CE 0.3628339469432831, LKD 0.4344884157180786, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4077705144882202, Reg Loss=0.46411871910095215
Clinet index 2, End of Epoch 3/6, Average Loss=0.8718892335891724, Class Loss=0.4077705144882202, Reg Loss=0.46411871910095215
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/12, Loss=0.8179318726062774
Loss made of: CE 0.40541213750839233, LKD 0.5330313444137573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36340487003326416, Reg Loss=0.4630924165248871
Clinet index 2, End of Epoch 4/6, Average Loss=0.8264973163604736, Class Loss=0.36340487003326416, Reg Loss=0.4630924165248871
Pseudo labeling is: None
Epoch 5, lr = 0.000235
Epoch 5, Batch 10/12, Loss=0.8272013559937477
Loss made of: CE 0.4477676749229431, LKD 0.5289666652679443, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.35470545291900635, Reg Loss=0.4556579291820526
Clinet index 2, End of Epoch 5/6, Average Loss=0.8103634119033813, Class Loss=0.35470545291900635, Reg Loss=0.4556579291820526
Pseudo labeling is: None
Epoch 6, lr = 0.000126
Epoch 6, Batch 10/12, Loss=0.8193638682365417
Loss made of: CE 0.3110120892524719, LKD 0.44664621353149414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3591934144496918, Reg Loss=0.46060824394226074
Clinet index 2, End of Epoch 6/6, Average Loss=0.8198016881942749, Class Loss=0.3591934144496918, Reg Loss=0.46060824394226074
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=0.610757052898407, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.823084
Mean Acc: 0.474590
FreqW Acc: 0.749856
Mean IoU: 0.373371
Class IoU:
	class 0: 0.8755784
	class 1: 0.58510745
	class 2: 0.32438728
	class 3: 0.075432785
	class 4: 0.26548788
	class 5: 0.5357774
	class 6: 0.6766451
	class 7: 0.83659697
	class 8: 0.6283025
	class 9: 0.09651814
	class 10: 0.0
	class 11: 0.0
	class 12: 0.19568375
	class 13: 0.14611718
	class 14: 0.20535928
	class 15: 0.7526733
	class 16: 0.14763919
Class Acc:
	class 0: 0.9370808
	class 1: 0.5884921
	class 2: 0.68844104
	class 3: 0.07544297
	class 4: 0.27534658
	class 5: 0.55908513
	class 6: 0.68588483
	class 7: 0.89664966
	class 8: 0.64555407
	class 9: 0.26727614
	class 10: 0.0
	class 11: 0.0
	class 12: 0.27687716
	class 13: 0.807752
	class 14: 0.2356312
	class 15: 0.9097205
	class 16: 0.21880046

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 25, step: 5
select part of clients to conduct local training
[24, 7, 4, 12]
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.4760988026857376
Loss made of: CE 0.7870277166366577, LKD 0.5976580381393433, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9286400675773621, Reg Loss=0.5325618386268616
Clinet index 24, End of Epoch 1/6, Average Loss=1.4612019062042236, Class Loss=0.9286400675773621, Reg Loss=0.5325618386268616
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2564802676439286
Loss made of: CE 0.6679109334945679, LKD 0.6341841220855713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6741640567779541, Reg Loss=0.558061957359314
Clinet index 24, End of Epoch 2/6, Average Loss=1.232226014137268, Class Loss=0.6741640567779541, Reg Loss=0.558061957359314
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.1290693491697312
Loss made of: CE 0.5524293184280396, LKD 0.6182568073272705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5750502347946167, Reg Loss=0.5479966998100281
Clinet index 24, End of Epoch 3/6, Average Loss=1.123046875, Class Loss=0.5750502347946167, Reg Loss=0.5479966998100281
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.0881068766117097
Loss made of: CE 0.5944563150405884, LKD 0.5618301630020142, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5299844145774841, Reg Loss=0.5615599751472473
Clinet index 24, End of Epoch 4/6, Average Loss=1.0915443897247314, Class Loss=0.5299844145774841, Reg Loss=0.5615599751472473
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0262470573186875
Loss made of: CE 0.4895913302898407, LKD 0.5807759761810303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4920712411403656, Reg Loss=0.5449841022491455
Clinet index 24, End of Epoch 5/6, Average Loss=1.0370553731918335, Class Loss=0.4920712411403656, Reg Loss=0.5449841022491455
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=1.0109041541814805
Loss made of: CE 0.44354066252708435, LKD 0.5066008567810059, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.47925829887390137, Reg Loss=0.552631676197052
Clinet index 24, End of Epoch 6/6, Average Loss=1.0318899154663086, Class Loss=0.47925829887390137, Reg Loss=0.552631676197052
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.4647272825241089, Reg Loss=0.540429949760437
Clinet index 7, End of Epoch 1/6, Average Loss=2.005157232284546, Class Loss=1.4647272825241089, Reg Loss=0.540429949760437
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Class Loss=1.046064853668213, Reg Loss=0.5374000072479248
Clinet index 7, End of Epoch 2/6, Average Loss=1.5834648609161377, Class Loss=1.046064853668213, Reg Loss=0.5374000072479248
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Class Loss=0.7752830386161804, Reg Loss=0.5990917682647705
Clinet index 7, End of Epoch 3/6, Average Loss=1.3743748664855957, Class Loss=0.7752830386161804, Reg Loss=0.5990917682647705
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Class Loss=0.6182453632354736, Reg Loss=0.6401022672653198
Clinet index 7, End of Epoch 4/6, Average Loss=1.2583476305007935, Class Loss=0.6182453632354736, Reg Loss=0.6401022672653198
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Class Loss=0.5317353010177612, Reg Loss=0.600559413433075
Clinet index 7, End of Epoch 5/6, Average Loss=1.1322946548461914, Class Loss=0.5317353010177612, Reg Loss=0.600559413433075
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Class Loss=0.4828759729862213, Reg Loss=0.5769003033638
Clinet index 7, End of Epoch 6/6, Average Loss=1.0597763061523438, Class Loss=0.4828759729862213, Reg Loss=0.5769003033638
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.54373180270195
Loss made of: CE 0.9071430563926697, LKD 0.5561233758926392, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9791252613067627, Reg Loss=0.5382922291755676
Clinet index 4, End of Epoch 1/6, Average Loss=1.5174174308776855, Class Loss=0.9791252613067627, Reg Loss=0.5382922291755676
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2735528588294982
Loss made of: CE 0.6075671315193176, LKD 0.5762249231338501, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7141010165214539, Reg Loss=0.5702281594276428
Clinet index 4, End of Epoch 2/6, Average Loss=1.2843291759490967, Class Loss=0.7141010165214539, Reg Loss=0.5702281594276428
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.182429736852646
Loss made of: CE 0.5815398693084717, LKD 0.5656914710998535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5963863134384155, Reg Loss=0.5800787210464478
Clinet index 4, End of Epoch 3/6, Average Loss=1.1764650344848633, Class Loss=0.5963863134384155, Reg Loss=0.5800787210464478
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.1351671934127807
Loss made of: CE 0.5826308727264404, LKD 0.56419438123703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5469262599945068, Reg Loss=0.5825886726379395
Clinet index 4, End of Epoch 4/6, Average Loss=1.1295149326324463, Class Loss=0.5469262599945068, Reg Loss=0.5825886726379395
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.1104322582483293
Loss made of: CE 0.6009393334388733, LKD 0.6135804653167725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.516418993473053, Reg Loss=0.5655230283737183
Clinet index 4, End of Epoch 5/6, Average Loss=1.081942081451416, Class Loss=0.516418993473053, Reg Loss=0.5655230283737183
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=1.049516224861145
Loss made of: CE 0.49646592140197754, LKD 0.5847548842430115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.49218565225601196, Reg Loss=0.5760114192962646
Clinet index 4, End of Epoch 6/6, Average Loss=1.0681970119476318, Class Loss=0.49218565225601196, Reg Loss=0.5760114192962646
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.4742947906255721
Loss made of: CE 0.9124007225036621, LKD 0.547355592250824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9260281920433044, Reg Loss=0.5267059803009033
Clinet index 12, End of Epoch 1/6, Average Loss=1.4527342319488525, Class Loss=0.9260281920433044, Reg Loss=0.5267059803009033
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.2464689254760741
Loss made of: CE 0.6909233927726746, LKD 0.5122075080871582, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6828032732009888, Reg Loss=0.5527002215385437
Clinet index 12, End of Epoch 2/6, Average Loss=1.2355034351348877, Class Loss=0.6828032732009888, Reg Loss=0.5527002215385437
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=1.1162469208240509
Loss made of: CE 0.6108596324920654, LKD 0.5519692301750183, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5660863518714905, Reg Loss=0.5566428899765015
Clinet index 12, End of Epoch 3/6, Average Loss=1.1227293014526367, Class Loss=0.5660863518714905, Reg Loss=0.5566428899765015
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=1.0974027693271637
Loss made of: CE 0.49081000685691833, LKD 0.5508467555046082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5254108309745789, Reg Loss=0.560979962348938
Clinet index 12, End of Epoch 4/6, Average Loss=1.086390733718872, Class Loss=0.5254108309745789, Reg Loss=0.560979962348938
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=1.0593179315328598
Loss made of: CE 0.453817218542099, LKD 0.5025308728218079, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4974101483821869, Reg Loss=0.5480475425720215
Clinet index 12, End of Epoch 5/6, Average Loss=1.0454577207565308, Class Loss=0.4974101483821869, Reg Loss=0.5480475425720215
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=1.0288522660732269
Loss made of: CE 0.49801918864250183, LKD 0.48434966802597046, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4746403694152832, Reg Loss=0.5525767207145691
Clinet index 12, End of Epoch 6/6, Average Loss=1.027217149734497, Class Loss=0.4746403694152832, Reg Loss=0.5525767207145691
federated aggregation...
Validation, Class Loss=0.8914206027984619, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.786503
Mean Acc: 0.351253
FreqW Acc: 0.686281
Mean IoU: 0.261506
Class IoU:
	class 0: 0.8376043
	class 1: 0.2566529
	class 2: 0.3335428
	class 3: 0.03188421
	class 4: 0.071728334
	class 5: 0.35878757
	class 6: 0.23588945
	class 7: 0.77743465
	class 8: 0.5537071
	class 9: 0.05824769
	class 10: 0.0
	class 11: 0.0
	class 12: 0.109018765
	class 13: 0.14587198
	class 14: 0.22473969
	class 15: 0.7585036
	class 16: 0.15802418
	class 17: 0.0
	class 18: 0.05698588
Class Acc:
	class 0: 0.9456234
	class 1: 0.25709572
	class 2: 0.6992263
	class 3: 0.031887773
	class 4: 0.07269492
	class 5: 0.36387262
	class 6: 0.23631237
	class 7: 0.811762
	class 8: 0.55948883
	class 9: 0.13856497
	class 10: 0.0
	class 11: 0.0
	class 12: 0.14300922
	class 13: 0.84402454
	class 14: 0.26223314
	class 15: 0.8979235
	class 16: 0.33193588
	class 17: 0.0
	class 18: 0.07814286

federated global round: 26, step: 5
select part of clients to conduct local training
[6, 28, 20, 4]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.143712130188942
Loss made of: CE 0.6330678462982178, LKD 0.5769501328468323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5729742050170898, Reg Loss=0.5585609674453735
Clinet index 6, End of Epoch 1/6, Average Loss=1.1315351724624634, Class Loss=0.5729742050170898, Reg Loss=0.5585609674453735
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=1.0989483147859573
Loss made of: CE 0.47636908292770386, LKD 0.5335742235183716, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5189264416694641, Reg Loss=0.5822153091430664
Clinet index 6, End of Epoch 2/6, Average Loss=1.1011416912078857, Class Loss=0.5189264416694641, Reg Loss=0.5822153091430664
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=1.0542359799146652
Loss made of: CE 0.5643864870071411, LKD 0.6181759834289551, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4898413121700287, Reg Loss=0.5674483776092529
Clinet index 6, End of Epoch 3/6, Average Loss=1.057289719581604, Class Loss=0.4898413121700287, Reg Loss=0.5674483776092529
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=1.029743456840515
Loss made of: CE 0.47632452845573425, LKD 0.5778980255126953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.45948129892349243, Reg Loss=0.5757507681846619
Clinet index 6, End of Epoch 4/6, Average Loss=1.0352320671081543, Class Loss=0.45948129892349243, Reg Loss=0.5757507681846619
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=1.031177780032158
Loss made of: CE 0.5144138336181641, LKD 0.6862122416496277, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4508799910545349, Reg Loss=0.565631628036499
Clinet index 6, End of Epoch 5/6, Average Loss=1.0165116786956787, Class Loss=0.4508799910545349, Reg Loss=0.565631628036499
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.9963758677244187
Loss made of: CE 0.43589553236961365, LKD 0.5233467817306519, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4290462136268616, Reg Loss=0.5621393918991089
Clinet index 6, End of Epoch 6/6, Average Loss=0.9911856055259705, Class Loss=0.4290462136268616, Reg Loss=0.5621393918991089
Current Client Index:  28
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.201464056968689, Reg Loss=0.561233401298523
Clinet index 28, End of Epoch 1/6, Average Loss=1.762697458267212, Class Loss=1.201464056968689, Reg Loss=0.561233401298523
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9729014039039612, Reg Loss=0.5587095022201538
Clinet index 28, End of Epoch 2/6, Average Loss=1.5316109657287598, Class Loss=0.9729014039039612, Reg Loss=0.5587095022201538
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7903056740760803, Reg Loss=0.6061359643936157
Clinet index 28, End of Epoch 3/6, Average Loss=1.3964416980743408, Class Loss=0.7903056740760803, Reg Loss=0.6061359643936157
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6258029341697693, Reg Loss=0.6280615925788879
Clinet index 28, End of Epoch 4/6, Average Loss=1.2538645267486572, Class Loss=0.6258029341697693, Reg Loss=0.6280615925788879
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.5394614934921265, Reg Loss=0.6050661206245422
Clinet index 28, End of Epoch 5/6, Average Loss=1.1445276737213135, Class Loss=0.5394614934921265, Reg Loss=0.6050661206245422
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.48222804069519043, Reg Loss=0.5820716619491577
Clinet index 28, End of Epoch 6/6, Average Loss=1.0642997026443481, Class Loss=0.48222804069519043, Reg Loss=0.5820716619491577
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=1.1750894784927368, Reg Loss=0.5347820520401001
Clinet index 20, End of Epoch 1/6, Average Loss=1.709871530532837, Class Loss=1.1750894784927368, Reg Loss=0.5347820520401001
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Class Loss=0.9845432043075562, Reg Loss=0.5569883584976196
Clinet index 20, End of Epoch 2/6, Average Loss=1.5415315628051758, Class Loss=0.9845432043075562, Reg Loss=0.5569883584976196
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Class Loss=0.7378138303756714, Reg Loss=0.554124653339386
Clinet index 20, End of Epoch 3/6, Average Loss=1.2919385433197021, Class Loss=0.7378138303756714, Reg Loss=0.554124653339386
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Class Loss=0.6161807179450989, Reg Loss=0.5916303396224976
Clinet index 20, End of Epoch 4/6, Average Loss=1.2078111171722412, Class Loss=0.6161807179450989, Reg Loss=0.5916303396224976
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Class Loss=0.5310022234916687, Reg Loss=0.5782313346862793
Clinet index 20, End of Epoch 5/6, Average Loss=1.1092336177825928, Class Loss=0.5310022234916687, Reg Loss=0.5782313346862793
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Class Loss=0.4829101860523224, Reg Loss=0.5824627876281738
Clinet index 20, End of Epoch 6/6, Average Loss=1.0653729438781738, Class Loss=0.4829101860523224, Reg Loss=0.5824627876281738
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=1.1234963655471801
Loss made of: CE 0.6165934801101685, LKD 0.5669026970863342, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5700557231903076, Reg Loss=0.5507449507713318
Clinet index 4, End of Epoch 1/6, Average Loss=1.1208007335662842, Class Loss=0.5700557231903076, Reg Loss=0.5507449507713318
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/12, Loss=1.06903073489666
Loss made of: CE 0.48820433020591736, LKD 0.5964857935905457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5238410234451294, Reg Loss=0.5663185715675354
Clinet index 4, End of Epoch 2/6, Average Loss=1.0901596546173096, Class Loss=0.5238410234451294, Reg Loss=0.5663185715675354
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/12, Loss=1.0534855872392654
Loss made of: CE 0.5033191442489624, LKD 0.5663334131240845, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.48911428451538086, Reg Loss=0.561488151550293
Clinet index 4, End of Epoch 3/6, Average Loss=1.0506024360656738, Class Loss=0.48911428451538086, Reg Loss=0.561488151550293
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/12, Loss=1.0367650181055068
Loss made of: CE 0.4905429780483246, LKD 0.5649201273918152, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46289652585983276, Reg Loss=0.5639825463294983
Clinet index 4, End of Epoch 4/6, Average Loss=1.026879072189331, Class Loss=0.46289652585983276, Reg Loss=0.5639825463294983
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=1.0507937699556351
Loss made of: CE 0.513649582862854, LKD 0.6104580760002136, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4515443742275238, Reg Loss=0.5732176303863525
Clinet index 4, End of Epoch 5/6, Average Loss=1.0247620344161987, Class Loss=0.4515443742275238, Reg Loss=0.5732176303863525
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/12, Loss=0.9721345365047455
Loss made of: CE 0.45250242948532104, LKD 0.5741722583770752, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.42437905073165894, Reg Loss=0.5600762367248535
Clinet index 4, End of Epoch 6/6, Average Loss=0.9844552874565125, Class Loss=0.42437905073165894, Reg Loss=0.5600762367248535
federated aggregation...
Validation, Class Loss=0.8960486650466919, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.777823
Mean Acc: 0.319853
FreqW Acc: 0.670430
Mean IoU: 0.234750
Class IoU:
	class 0: 0.8273336
	class 1: 0.13887848
	class 2: 0.3258644
	class 3: 0.019751962
	class 4: 0.04508285
	class 5: 0.30516616
	class 6: 0.17516634
	class 7: 0.748066
	class 8: 0.49660093
	class 9: 0.045786463
	class 10: 0.0
	class 11: 0.0
	class 12: 0.09501484
	class 13: 0.14490451
	class 14: 0.17354716
	class 15: 0.73579174
	class 16: 0.124117784
	class 17: 0.0
	class 18: 0.059183806
Class Acc:
	class 0: 0.9447549
	class 1: 0.13898525
	class 2: 0.69462705
	class 3: 0.019754019
	class 4: 0.045403063
	class 5: 0.30802596
	class 6: 0.1753319
	class 7: 0.7881819
	class 8: 0.5005307
	class 9: 0.10867246
	class 10: 0.0
	class 11: 0.0
	class 12: 0.12975036
	class 13: 0.80873215
	class 14: 0.19711897
	class 15: 0.90343
	class 16: 0.23241217
	class 17: 0.0
	class 18: 0.081487395

federated global round: 27, step: 5
select part of clients to conduct local training
[24, 8, 26, 0]
Current Client Index:  24
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=1.0853621006011962
Loss made of: CE 0.49568694829940796, LKD 0.6243796348571777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5428575873374939, Reg Loss=0.5400760173797607
Clinet index 24, End of Epoch 1/6, Average Loss=1.0829336643218994, Class Loss=0.5428575873374939, Reg Loss=0.5400760173797607
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/12, Loss=1.0695013642311095
Loss made of: CE 0.4814022481441498, LKD 0.6339093446731567, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.49257969856262207, Reg Loss=0.5573083758354187
Clinet index 24, End of Epoch 2/6, Average Loss=1.0498881340026855, Class Loss=0.49257969856262207, Reg Loss=0.5573083758354187
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/12, Loss=1.0031334429979324
Loss made of: CE 0.43931683897972107, LKD 0.5981327295303345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4557149410247803, Reg Loss=0.5437551736831665
Clinet index 24, End of Epoch 3/6, Average Loss=0.9994701147079468, Class Loss=0.4557149410247803, Reg Loss=0.5437551736831665
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/12, Loss=0.9806973576545716
Loss made of: CE 0.4513760209083557, LKD 0.5574967861175537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.43341299891471863, Reg Loss=0.552249014377594
Clinet index 24, End of Epoch 4/6, Average Loss=0.9856619834899902, Class Loss=0.43341299891471863, Reg Loss=0.552249014377594
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/12, Loss=0.9416961073875427
Loss made of: CE 0.41301387548446655, LKD 0.590274453163147, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.40868982672691345, Reg Loss=0.5381735563278198
Clinet index 24, End of Epoch 5/6, Average Loss=0.9468634128570557, Class Loss=0.40868982672691345, Reg Loss=0.5381735563278198
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/12, Loss=0.9457893818616867
Loss made of: CE 0.38476628065109253, LKD 0.5108191967010498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4072446823120117, Reg Loss=0.555510938167572
Clinet index 24, End of Epoch 6/6, Average Loss=0.9627556204795837, Class Loss=0.4072446823120117, Reg Loss=0.555510938167572
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.7927873730659485, Reg Loss=0.5013174414634705
Clinet index 8, End of Epoch 1/6, Average Loss=1.294104814529419, Class Loss=0.7927873730659485, Reg Loss=0.5013174414634705
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Class Loss=0.6708127856254578, Reg Loss=0.5339938998222351
Clinet index 8, End of Epoch 2/6, Average Loss=1.2048066854476929, Class Loss=0.6708127856254578, Reg Loss=0.5339938998222351
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Class Loss=0.537625253200531, Reg Loss=0.5515016317367554
Clinet index 8, End of Epoch 3/6, Average Loss=1.0891268253326416, Class Loss=0.537625253200531, Reg Loss=0.5515016317367554
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Class Loss=0.44864046573638916, Reg Loss=0.5451661944389343
Clinet index 8, End of Epoch 4/6, Average Loss=0.9938066601753235, Class Loss=0.44864046573638916, Reg Loss=0.5451661944389343
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Class Loss=0.400745689868927, Reg Loss=0.5553513169288635
Clinet index 8, End of Epoch 5/6, Average Loss=0.9560970067977905, Class Loss=0.400745689868927, Reg Loss=0.5553513169288635
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Class Loss=0.37455958127975464, Reg Loss=0.5652201175689697
Clinet index 8, End of Epoch 6/6, Average Loss=0.9397796988487244, Class Loss=0.37455958127975464, Reg Loss=0.5652201175689697
Current Client Index:  26
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.0882507652044295
Loss made of: CE 0.47515901923179626, LKD 0.5137977600097656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5487625598907471, Reg Loss=0.545661985874176
Clinet index 26, End of Epoch 1/6, Average Loss=1.0944244861602783, Class Loss=0.5487625598907471, Reg Loss=0.545661985874176
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=1.054436057806015
Loss made of: CE 0.5800372362136841, LKD 0.5490962862968445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4892294108867645, Reg Loss=0.5425848960876465
Clinet index 26, End of Epoch 2/6, Average Loss=1.0318143367767334, Class Loss=0.4892294108867645, Reg Loss=0.5425848960876465
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=1.0201602637767793
Loss made of: CE 0.419298380613327, LKD 0.4407826066017151, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.45042964816093445, Reg Loss=0.5559337735176086
Clinet index 26, End of Epoch 3/6, Average Loss=1.0063633918762207, Class Loss=0.45042964816093445, Reg Loss=0.5559337735176086
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.9799352139234543
Loss made of: CE 0.41386938095092773, LKD 0.5306085348129272, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.42077410221099854, Reg Loss=0.5557111501693726
Clinet index 26, End of Epoch 4/6, Average Loss=0.9764852523803711, Class Loss=0.42077410221099854, Reg Loss=0.5557111501693726
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.9515955865383148
Loss made of: CE 0.4040536880493164, LKD 0.4748058319091797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4110543429851532, Reg Loss=0.5582049489021301
Clinet index 26, End of Epoch 5/6, Average Loss=0.9692592620849609, Class Loss=0.4110543429851532, Reg Loss=0.5582049489021301
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.951181510090828
Loss made of: CE 0.35592031478881836, LKD 0.514353334903717, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.39272210001945496, Reg Loss=0.5511626601219177
Clinet index 26, End of Epoch 6/6, Average Loss=0.9438847303390503, Class Loss=0.39272210001945496, Reg Loss=0.5511626601219177
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.152514684200287
Loss made of: CE 0.5135947465896606, LKD 0.529364824295044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5766931772232056, Reg Loss=0.5662431120872498
Clinet index 0, End of Epoch 1/6, Average Loss=1.1429362297058105, Class Loss=0.5766931772232056, Reg Loss=0.5662431120872498
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=1.0604440361261367
Loss made of: CE 0.44150012731552124, LKD 0.5469051599502563, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.497575581073761, Reg Loss=0.5653793811798096
Clinet index 0, End of Epoch 2/6, Average Loss=1.0629549026489258, Class Loss=0.497575581073761, Reg Loss=0.5653793811798096
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=1.0184699416160583
Loss made of: CE 0.45717257261276245, LKD 0.48103317618370056, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4625692069530487, Reg Loss=0.5615817308425903
Clinet index 0, End of Epoch 3/6, Average Loss=1.0241509675979614, Class Loss=0.4625692069530487, Reg Loss=0.5615817308425903
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.9937218219041825
Loss made of: CE 0.3949107825756073, LKD 0.5569751262664795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.42549654841423035, Reg Loss=0.570210337638855
Clinet index 0, End of Epoch 4/6, Average Loss=0.9957069158554077, Class Loss=0.42549654841423035, Reg Loss=0.570210337638855
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.973547300696373
Loss made of: CE 0.41647905111312866, LKD 0.5495890378952026, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4036563038825989, Reg Loss=0.5652951002120972
Clinet index 0, End of Epoch 5/6, Average Loss=0.968951404094696, Class Loss=0.4036563038825989, Reg Loss=0.5652951002120972
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.9680445581674576
Loss made of: CE 0.36859947443008423, LKD 0.49355435371398926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4059661328792572, Reg Loss=0.570974588394165
Clinet index 0, End of Epoch 6/6, Average Loss=0.9769407510757446, Class Loss=0.4059661328792572, Reg Loss=0.570974588394165
federated aggregation...
Validation, Class Loss=0.8881046772003174, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.747651
Mean Acc: 0.351668
FreqW Acc: 0.657361
Mean IoU: 0.252496
Class IoU:
	class 0: 0.79571915
	class 1: 0.20922725
	class 2: 0.32790154
	class 3: 0.018869797
	class 4: 0.046284024
	class 5: 0.3342072
	class 6: 0.19678563
	class 7: 0.7807894
	class 8: 0.5831024
	class 9: 0.050147302
	class 10: 0.0
	class 11: 0.0
	class 12: 0.15134001
	class 13: 0.14408639
	class 14: 0.13199693
	class 15: 0.7702082
	class 16: 0.15863246
	class 17: 0.0
	class 18: 0.09811926
Class Acc:
	class 0: 0.8830393
	class 1: 0.20953344
	class 2: 0.7065878
	class 3: 0.018871475
	class 4: 0.04669003
	class 5: 0.33869594
	class 6: 0.19708543
	class 7: 0.81354755
	class 8: 0.590261
	class 9: 0.11718356
	class 10: 0.0
	class 11: 0.0
	class 12: 0.21333791
	class 13: 0.82786256
	class 14: 0.14161581
	class 15: 0.89830375
	class 16: 0.18376565
	class 17: 0.0
	class 18: 0.4953198

federated global round: 28, step: 5
select part of clients to conduct local training
[8, 9, 16, 3]
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Class Loss=0.9100840091705322, Reg Loss=0.490613728761673
Clinet index 8, End of Epoch 1/6, Average Loss=1.4006977081298828, Class Loss=0.9100840091705322, Reg Loss=0.490613728761673
Pseudo labeling is: None
Epoch 2, lr = 0.000642
Epoch 2, Class Loss=0.7825220227241516, Reg Loss=0.5117496848106384
Clinet index 8, End of Epoch 2/6, Average Loss=1.29427170753479, Class Loss=0.7825220227241516, Reg Loss=0.5117496848106384
Pseudo labeling is: None
Epoch 3, lr = 0.000589
Epoch 3, Class Loss=0.6541855931282043, Reg Loss=0.5430229902267456
Clinet index 8, End of Epoch 3/6, Average Loss=1.1972086429595947, Class Loss=0.6541855931282043, Reg Loss=0.5430229902267456
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.5468499660491943, Reg Loss=0.5481233596801758
Clinet index 8, End of Epoch 4/6, Average Loss=1.0949733257293701, Class Loss=0.5468499660491943, Reg Loss=0.5481233596801758
Pseudo labeling is: None
Epoch 5, lr = 0.000482
Epoch 5, Class Loss=0.4711558222770691, Reg Loss=0.5360739827156067
Clinet index 8, End of Epoch 5/6, Average Loss=1.0072298049926758, Class Loss=0.4711558222770691, Reg Loss=0.5360739827156067
Pseudo labeling is: None
Epoch 6, lr = 0.000427
Epoch 6, Class Loss=0.4305324852466583, Reg Loss=0.5570384860038757
Clinet index 8, End of Epoch 6/6, Average Loss=0.9875710010528564, Class Loss=0.4305324852466583, Reg Loss=0.5570384860038757
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.9176520109176636, Reg Loss=0.5113469362258911
Clinet index 9, End of Epoch 1/6, Average Loss=1.4289989471435547, Class Loss=0.9176520109176636, Reg Loss=0.5113469362258911
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Class Loss=0.772754430770874, Reg Loss=0.5544885993003845
Clinet index 9, End of Epoch 2/6, Average Loss=1.3272430896759033, Class Loss=0.772754430770874, Reg Loss=0.5544885993003845
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Class Loss=0.5834426879882812, Reg Loss=0.5583440661430359
Clinet index 9, End of Epoch 3/6, Average Loss=1.141786813735962, Class Loss=0.5834426879882812, Reg Loss=0.5583440661430359
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Class Loss=0.4734330177307129, Reg Loss=0.5806699991226196
Clinet index 9, End of Epoch 4/6, Average Loss=1.0541030168533325, Class Loss=0.4734330177307129, Reg Loss=0.5806699991226196
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Class Loss=0.41039353609085083, Reg Loss=0.5872960090637207
Clinet index 9, End of Epoch 5/6, Average Loss=0.9976895451545715, Class Loss=0.41039353609085083, Reg Loss=0.5872960090637207
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Class Loss=0.37607166171073914, Reg Loss=0.6003068089485168
Clinet index 9, End of Epoch 6/6, Average Loss=0.9763784408569336, Class Loss=0.37607166171073914, Reg Loss=0.6003068089485168
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9969935953617096
Loss made of: CE 0.3977343440055847, LKD 0.47290152311325073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4448648691177368, Reg Loss=0.5425496101379395
Clinet index 16, End of Epoch 1/6, Average Loss=0.9874144792556763, Class Loss=0.4448648691177368, Reg Loss=0.5425496101379395
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.9346173286437989
Loss made of: CE 0.3800834119319916, LKD 0.5074808597564697, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.40293657779693604, Reg Loss=0.5345842838287354
Clinet index 16, End of Epoch 2/6, Average Loss=0.9375208616256714, Class Loss=0.40293657779693604, Reg Loss=0.5345842838287354
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.9212209463119507
Loss made of: CE 0.36904096603393555, LKD 0.49617743492126465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38822275400161743, Reg Loss=0.5427055954933167
Clinet index 16, End of Epoch 3/6, Average Loss=0.9309283494949341, Class Loss=0.38822275400161743, Reg Loss=0.5427055954933167
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.912070506811142
Loss made of: CE 0.4188838005065918, LKD 0.526095449924469, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.37085163593292236, Reg Loss=0.546074628829956
Clinet index 16, End of Epoch 4/6, Average Loss=0.9169262647628784, Class Loss=0.37085163593292236, Reg Loss=0.546074628829956
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.9028084248304367
Loss made of: CE 0.3335213363170624, LKD 0.5268139243125916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3617027699947357, Reg Loss=0.535571277141571
Clinet index 16, End of Epoch 5/6, Average Loss=0.8972740173339844, Class Loss=0.3617027699947357, Reg Loss=0.535571277141571
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.9028982847929001
Loss made of: CE 0.3908185660839081, LKD 0.5962074995040894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35736024379730225, Reg Loss=0.5469189882278442
Clinet index 16, End of Epoch 6/6, Average Loss=0.9042792320251465, Class Loss=0.35736024379730225, Reg Loss=0.5469189882278442
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.9903277337551117
Loss made of: CE 0.39297136664390564, LKD 0.603123664855957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4439111649990082, Reg Loss=0.5339914560317993
Clinet index 3, End of Epoch 1/6, Average Loss=0.9779026508331299, Class Loss=0.4439111649990082, Reg Loss=0.5339914560317993
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.9463666766881943
Loss made of: CE 0.47480472922325134, LKD 0.582915186882019, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4121156930923462, Reg Loss=0.5410728454589844
Clinet index 3, End of Epoch 2/6, Average Loss=0.9531885385513306, Class Loss=0.4121156930923462, Reg Loss=0.5410728454589844
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.9316781550645828
Loss made of: CE 0.39159685373306274, LKD 0.6561344265937805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.39396369457244873, Reg Loss=0.5488736033439636
Clinet index 3, End of Epoch 3/6, Average Loss=0.9428372979164124, Class Loss=0.39396369457244873, Reg Loss=0.5488736033439636
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.957767915725708
Loss made of: CE 0.3669334352016449, LKD 0.5755153298377991, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3809652030467987, Reg Loss=0.5603816509246826
Clinet index 3, End of Epoch 4/6, Average Loss=0.9413468837738037, Class Loss=0.3809652030467987, Reg Loss=0.5603816509246826
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.937097555398941
Loss made of: CE 0.3566088080406189, LKD 0.44653624296188354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3630017638206482, Reg Loss=0.5592313408851624
Clinet index 3, End of Epoch 5/6, Average Loss=0.9222331047058105, Class Loss=0.3630017638206482, Reg Loss=0.5592313408851624
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.9143645375967026
Loss made of: CE 0.3575206696987152, LKD 0.5970380306243896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3597766160964966, Reg Loss=0.5613232851028442
Clinet index 3, End of Epoch 6/6, Average Loss=0.9210999011993408, Class Loss=0.3597766160964966, Reg Loss=0.5613232851028442
federated aggregation...
Validation, Class Loss=0.877589762210846, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.763471
Mean Acc: 0.335488
FreqW Acc: 0.664383
Mean IoU: 0.239580
Class IoU:
	class 0: 0.81472
	class 1: 0.14716932
	class 2: 0.3261528
	class 3: 0.012090207
	class 4: 0.033583283
	class 5: 0.30971786
	class 6: 0.18166736
	class 7: 0.7721839
	class 8: 0.511808
	class 9: 0.04463215
	class 10: 0.0
	class 11: 0.0
	class 12: 0.109989226
	class 13: 0.14478992
	class 14: 0.14249341
	class 15: 0.743964
	class 16: 0.120637335
	class 17: 0.0060857073
	class 18: 0.13033319
Class Acc:
	class 0: 0.9142881
	class 1: 0.14729384
	class 2: 0.7077023
	class 3: 0.012091339
	class 4: 0.03384129
	class 5: 0.3129972
	class 6: 0.18185239
	class 7: 0.81232864
	class 8: 0.5162117
	class 9: 0.10748374
	class 10: 0.0
	class 11: 0.0
	class 12: 0.15657672
	class 13: 0.8214932
	class 14: 0.15648255
	class 15: 0.91089153
	class 16: 0.17134899
	class 17: 0.0064485637
	class 18: 0.4049376

federated global round: 29, step: 5
select part of clients to conduct local training
[29, 27, 26, 18]
Current Client Index:  29
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.0300171971321106
Loss made of: CE 0.5007213354110718, LKD 0.4645543694496155, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4799465537071228, Reg Loss=0.5431531667709351
Clinet index 29, End of Epoch 1/6, Average Loss=1.023099660873413, Class Loss=0.4799465537071228, Reg Loss=0.5431531667709351
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.9659573674201966
Loss made of: CE 0.38031005859375, LKD 0.5516728162765503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.41307300329208374, Reg Loss=0.5496315956115723
Clinet index 29, End of Epoch 2/6, Average Loss=0.962704598903656, Class Loss=0.41307300329208374, Reg Loss=0.5496315956115723
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.9176155835390091
Loss made of: CE 0.3909081220626831, LKD 0.5272858142852783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37981554865837097, Reg Loss=0.5472468137741089
Clinet index 29, End of Epoch 3/6, Average Loss=0.9270623922348022, Class Loss=0.37981554865837097, Reg Loss=0.5472468137741089
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.926455882191658
Loss made of: CE 0.3454086184501648, LKD 0.5740488767623901, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3700065612792969, Reg Loss=0.5465705394744873
Clinet index 29, End of Epoch 4/6, Average Loss=0.9165771007537842, Class Loss=0.3700065612792969, Reg Loss=0.5465705394744873
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.9276196837425232
Loss made of: CE 0.3496355414390564, LKD 0.5603125095367432, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3613970875740051, Reg Loss=0.5542188882827759
Clinet index 29, End of Epoch 5/6, Average Loss=0.915615975856781, Class Loss=0.3613970875740051, Reg Loss=0.5542188882827759
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.9328073978424072
Loss made of: CE 0.3416541516780853, LKD 0.5993136167526245, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.36394810676574707, Reg Loss=0.550835371017456
Clinet index 29, End of Epoch 6/6, Average Loss=0.9147834777832031, Class Loss=0.36394810676574707, Reg Loss=0.550835371017456
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Class Loss=0.7243768572807312, Reg Loss=0.5535733103752136
Clinet index 27, End of Epoch 1/6, Average Loss=1.2779501676559448, Class Loss=0.7243768572807312, Reg Loss=0.5535733103752136
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Class Loss=0.6047804355621338, Reg Loss=0.5775924921035767
Clinet index 27, End of Epoch 2/6, Average Loss=1.1823729276657104, Class Loss=0.6047804355621338, Reg Loss=0.5775924921035767
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Class Loss=0.474703311920166, Reg Loss=0.5635753870010376
Clinet index 27, End of Epoch 3/6, Average Loss=1.0382786989212036, Class Loss=0.474703311920166, Reg Loss=0.5635753870010376
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Class Loss=0.4234888255596161, Reg Loss=0.6037929654121399
Clinet index 27, End of Epoch 4/6, Average Loss=1.0272817611694336, Class Loss=0.4234888255596161, Reg Loss=0.6037929654121399
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Class Loss=0.39944589138031006, Reg Loss=0.5935142040252686
Clinet index 27, End of Epoch 5/6, Average Loss=0.9929600954055786, Class Loss=0.39944589138031006, Reg Loss=0.5935142040252686
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Class Loss=0.3881138265132904, Reg Loss=0.6008340716362
Clinet index 27, End of Epoch 6/6, Average Loss=0.988947868347168, Class Loss=0.3881138265132904, Reg Loss=0.6008340716362
Current Client Index:  26
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/12, Loss=0.9913069933652878
Loss made of: CE 0.3722260594367981, LKD 0.47644639015197754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.46426960825920105, Reg Loss=0.535365879535675
Clinet index 26, End of Epoch 1/6, Average Loss=0.9996354579925537, Class Loss=0.46426960825920105, Reg Loss=0.535365879535675
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/12, Loss=1.009476798772812
Loss made of: CE 0.5446193218231201, LKD 0.5671016573905945, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4336085319519043, Reg Loss=0.5536386966705322
Clinet index 26, End of Epoch 2/6, Average Loss=0.9872472286224365, Class Loss=0.4336085319519043, Reg Loss=0.5536386966705322
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/12, Loss=0.9669292986392974
Loss made of: CE 0.3685879111289978, LKD 0.4456954598426819, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.399311363697052, Reg Loss=0.5565816760063171
Clinet index 26, End of Epoch 3/6, Average Loss=0.9558930397033691, Class Loss=0.399311363697052, Reg Loss=0.5565816760063171
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/12, Loss=0.9478225260972977
Loss made of: CE 0.37336593866348267, LKD 0.5327712893486023, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.38357746601104736, Reg Loss=0.5643191337585449
Clinet index 26, End of Epoch 4/6, Average Loss=0.9478965997695923, Class Loss=0.38357746601104736, Reg Loss=0.5643191337585449
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/12, Loss=0.9057352989912033
Loss made of: CE 0.3555465340614319, LKD 0.4571845531463623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.37771934270858765, Reg Loss=0.5482301712036133
Clinet index 26, End of Epoch 5/6, Average Loss=0.9259495139122009, Class Loss=0.37771934270858765, Reg Loss=0.5482301712036133
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/12, Loss=0.943121737241745
Loss made of: CE 0.3574686050415039, LKD 0.48274022340774536, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3761347532272339, Reg Loss=0.5637319684028625
Clinet index 26, End of Epoch 6/6, Average Loss=0.9398667216300964, Class Loss=0.3761347532272339, Reg Loss=0.5637319684028625
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.0481680542230607
Loss made of: CE 0.39150089025497437, LKD 0.5350214838981628, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.48309358954429626, Reg Loss=0.5603815913200378
Clinet index 18, End of Epoch 1/6, Average Loss=1.0434751510620117, Class Loss=0.48309358954429626, Reg Loss=0.5603815913200378
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/12, Loss=0.9767652094364166
Loss made of: CE 0.38670945167541504, LKD 0.4855386018753052, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4121187627315521, Reg Loss=0.556856632232666
Clinet index 18, End of Epoch 2/6, Average Loss=0.9689754247665405, Class Loss=0.4121187627315521, Reg Loss=0.556856632232666
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.9517959147691727
Loss made of: CE 0.31526511907577515, LKD 0.5443196892738342, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3822566270828247, Reg Loss=0.5639870166778564
Clinet index 18, End of Epoch 3/6, Average Loss=0.9462436437606812, Class Loss=0.3822566270828247, Reg Loss=0.5639870166778564
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/12, Loss=0.9586459517478942
Loss made of: CE 0.3518393933773041, LKD 0.6232060790061951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.38203054666519165, Reg Loss=0.5662281513214111
Clinet index 18, End of Epoch 4/6, Average Loss=0.9482586979866028, Class Loss=0.38203054666519165, Reg Loss=0.5662281513214111
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/12, Loss=0.9443572849035263
Loss made of: CE 0.3410380780696869, LKD 0.5707602500915527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.36567363142967224, Reg Loss=0.5776211619377136
Clinet index 18, End of Epoch 5/6, Average Loss=0.9432947635650635, Class Loss=0.36567363142967224, Reg Loss=0.5776211619377136
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/12, Loss=0.9076780766248703
Loss made of: CE 0.3926098346710205, LKD 0.48161011934280396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3556358814239502, Reg Loss=0.5631353259086609
Clinet index 18, End of Epoch 6/6, Average Loss=0.9187712073326111, Class Loss=0.3556358814239502, Reg Loss=0.5631353259086609
federated aggregation...
Validation, Class Loss=0.8823807239532471, Reg Loss=0.0 (without scaling)

Total samples: 1353.000000
Overall Acc: 0.744136
Mean Acc: 0.359544
FreqW Acc: 0.657221
Mean IoU: 0.253984
Class IoU:
	class 0: 0.7938157
	class 1: 0.23969884
	class 2: 0.32557678
	class 3: 0.01454377
	class 4: 0.05258341
	class 5: 0.33090183
	class 6: 0.21623234
	class 7: 0.78295267
	class 8: 0.59549874
	class 9: 0.047302086
	class 10: 0.0
	class 11: 0.0
	class 12: 0.17214103
	class 13: 0.14654113
	class 14: 0.10512875
	class 15: 0.76786476
	class 16: 0.12265058
	class 17: 0.0015903378
	class 18: 0.11067418
Class Acc:
	class 0: 0.87199605
	class 1: 0.24012558
	class 2: 0.7058238
	class 3: 0.014544877
	class 4: 0.05303744
	class 5: 0.33567038
	class 6: 0.21663502
	class 7: 0.814841
	class 8: 0.6040906
	class 9: 0.102175914
	class 10: 0.0
	class 11: 0.0
	class 12: 0.25345254
	class 13: 0.8192311
	class 14: 0.111064106
	class 15: 0.90405554
	class 16: 0.1323001
	class 17: 0.0016062709
	class 18: 0.6506936

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 30, step: 6
select part of clients to conduct local training
[10, 30, 4, 33]
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.6134485572576522
Loss made of: CE 1.025808334350586, LKD 0.578050971031189, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.054683804512024, Reg Loss=0.525968074798584
Clinet index 10, End of Epoch 1/6, Average Loss=1.580651879310608, Class Loss=1.054683804512024, Reg Loss=0.525968074798584
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.1294261306524276
Loss made of: CE 0.6645231246948242, LKD 0.4912188649177551, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6548309326171875, Reg Loss=0.460612952709198
Clinet index 10, End of Epoch 2/6, Average Loss=1.1154439449310303, Class Loss=0.6548309326171875, Reg Loss=0.460612952709198
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.9619284868240356
Loss made of: CE 0.5264143943786621, LKD 0.4297123849391937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5269556045532227, Reg Loss=0.4287455677986145
Clinet index 10, End of Epoch 3/6, Average Loss=0.9557011723518372, Class Loss=0.5269556045532227, Reg Loss=0.4287455677986145
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.8588944166898728
Loss made of: CE 0.4146743714809418, LKD 0.3497637212276459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46201491355895996, Reg Loss=0.38456296920776367
Clinet index 10, End of Epoch 4/6, Average Loss=0.8465778827667236, Class Loss=0.46201491355895996, Reg Loss=0.38456296920776367
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.7555459409952163
Loss made of: CE 0.36785969138145447, LKD 0.3845042884349823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39922016859054565, Reg Loss=0.36954864859580994
Clinet index 10, End of Epoch 5/6, Average Loss=0.7687687873840332, Class Loss=0.39922016859054565, Reg Loss=0.36954864859580994
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.7068434953689575
Loss made of: CE 0.3262408375740051, LKD 0.297612726688385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35669565200805664, Reg Loss=0.3445473313331604
Clinet index 10, End of Epoch 6/6, Average Loss=0.701242983341217, Class Loss=0.35669565200805664, Reg Loss=0.3445473313331604
Current Client Index:  30
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.2566701918840408
Loss made of: CE 0.6841298937797546, LKD 0.4854629933834076, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6865465641021729, Reg Loss=0.5265704393386841
Clinet index 30, End of Epoch 1/6, Average Loss=1.213117003440857, Class Loss=0.6865465641021729, Reg Loss=0.5265704393386841
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/13, Loss=1.0435446113348008
Loss made of: CE 0.5202659964561462, LKD 0.49968189001083374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5226278901100159, Reg Loss=0.5096648931503296
Clinet index 30, End of Epoch 2/6, Average Loss=1.0322928428649902, Class Loss=0.5226278901100159, Reg Loss=0.5096648931503296
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/13, Loss=0.9347738653421402
Loss made of: CE 0.41544097661972046, LKD 0.5366226434707642, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.45455077290534973, Reg Loss=0.48495206236839294
Clinet index 30, End of Epoch 3/6, Average Loss=0.9395028352737427, Class Loss=0.45455077290534973, Reg Loss=0.48495206236839294
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/13, Loss=0.8761068522930145
Loss made of: CE 0.4804633557796478, LKD 0.480838418006897, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4119220972061157, Reg Loss=0.46892672777175903
Clinet index 30, End of Epoch 4/6, Average Loss=0.8808488249778748, Class Loss=0.4119220972061157, Reg Loss=0.46892672777175903
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/13, Loss=0.8543210625648499
Loss made of: CE 0.46024736762046814, LKD 0.4042247235774994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.395048588514328, Reg Loss=0.46383950114250183
Clinet index 30, End of Epoch 5/6, Average Loss=0.8588880896568298, Class Loss=0.395048588514328, Reg Loss=0.46383950114250183
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/13, Loss=0.8599941998720169
Loss made of: CE 0.43830329179763794, LKD 0.49901020526885986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3770497441291809, Reg Loss=0.4630454182624817
Clinet index 30, End of Epoch 6/6, Average Loss=0.8400951623916626, Class Loss=0.3770497441291809, Reg Loss=0.4630454182624817
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.637252476811409
Loss made of: CE 0.9677642583847046, LKD 0.5256585478782654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.0575292110443115, Reg Loss=0.5312503576278687
Clinet index 4, End of Epoch 1/6, Average Loss=1.5887795686721802, Class Loss=1.0575292110443115, Reg Loss=0.5312503576278687
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.1147661805152893
Loss made of: CE 0.5796951055526733, LKD 0.5071158409118652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6484843492507935, Reg Loss=0.4652944505214691
Clinet index 4, End of Epoch 2/6, Average Loss=1.113778829574585, Class Loss=0.6484843492507935, Reg Loss=0.4652944505214691
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.9513522237539291
Loss made of: CE 0.5411204695701599, LKD 0.44336479902267456, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5256626605987549, Reg Loss=0.4230278432369232
Clinet index 4, End of Epoch 3/6, Average Loss=0.9486905336380005, Class Loss=0.5256626605987549, Reg Loss=0.4230278432369232
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.8494789779186249
Loss made of: CE 0.41763466596603394, LKD 0.3205915093421936, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4563039541244507, Reg Loss=0.37877005338668823
Clinet index 4, End of Epoch 4/6, Average Loss=0.8350740075111389, Class Loss=0.4563039541244507, Reg Loss=0.37877005338668823
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.741215568780899
Loss made of: CE 0.3707275092601776, LKD 0.32405075430870056, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3920248746871948, Reg Loss=0.3554290533065796
Clinet index 4, End of Epoch 5/6, Average Loss=0.7474539279937744, Class Loss=0.3920248746871948, Reg Loss=0.3554290533065796
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.700700455904007
Loss made of: CE 0.298566997051239, LKD 0.2526836395263672, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35046932101249695, Reg Loss=0.33715546131134033
Clinet index 4, End of Epoch 6/6, Average Loss=0.6876248121261597, Class Loss=0.35046932101249695, Reg Loss=0.33715546131134033
Current Client Index:  33
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.643799102306366
Loss made of: CE 0.8280858993530273, LKD 0.49515485763549805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.075119137763977, Reg Loss=0.5309202671051025
Clinet index 33, End of Epoch 1/6, Average Loss=1.6060394048690796, Class Loss=1.075119137763977, Reg Loss=0.5309202671051025
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/12, Loss=1.1278250008821487
Loss made of: CE 0.577011227607727, LKD 0.43882283568382263, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6557630300521851, Reg Loss=0.4604993760585785
Clinet index 33, End of Epoch 2/6, Average Loss=1.116262435913086, Class Loss=0.6557630300521851, Reg Loss=0.4604993760585785
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/12, Loss=0.9461506366729736
Loss made of: CE 0.507563591003418, LKD 0.39412039518356323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5237810611724854, Reg Loss=0.4231121242046356
Clinet index 33, End of Epoch 3/6, Average Loss=0.9468932151794434, Class Loss=0.5237810611724854, Reg Loss=0.4231121242046356
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/12, Loss=0.8460606426000595
Loss made of: CE 0.4072824716567993, LKD 0.36949047446250916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46167299151420593, Reg Loss=0.38155731558799744
Clinet index 33, End of Epoch 4/6, Average Loss=0.8432303071022034, Class Loss=0.46167299151420593, Reg Loss=0.38155731558799744
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/12, Loss=0.771313390135765
Loss made of: CE 0.4198814630508423, LKD 0.4015462100505829, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3997820019721985, Reg Loss=0.36553436517715454
Clinet index 33, End of Epoch 5/6, Average Loss=0.765316367149353, Class Loss=0.3997820019721985, Reg Loss=0.36553436517715454
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/12, Loss=0.6997419595718384
Loss made of: CE 0.35545381903648376, LKD 0.314028263092041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34594547748565674, Reg Loss=0.3442104458808899
Clinet index 33, End of Epoch 6/6, Average Loss=0.6901559233665466, Class Loss=0.34594547748565674, Reg Loss=0.3442104458808899
federated aggregation...
Validation, Class Loss=1.1601734161376953, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.753481
Mean Acc: 0.216468
FreqW Acc: 0.607861
Mean IoU: 0.166898
Class IoU:
	class 0: 0.7763556
	class 1: 0.03231273
	class 2: 0.27210176
	class 3: 6.426914e-06
	class 4: 0.005423842
	class 5: 0.1621146
	class 6: 0.11044972
	class 7: 0.5728596
	class 8: 0.22487198
	class 9: 0.021324633
	class 10: 0.0
	class 11: 0.0
	class 12: 0.07641905
	class 13: 0.12996885
	class 14: 0.064695895
	class 15: 0.6919467
	class 16: 0.0139204925
	class 17: 0.0
	class 18: 0.1385581
	class 19: 0.21153013
	class 20: 0.0
Class Acc:
	class 0: 0.96779746
	class 1: 0.03231293
	class 2: 0.45746487
	class 3: 6.426914e-06
	class 4: 0.005427254
	class 5: 0.16234425
	class 6: 0.11056164
	class 7: 0.5899704
	class 8: 0.22501493
	class 9: 0.030835647
	class 10: 0.0
	class 11: 0.0
	class 12: 0.10507596
	class 13: 0.30810064
	class 14: 0.065632455
	class 15: 0.7461527
	class 16: 0.014020412
	class 17: 0.0
	class 18: 0.29171193
	class 19: 0.43340293
	class 20: 0.0

federated global round: 31, step: 6
select part of clients to conduct local training
[9, 17, 14, 1]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.204789611697197
Loss made of: CE 0.7372959852218628, LKD 0.4802855849266052, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6753876209259033, Reg Loss=0.4814363121986389
Clinet index 9, End of Epoch 1/6, Average Loss=1.1568238735198975, Class Loss=0.6753876209259033, Reg Loss=0.4814363121986389
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=1.0366312563419342
Loss made of: CE 0.3963339924812317, LKD 0.4837779700756073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5464717745780945, Reg Loss=0.4659213423728943
Clinet index 9, End of Epoch 2/6, Average Loss=1.0123931169509888, Class Loss=0.5464717745780945, Reg Loss=0.4659213423728943
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.8989910036325455
Loss made of: CE 0.4114440083503723, LKD 0.46412670612335205, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4237350821495056, Reg Loss=0.4671097993850708
Clinet index 9, End of Epoch 3/6, Average Loss=0.8908448815345764, Class Loss=0.4237350821495056, Reg Loss=0.4671097993850708
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.8513827532529831
Loss made of: CE 0.34968823194503784, LKD 0.5123335123062134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3745439648628235, Reg Loss=0.46579819917678833
Clinet index 9, End of Epoch 4/6, Average Loss=0.8403421640396118, Class Loss=0.3745439648628235, Reg Loss=0.46579819917678833
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.810431319475174
Loss made of: CE 0.3064078092575073, LKD 0.48596084117889404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3458571135997772, Reg Loss=0.46985137462615967
Clinet index 9, End of Epoch 5/6, Average Loss=0.8157085180282593, Class Loss=0.3458571135997772, Reg Loss=0.46985137462615967
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.8209652334451676
Loss made of: CE 0.2712791860103607, LKD 0.4094039797782898, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.32754194736480713, Reg Loss=0.4755641222000122
Clinet index 9, End of Epoch 6/6, Average Loss=0.8031060695648193, Class Loss=0.32754194736480713, Reg Loss=0.4755641222000122
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.8020403265953064
Loss made of: CE 0.34089571237564087, LKD 0.31879937648773193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4507676064968109, Reg Loss=0.34235653281211853
Clinet index 17, End of Epoch 1/6, Average Loss=0.7931241393089294, Class Loss=0.4507676064968109, Reg Loss=0.34235653281211853
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.6886563718318939
Loss made of: CE 0.3061569333076477, LKD 0.3409237265586853, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.34982287883758545, Reg Loss=0.34654781222343445
Clinet index 17, End of Epoch 2/6, Average Loss=0.6963707208633423, Class Loss=0.34982287883758545, Reg Loss=0.34654781222343445
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.6434507608413697
Loss made of: CE 0.3283168077468872, LKD 0.4215463399887085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3011866509914398, Reg Loss=0.3430267572402954
Clinet index 17, End of Epoch 3/6, Average Loss=0.6442134380340576, Class Loss=0.3011866509914398, Reg Loss=0.3430267572402954
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.6237034693360328
Loss made of: CE 0.2599543333053589, LKD 0.3595386743545532, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.26900285482406616, Reg Loss=0.35029810667037964
Clinet index 17, End of Epoch 4/6, Average Loss=0.6193009614944458, Class Loss=0.26900285482406616, Reg Loss=0.35029810667037964
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.5824987962841988
Loss made of: CE 0.29856669902801514, LKD 0.37205344438552856, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24632279574871063, Reg Loss=0.3443754315376282
Clinet index 17, End of Epoch 5/6, Average Loss=0.5906982421875, Class Loss=0.24632279574871063, Reg Loss=0.3443754315376282
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.5496901825070382
Loss made of: CE 0.21226879954338074, LKD 0.3345171809196472, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22036930918693542, Reg Loss=0.328568696975708
Clinet index 17, End of Epoch 6/6, Average Loss=0.5489380359649658, Class Loss=0.22036930918693542, Reg Loss=0.328568696975708
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.163679775595665
Loss made of: CE 0.7012901306152344, LKD 0.48951467871665955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6553531289100647, Reg Loss=0.4783475995063782
Clinet index 14, End of Epoch 1/6, Average Loss=1.1337007284164429, Class Loss=0.6553531289100647, Reg Loss=0.4783475995063782
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/13, Loss=0.9887943953275681
Loss made of: CE 0.37891513109207153, LKD 0.4419547915458679, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5128462910652161, Reg Loss=0.4712924063205719
Clinet index 14, End of Epoch 2/6, Average Loss=0.9841387271881104, Class Loss=0.5128462910652161, Reg Loss=0.4712924063205719
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/13, Loss=0.8733526438474655
Loss made of: CE 0.3349718451499939, LKD 0.48850569128990173, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.40820327401161194, Reg Loss=0.461655855178833
Clinet index 14, End of Epoch 3/6, Average Loss=0.8698590993881226, Class Loss=0.40820327401161194, Reg Loss=0.461655855178833
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/13, Loss=0.8230735898017884
Loss made of: CE 0.28392493724823, LKD 0.42331796884536743, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3658568561077118, Reg Loss=0.45505478978157043
Clinet index 14, End of Epoch 4/6, Average Loss=0.8209116458892822, Class Loss=0.3658568561077118, Reg Loss=0.45505478978157043
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/13, Loss=0.8101423949003219
Loss made of: CE 0.29269665479660034, LKD 0.4484163224697113, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3409535884857178, Reg Loss=0.4729604125022888
Clinet index 14, End of Epoch 5/6, Average Loss=0.8139140009880066, Class Loss=0.3409535884857178, Reg Loss=0.4729604125022888
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/13, Loss=0.785798716545105
Loss made of: CE 0.4352966547012329, LKD 0.5017917156219482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3238706588745117, Reg Loss=0.46044591069221497
Clinet index 14, End of Epoch 6/6, Average Loss=0.7843165397644043, Class Loss=0.3238706588745117, Reg Loss=0.46044591069221497
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.7865944594144821
Loss made of: CE 0.3853282928466797, LKD 0.2854020297527313, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.454473614692688, Reg Loss=0.3351331353187561
Clinet index 1, End of Epoch 1/6, Average Loss=0.7896067500114441, Class Loss=0.454473614692688, Reg Loss=0.3351331353187561
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/12, Loss=0.7048162609338761
Loss made of: CE 0.32742375135421753, LKD 0.3363977372646332, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3577383756637573, Reg Loss=0.34046292304992676
Clinet index 1, End of Epoch 2/6, Average Loss=0.6982012987136841, Class Loss=0.3577383756637573, Reg Loss=0.34046292304992676
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/12, Loss=0.6479929447174072
Loss made of: CE 0.3110979497432709, LKD 0.3744521141052246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.304135262966156, Reg Loss=0.3444928526878357
Clinet index 1, End of Epoch 3/6, Average Loss=0.6486281156539917, Class Loss=0.304135262966156, Reg Loss=0.3444928526878357
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/12, Loss=0.598847396671772
Loss made of: CE 0.22973202168941498, LKD 0.3386889696121216, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.266067236661911, Reg Loss=0.3317317068576813
Clinet index 1, End of Epoch 4/6, Average Loss=0.5977989435195923, Class Loss=0.266067236661911, Reg Loss=0.3317317068576813
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/12, Loss=0.5866034001111984
Loss made of: CE 0.2552345395088196, LKD 0.33878588676452637, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25287389755249023, Reg Loss=0.3247401714324951
Clinet index 1, End of Epoch 5/6, Average Loss=0.5776140689849854, Class Loss=0.25287389755249023, Reg Loss=0.3247401714324951
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/12, Loss=0.5773295611143112
Loss made of: CE 0.25017836689949036, LKD 0.27754124999046326, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23499533534049988, Reg Loss=0.3351336419582367
Clinet index 1, End of Epoch 6/6, Average Loss=0.5701289772987366, Class Loss=0.23499533534049988, Reg Loss=0.3351336419582367
federated aggregation...
Validation, Class Loss=0.9822112321853638, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.765155
Mean Acc: 0.236071
FreqW Acc: 0.621057
Mean IoU: 0.190829
Class IoU:
	class 0: 0.78138083
	class 1: 0.086319216
	class 2: 0.30170795
	class 3: 0.00019383572
	class 4: 0.015120953
	class 5: 0.25141513
	class 6: 0.20000471
	class 7: 0.69526416
	class 8: 0.33144936
	class 9: 0.03058848
	class 10: 0.0
	class 11: 0.0
	class 12: 0.10059261
	class 13: 0.1286547
	class 14: 0.07504946
	class 15: 0.71979284
	class 16: 0.010034378
	class 17: 0.0
	class 18: 0.12592621
	class 19: 0.15390758
	class 20: 0.0
Class Acc:
	class 0: 0.9741089
	class 1: 0.08632617
	class 2: 0.5470082
	class 3: 0.00019383572
	class 4: 0.015159588
	class 5: 0.25209862
	class 6: 0.20106551
	class 7: 0.7218791
	class 8: 0.33261463
	class 9: 0.04451538
	class 10: 0.0
	class 11: 0.0
	class 12: 0.13464504
	class 13: 0.2874691
	class 14: 0.076357074
	class 15: 0.77278
	class 16: 0.010105082
	class 17: 0.0
	class 18: 0.21455869
	class 19: 0.2866119
	class 20: 0.0

federated global round: 32, step: 6
select part of clients to conduct local training
[3, 8, 27, 7]
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=0.8369728654623032
Loss made of: CE 0.43344029784202576, LKD 0.3607513904571533, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.47940176725387573, Reg Loss=0.33707356452941895
Clinet index 3, End of Epoch 1/6, Average Loss=0.8164753317832947, Class Loss=0.47940176725387573, Reg Loss=0.33707356452941895
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/12, Loss=0.6636418581008912
Loss made of: CE 0.31729015707969666, LKD 0.38992413878440857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.30839547514915466, Reg Loss=0.35181695222854614
Clinet index 3, End of Epoch 2/6, Average Loss=0.6602123975753784, Class Loss=0.30839547514915466, Reg Loss=0.35181695222854614
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/12, Loss=0.613302330672741
Loss made of: CE 0.22266094386577606, LKD 0.32735976576805115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2574593424797058, Reg Loss=0.34430617094039917
Clinet index 3, End of Epoch 3/6, Average Loss=0.601765513420105, Class Loss=0.2574593424797058, Reg Loss=0.34430617094039917
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/12, Loss=0.5725498005747796
Loss made of: CE 0.2102632224559784, LKD 0.29161760210990906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22839246690273285, Reg Loss=0.34500086307525635
Clinet index 3, End of Epoch 4/6, Average Loss=0.5733933448791504, Class Loss=0.22839246690273285, Reg Loss=0.34500086307525635
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/12, Loss=0.5553480193018914
Loss made of: CE 0.18100246787071228, LKD 0.2912191152572632, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21759752929210663, Reg Loss=0.34503018856048584
Clinet index 3, End of Epoch 5/6, Average Loss=0.5626277327537537, Class Loss=0.21759752929210663, Reg Loss=0.34503018856048584
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/12, Loss=0.5304259061813354
Loss made of: CE 0.1843951940536499, LKD 0.2829396426677704, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20144250988960266, Reg Loss=0.339024156332016
Clinet index 3, End of Epoch 6/6, Average Loss=0.5404666662216187, Class Loss=0.20144250988960266, Reg Loss=0.339024156332016
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.9858016550540925
Loss made of: CE 0.33979320526123047, LKD 0.43104445934295654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5017411708831787, Reg Loss=0.4558126926422119
Clinet index 8, End of Epoch 1/6, Average Loss=0.9575538635253906, Class Loss=0.5017411708831787, Reg Loss=0.4558126926422119
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.8765110284090042
Loss made of: CE 0.4136746823787689, LKD 0.43856745958328247, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4001120328903198, Reg Loss=0.4633921980857849
Clinet index 8, End of Epoch 2/6, Average Loss=0.8635042309761047, Class Loss=0.4001120328903198, Reg Loss=0.4633921980857849
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.7967870950698852
Loss made of: CE 0.34180474281311035, LKD 0.40311259031295776, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3332644999027252, Reg Loss=0.4626753330230713
Clinet index 8, End of Epoch 3/6, Average Loss=0.7959398031234741, Class Loss=0.3332644999027252, Reg Loss=0.4626753330230713
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.7493389248847961
Loss made of: CE 0.3900967538356781, LKD 0.4047824740409851, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.29756754636764526, Reg Loss=0.457379549741745
Clinet index 8, End of Epoch 4/6, Average Loss=0.7549470663070679, Class Loss=0.29756754636764526, Reg Loss=0.457379549741745
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.7519731402397156
Loss made of: CE 0.2737809121608734, LKD 0.4485543966293335, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2796497941017151, Reg Loss=0.46151506900787354
Clinet index 8, End of Epoch 5/6, Average Loss=0.7411648631095886, Class Loss=0.2796497941017151, Reg Loss=0.46151506900787354
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.7130064591765404
Loss made of: CE 0.2920927405357361, LKD 0.49963173270225525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2634037435054779, Reg Loss=0.45338088274002075
Clinet index 8, End of Epoch 6/6, Average Loss=0.7167845964431763, Class Loss=0.2634037435054779, Reg Loss=0.45338088274002075
Current Client Index:  27
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=1.0140038907527924
Loss made of: CE 0.43427205085754395, LKD 0.45247530937194824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5191038250923157, Reg Loss=0.4720785617828369
Clinet index 27, End of Epoch 1/6, Average Loss=0.9911823868751526, Class Loss=0.5191038250923157, Reg Loss=0.4720785617828369
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.8624291270971298
Loss made of: CE 0.5634016394615173, LKD 0.41010546684265137, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3960869014263153, Reg Loss=0.46807411313056946
Clinet index 27, End of Epoch 2/6, Average Loss=0.8641610145568848, Class Loss=0.3960869014263153, Reg Loss=0.46807411313056946
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.7903196096420289
Loss made of: CE 0.3105587363243103, LKD 0.48871397972106934, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.33720967173576355, Reg Loss=0.47070956230163574
Clinet index 27, End of Epoch 3/6, Average Loss=0.8079192638397217, Class Loss=0.33720967173576355, Reg Loss=0.47070956230163574
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.7812583923339844
Loss made of: CE 0.2871723473072052, LKD 0.4909982681274414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.30886024236679077, Reg Loss=0.4657464325428009
Clinet index 27, End of Epoch 4/6, Average Loss=0.7746067047119141, Class Loss=0.30886024236679077, Reg Loss=0.4657464325428009
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.7676553830504418
Loss made of: CE 0.2806382179260254, LKD 0.5091820359230042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.28383591771125793, Reg Loss=0.47084206342697144
Clinet index 27, End of Epoch 5/6, Average Loss=0.7546780109405518, Class Loss=0.28383591771125793, Reg Loss=0.47084206342697144
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.734652316570282
Loss made of: CE 0.2762373089790344, LKD 0.4758926331996918, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2661825716495514, Reg Loss=0.47591233253479004
Clinet index 27, End of Epoch 6/6, Average Loss=0.742094874382019, Class Loss=0.2661825716495514, Reg Loss=0.47591233253479004
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.9871421784162522
Loss made of: CE 0.4957740008831024, LKD 0.4305918216705322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5080564618110657, Reg Loss=0.471889853477478
Clinet index 7, End of Epoch 1/6, Average Loss=0.9799463152885437, Class Loss=0.5080564618110657, Reg Loss=0.471889853477478
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/13, Loss=0.9272861331701279
Loss made of: CE 0.4094407558441162, LKD 0.44354838132858276, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4109606444835663, Reg Loss=0.49062415957450867
Clinet index 7, End of Epoch 2/6, Average Loss=0.901584804058075, Class Loss=0.4109606444835663, Reg Loss=0.49062415957450867
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/13, Loss=0.8023370653390884
Loss made of: CE 0.30446097254753113, LKD 0.47389739751815796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.33519691228866577, Reg Loss=0.47680142521858215
Clinet index 7, End of Epoch 3/6, Average Loss=0.8119983673095703, Class Loss=0.33519691228866577, Reg Loss=0.47680142521858215
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/13, Loss=0.8021488696336746
Loss made of: CE 0.23196029663085938, LKD 0.4912804067134857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3137367069721222, Reg Loss=0.4681752920150757
Clinet index 7, End of Epoch 4/6, Average Loss=0.7819119691848755, Class Loss=0.3137367069721222, Reg Loss=0.4681752920150757
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/13, Loss=0.765213729441166
Loss made of: CE 0.2701255679130554, LKD 0.5241239070892334, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2811814546585083, Reg Loss=0.47903287410736084
Clinet index 7, End of Epoch 5/6, Average Loss=0.7602143287658691, Class Loss=0.2811814546585083, Reg Loss=0.47903287410736084
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/13, Loss=0.7228133171796799
Loss made of: CE 0.2554146945476532, LKD 0.513319730758667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25883835554122925, Reg Loss=0.4713021218776703
Clinet index 7, End of Epoch 6/6, Average Loss=0.7301404476165771, Class Loss=0.25883835554122925, Reg Loss=0.4713021218776703
federated aggregation...
Validation, Class Loss=0.9173415899276733, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.769013
Mean Acc: 0.291776
FreqW Acc: 0.645775
Mean IoU: 0.218843
Class IoU:
	class 0: 0.8045212
	class 1: 0.17888959
	class 2: 0.3143469
	class 3: 0.0045035295
	class 4: 0.036032375
	class 5: 0.33390695
	class 6: 0.22451943
	class 7: 0.74426436
	class 8: 0.45621863
	class 9: 0.036927104
	class 10: 0.0
	class 11: 2.3498167e-07
	class 12: 0.13336343
	class 13: 0.14116572
	class 14: 0.12184095
	class 15: 0.746355
	class 16: 0.029232306
	class 17: 0.0
	class 18: 0.17481604
	class 19: 0.0
	class 20: 0.11479664
Class Acc:
	class 0: 0.955572
	class 1: 0.17892736
	class 2: 0.6110641
	class 3: 0.004503724
	class 4: 0.036275104
	class 5: 0.33699614
	class 6: 0.22662607
	class 7: 0.77743584
	class 8: 0.4600846
	class 9: 0.061418954
	class 10: 0.0
	class 11: 2.3498167e-07
	class 12: 0.18780583
	class 13: 0.46706823
	class 14: 0.12511264
	class 15: 0.83562464
	class 16: 0.029659161
	class 17: 0.0
	class 18: 0.42853183
	class 19: 0.0
	class 20: 0.4045883

federated global round: 33, step: 6
select part of clients to conduct local training
[6, 20, 13, 10]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.7936831384897232
Loss made of: CE 0.26969218254089355, LKD 0.5106542110443115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3142578899860382, Reg Loss=0.46323806047439575
Clinet index 6, End of Epoch 1/6, Average Loss=0.7774959802627563, Class Loss=0.3142578899860382, Reg Loss=0.46323806047439575
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=0.758786229789257
Loss made of: CE 0.23103630542755127, LKD 0.4673722982406616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2874520719051361, Reg Loss=0.466226190328598
Clinet index 6, End of Epoch 2/6, Average Loss=0.7536782622337341, Class Loss=0.2874520719051361, Reg Loss=0.466226190328598
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=0.7487193882465363
Loss made of: CE 0.23272757232189178, LKD 0.45002537965774536, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25487232208251953, Reg Loss=0.4842010736465454
Clinet index 6, End of Epoch 3/6, Average Loss=0.7390733957290649, Class Loss=0.25487232208251953, Reg Loss=0.4842010736465454
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=0.7280256435275078
Loss made of: CE 0.24911539256572723, LKD 0.4472268521785736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24947401881217957, Reg Loss=0.4752587080001831
Clinet index 6, End of Epoch 4/6, Average Loss=0.7247327566146851, Class Loss=0.24947401881217957, Reg Loss=0.4752587080001831
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=0.7195734664797783
Loss made of: CE 0.21154414117336273, LKD 0.5027231574058533, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2301199585199356, Reg Loss=0.4845573604106903
Clinet index 6, End of Epoch 5/6, Average Loss=0.7146773338317871, Class Loss=0.2301199585199356, Reg Loss=0.4845573604106903
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=0.6934873387217522
Loss made of: CE 0.18893226981163025, LKD 0.4553004205226898, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21676841378211975, Reg Loss=0.47365668416023254
Clinet index 6, End of Epoch 6/6, Average Loss=0.6904250979423523, Class Loss=0.21676841378211975, Reg Loss=0.47365668416023254
Current Client Index:  20
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.7727779507637024
Loss made of: CE 0.2604844570159912, LKD 0.5469847917556763, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.30619895458221436, Reg Loss=0.47271209955215454
Clinet index 20, End of Epoch 1/6, Average Loss=0.7789110541343689, Class Loss=0.30619895458221436, Reg Loss=0.47271209955215454
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/13, Loss=0.7415449291467666
Loss made of: CE 0.3349857032299042, LKD 0.4381842613220215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2718697786331177, Reg Loss=0.47432562708854675
Clinet index 20, End of Epoch 2/6, Average Loss=0.7461954355239868, Class Loss=0.2718697786331177, Reg Loss=0.47432562708854675
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/13, Loss=0.7301936641335487
Loss made of: CE 0.21913036704063416, LKD 0.4479319453239441, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25898876786231995, Reg Loss=0.47594696283340454
Clinet index 20, End of Epoch 3/6, Average Loss=0.7349357604980469, Class Loss=0.25898876786231995, Reg Loss=0.47594696283340454
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/13, Loss=0.7105601042509079
Loss made of: CE 0.26179105043411255, LKD 0.5255749225616455, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.238008514046669, Reg Loss=0.475314736366272
Clinet index 20, End of Epoch 4/6, Average Loss=0.7133232355117798, Class Loss=0.238008514046669, Reg Loss=0.475314736366272
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/13, Loss=0.7049490496516228
Loss made of: CE 0.21750406920909882, LKD 0.4239983558654785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2330983579158783, Reg Loss=0.4785948693752289
Clinet index 20, End of Epoch 5/6, Average Loss=0.7116932272911072, Class Loss=0.2330983579158783, Reg Loss=0.4785948693752289
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/13, Loss=0.6841450706124306
Loss made of: CE 0.16489650309085846, LKD 0.5579923391342163, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21809819340705872, Reg Loss=0.4680526554584503
Clinet index 20, End of Epoch 6/6, Average Loss=0.686150848865509, Class Loss=0.21809819340705872, Reg Loss=0.4680526554584503
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/12, Loss=1.0135543465614318
Loss made of: CE 0.6189286112785339, LKD 0.32436737418174744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6483144760131836, Reg Loss=0.32515203952789307
Clinet index 13, End of Epoch 1/6, Average Loss=0.9734665155410767, Class Loss=0.6483144760131836, Reg Loss=0.32515203952789307
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/12, Loss=0.7056327342987061
Loss made of: CE 0.3277662694454193, LKD 0.3503422439098358, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.34986424446105957, Reg Loss=0.33344218134880066
Clinet index 13, End of Epoch 2/6, Average Loss=0.6833064556121826, Class Loss=0.34986424446105957, Reg Loss=0.33344218134880066
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/12, Loss=0.5683449029922485
Loss made of: CE 0.24771885573863983, LKD 0.33717262744903564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23181024193763733, Reg Loss=0.3470277786254883
Clinet index 13, End of Epoch 3/6, Average Loss=0.5788379907608032, Class Loss=0.23181024193763733, Reg Loss=0.3470277786254883
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/12, Loss=0.5518156692385674
Loss made of: CE 0.20619851350784302, LKD 0.40697169303894043, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.20724403858184814, Reg Loss=0.3400048017501831
Clinet index 13, End of Epoch 4/6, Average Loss=0.5472488403320312, Class Loss=0.20724403858184814, Reg Loss=0.3400048017501831
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/12, Loss=0.5411650255322457
Loss made of: CE 0.18348324298858643, LKD 0.26290273666381836, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19893038272857666, Reg Loss=0.3462662398815155
Clinet index 13, End of Epoch 5/6, Average Loss=0.5451966524124146, Class Loss=0.19893038272857666, Reg Loss=0.3462662398815155
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/12, Loss=0.5274360120296478
Loss made of: CE 0.1964516043663025, LKD 0.28518134355545044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19419269263744354, Reg Loss=0.3338560461997986
Clinet index 13, End of Epoch 6/6, Average Loss=0.5280487537384033, Class Loss=0.19419269263744354, Reg Loss=0.3338560461997986
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/12, Loss=0.9902885288000107
Loss made of: CE 0.781672477722168, LKD 0.42661720514297485, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6704611778259277, Reg Loss=0.31836357712745667
Clinet index 10, End of Epoch 1/6, Average Loss=0.988824725151062, Class Loss=0.6704611778259277, Reg Loss=0.31836357712745667
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/12, Loss=0.7266569107770919
Loss made of: CE 0.5374901294708252, LKD 0.38862690329551697, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3908323645591736, Reg Loss=0.31883174180984497
Clinet index 10, End of Epoch 2/6, Average Loss=0.7096641063690186, Class Loss=0.3908323645591736, Reg Loss=0.31883174180984497
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/12, Loss=0.590157987177372
Loss made of: CE 0.27890485525131226, LKD 0.34080085158348083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2592182159423828, Reg Loss=0.330361008644104
Clinet index 10, End of Epoch 3/6, Average Loss=0.5895792245864868, Class Loss=0.2592182159423828, Reg Loss=0.330361008644104
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/12, Loss=0.5673690512776375
Loss made of: CE 0.1829361915588379, LKD 0.3185703754425049, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22585473954677582, Reg Loss=0.3364642858505249
Clinet index 10, End of Epoch 4/6, Average Loss=0.5623190402984619, Class Loss=0.22585473954677582, Reg Loss=0.3364642858505249
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/12, Loss=0.525492587685585
Loss made of: CE 0.19003784656524658, LKD 0.3247981369495392, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20228451490402222, Reg Loss=0.3401084840297699
Clinet index 10, End of Epoch 5/6, Average Loss=0.5423929691314697, Class Loss=0.20228451490402222, Reg Loss=0.3401084840297699
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/12, Loss=0.5457938328385353
Loss made of: CE 0.1950216293334961, LKD 0.288911908864975, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2056731879711151, Reg Loss=0.33540958166122437
Clinet index 10, End of Epoch 6/6, Average Loss=0.5410827398300171, Class Loss=0.2056731879711151, Reg Loss=0.33540958166122437
federated aggregation...
Validation, Class Loss=0.9151012301445007, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.772196
Mean Acc: 0.297047
FreqW Acc: 0.653755
Mean IoU: 0.223056
Class IoU:
	class 0: 0.8146532
	class 1: 0.17555368
	class 2: 0.32152617
	class 3: 0.0042437455
	class 4: 0.04270684
	class 5: 0.33739302
	class 6: 0.18104471
	class 7: 0.7449497
	class 8: 0.41187838
	class 9: 0.033534702
	class 10: 0.0
	class 11: 0.0
	class 12: 0.09859741
	class 13: 0.13955837
	class 14: 0.1531645
	class 15: 0.74057597
	class 16: 0.033322614
	class 17: 0.0
	class 18: 0.16107346
	class 19: 0.23886608
	class 20: 0.051538695
Class Acc:
	class 0: 0.9531913
	class 1: 0.17560682
	class 2: 0.6264192
	class 3: 0.0042438195
	class 4: 0.042905252
	class 5: 0.33975962
	class 6: 0.18154092
	class 7: 0.77497756
	class 8: 0.41424447
	class 9: 0.053234775
	class 10: 0.0
	class 11: 0.0
	class 12: 0.13568047
	class 13: 0.48746812
	class 14: 0.16132408
	class 15: 0.83395374
	class 16: 0.033571202
	class 17: 0.0
	class 18: 0.4176869
	class 19: 0.54746103
	class 20: 0.05471851

federated global round: 34, step: 6
select part of clients to conduct local training
[19, 18, 27, 14]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.8674430698156357
Loss made of: CE 0.32048386335372925, LKD 0.5211111307144165, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.37551212310791016, Reg Loss=0.4793660342693329
Clinet index 19, End of Epoch 1/6, Average Loss=0.8548781871795654, Class Loss=0.37551212310791016, Reg Loss=0.4793660342693329
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=0.7862590745091438
Loss made of: CE 0.3236907720565796, LKD 0.4667820632457733, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29155874252319336, Reg Loss=0.4863487482070923
Clinet index 19, End of Epoch 2/6, Average Loss=0.7779074907302856, Class Loss=0.29155874252319336, Reg Loss=0.4863487482070923
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.7438914865255356
Loss made of: CE 0.22557640075683594, LKD 0.4305053651332855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25010597705841064, Reg Loss=0.481156587600708
Clinet index 19, End of Epoch 3/6, Average Loss=0.7312625646591187, Class Loss=0.25010597705841064, Reg Loss=0.481156587600708
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=0.7331899553537369
Loss made of: CE 0.22948965430259705, LKD 0.5057053565979004, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2416754961013794, Reg Loss=0.4841992259025574
Clinet index 19, End of Epoch 4/6, Average Loss=0.7258747220039368, Class Loss=0.2416754961013794, Reg Loss=0.4841992259025574
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=0.7139364391565323
Loss made of: CE 0.2111905813217163, LKD 0.48974308371543884, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22884193062782288, Reg Loss=0.4837482273578644
Clinet index 19, End of Epoch 5/6, Average Loss=0.7125901579856873, Class Loss=0.22884193062782288, Reg Loss=0.4837482273578644
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=0.6972918570041656
Loss made of: CE 0.21585515141487122, LKD 0.4588228166103363, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23051537573337555, Reg Loss=0.47652775049209595
Clinet index 19, End of Epoch 6/6, Average Loss=0.7070431113243103, Class Loss=0.23051537573337555, Reg Loss=0.47652775049209595
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/13, Loss=0.8504842787981033
Loss made of: CE 0.3565997779369354, LKD 0.5200445055961609, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3498361110687256, Reg Loss=0.4902343153953552
Clinet index 18, End of Epoch 1/6, Average Loss=0.8400704264640808, Class Loss=0.3498361110687256, Reg Loss=0.4902343153953552
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/13, Loss=0.7746438562870026
Loss made of: CE 0.27985700964927673, LKD 0.47411224246025085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27570462226867676, Reg Loss=0.4860035181045532
Clinet index 18, End of Epoch 2/6, Average Loss=0.76170814037323, Class Loss=0.27570462226867676, Reg Loss=0.4860035181045532
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/13, Loss=0.745810754597187
Loss made of: CE 0.24885813891887665, LKD 0.4996452331542969, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25050464272499084, Reg Loss=0.4830488860607147
Clinet index 18, End of Epoch 3/6, Average Loss=0.7335535287857056, Class Loss=0.25050464272499084, Reg Loss=0.4830488860607147
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/13, Loss=0.715386375784874
Loss made of: CE 0.22869758307933807, LKD 0.4564351439476013, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23539508879184723, Reg Loss=0.487958699464798
Clinet index 18, End of Epoch 4/6, Average Loss=0.7233538031578064, Class Loss=0.23539508879184723, Reg Loss=0.487958699464798
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/13, Loss=0.7325675114989281
Loss made of: CE 0.280635803937912, LKD 0.5145909786224365, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22150518000125885, Reg Loss=0.491688996553421
Clinet index 18, End of Epoch 5/6, Average Loss=0.7131941914558411, Class Loss=0.22150518000125885, Reg Loss=0.491688996553421
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/13, Loss=0.7071139737963676
Loss made of: CE 0.22705867886543274, LKD 0.44061845541000366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22536279261112213, Reg Loss=0.4931366741657257
Clinet index 18, End of Epoch 6/6, Average Loss=0.718499481678009, Class Loss=0.22536279261112213, Reg Loss=0.4931366741657257
Current Client Index:  27
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/13, Loss=0.8637644171714782
Loss made of: CE 0.31907424330711365, LKD 0.47276216745376587, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3743838369846344, Reg Loss=0.4804299473762512
Clinet index 27, End of Epoch 1/6, Average Loss=0.854813814163208, Class Loss=0.3743838369846344, Reg Loss=0.4804299473762512
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/13, Loss=0.7803534910082817
Loss made of: CE 0.4416743218898773, LKD 0.3689095377922058, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31421175599098206, Reg Loss=0.47158724069595337
Clinet index 27, End of Epoch 2/6, Average Loss=0.7857990264892578, Class Loss=0.31421175599098206, Reg Loss=0.47158724069595337
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/13, Loss=0.7309336483478546
Loss made of: CE 0.27682968974113464, LKD 0.5129873752593994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27659696340560913, Reg Loss=0.47016140818595886
Clinet index 27, End of Epoch 3/6, Average Loss=0.7467583417892456, Class Loss=0.27659696340560913, Reg Loss=0.47016140818595886
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/13, Loss=0.7279488906264305
Loss made of: CE 0.22980740666389465, LKD 0.5056362748146057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.25452983379364014, Reg Loss=0.4660649597644806
Clinet index 27, End of Epoch 4/6, Average Loss=0.7205947637557983, Class Loss=0.25452983379364014, Reg Loss=0.4660649597644806
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/13, Loss=0.7530423015356064
Loss made of: CE 0.2411011904478073, LKD 0.5042504072189331, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2594616711139679, Reg Loss=0.48295432329177856
Clinet index 27, End of Epoch 5/6, Average Loss=0.7424160242080688, Class Loss=0.2594616711139679, Reg Loss=0.48295432329177856
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/13, Loss=0.7067935660481452
Loss made of: CE 0.2457447648048401, LKD 0.46436047554016113, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24133607745170593, Reg Loss=0.47405174374580383
Clinet index 27, End of Epoch 6/6, Average Loss=0.7153878211975098, Class Loss=0.24133607745170593, Reg Loss=0.47405174374580383
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/13, Loss=0.8447035908699035
Loss made of: CE 0.3676850199699402, LKD 0.4945371150970459, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3551909923553467, Reg Loss=0.4759543240070343
Clinet index 14, End of Epoch 1/6, Average Loss=0.8311452865600586, Class Loss=0.3551909923553467, Reg Loss=0.4759543240070343
Pseudo labeling is: None
Epoch 2, lr = 0.000655
Epoch 2, Batch 10/13, Loss=0.7724192529916764
Loss made of: CE 0.23079049587249756, LKD 0.47571903467178345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2942970097064972, Reg Loss=0.47445982694625854
Clinet index 14, End of Epoch 2/6, Average Loss=0.7687568664550781, Class Loss=0.2942970097064972, Reg Loss=0.47445982694625854
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/13, Loss=0.734527812898159
Loss made of: CE 0.2155807912349701, LKD 0.5273084044456482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2627645432949066, Reg Loss=0.462510347366333
Clinet index 14, End of Epoch 3/6, Average Loss=0.725274920463562, Class Loss=0.2627645432949066, Reg Loss=0.462510347366333
Pseudo labeling is: None
Epoch 4, lr = 0.000414
Epoch 4, Batch 10/13, Loss=0.6989125102758408
Loss made of: CE 0.21434228122234344, LKD 0.4211716055870056, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24527563154697418, Reg Loss=0.459318608045578
Clinet index 14, End of Epoch 4/6, Average Loss=0.7045942544937134, Class Loss=0.24527563154697418, Reg Loss=0.459318608045578
Pseudo labeling is: None
Epoch 5, lr = 0.000287
Epoch 5, Batch 10/13, Loss=0.6919117614626884
Loss made of: CE 0.19227175414562225, LKD 0.44486063718795776, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2315959483385086, Reg Loss=0.4680810570716858
Clinet index 14, End of Epoch 5/6, Average Loss=0.6996769905090332, Class Loss=0.2315959483385086, Reg Loss=0.4680810570716858
Pseudo labeling is: None
Epoch 6, lr = 0.000154
Epoch 6, Batch 10/13, Loss=0.6978774160146713
Loss made of: CE 0.2873435914516449, LKD 0.507265567779541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23290690779685974, Reg Loss=0.46829479932785034
Clinet index 14, End of Epoch 6/6, Average Loss=0.7012016773223877, Class Loss=0.23290690779685974, Reg Loss=0.46829479932785034
federated aggregation...
Validation, Class Loss=0.9060375690460205, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.764611
Mean Acc: 0.325729
FreqW Acc: 0.659706
Mean IoU: 0.226743
Class IoU:
	class 0: 0.8215095
	class 1: 0.26061848
	class 2: 0.32024792
	class 3: 0.016554989
	class 4: 0.05773452
	class 5: 0.3531667
	class 6: 0.077551216
	class 7: 0.725096
	class 8: 0.58390266
	class 9: 0.041120503
	class 10: 0.0
	class 11: 6.1095234e-06
	class 12: 0.1584713
	class 13: 0.14416327
	class 14: 0.12287087
	class 15: 0.747391
	class 16: 0.029371163
	class 17: 0.0
	class 18: 0.17483582
	class 19: 0.0
	class 20: 0.1270018
Class Acc:
	class 0: 0.9367208
	class 1: 0.26072252
	class 2: 0.6425577
	class 3: 0.016557015
	class 4: 0.05856131
	class 5: 0.3570302
	class 6: 0.07758779
	class 7: 0.7509386
	class 8: 0.5958712
	class 9: 0.069436625
	class 10: 0.0
	class 11: 6.1095234e-06
	class 12: 0.21838082
	class 13: 0.5727446
	class 14: 0.12756555
	class 15: 0.84356725
	class 16: 0.029879738
	class 17: 0.0
	class 18: 0.51498973
	class 19: 0.0
	class 20: 0.76718736

voc_8-2_MiB On GPUs 0
Run in 45349s
