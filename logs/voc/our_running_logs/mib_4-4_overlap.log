nohup: ignoring input
25
kvoc_4-4_MiB On GPUs 0\Writing in results/seed_2023-ov/2023-03-10_voc_4-4_MiB.csv
Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 0, step: 0
select part of clients to conduct local training
[6, 7, 9, 2]
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
federated aggregation...
federated global round: 1, step: 0
select part of clients to conduct local training
[6, 0, 7, 2]
Current Client Index:  6
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
Current Client Index:  2
federated aggregation...
federated global round: 2, step: 0
select part of clients to conduct local training
[8, 5, 3, 7]
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
federated aggregation...
federated global round: 3, step: 0
select part of clients to conduct local training
[5, 2, 0, 3]
Current Client Index:  5
Current Client Index:  2
Current Client Index:  0
Current Client Index:  3
federated aggregation...
federated global round: 4, step: 0
select part of clients to conduct local training
[3, 6, 1, 7]
Current Client Index:  3
Current Client Index:  6
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
Current Client Index:  7
federated aggregation...
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Validation, Class Loss=0.09879439324140549, Reg Loss=0.0 (without scaling)

Total samples: 341.000000
Overall Acc: 0.957759
Mean Acc: 0.761733
FreqW Acc: 0.923270
Mean IoU: 0.703965
Class IoU:
	class 0: 0.9539515191877496
	class 1: 0.7615770129403676
	class 2: 0.2054173196242969
	class 3: 0.8920301311931925
	class 4: 0.7068509839220561
Class Acc:
	class 0: 0.9848764620456163
	class 1: 0.7738026584549321
	class 2: 0.27733822617675347
	class 3: 0.9519182023560161
	class 4: 0.8207287142557349

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 5, step: 1
select part of clients to conduct local training
[0, 12, 6, 10]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError("/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/apex-0.1-py3.6-linux-x86_64.egg/amp_C.cpython-36m-x86_64-linux-gnu.so)",)
Pseudo labeling is: None
Epoch 1, lr = 0.001000
/home/amax/anaconda3/envs/FCIL/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Epoch 1, Batch 10/52, Loss=2.2007911026477815
Loss made of: CE 1.3212223052978516, LKD 0.522948145866394, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=1.4847408950328826
Loss made of: CE 0.915626049041748, LKD 0.5295467376708984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=1.2917102932929994
Loss made of: CE 0.8477026224136353, LKD 0.3550189733505249, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=1.061582411825657
Loss made of: CE 0.5838921666145325, LKD 0.28333666920661926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=1.127348494529724
Loss made of: CE 0.6003572344779968, LKD 0.25796782970428467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9683829545974731, Reg Loss=0.45117199420928955
Clinet index 0, End of Epoch 1/6, Average Loss=1.4195549488067627, Class Loss=0.9683829545974731, Reg Loss=0.45117199420928955
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/52, Loss=0.9823821276426316
Loss made of: CE 0.6212529540061951, LKD 0.3547307848930359, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.9317537933588028
Loss made of: CE 0.5475307703018188, LKD 0.2945557236671448, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.9237744361162186
Loss made of: CE 0.5506770014762878, LKD 0.37758469581604004, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.9188902616500855
Loss made of: CE 0.47133979201316833, LKD 0.5007619261741638, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.8605141073465348
Loss made of: CE 0.5406603813171387, LKD 0.48882874846458435, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5285751223564148, Reg Loss=0.38576802611351013
Clinet index 0, End of Epoch 2/6, Average Loss=0.9143431186676025, Class Loss=0.5285751223564148, Reg Loss=0.38576802611351013
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/52, Loss=0.8173044592142105
Loss made of: CE 0.34017783403396606, LKD 0.4126088321208954, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.8846890330314636
Loss made of: CE 0.3585214614868164, LKD 0.42117244005203247, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.7976227819919586
Loss made of: CE 0.49589937925338745, LKD 0.5983188152313232, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.776590833067894
Loss made of: CE 0.3082599639892578, LKD 0.2920686602592468, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.7129427641630173
Loss made of: CE 0.326856791973114, LKD 0.3556908071041107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4016522765159607, Reg Loss=0.39227065443992615
Clinet index 0, End of Epoch 3/6, Average Loss=0.7939229011535645, Class Loss=0.4016522765159607, Reg Loss=0.39227065443992615
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/52, Loss=0.7900691762566566
Loss made of: CE 0.4892795979976654, LKD 0.5137728452682495, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.713780066370964
Loss made of: CE 0.3111207187175751, LKD 0.39229029417037964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.7722169399261475
Loss made of: CE 0.25402241945266724, LKD 0.34083467721939087, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.7067656308412552
Loss made of: CE 0.2764713168144226, LKD 0.3025726079940796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.6400089338421822
Loss made of: CE 0.3133915364742279, LKD 0.3129357695579529, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3390083909034729, Reg Loss=0.3856222331523895
Clinet index 0, End of Epoch 4/6, Average Loss=0.72463059425354, Class Loss=0.3390083909034729, Reg Loss=0.3856222331523895
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/52, Loss=0.694361075758934
Loss made of: CE 0.36953604221343994, LKD 0.3743351697921753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.6668905943632126
Loss made of: CE 0.23337921500205994, LKD 0.3613661527633667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.6794813722372055
Loss made of: CE 0.30873364210128784, LKD 0.3257875442504883, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.6419970005750656
Loss made of: CE 0.3091561198234558, LKD 0.37480801343917847, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.6801073163747787
Loss made of: CE 0.24080190062522888, LKD 0.3653758466243744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.30638593435287476, Reg Loss=0.3709482252597809
Clinet index 0, End of Epoch 5/6, Average Loss=0.677334189414978, Class Loss=0.30638593435287476, Reg Loss=0.3709482252597809
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/52, Loss=0.6326625734567642
Loss made of: CE 0.2531937062740326, LKD 0.3599422872066498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.6906644344329834
Loss made of: CE 0.26205870509147644, LKD 0.33826470375061035, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.6958827778697014
Loss made of: CE 0.3450551927089691, LKD 0.29395604133605957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.6469102263450622
Loss made of: CE 0.2819816470146179, LKD 0.24707293510437012, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.6639752894639969
Loss made of: CE 0.31100937724113464, LKD 0.24959418177604675, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29307451844215393, Reg Loss=0.37157732248306274
Clinet index 0, End of Epoch 6/6, Average Loss=0.6646518707275391, Class Loss=0.29307451844215393, Reg Loss=0.37157732248306274
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/40, Loss=2.169575718045235
Loss made of: CE 1.1891233921051025, LKD 0.576941192150116, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/40, Loss=1.53041051030159
Loss made of: CE 0.7459704279899597, LKD 0.3917224407196045, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/40, Loss=1.1307453155517577
Loss made of: CE 0.7177619934082031, LKD 0.3518301248550415, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/40, Loss=1.0688158869743347
Loss made of: CE 0.6090859770774841, LKD 0.5785987377166748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.9572140574455261, Reg Loss=0.5176728367805481
Clinet index 12, End of Epoch 1/6, Average Loss=1.4748868942260742, Class Loss=0.9572140574455261, Reg Loss=0.5176728367805481
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/40, Loss=1.0369186311960221
Loss made of: CE 0.40045714378356934, LKD 0.4195879101753235, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/40, Loss=0.9085548043251037
Loss made of: CE 0.4886576533317566, LKD 0.4338352084159851, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/40, Loss=0.8777739882469178
Loss made of: CE 0.48067188262939453, LKD 0.2745312452316284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/40, Loss=0.8587002873420715
Loss made of: CE 0.4639662206172943, LKD 0.5440529584884644, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.49358507990837097, Reg Loss=0.4269018769264221
Clinet index 12, End of Epoch 2/6, Average Loss=0.9204869270324707, Class Loss=0.49358507990837097, Reg Loss=0.4269018769264221
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/40, Loss=0.8313708871603012
Loss made of: CE 0.32151341438293457, LKD 0.45008227229118347, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/40, Loss=0.7488970339298249
Loss made of: CE 0.4834129810333252, LKD 0.45299991965293884, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/40, Loss=0.7295731991529465
Loss made of: CE 0.31596487760543823, LKD 0.36437246203422546, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/40, Loss=0.8391314595937729
Loss made of: CE 0.2784882187843323, LKD 0.49329620599746704, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3881499171257019, Reg Loss=0.39909324049949646
Clinet index 12, End of Epoch 3/6, Average Loss=0.787243127822876, Class Loss=0.3881499171257019, Reg Loss=0.39909324049949646
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/40, Loss=0.7589489936828613
Loss made of: CE 0.3972061574459076, LKD 0.31681281328201294, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/40, Loss=0.7934416308999062
Loss made of: CE 0.23784826695919037, LKD 0.4027833938598633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/40, Loss=0.7245763942599297
Loss made of: CE 0.3216956555843353, LKD 0.29298141598701477, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/40, Loss=0.753463277220726
Loss made of: CE 0.3390936851501465, LKD 0.5039479732513428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3469533622264862, Reg Loss=0.410654217004776
Clinet index 12, End of Epoch 4/6, Average Loss=0.7576075792312622, Class Loss=0.3469533622264862, Reg Loss=0.410654217004776
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/40, Loss=0.7481140255928039
Loss made of: CE 0.28422003984451294, LKD 0.3621074855327606, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/40, Loss=0.7022802710533143
Loss made of: CE 0.39150509238243103, LKD 0.48131439089775085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/40, Loss=0.6455143630504608
Loss made of: CE 0.2458895444869995, LKD 0.3764912486076355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/40, Loss=0.7438674986362457
Loss made of: CE 0.2710278630256653, LKD 0.40619492530822754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.30908235907554626, Reg Loss=0.4008617103099823
Clinet index 12, End of Epoch 5/6, Average Loss=0.7099440693855286, Class Loss=0.30908235907554626, Reg Loss=0.4008617103099823
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/40, Loss=0.706021049618721
Loss made of: CE 0.25433188676834106, LKD 0.4902423322200775, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/40, Loss=0.6671617776155472
Loss made of: CE 0.2835615575313568, LKD 0.4311900734901428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/40, Loss=0.7185291677713395
Loss made of: CE 0.27260053157806396, LKD 0.3726290166378021, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/40, Loss=0.6558399885892868
Loss made of: CE 0.26535651087760925, LKD 0.3396932780742645, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.29084718227386475, Reg Loss=0.39604079723358154
Clinet index 12, End of Epoch 6/6, Average Loss=0.6868879795074463, Class Loss=0.29084718227386475, Reg Loss=0.39604079723358154
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/34, Loss=2.3008753269910813
Loss made of: CE 1.3971145153045654, LKD 0.6969009637832642, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=1.5784009486436843
Loss made of: CE 0.8910535573959351, LKD 0.48718544840812683, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=1.48435420691967
Loss made of: CE 0.9001798629760742, LKD 0.48901256918907166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.1589823961257935, Reg Loss=0.5650471448898315
Clinet index 6, End of Epoch 1/6, Average Loss=1.724029541015625, Class Loss=1.1589823961257935, Reg Loss=0.5650471448898315
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/34, Loss=1.1087625980377198
Loss made of: CE 0.6270387172698975, LKD 0.4600575566291809, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=1.0637182861566543
Loss made of: CE 0.6570237874984741, LKD 0.4650023579597473, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=1.0474973052740097
Loss made of: CE 0.5514503717422485, LKD 0.6226128339767456, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6206243634223938, Reg Loss=0.4338248074054718
Clinet index 6, End of Epoch 2/6, Average Loss=1.054449200630188, Class Loss=0.6206243634223938, Reg Loss=0.4338248074054718
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/34, Loss=0.9118936955928802
Loss made of: CE 0.5008035898208618, LKD 0.48811954259872437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.8753765881061554
Loss made of: CE 0.426125168800354, LKD 0.3641281723976135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.8578846633434296
Loss made of: CE 0.4093334674835205, LKD 0.430633008480072, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.44561144709587097, Reg Loss=0.43113449215888977
Clinet index 6, End of Epoch 3/6, Average Loss=0.8767459392547607, Class Loss=0.44561144709587097, Reg Loss=0.43113449215888977
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/34, Loss=0.8077105432748795
Loss made of: CE 0.34730851650238037, LKD 0.27155688405036926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.7500196844339371
Loss made of: CE 0.34828099608421326, LKD 0.32547491788864136, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.797270679473877
Loss made of: CE 0.4830467700958252, LKD 0.4426111876964569, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36562442779541016, Reg Loss=0.4122120141983032
Clinet index 6, End of Epoch 4/6, Average Loss=0.7778364419937134, Class Loss=0.36562442779541016, Reg Loss=0.4122120141983032
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/34, Loss=0.7429336458444595
Loss made of: CE 0.2795693874359131, LKD 0.3668273687362671, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.7477644950151443
Loss made of: CE 0.3381147086620331, LKD 0.5862830877304077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.7034091621637344
Loss made of: CE 0.2756287753582001, LKD 0.48782533407211304, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.31889986991882324, Reg Loss=0.41991373896598816
Clinet index 6, End of Epoch 5/6, Average Loss=0.7388136386871338, Class Loss=0.31889986991882324, Reg Loss=0.41991373896598816
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/34, Loss=0.7659462094306946
Loss made of: CE 0.2900537848472595, LKD 0.30841225385665894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.6697307616472244
Loss made of: CE 0.34005361795425415, LKD 0.48673877120018005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.7130051255226135
Loss made of: CE 0.2503049671649933, LKD 0.3980143964290619, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2930360734462738, Reg Loss=0.4162741005420685
Clinet index 6, End of Epoch 6/6, Average Loss=0.7093101739883423, Class Loss=0.2930360734462738, Reg Loss=0.4162741005420685
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=2.1042432337999344
Loss made of: CE 1.1979390382766724, LKD 0.34760400652885437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=1.3826921164989472
Loss made of: CE 0.9481350779533386, LKD 0.41121789813041687, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=1.1580356419086457
Loss made of: CE 0.7527797222137451, LKD 0.2723453938961029, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.070804238319397, Reg Loss=0.432078093290329
Clinet index 10, End of Epoch 1/6, Average Loss=1.5028823614120483, Class Loss=1.070804238319397, Reg Loss=0.432078093290329
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/33, Loss=1.052437949180603
Loss made of: CE 0.7360500693321228, LKD 0.4444352090358734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.97214295566082
Loss made of: CE 0.8963207602500916, LKD 0.5005379915237427, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.9414145320653915
Loss made of: CE 0.5241010189056396, LKD 0.21533235907554626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6735738515853882, Reg Loss=0.30960726737976074
Clinet index 10, End of Epoch 2/6, Average Loss=0.9831811189651489, Class Loss=0.6735738515853882, Reg Loss=0.30960726737976074
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/33, Loss=0.8687905266880989
Loss made of: CE 0.5831798315048218, LKD 0.31460142135620117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.8358711034059525
Loss made of: CE 0.5063896775245667, LKD 0.3940351903438568, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.8464199438691139
Loss made of: CE 0.4628264904022217, LKD 0.16256922483444214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.536770761013031, Reg Loss=0.3029079735279083
Clinet index 10, End of Epoch 3/6, Average Loss=0.8396787643432617, Class Loss=0.536770761013031, Reg Loss=0.3029079735279083
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/33, Loss=0.7395655646920204
Loss made of: CE 0.36482250690460205, LKD 0.24008890986442566, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.7133902058005333
Loss made of: CE 0.36997732520103455, LKD 0.2427421510219574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.7282572880387306
Loss made of: CE 0.372501939535141, LKD 0.2838837504386902, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4303125739097595, Reg Loss=0.2908652722835541
Clinet index 10, End of Epoch 4/6, Average Loss=0.7211778163909912, Class Loss=0.4303125739097595, Reg Loss=0.2908652722835541
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/33, Loss=0.6988796412944793
Loss made of: CE 0.4939758777618408, LKD 0.49111127853393555, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.6310282155871392
Loss made of: CE 0.32091718912124634, LKD 0.32629722356796265, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.6420056104660035
Loss made of: CE 0.368123859167099, LKD 0.28636690974235535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3542340099811554, Reg Loss=0.29185763001441956
Clinet index 10, End of Epoch 5/6, Average Loss=0.646091639995575, Class Loss=0.3542340099811554, Reg Loss=0.29185763001441956
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/33, Loss=0.7018731832504272
Loss made of: CE 0.4845743179321289, LKD 0.4489092230796814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.5515257075428963
Loss made of: CE 0.2622935175895691, LKD 0.29303959012031555, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.5638235047459602
Loss made of: CE 0.27399179339408875, LKD 0.22893385589122772, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3083408772945404, Reg Loss=0.30075037479400635
Clinet index 10, End of Epoch 6/6, Average Loss=0.6090912818908691, Class Loss=0.3083408772945404, Reg Loss=0.30075037479400635
federated aggregation...
Validation, Class Loss=0.37119773030281067, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.849285
Mean Acc: 0.486081
FreqW Acc: 0.733538
Mean IoU: 0.374453
Class IoU:
	class 0: 0.85764587
	class 1: 0.70592344
	class 2: 0.24350233
	class 3: 0.50992465
	class 4: 0.46976244
	class 5: 0.0
	class 6: 0.0406722
	class 7: 0.036022708
	class 8: 0.5066214
Class Acc:
	class 0: 0.9853976
	class 1: 0.7747878
	class 2: 0.402859
	class 3: 0.8507812
	class 4: 0.7372935
	class 5: 0.0
	class 6: 0.040680047
	class 7: 0.03605862
	class 8: 0.54687464

federated global round: 6, step: 1
select part of clients to conduct local training
[11, 5, 8, 12]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/43, Loss=0.9437703967094422
Loss made of: CE 0.401976078748703, LKD 0.25111156702041626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/43, Loss=0.8431563347578048
Loss made of: CE 0.5775959491729736, LKD 0.34162193536758423, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/43, Loss=0.7150710955262184
Loss made of: CE 0.40068721771240234, LKD 0.21700797975063324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/43, Loss=0.696578948199749
Loss made of: CE 0.4355299472808838, LKD 0.3683343529701233, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.49158725142478943, Reg Loss=0.29854005575180054
Clinet index 11, End of Epoch 1/6, Average Loss=0.7901272773742676, Class Loss=0.49158725142478943, Reg Loss=0.29854005575180054
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/43, Loss=0.6091743752360343
Loss made of: CE 0.3075483739376068, LKD 0.15765313804149628, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/43, Loss=0.6347399145364762
Loss made of: CE 0.2803344428539276, LKD 0.20508317649364471, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/43, Loss=0.6411522418260575
Loss made of: CE 0.4114561676979065, LKD 0.2996836006641388, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/43, Loss=0.6612445995211601
Loss made of: CE 0.36799734830856323, LKD 0.24308037757873535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35316959023475647, Reg Loss=0.2801685929298401
Clinet index 11, End of Epoch 2/6, Average Loss=0.633338212966919, Class Loss=0.35316959023475647, Reg Loss=0.2801685929298401
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/43, Loss=0.620836217701435
Loss made of: CE 0.3541434705257416, LKD 0.31509625911712646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/43, Loss=0.5371191039681434
Loss made of: CE 0.2501831650733948, LKD 0.18780189752578735, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/43, Loss=0.5749672085046769
Loss made of: CE 0.37936490774154663, LKD 0.2462683767080307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/43, Loss=0.6311972752213478
Loss made of: CE 0.19749054312705994, LKD 0.1963285207748413, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3158212900161743, Reg Loss=0.27186381816864014
Clinet index 11, End of Epoch 3/6, Average Loss=0.5876851081848145, Class Loss=0.3158212900161743, Reg Loss=0.27186381816864014
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/43, Loss=0.5641197606921196
Loss made of: CE 0.3448546826839447, LKD 0.3067207336425781, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/43, Loss=0.550383771955967
Loss made of: CE 0.30197054147720337, LKD 0.3277062773704529, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/43, Loss=0.5570426523685456
Loss made of: CE 0.31921321153640747, LKD 0.27574074268341064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/43, Loss=0.5809876933693886
Loss made of: CE 0.2380119413137436, LKD 0.22836634516716003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.287628173828125, Reg Loss=0.2705748379230499
Clinet index 11, End of Epoch 4/6, Average Loss=0.5582029819488525, Class Loss=0.287628173828125, Reg Loss=0.2705748379230499
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/43, Loss=0.5420031040906906
Loss made of: CE 0.22853080928325653, LKD 0.3001563549041748, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/43, Loss=0.5187383234500885
Loss made of: CE 0.3187037408351898, LKD 0.21162068843841553, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/43, Loss=0.5525646314024926
Loss made of: CE 0.2483605593442917, LKD 0.19573771953582764, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/43, Loss=0.5169245928525925
Loss made of: CE 0.24345684051513672, LKD 0.2266426980495453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26925066113471985, Reg Loss=0.27088940143585205
Clinet index 11, End of Epoch 5/6, Average Loss=0.5401400327682495, Class Loss=0.26925066113471985, Reg Loss=0.27088940143585205
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/43, Loss=0.46983185708522796
Loss made of: CE 0.2432522177696228, LKD 0.20404908061027527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/43, Loss=0.5206951200962067
Loss made of: CE 0.2702293395996094, LKD 0.24447757005691528, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/43, Loss=0.5377105653285981
Loss made of: CE 0.23706701397895813, LKD 0.34713301062583923, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/43, Loss=0.5243286564946175
Loss made of: CE 0.258768767118454, LKD 0.2573974132537842, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24137796461582184, Reg Loss=0.2709898054599762
Clinet index 11, End of Epoch 6/6, Average Loss=0.5123677849769592, Class Loss=0.24137796461582184, Reg Loss=0.2709898054599762
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/34, Loss=0.9818478673696518
Loss made of: CE 0.5241155028343201, LKD 0.32337504625320435, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.8516256541013718
Loss made of: CE 0.375837504863739, LKD 0.47058218717575073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.8067335993051529
Loss made of: CE 0.37355780601501465, LKD 0.9360017776489258, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4278423488140106, Reg Loss=0.44657671451568604
Clinet index 5, End of Epoch 1/6, Average Loss=0.874419093132019, Class Loss=0.4278423488140106, Reg Loss=0.44657671451568604
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/34, Loss=0.8119756549596786
Loss made of: CE 0.2831173539161682, LKD 0.4204282760620117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.6950025141239167
Loss made of: CE 0.3073108196258545, LKD 0.43242162466049194, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.7740895509719848
Loss made of: CE 0.3765396773815155, LKD 0.5669021606445312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31706592440605164, Reg Loss=0.436008095741272
Clinet index 5, End of Epoch 2/6, Average Loss=0.753074049949646, Class Loss=0.31706592440605164, Reg Loss=0.436008095741272
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/34, Loss=0.6952822044491768
Loss made of: CE 0.2900310754776001, LKD 0.4977979063987732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.6524730205535889
Loss made of: CE 0.2664068341255188, LKD 0.41416439414024353, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.7360380083322525
Loss made of: CE 0.31093132495880127, LKD 0.5295566916465759, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2738173007965088, Reg Loss=0.42293471097946167
Clinet index 5, End of Epoch 3/6, Average Loss=0.6967520117759705, Class Loss=0.2738173007965088, Reg Loss=0.42293471097946167
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/34, Loss=0.6753622636198997
Loss made of: CE 0.2369377315044403, LKD 0.37297195196151733, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.7200770288705826
Loss made of: CE 0.27993571758270264, LKD 0.5043115615844727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.667785769701004
Loss made of: CE 0.2609764337539673, LKD 0.447601318359375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2602841854095459, Reg Loss=0.4244556128978729
Clinet index 5, End of Epoch 4/6, Average Loss=0.6847398281097412, Class Loss=0.2602841854095459, Reg Loss=0.4244556128978729
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/34, Loss=0.6789267912507058
Loss made of: CE 0.23445677757263184, LKD 0.5125184059143066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.6334094896912574
Loss made of: CE 0.26776883006095886, LKD 0.4014432430267334, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.692521122097969
Loss made of: CE 0.2688819169998169, LKD 0.5010024905204773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24801358580589294, Reg Loss=0.4170858561992645
Clinet index 5, End of Epoch 5/6, Average Loss=0.6650994420051575, Class Loss=0.24801358580589294, Reg Loss=0.4170858561992645
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/34, Loss=0.7078326866030693
Loss made of: CE 0.2814609110355377, LKD 0.42251691222190857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.605487397313118
Loss made of: CE 0.19172708690166473, LKD 0.41111016273498535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.6967306807637215
Loss made of: CE 0.34908008575439453, LKD 0.665317177772522, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.24834467470645905, Reg Loss=0.41878771781921387
Clinet index 5, End of Epoch 6/6, Average Loss=0.6671323776245117, Class Loss=0.24834467470645905, Reg Loss=0.41878771781921387
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/40, Loss=0.8413709551095963
Loss made of: CE 0.5188580751419067, LKD 0.401842325925827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/40, Loss=0.8307816535234451
Loss made of: CE 0.3071288764476776, LKD 0.5211447477340698, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/40, Loss=0.7534257143735885
Loss made of: CE 0.3814738690853119, LKD 0.32339584827423096, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/40, Loss=0.8121032446622849
Loss made of: CE 0.3141149878501892, LKD 0.41677314043045044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4016354978084564, Reg Loss=0.40778490900993347
Clinet index 8, End of Epoch 1/6, Average Loss=0.8094204068183899, Class Loss=0.4016354978084564, Reg Loss=0.40778490900993347
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/40, Loss=0.7217836588621139
Loss made of: CE 0.3217005729675293, LKD 0.42345142364501953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/40, Loss=0.6618853822350502
Loss made of: CE 0.22612816095352173, LKD 0.42725056409835815, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/40, Loss=0.7891272485256196
Loss made of: CE 0.365553081035614, LKD 0.42745065689086914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/40, Loss=0.7080291479825973
Loss made of: CE 0.29708871245384216, LKD 0.2869473695755005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3255684971809387, Reg Loss=0.3946378827095032
Clinet index 8, End of Epoch 2/6, Average Loss=0.7202063798904419, Class Loss=0.3255684971809387, Reg Loss=0.3946378827095032
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/40, Loss=0.6441170051693916
Loss made of: CE 0.20783373713493347, LKD 0.22814399003982544, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/40, Loss=0.6494733318686485
Loss made of: CE 0.2690957188606262, LKD 0.3934020400047302, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/40, Loss=0.7091918960213661
Loss made of: CE 0.3469340205192566, LKD 0.5863569974899292, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/40, Loss=0.6942179054021835
Loss made of: CE 0.25374388694763184, LKD 0.37122154235839844, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2899380624294281, Reg Loss=0.3843120038509369
Clinet index 8, End of Epoch 3/6, Average Loss=0.674250066280365, Class Loss=0.2899380624294281, Reg Loss=0.3843120038509369
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/40, Loss=0.6208658441901207
Loss made of: CE 0.3595392107963562, LKD 0.3990563154220581, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/40, Loss=0.6492695122957229
Loss made of: CE 0.26026514172554016, LKD 0.3799535632133484, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/40, Loss=0.6356361493468284
Loss made of: CE 0.24139246344566345, LKD 0.23935669660568237, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/40, Loss=0.6779115170240402
Loss made of: CE 0.24792516231536865, LKD 0.4540531039237976, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2698240876197815, Reg Loss=0.3760966956615448
Clinet index 8, End of Epoch 4/6, Average Loss=0.6459207534790039, Class Loss=0.2698240876197815, Reg Loss=0.3760966956615448
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/40, Loss=0.6166577711701393
Loss made of: CE 0.221029132604599, LKD 0.2851518392562866, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/40, Loss=0.6486419633030891
Loss made of: CE 0.3053297996520996, LKD 0.26244911551475525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/40, Loss=0.6358996674418449
Loss made of: CE 0.2940943241119385, LKD 0.37333330512046814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/40, Loss=0.5940476596355438
Loss made of: CE 0.2247934192419052, LKD 0.3776489198207855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25126075744628906, Reg Loss=0.3725510239601135
Clinet index 8, End of Epoch 5/6, Average Loss=0.6238117814064026, Class Loss=0.25126075744628906, Reg Loss=0.3725510239601135
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/40, Loss=0.5972422659397125
Loss made of: CE 0.19838225841522217, LKD 0.3173401355743408, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/40, Loss=0.5933598548173904
Loss made of: CE 0.20968633890151978, LKD 0.3969062268733978, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/40, Loss=0.6437717199325561
Loss made of: CE 0.27120116353034973, LKD 0.3733866214752197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/40, Loss=0.6224362045526505
Loss made of: CE 0.21408861875534058, LKD 0.47605007886886597, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23817510902881622, Reg Loss=0.3760274350643158
Clinet index 8, End of Epoch 6/6, Average Loss=0.6142025589942932, Class Loss=0.23817510902881622, Reg Loss=0.3760274350643158
Current Client Index:  12
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/40, Loss=0.8392534494400025
Loss made of: CE 0.4012220501899719, LKD 0.37823641300201416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/40, Loss=0.8803229928016663
Loss made of: CE 0.3526485562324524, LKD 0.3476686477661133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/40, Loss=0.7546710640192031
Loss made of: CE 0.4801015853881836, LKD 0.402660071849823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/40, Loss=0.815332880616188
Loss made of: CE 0.36467334628105164, LKD 0.601280689239502, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4174880087375641, Reg Loss=0.40490713715553284
Clinet index 12, End of Epoch 1/6, Average Loss=0.8223951458930969, Class Loss=0.4174880087375641, Reg Loss=0.40490713715553284
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/40, Loss=0.8023894354701042
Loss made of: CE 0.24769918620586395, LKD 0.4469034671783447, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/40, Loss=0.7177529320120811
Loss made of: CE 0.30528104305267334, LKD 0.39354750514030457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/40, Loss=0.7485887378454208
Loss made of: CE 0.35438212752342224, LKD 0.3007403016090393, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/40, Loss=0.718019038438797
Loss made of: CE 0.33911821246147156, LKD 0.47402095794677734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3362138867378235, Reg Loss=0.41047367453575134
Clinet index 12, End of Epoch 2/6, Average Loss=0.7466875314712524, Class Loss=0.3362138867378235, Reg Loss=0.41047367453575134
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/40, Loss=0.7146590232849122
Loss made of: CE 0.2319502830505371, LKD 0.4769335687160492, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/40, Loss=0.6565046519041061
Loss made of: CE 0.3788798451423645, LKD 0.393027663230896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/40, Loss=0.6552023395895958
Loss made of: CE 0.27424412965774536, LKD 0.3927451968193054, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/40, Loss=0.7597205668687821
Loss made of: CE 0.2220420241355896, LKD 0.4271888732910156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3083809018135071, Reg Loss=0.3881407678127289
Clinet index 12, End of Epoch 3/6, Average Loss=0.6965216398239136, Class Loss=0.3083809018135071, Reg Loss=0.3881407678127289
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/40, Loss=0.6949861481785774
Loss made of: CE 0.3035452365875244, LKD 0.3538352847099304, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/40, Loss=0.6639701023697853
Loss made of: CE 0.18752877414226532, LKD 0.36001941561698914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/40, Loss=0.6730880320072175
Loss made of: CE 0.26593324542045593, LKD 0.2826014459133148, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/40, Loss=0.6926787585020066
Loss made of: CE 0.2968895137310028, LKD 0.4566441774368286, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2863186299800873, Reg Loss=0.3948621451854706
Clinet index 12, End of Epoch 4/6, Average Loss=0.6811807751655579, Class Loss=0.2863186299800873, Reg Loss=0.3948621451854706
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/40, Loss=0.6910878479480743
Loss made of: CE 0.2429838627576828, LKD 0.3506118655204773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/40, Loss=0.6398174077272415
Loss made of: CE 0.2998257279396057, LKD 0.4774113595485687, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/40, Loss=0.594335389137268
Loss made of: CE 0.21510860323905945, LKD 0.36853957176208496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/40, Loss=0.6708234503865242
Loss made of: CE 0.24187330901622772, LKD 0.43326765298843384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.25913137197494507, Reg Loss=0.38988468050956726
Clinet index 12, End of Epoch 5/6, Average Loss=0.6490160226821899, Class Loss=0.25913137197494507, Reg Loss=0.38988468050956726
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/40, Loss=0.6651704475283623
Loss made of: CE 0.21089982986450195, LKD 0.4940411448478699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/40, Loss=0.6215216636657714
Loss made of: CE 0.25291699171066284, LKD 0.4431208074092865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/40, Loss=0.6686516925692558
Loss made of: CE 0.23466911911964417, LKD 0.342845618724823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/40, Loss=0.6009535163640976
Loss made of: CE 0.21596276760101318, LKD 0.30488380789756775, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2489026039838791, Reg Loss=0.39017173647880554
Clinet index 12, End of Epoch 6/6, Average Loss=0.6390743255615234, Class Loss=0.2489026039838791, Reg Loss=0.39017173647880554
federated aggregation...
Validation, Class Loss=0.28522658348083496, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.888862
Mean Acc: 0.580196
FreqW Acc: 0.798792
Mean IoU: 0.496315
Class IoU:
	class 0: 0.8870542
	class 1: 0.75352836
	class 2: 0.22615355
	class 3: 0.6257156
	class 4: 0.56043583
	class 5: 0.012069786
	class 6: 0.52349323
	class 7: 0.18186058
	class 8: 0.6965215
Class Acc:
	class 0: 0.98318887
	class 1: 0.77912945
	class 2: 0.34921142
	class 3: 0.8167466
	class 4: 0.75937015
	class 5: 0.01207807
	class 6: 0.53107506
	class 7: 0.1826098
	class 8: 0.8083513

federated global round: 7, step: 1
select part of clients to conduct local training
[0, 6, 13, 5]
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/52, Loss=0.8152976006269455
Loss made of: CE 0.5785521864891052, LKD 0.41341978311538696, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.775906303524971
Loss made of: CE 0.33067238330841064, LKD 0.4363532066345215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.6804688006639481
Loss made of: CE 0.30478838086128235, LKD 0.34168657660484314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.6200913697481155
Loss made of: CE 0.2722063362598419, LKD 0.2800259590148926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.6664428040385246
Loss made of: CE 0.21385638415813446, LKD 0.238770991563797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3408201038837433, Reg Loss=0.3662083148956299
Clinet index 0, End of Epoch 1/6, Average Loss=0.7070283889770508, Class Loss=0.3408201038837433, Reg Loss=0.3662083148956299
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/52, Loss=0.6325359866023064
Loss made of: CE 0.28316715359687805, LKD 0.39841556549072266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.6532004222273826
Loss made of: CE 0.2551480531692505, LKD 0.35998019576072693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.6567790776491165
Loss made of: CE 0.30896127223968506, LKD 0.3152979016304016, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.6580315038561821
Loss made of: CE 0.2847440242767334, LKD 0.4677555561065674, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.6491717115044594
Loss made of: CE 0.3149666488170624, LKD 0.4001408517360687, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2702891230583191, Reg Loss=0.37275877594947815
Clinet index 0, End of Epoch 2/6, Average Loss=0.6430479288101196, Class Loss=0.2702891230583191, Reg Loss=0.37275877594947815
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/52, Loss=0.6238328501582145
Loss made of: CE 0.21070413291454315, LKD 0.38982510566711426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.6946199879050254
Loss made of: CE 0.23818658292293549, LKD 0.362373948097229, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.6441269025206566
Loss made of: CE 0.34802234172821045, LKD 0.555396556854248, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.6297607004642487
Loss made of: CE 0.24277719855308533, LKD 0.27917155623435974, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.5710101783275604
Loss made of: CE 0.23696860671043396, LKD 0.36475762724876404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2557494044303894, Reg Loss=0.3737074136734009
Clinet index 0, End of Epoch 3/6, Average Loss=0.6294568181037903, Class Loss=0.2557494044303894, Reg Loss=0.3737074136734009
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/52, Loss=0.6320391282439232
Loss made of: CE 0.3432180881500244, LKD 0.4676297903060913, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.5763552144169808
Loss made of: CE 0.179592102766037, LKD 0.3707396984100342, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.6209855318069458
Loss made of: CE 0.2048918604850769, LKD 0.3388219475746155, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.6177950009703637
Loss made of: CE 0.18824106454849243, LKD 0.2436804473400116, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.5460110321640969
Loss made of: CE 0.19919995963573456, LKD 0.35869884490966797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2329980432987213, Reg Loss=0.36429107189178467
Clinet index 0, End of Epoch 4/6, Average Loss=0.5972890853881836, Class Loss=0.2329980432987213, Reg Loss=0.36429107189178467
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/52, Loss=0.5972779065370559
Loss made of: CE 0.28347617387771606, LKD 0.39158934354782104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.5783696472644806
Loss made of: CE 0.17143523693084717, LKD 0.3789304196834564, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.6038240969181061
Loss made of: CE 0.23535308241844177, LKD 0.3224412798881531, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.5680353716015816
Loss made of: CE 0.25376513600349426, LKD 0.37890028953552246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.6006666079163552
Loss made of: CE 0.2302822768688202, LKD 0.4065840244293213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22575683891773224, Reg Loss=0.36774736642837524
Clinet index 0, End of Epoch 5/6, Average Loss=0.5935041904449463, Class Loss=0.22575683891773224, Reg Loss=0.36774736642837524
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/52, Loss=0.5596872821450234
Loss made of: CE 0.21645104885101318, LKD 0.37659305334091187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.6258899793028831
Loss made of: CE 0.19429640471935272, LKD 0.3611482083797455, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.6429476320743561
Loss made of: CE 0.2642672657966614, LKD 0.28688478469848633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.565390145778656
Loss made of: CE 0.19399534165859222, LKD 0.24238470196723938, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.576575443148613
Loss made of: CE 0.2062797248363495, LKD 0.24021486937999725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22485943138599396, Reg Loss=0.37071123719215393
Clinet index 0, End of Epoch 6/6, Average Loss=0.5955706834793091, Class Loss=0.22485943138599396, Reg Loss=0.37071123719215393
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/34, Loss=0.8571725189685822
Loss made of: CE 0.510787844657898, LKD 0.3333272635936737, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.7492124140262604
Loss made of: CE 0.2496509850025177, LKD 0.3822266757488251, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.8180287212133408
Loss made of: CE 0.3152831494808197, LKD 0.4103568494319916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3650088608264923, Reg Loss=0.4263172745704651
Clinet index 6, End of Epoch 1/6, Average Loss=0.7913261651992798, Class Loss=0.3650088608264923, Reg Loss=0.4263172745704651
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/34, Loss=0.655554823577404
Loss made of: CE 0.26562175154685974, LKD 0.4450734853744507, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.6544391185045242
Loss made of: CE 0.27680525183677673, LKD 0.42660921812057495, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.7259397864341736
Loss made of: CE 0.24901090562343597, LKD 0.5854457020759583, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2649320960044861, Reg Loss=0.409508615732193
Clinet index 6, End of Epoch 2/6, Average Loss=0.6744407415390015, Class Loss=0.2649320960044861, Reg Loss=0.409508615732193
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/34, Loss=0.6509183928370476
Loss made of: CE 0.26054903864860535, LKD 0.42838943004608154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.6542086511850357
Loss made of: CE 0.20487754046916962, LKD 0.3319091200828552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.6900064006447792
Loss made of: CE 0.2553706169128418, LKD 0.39989155530929565, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2532983720302582, Reg Loss=0.4133843183517456
Clinet index 6, End of Epoch 3/6, Average Loss=0.6666827201843262, Class Loss=0.2532983720302582, Reg Loss=0.4133843183517456
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/34, Loss=0.6778252333402633
Loss made of: CE 0.2181628942489624, LKD 0.3716556429862976, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.6017143458127976
Loss made of: CE 0.2451077401638031, LKD 0.2922026813030243, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.6726072937250137
Loss made of: CE 0.3729684352874756, LKD 0.4555797278881073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24783308804035187, Reg Loss=0.40451234579086304
Clinet index 6, End of Epoch 4/6, Average Loss=0.6523454189300537, Class Loss=0.24783308804035187, Reg Loss=0.40451234579086304
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/34, Loss=0.6524913787841797
Loss made of: CE 0.21006155014038086, LKD 0.34083378314971924, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.6488520666956902
Loss made of: CE 0.289879709482193, LKD 0.6138514280319214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.6196494311094284
Loss made of: CE 0.23269253969192505, LKD 0.47739553451538086, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.239032581448555, Reg Loss=0.4049856960773468
Clinet index 6, End of Epoch 5/6, Average Loss=0.644018292427063, Class Loss=0.239032581448555, Reg Loss=0.4049856960773468
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/34, Loss=0.6576282307505608
Loss made of: CE 0.22940000891685486, LKD 0.2643645405769348, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.6201193615794182
Loss made of: CE 0.30287253856658936, LKD 0.46058711409568787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.6275743201375008
Loss made of: CE 0.20801126956939697, LKD 0.4149877429008484, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23263265192508698, Reg Loss=0.40189358592033386
Clinet index 6, End of Epoch 6/6, Average Loss=0.634526252746582, Class Loss=0.23263265192508698, Reg Loss=0.40189358592033386
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=1.193006730079651
Loss made of: CE 0.6394939422607422, LKD 0.4519728124141693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=1.0226172178983688
Loss made of: CE 0.6290445327758789, LKD 0.25835666060447693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.7697385177016258
Loss made of: CE 0.3764622211456299, LKD 0.3343317210674286, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6225327253341675, Reg Loss=0.3554608225822449
Clinet index 13, End of Epoch 1/6, Average Loss=0.9779935479164124, Class Loss=0.6225327253341675, Reg Loss=0.3554608225822449
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/33, Loss=0.6538669660687446
Loss made of: CE 0.38264259696006775, LKD 0.38564175367355347, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.6347658425569535
Loss made of: CE 0.2531457543373108, LKD 0.2843860983848572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.5711728900671005
Loss made of: CE 0.4249422550201416, LKD 0.3733709752559662, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31488552689552307, Reg Loss=0.3012567460536957
Clinet index 13, End of Epoch 2/6, Average Loss=0.6161422729492188, Class Loss=0.31488552689552307, Reg Loss=0.3012567460536957
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/33, Loss=0.5956821799278259
Loss made of: CE 0.27013134956359863, LKD 0.279643714427948, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.5652445510029793
Loss made of: CE 0.23005740344524384, LKD 0.36347055435180664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.5492027521133422
Loss made of: CE 0.2189016044139862, LKD 0.24227991700172424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.26239731907844543, Reg Loss=0.30919650197029114
Clinet index 13, End of Epoch 3/6, Average Loss=0.5715938210487366, Class Loss=0.26239731907844543, Reg Loss=0.30919650197029114
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/33, Loss=0.5458679974079133
Loss made of: CE 0.1866304874420166, LKD 0.1979609578847885, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.5051932856440544
Loss made of: CE 0.28416574001312256, LKD 0.26674214005470276, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.5182127520442009
Loss made of: CE 0.23410555720329285, LKD 0.2649756073951721, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2294594794511795, Reg Loss=0.29169487953186035
Clinet index 13, End of Epoch 4/6, Average Loss=0.5211543440818787, Class Loss=0.2294594794511795, Reg Loss=0.29169487953186035
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/33, Loss=0.5290462225675583
Loss made of: CE 0.2292420119047165, LKD 0.3603406846523285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.5466873452067376
Loss made of: CE 0.20030704140663147, LKD 0.2688019275665283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.5231979861855507
Loss made of: CE 0.17654874920845032, LKD 0.1966656744480133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2199009209871292, Reg Loss=0.3060474097728729
Clinet index 13, End of Epoch 5/6, Average Loss=0.5259483456611633, Class Loss=0.2199009209871292, Reg Loss=0.3060474097728729
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/33, Loss=0.5731881842017174
Loss made of: CE 0.2910512089729309, LKD 0.34086817502975464, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.49480993002653123
Loss made of: CE 0.17707133293151855, LKD 0.32040393352508545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.5071869283914566
Loss made of: CE 0.19254618883132935, LKD 0.19138526916503906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21572740375995636, Reg Loss=0.296935498714447
Clinet index 13, End of Epoch 6/6, Average Loss=0.5126628875732422, Class Loss=0.21572740375995636, Reg Loss=0.296935498714447
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/34, Loss=0.8736383855342865
Loss made of: CE 0.4816816449165344, LKD 0.37881308794021606, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.7943513333797455
Loss made of: CE 0.32984641194343567, LKD 0.45728635787963867, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.7572135016322136
Loss made of: CE 0.3100709319114685, LKD 0.7609013915061951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3669625222682953, Reg Loss=0.4376205503940582
Clinet index 5, End of Epoch 1/6, Average Loss=0.8045830726623535, Class Loss=0.3669625222682953, Reg Loss=0.4376205503940582
Pseudo labeling is: None
Epoch 2, lr = 0.000733
Epoch 2, Batch 10/34, Loss=0.7462326988577843
Loss made of: CE 0.21702226996421814, LKD 0.35892337560653687, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.6250622063875199
Loss made of: CE 0.26662781834602356, LKD 0.3763297200202942, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.7244838297367096
Loss made of: CE 0.32326990365982056, LKD 0.6027036905288696, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2726081311702728, Reg Loss=0.42054659128189087
Clinet index 5, End of Epoch 2/6, Average Loss=0.6931546926498413, Class Loss=0.2726081311702728, Reg Loss=0.42054659128189087
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/34, Loss=0.6425752356648445
Loss made of: CE 0.2509608864784241, LKD 0.4586687982082367, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.633378367125988
Loss made of: CE 0.2394903153181076, LKD 0.4594154953956604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.7015168517827988
Loss made of: CE 0.26721930503845215, LKD 0.46664202213287354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.24397550523281097, Reg Loss=0.41812288761138916
Clinet index 5, End of Epoch 3/6, Average Loss=0.6620984077453613, Class Loss=0.24397550523281097, Reg Loss=0.41812288761138916
Pseudo labeling is: None
Epoch 4, lr = 0.000655
Epoch 4, Batch 10/34, Loss=0.6421076402068138
Loss made of: CE 0.22877603769302368, LKD 0.38072213530540466, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.6749795123934745
Loss made of: CE 0.2641197144985199, LKD 0.4393617808818817, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.6463297724723815
Loss made of: CE 0.2852681279182434, LKD 0.43396899104118347, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2431766837835312, Reg Loss=0.40931713581085205
Clinet index 5, End of Epoch 4/6, Average Loss=0.6524938344955444, Class Loss=0.2431766837835312, Reg Loss=0.40931713581085205
Pseudo labeling is: None
Epoch 5, lr = 0.000616
Epoch 5, Batch 10/34, Loss=0.6604999586939811
Loss made of: CE 0.25189587473869324, LKD 0.4620850086212158, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.610828809440136
Loss made of: CE 0.2596370577812195, LKD 0.3729003369808197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.6800048172473907
Loss made of: CE 0.23388426005840302, LKD 0.4803871810436249, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23438391089439392, Reg Loss=0.415343314409256
Clinet index 5, End of Epoch 5/6, Average Loss=0.6497272253036499, Class Loss=0.23438391089439392, Reg Loss=0.415343314409256
Pseudo labeling is: None
Epoch 6, lr = 0.000576
Epoch 6, Batch 10/34, Loss=0.6990730658173561
Loss made of: CE 0.25089263916015625, LKD 0.442981481552124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.5897743478417397
Loss made of: CE 0.1958596110343933, LKD 0.37319302558898926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.660242635011673
Loss made of: CE 0.30065056681632996, LKD 0.5532008409500122, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.23606126010417938, Reg Loss=0.41461992263793945
Clinet index 5, End of Epoch 6/6, Average Loss=0.65068119764328, Class Loss=0.23606126010417938, Reg Loss=0.41461992263793945
federated aggregation...
Validation, Class Loss=0.23845313489437103, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.928066
Mean Acc: 0.694535
FreqW Acc: 0.869601
Mean IoU: 0.612588
Class IoU:
	class 0: 0.9285151
	class 1: 0.7986941
	class 2: 0.19776243
	class 3: 0.68514854
	class 4: 0.5971822
	class 5: 0.0
	class 6: 0.85089004
	class 7: 0.7145382
	class 8: 0.7405575
Class Acc:
	class 0: 0.9788992
	class 1: 0.8161868
	class 2: 0.30274326
	class 3: 0.8177528
	class 4: 0.7641909
	class 5: 0.0
	class 6: 0.9306195
	class 7: 0.7777434
	class 8: 0.86267453

federated global round: 8, step: 1
select part of clients to conduct local training
[4, 11, 9, 6]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/25, Loss=0.845348808169365
Loss made of: CE 0.5039733648300171, LKD 0.3049513101577759, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/25, Loss=0.692959901690483
Loss made of: CE 0.3567908704280853, LKD 0.27601855993270874, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.46577906608581543, Reg Loss=0.27980920672416687
Clinet index 4, End of Epoch 1/6, Average Loss=0.7455883026123047, Class Loss=0.46577906608581543, Reg Loss=0.27980920672416687
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/25, Loss=0.6132686287164688
Loss made of: CE 0.33790525794029236, LKD 0.2011224925518036, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/25, Loss=0.5126598939299584
Loss made of: CE 0.3569999933242798, LKD 0.3761085271835327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.31563428044319153, Reg Loss=0.25153258442878723
Clinet index 4, End of Epoch 2/6, Average Loss=0.5671668648719788, Class Loss=0.31563428044319153, Reg Loss=0.25153258442878723
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/25, Loss=0.5100443691015244
Loss made of: CE 0.2400682419538498, LKD 0.21492378413677216, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/25, Loss=0.5512436553835869
Loss made of: CE 0.2672681212425232, LKD 0.2656388580799103, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27539652585983276, Reg Loss=0.25221380591392517
Clinet index 4, End of Epoch 3/6, Average Loss=0.5276103019714355, Class Loss=0.27539652585983276, Reg Loss=0.25221380591392517
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/25, Loss=0.5080673262476921
Loss made of: CE 0.22689354419708252, LKD 0.25318750739097595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/25, Loss=0.46066252142190933
Loss made of: CE 0.20561008155345917, LKD 0.37377530336380005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2274981439113617, Reg Loss=0.24380208551883698
Clinet index 4, End of Epoch 4/6, Average Loss=0.47130024433135986, Class Loss=0.2274981439113617, Reg Loss=0.24380208551883698
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/25, Loss=0.467527462542057
Loss made of: CE 0.1726292073726654, LKD 0.27503538131713867, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/25, Loss=0.5225011244416237
Loss made of: CE 0.4391457438468933, LKD 0.3134216070175171, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23160722851753235, Reg Loss=0.24491249024868011
Clinet index 4, End of Epoch 5/6, Average Loss=0.47651970386505127, Class Loss=0.23160722851753235, Reg Loss=0.24491249024868011
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/25, Loss=0.4389181837439537
Loss made of: CE 0.2325018346309662, LKD 0.31096532940864563, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/25, Loss=0.45268484503030776
Loss made of: CE 0.22009317576885223, LKD 0.23319397866725922, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.19493484497070312, Reg Loss=0.24842582643032074
Clinet index 4, End of Epoch 6/6, Average Loss=0.44336068630218506, Class Loss=0.19493484497070312, Reg Loss=0.24842582643032074
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/43, Loss=0.8052471235394478
Loss made of: CE 0.34791362285614014, LKD 0.22363781929016113, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/43, Loss=0.7379260063171387
Loss made of: CE 0.47439372539520264, LKD 0.3585413694381714, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/43, Loss=0.633342333137989
Loss made of: CE 0.28591763973236084, LKD 0.22558289766311646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/43, Loss=0.601605835556984
Loss made of: CE 0.3924718499183655, LKD 0.36572903394699097, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3953508734703064, Reg Loss=0.290759801864624
Clinet index 11, End of Epoch 1/6, Average Loss=0.6861106753349304, Class Loss=0.3953508734703064, Reg Loss=0.290759801864624
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/43, Loss=0.5310718104243278
Loss made of: CE 0.2151622623205185, LKD 0.16633164882659912, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/43, Loss=0.5394799470901489
Loss made of: CE 0.2107814997434616, LKD 0.22001111507415771, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/43, Loss=0.569904588162899
Loss made of: CE 0.3533705174922943, LKD 0.3033074140548706, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/43, Loss=0.5700276643037796
Loss made of: CE 0.27258235216140747, LKD 0.18798556923866272, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2783316969871521, Reg Loss=0.27584198117256165
Clinet index 11, End of Epoch 2/6, Average Loss=0.5541737079620361, Class Loss=0.2783316969871521, Reg Loss=0.27584198117256165
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/43, Loss=0.5486340418457984
Loss made of: CE 0.2646694779396057, LKD 0.2936694622039795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/43, Loss=0.48992935568094254
Loss made of: CE 0.21166491508483887, LKD 0.18398845195770264, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/43, Loss=0.5060340315103531
Loss made of: CE 0.28040647506713867, LKD 0.23659305274486542, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/43, Loss=0.5763380974531174
Loss made of: CE 0.1626676768064499, LKD 0.22698050737380981, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25480759143829346, Reg Loss=0.27390602231025696
Clinet index 11, End of Epoch 3/6, Average Loss=0.528713583946228, Class Loss=0.25480759143829346, Reg Loss=0.27390602231025696
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/43, Loss=0.508553895354271
Loss made of: CE 0.3020181357860565, LKD 0.39527249336242676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/43, Loss=0.4843805760145187
Loss made of: CE 0.2516055703163147, LKD 0.34012269973754883, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/43, Loss=0.5004687741398811
Loss made of: CE 0.24002861976623535, LKD 0.2297198474407196, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/43, Loss=0.5356207340955734
Loss made of: CE 0.19437459111213684, LKD 0.20234793424606323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22951717674732208, Reg Loss=0.2724473476409912
Clinet index 11, End of Epoch 4/6, Average Loss=0.5019645094871521, Class Loss=0.22951717674732208, Reg Loss=0.2724473476409912
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/43, Loss=0.5107619509100914
Loss made of: CE 0.17073273658752441, LKD 0.34355753660202026, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/43, Loss=0.48324463367462156
Loss made of: CE 0.24235843122005463, LKD 0.23427610099315643, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/43, Loss=0.5249907195568084
Loss made of: CE 0.20837819576263428, LKD 0.20004944503307343, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/43, Loss=0.4691665068268776
Loss made of: CE 0.1739710420370102, LKD 0.2468174695968628, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.22442151606082916, Reg Loss=0.276242733001709
Clinet index 11, End of Epoch 5/6, Average Loss=0.500664234161377, Class Loss=0.22442151606082916, Reg Loss=0.276242733001709
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/43, Loss=0.4372818320989609
Loss made of: CE 0.1913822740316391, LKD 0.22873958945274353, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/43, Loss=0.45956253707408906
Loss made of: CE 0.1986747682094574, LKD 0.17526690661907196, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/43, Loss=0.48862890154123306
Loss made of: CE 0.19428789615631104, LKD 0.31627678871154785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/43, Loss=0.4873721644282341
Loss made of: CE 0.24037468433380127, LKD 0.26240408420562744, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2030506134033203, Reg Loss=0.2681526243686676
Clinet index 11, End of Epoch 6/6, Average Loss=0.4712032377719879, Class Loss=0.2030506134033203, Reg Loss=0.2681526243686676
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/52, Loss=0.6727415636181832
Loss made of: CE 0.33647507429122925, LKD 0.44049549102783203, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.6703236043453217
Loss made of: CE 0.23038630187511444, LKD 0.44734954833984375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.6450655922293663
Loss made of: CE 0.2429124116897583, LKD 0.36519521474838257, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.6223876357078553
Loss made of: CE 0.2902514338493347, LKD 0.3943461775779724, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.6551895886659622
Loss made of: CE 0.25501471757888794, LKD 0.288385272026062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2659439444541931, Reg Loss=0.38488146662712097
Clinet index 9, End of Epoch 1/6, Average Loss=0.6508253812789917, Class Loss=0.2659439444541931, Reg Loss=0.38488146662712097
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/52, Loss=0.614798666536808
Loss made of: CE 0.2359883040189743, LKD 0.3867788314819336, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.6569159910082817
Loss made of: CE 0.24624642729759216, LKD 0.43115267157554626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.6796193644404411
Loss made of: CE 0.249629944562912, LKD 0.44730815291404724, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.5647285148501396
Loss made of: CE 0.1904102861881256, LKD 0.30581021308898926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.6111918300390243
Loss made of: CE 0.2030077427625656, LKD 0.34657716751098633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24292132258415222, Reg Loss=0.39421841502189636
Clinet index 9, End of Epoch 2/6, Average Loss=0.6371397376060486, Class Loss=0.24292132258415222, Reg Loss=0.39421841502189636
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/52, Loss=0.6021633997559548
Loss made of: CE 0.25862622261047363, LKD 0.4838358759880066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.5655000120401382
Loss made of: CE 0.20259085297584534, LKD 0.30489298701286316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.6293598040938377
Loss made of: CE 0.2197808474302292, LKD 0.33109158277511597, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.6453204736113548
Loss made of: CE 0.26298412680625916, LKD 0.45689618587493896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.6001731589436531
Loss made of: CE 0.20222829282283783, LKD 0.40664511919021606, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22612060606479645, Reg Loss=0.3897791802883148
Clinet index 9, End of Epoch 3/6, Average Loss=0.6158998012542725, Class Loss=0.22612060606479645, Reg Loss=0.3897791802883148
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/52, Loss=0.628415122628212
Loss made of: CE 0.213657945394516, LKD 0.40793377161026, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.6230296403169632
Loss made of: CE 0.22594982385635376, LKD 0.3488330543041229, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.5796770632266999
Loss made of: CE 0.2237517535686493, LKD 0.35588738322257996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.6048507496714592
Loss made of: CE 0.18694089353084564, LKD 0.43582677841186523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.5864426329731941
Loss made of: CE 0.22672495245933533, LKD 0.5063961148262024, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2178475558757782, Reg Loss=0.3854113221168518
Clinet index 9, End of Epoch 4/6, Average Loss=0.6032588481903076, Class Loss=0.2178475558757782, Reg Loss=0.3854113221168518
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/52, Loss=0.5855250597000122
Loss made of: CE 0.17709499597549438, LKD 0.27168482542037964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.5947711378335953
Loss made of: CE 0.2219284474849701, LKD 0.35646653175354004, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.5914411514997482
Loss made of: CE 0.2405218780040741, LKD 0.5299355983734131, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.6244351327419281
Loss made of: CE 0.21503375470638275, LKD 0.4178808629512787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.5804055228829383
Loss made of: CE 0.23459383845329285, LKD 0.4229419231414795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21322649717330933, Reg Loss=0.38063135743141174
Clinet index 9, End of Epoch 5/6, Average Loss=0.5938578844070435, Class Loss=0.21322649717330933, Reg Loss=0.38063135743141174
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/52, Loss=0.560958169400692
Loss made of: CE 0.15829840302467346, LKD 0.3447515666484833, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.6220970422029495
Loss made of: CE 0.18033385276794434, LKD 0.3712587356567383, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.6085328549146652
Loss made of: CE 0.16948281228542328, LKD 0.38310110569000244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.614337632060051
Loss made of: CE 0.21470193564891815, LKD 0.43823736906051636, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.5414084598422051
Loss made of: CE 0.18071362376213074, LKD 0.36358484625816345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20727819204330444, Reg Loss=0.38091129064559937
Clinet index 9, End of Epoch 6/6, Average Loss=0.5881894826889038, Class Loss=0.20727819204330444, Reg Loss=0.38091129064559937
Current Client Index:  6
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/34, Loss=0.7109779596328736
Loss made of: CE 0.3712701201438904, LKD 0.30587950348854065, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.6689640298485756
Loss made of: CE 0.21914154291152954, LKD 0.40332576632499695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.7813319772481918
Loss made of: CE 0.24528837203979492, LKD 0.4289987087249756, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.28862854838371277, Reg Loss=0.4183182418346405
Clinet index 6, End of Epoch 1/6, Average Loss=0.7069467902183533, Class Loss=0.28862854838371277, Reg Loss=0.4183182418346405
Pseudo labeling is: None
Epoch 2, lr = 0.000525
Epoch 2, Batch 10/34, Loss=0.6357594504952431
Loss made of: CE 0.25560930371284485, LKD 0.4518388509750366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.6501227423548699
Loss made of: CE 0.2149360477924347, LKD 0.41937875747680664, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.6887758150696754
Loss made of: CE 0.2185022085905075, LKD 0.5384387969970703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2417217642068863, Reg Loss=0.4087843894958496
Clinet index 6, End of Epoch 2/6, Average Loss=0.6505061388015747, Class Loss=0.2417217642068863, Reg Loss=0.4087843894958496
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/34, Loss=0.6138949513435363
Loss made of: CE 0.21557718515396118, LKD 0.5023497939109802, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.6367286428809166
Loss made of: CE 0.1822044849395752, LKD 0.3443741202354431, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.6526343867182731
Loss made of: CE 0.1989906132221222, LKD 0.40909990668296814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.230914905667305, Reg Loss=0.4061511754989624
Clinet index 6, End of Epoch 3/6, Average Loss=0.6370660662651062, Class Loss=0.230914905667305, Reg Loss=0.4061511754989624
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/34, Loss=0.6482857525348663
Loss made of: CE 0.19945001602172852, LKD 0.315105140209198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.5756841763854027
Loss made of: CE 0.2232241928577423, LKD 0.3632500171661377, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.6782795190811157
Loss made of: CE 0.3392776846885681, LKD 0.4540861248970032, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23099945485591888, Reg Loss=0.40156498551368713
Clinet index 6, End of Epoch 4/6, Average Loss=0.6325644254684448, Class Loss=0.23099945485591888, Reg Loss=0.40156498551368713
Pseudo labeling is: None
Epoch 5, lr = 0.000394
Epoch 5, Batch 10/34, Loss=0.6435503184795379
Loss made of: CE 0.18842026591300964, LKD 0.39042505621910095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.6330784320831299
Loss made of: CE 0.3138842284679413, LKD 0.6136727929115295, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.6036777198314667
Loss made of: CE 0.20398467779159546, LKD 0.45100969076156616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2242235541343689, Reg Loss=0.40461474657058716
Clinet index 6, End of Epoch 5/6, Average Loss=0.628838300704956, Class Loss=0.2242235541343689, Reg Loss=0.40461474657058716
Pseudo labeling is: None
Epoch 6, lr = 0.000350
Epoch 6, Batch 10/34, Loss=0.661887115240097
Loss made of: CE 0.2217269390821457, LKD 0.28700917959213257, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.6082977935671806
Loss made of: CE 0.2851867079734802, LKD 0.48164090514183044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.6030299603939057
Loss made of: CE 0.18554386496543884, LKD 0.3957170248031616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22484928369522095, Reg Loss=0.3994934558868408
Clinet index 6, End of Epoch 6/6, Average Loss=0.6243427395820618, Class Loss=0.22484928369522095, Reg Loss=0.3994934558868408
federated aggregation...
Validation, Class Loss=0.2108801156282425, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.931003
Mean Acc: 0.710018
FreqW Acc: 0.874808
Mean IoU: 0.626969
Class IoU:
	class 0: 0.9314679
	class 1: 0.80569094
	class 2: 0.20155832
	class 3: 0.6686625
	class 4: 0.614243
	class 5: 0.074650094
	class 6: 0.8799615
	class 7: 0.7400367
	class 8: 0.72645074
Class Acc:
	class 0: 0.98112553
	class 1: 0.82670486
	class 2: 0.3021756
	class 3: 0.858604
	class 4: 0.78187716
	class 5: 0.07476922
	class 6: 0.9329183
	class 7: 0.8386383
	class 8: 0.79334897

federated global round: 9, step: 1
select part of clients to conduct local training
[5, 0, 9, 2]
Current Client Index:  5
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/34, Loss=0.8175689980387688
Loss made of: CE 0.36067652702331543, LKD 0.3423638939857483, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/34, Loss=0.7829817831516266
Loss made of: CE 0.37554439902305603, LKD 0.46199989318847656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/34, Loss=0.7288224771618843
Loss made of: CE 0.3830852508544922, LKD 0.7462837100028992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.33893445134162903, Reg Loss=0.4395444691181183
Clinet index 5, End of Epoch 1/6, Average Loss=0.7784789204597473, Class Loss=0.33893445134162903, Reg Loss=0.4395444691181183
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/34, Loss=0.7048052996397018
Loss made of: CE 0.2054266631603241, LKD 0.37615466117858887, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/34, Loss=0.6002896547317504
Loss made of: CE 0.23472926020622253, LKD 0.4326813220977783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/34, Loss=0.7269353225827218
Loss made of: CE 0.31553685665130615, LKD 0.5685607194900513, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.24320383369922638, Reg Loss=0.4302651286125183
Clinet index 5, End of Epoch 2/6, Average Loss=0.6734689474105835, Class Loss=0.24320383369922638, Reg Loss=0.4302651286125183
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/34, Loss=0.6228036001324654
Loss made of: CE 0.22479388117790222, LKD 0.4677395224571228, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/34, Loss=0.587085784971714
Loss made of: CE 0.22965285181999207, LKD 0.37533557415008545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/34, Loss=0.6927068024873734
Loss made of: CE 0.29930564761161804, LKD 0.5428744554519653, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.23063696920871735, Reg Loss=0.4179392158985138
Clinet index 5, End of Epoch 3/6, Average Loss=0.6485762000083923, Class Loss=0.23063696920871735, Reg Loss=0.4179392158985138
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/34, Loss=0.6245009779930115
Loss made of: CE 0.2283339500427246, LKD 0.3665606379508972, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/34, Loss=0.6615607723593712
Loss made of: CE 0.2927369475364685, LKD 0.4480053782463074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/34, Loss=0.6149520576000214
Loss made of: CE 0.22945281863212585, LKD 0.4380478262901306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2244245409965515, Reg Loss=0.40869277715682983
Clinet index 5, End of Epoch 4/6, Average Loss=0.6331173181533813, Class Loss=0.2244245409965515, Reg Loss=0.40869277715682983
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/34, Loss=0.6449223980307579
Loss made of: CE 0.2153831422328949, LKD 0.45332640409469604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/34, Loss=0.611987079679966
Loss made of: CE 0.2370353639125824, LKD 0.3750919699668884, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/34, Loss=0.6538528725504875
Loss made of: CE 0.24457022547721863, LKD 0.40772613883018494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2220969796180725, Reg Loss=0.4161592721939087
Clinet index 5, End of Epoch 5/6, Average Loss=0.6382562518119812, Class Loss=0.2220969796180725, Reg Loss=0.4161592721939087
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/34, Loss=0.6972958445549011
Loss made of: CE 0.25108492374420166, LKD 0.40187859535217285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/34, Loss=0.5992476761341095
Loss made of: CE 0.17893853783607483, LKD 0.3823811709880829, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/34, Loss=0.6581251457333565
Loss made of: CE 0.31104791164398193, LKD 0.5948339700698853, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22813713550567627, Reg Loss=0.42302361130714417
Clinet index 5, End of Epoch 6/6, Average Loss=0.651160717010498, Class Loss=0.22813713550567627, Reg Loss=0.42302361130714417
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/52, Loss=0.7043570905923844
Loss made of: CE 0.4048091769218445, LKD 0.38263314962387085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.6487683832645417
Loss made of: CE 0.26533016562461853, LKD 0.48570141196250916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.6075613781809807
Loss made of: CE 0.22539186477661133, LKD 0.2958669066429138, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.550929170846939
Loss made of: CE 0.22021429240703583, LKD 0.2721174955368042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.6288624122738838
Loss made of: CE 0.19170956313610077, LKD 0.2603740692138672, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.263383150100708, Reg Loss=0.3643178343772888
Clinet index 0, End of Epoch 1/6, Average Loss=0.6277009844779968, Class Loss=0.263383150100708, Reg Loss=0.3643178343772888
Pseudo labeling is: None
Epoch 2, lr = 0.000482
Epoch 2, Batch 10/52, Loss=0.5839352861046792
Loss made of: CE 0.2427574247121811, LKD 0.37072011828422546, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.6024572968482971
Loss made of: CE 0.19752871990203857, LKD 0.33448153734207153, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.6284993603825569
Loss made of: CE 0.26571139693260193, LKD 0.264904260635376, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.5942280814051628
Loss made of: CE 0.25990527868270874, LKD 0.45180079340934753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.5835016772150994
Loss made of: CE 0.2790071368217468, LKD 0.44240832328796387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.22543857991695404, Reg Loss=0.36661648750305176
Clinet index 0, End of Epoch 2/6, Average Loss=0.592055082321167, Class Loss=0.22543857991695404, Reg Loss=0.36661648750305176
Pseudo labeling is: None
Epoch 3, lr = 0.000394
Epoch 3, Batch 10/52, Loss=0.5977968871593475
Loss made of: CE 0.2012995481491089, LKD 0.39269524812698364, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.6423369660973549
Loss made of: CE 0.18840143084526062, LKD 0.41325968503952026, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.5842792049050332
Loss made of: CE 0.272275447845459, LKD 0.45201390981674194, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.6032703921198845
Loss made of: CE 0.21548877656459808, LKD 0.2906962037086487, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.5435174107551575
Loss made of: CE 0.2238081693649292, LKD 0.41717368364334106, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2227497547864914, Reg Loss=0.3679466247558594
Clinet index 0, End of Epoch 3/6, Average Loss=0.590696394443512, Class Loss=0.2227497547864914, Reg Loss=0.3679466247558594
Pseudo labeling is: None
Epoch 4, lr = 0.000304
Epoch 4, Batch 10/52, Loss=0.5972555235028267
Loss made of: CE 0.28635919094085693, LKD 0.4467894434928894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.5612626895308495
Loss made of: CE 0.1662205457687378, LKD 0.39582324028015137, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.5860489413142205
Loss made of: CE 0.1904977560043335, LKD 0.29051944613456726, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.6027505785226822
Loss made of: CE 0.1737070530653, LKD 0.27485159039497375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.532978005707264
Loss made of: CE 0.14882174134254456, LKD 0.3409854769706726, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.20810315012931824, Reg Loss=0.3658027648925781
Clinet index 0, End of Epoch 4/6, Average Loss=0.5739059448242188, Class Loss=0.20810315012931824, Reg Loss=0.3658027648925781
Pseudo labeling is: None
Epoch 5, lr = 0.000211
Epoch 5, Batch 10/52, Loss=0.5714944198727607
Loss made of: CE 0.23837903141975403, LKD 0.35137343406677246, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.562268503010273
Loss made of: CE 0.17232128977775574, LKD 0.34562885761260986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.5767265647649765
Loss made of: CE 0.23692312836647034, LKD 0.3331075608730316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.5637029752135276
Loss made of: CE 0.2300206422805786, LKD 0.36532825231552124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.5838406071066856
Loss made of: CE 0.2183542549610138, LKD 0.36820900440216064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21050116419792175, Reg Loss=0.3626803457736969
Clinet index 0, End of Epoch 5/6, Average Loss=0.5731815099716187, Class Loss=0.21050116419792175, Reg Loss=0.3626803457736969
Pseudo labeling is: None
Epoch 6, lr = 0.000113
Epoch 6, Batch 10/52, Loss=0.5503313481807709
Loss made of: CE 0.1947825849056244, LKD 0.3653557300567627, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.6050569981336593
Loss made of: CE 0.18459640443325043, LKD 0.3420751094818115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.5875368982553482
Loss made of: CE 0.2503228783607483, LKD 0.24431249499320984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.5568985655903816
Loss made of: CE 0.17667102813720703, LKD 0.25413617491722107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.5533245265483856
Loss made of: CE 0.18749690055847168, LKD 0.21436238288879395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2101806402206421, Reg Loss=0.36070752143859863
Clinet index 0, End of Epoch 6/6, Average Loss=0.5708881616592407, Class Loss=0.2101806402206421, Reg Loss=0.36070752143859863
Current Client Index:  9
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/52, Loss=0.6679351300001144
Loss made of: CE 0.3250773549079895, LKD 0.42997634410858154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/52, Loss=0.7065468817949295
Loss made of: CE 0.2836418151855469, LKD 0.40278586745262146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/52, Loss=0.6846171915531158
Loss made of: CE 0.23608919978141785, LKD 0.40508192777633667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/52, Loss=0.6340482711791993
Loss made of: CE 0.2885048985481262, LKD 0.4354282021522522, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/52, Loss=0.6550807401537895
Loss made of: CE 0.23628410696983337, LKD 0.27917736768722534, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2775929570198059, Reg Loss=0.39104795455932617
Clinet index 9, End of Epoch 1/6, Average Loss=0.6686409115791321, Class Loss=0.2775929570198059, Reg Loss=0.39104795455932617
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/52, Loss=0.6220598846673966
Loss made of: CE 0.27057120203971863, LKD 0.41325172781944275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/52, Loss=0.652786485850811
Loss made of: CE 0.27272331714630127, LKD 0.43278297781944275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/52, Loss=0.6624196529388428
Loss made of: CE 0.23153150081634521, LKD 0.4501482844352722, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/52, Loss=0.556351163983345
Loss made of: CE 0.17667728662490845, LKD 0.2886873483657837, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/52, Loss=0.6053425759077072
Loss made of: CE 0.20114359259605408, LKD 0.3521974980831146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2385323941707611, Reg Loss=0.39043644070625305
Clinet index 9, End of Epoch 2/6, Average Loss=0.6289688348770142, Class Loss=0.2385323941707611, Reg Loss=0.39043644070625305
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/52, Loss=0.5927282333374023
Loss made of: CE 0.2340478003025055, LKD 0.5052312612533569, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/52, Loss=0.5625682607293129
Loss made of: CE 0.2279054820537567, LKD 0.30455631017684937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/52, Loss=0.6249079212546349
Loss made of: CE 0.20594201982021332, LKD 0.30341386795043945, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/52, Loss=0.6416113436222076
Loss made of: CE 0.2317650318145752, LKD 0.40313848853111267, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/52, Loss=0.6182424262166023
Loss made of: CE 0.20781007409095764, LKD 0.3992215096950531, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.22749367356300354, Reg Loss=0.3886444866657257
Clinet index 9, End of Epoch 3/6, Average Loss=0.6161381602287292, Class Loss=0.22749367356300354, Reg Loss=0.3886444866657257
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/52, Loss=0.6128920078277588
Loss made of: CE 0.22764548659324646, LKD 0.4469783306121826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/52, Loss=0.6253369316458702
Loss made of: CE 0.24877819418907166, LKD 0.3042193353176117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/52, Loss=0.5852002203464508
Loss made of: CE 0.24806320667266846, LKD 0.36686432361602783, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/52, Loss=0.6172426030039787
Loss made of: CE 0.18678054213523865, LKD 0.4504104554653168, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/52, Loss=0.5987075358629227
Loss made of: CE 0.18174874782562256, LKD 0.46813341975212097, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.22242394089698792, Reg Loss=0.3824315071105957
Clinet index 9, End of Epoch 4/6, Average Loss=0.6048554182052612, Class Loss=0.22242394089698792, Reg Loss=0.3824315071105957
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/52, Loss=0.5879342660307885
Loss made of: CE 0.16825327277183533, LKD 0.24756979942321777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/52, Loss=0.6029585167765618
Loss made of: CE 0.21265093982219696, LKD 0.4290351867675781, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/52, Loss=0.600665645301342
Loss made of: CE 0.25451552867889404, LKD 0.49746233224868774, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/52, Loss=0.6241552963852882
Loss made of: CE 0.2269706428050995, LKD 0.42372187972068787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/52, Loss=0.5907332018017769
Loss made of: CE 0.2445061206817627, LKD 0.4028242528438568, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.21673136949539185, Reg Loss=0.38341137766838074
Clinet index 9, End of Epoch 5/6, Average Loss=0.6001427173614502, Class Loss=0.21673136949539185, Reg Loss=0.38341137766838074
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/52, Loss=0.5760953262448311
Loss made of: CE 0.17662177979946136, LKD 0.33202508091926575, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/52, Loss=0.61117984354496
Loss made of: CE 0.17895552515983582, LKD 0.3548555076122284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/52, Loss=0.6393882229924202
Loss made of: CE 0.19298294186592102, LKD 0.3995889127254486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/52, Loss=0.6322677865624428
Loss made of: CE 0.23930227756500244, LKD 0.5245858430862427, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/52, Loss=0.5430600970983506
Loss made of: CE 0.2035829722881317, LKD 0.3424856662750244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.21923880279064178, Reg Loss=0.37997668981552124
Clinet index 9, End of Epoch 6/6, Average Loss=0.5992155075073242, Class Loss=0.21923880279064178, Reg Loss=0.37997668981552124
Current Client Index:  2
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/25, Loss=0.6824824869632721
Loss made of: CE 0.35569465160369873, LKD 0.32359811663627625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/25, Loss=0.5838460236787796
Loss made of: CE 0.3938957154750824, LKD 0.2850807309150696, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3425483703613281, Reg Loss=0.2733911871910095
Clinet index 2, End of Epoch 1/6, Average Loss=0.6159395575523376, Class Loss=0.3425483703613281, Reg Loss=0.2733911871910095
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/25, Loss=0.5259585484862328
Loss made of: CE 0.25876936316490173, LKD 0.3471885323524475, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/25, Loss=0.534308385848999
Loss made of: CE 0.15424558520317078, LKD 0.24037611484527588, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2408161610364914, Reg Loss=0.2593747675418854
Clinet index 2, End of Epoch 2/6, Average Loss=0.5001909136772156, Class Loss=0.2408161610364914, Reg Loss=0.2593747675418854
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/25, Loss=0.46388030648231504
Loss made of: CE 0.15117484331130981, LKD 0.19779710471630096, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/25, Loss=0.4661065474152565
Loss made of: CE 0.20802411437034607, LKD 0.2585095763206482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21374183893203735, Reg Loss=0.24451231956481934
Clinet index 2, End of Epoch 3/6, Average Loss=0.4582541584968567, Class Loss=0.21374183893203735, Reg Loss=0.24451231956481934
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/25, Loss=0.45941525399684907
Loss made of: CE 0.21684817969799042, LKD 0.26912394165992737, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/25, Loss=0.4475878462195396
Loss made of: CE 0.1528235524892807, LKD 0.20745110511779785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.19887252151966095, Reg Loss=0.2529904246330261
Clinet index 2, End of Epoch 4/6, Average Loss=0.4518629312515259, Class Loss=0.19887252151966095, Reg Loss=0.2529904246330261
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/25, Loss=0.4389417290687561
Loss made of: CE 0.11568228900432587, LKD 0.20144686102867126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/25, Loss=0.4382244497537613
Loss made of: CE 0.190565824508667, LKD 0.2885870039463043, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18193049728870392, Reg Loss=0.2527688145637512
Clinet index 2, End of Epoch 5/6, Average Loss=0.43469929695129395, Class Loss=0.18193049728870392, Reg Loss=0.2527688145637512
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/25, Loss=0.4405030786991119
Loss made of: CE 0.2235889881849289, LKD 0.2622509002685547, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/25, Loss=0.4562531590461731
Loss made of: CE 0.19932281970977783, LKD 0.21188393235206604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1907670497894287, Reg Loss=0.24995960295200348
Clinet index 2, End of Epoch 6/6, Average Loss=0.440726637840271, Class Loss=0.1907670497894287, Reg Loss=0.24995960295200348
federated aggregation...
Validation, Class Loss=0.19744642078876495, Reg Loss=0.0 (without scaling)

Total samples: 699.000000
Overall Acc: 0.936159
Mean Acc: 0.731210
FreqW Acc: 0.884458
Mean IoU: 0.647652
Class IoU:
	class 0: 0.93703336
	class 1: 0.8189627
	class 2: 0.18729728
	class 3: 0.6719955
	class 4: 0.61784613
	class 5: 0.19672613
	class 6: 0.8892205
	class 7: 0.75176275
	class 8: 0.7580279
Class Acc:
	class 0: 0.9783778
	class 1: 0.83939475
	class 2: 0.27043617
	class 3: 0.8319843
	class 4: 0.7936748
	class 5: 0.19813319
	class 6: 0.93830264
	class 7: 0.8659922
	class 8: 0.8645894

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 10, step: 2
select part of clients to conduct local training
[0, 15, 1, 4]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=2.0869983971118926
Loss made of: CE 1.1640608310699463, LKD 0.543556809425354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.2993282079696655, Reg Loss=0.5088434219360352
Clinet index 0, End of Epoch 1/6, Average Loss=1.8081716299057007, Class Loss=1.2993282079696655, Reg Loss=0.5088434219360352
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=1.2823775649070739
Loss made of: CE 0.9479845762252808, LKD 0.4113653600215912, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8756443858146667, Reg Loss=0.3813031017780304
Clinet index 0, End of Epoch 2/6, Average Loss=1.2569475173950195, Class Loss=0.8756443858146667, Reg Loss=0.3813031017780304
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=1.1717100903391837
Loss made of: CE 0.9443203210830688, LKD 0.3721329867839813, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8085469007492065, Reg Loss=0.3172139525413513
Clinet index 0, End of Epoch 3/6, Average Loss=1.125760793685913, Class Loss=0.8085469007492065, Reg Loss=0.3172139525413513
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=1.043318635225296
Loss made of: CE 0.8014112710952759, LKD 0.24660831689834595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.7510762214660645, Reg Loss=0.3059474229812622
Clinet index 0, End of Epoch 4/6, Average Loss=1.0570236444473267, Class Loss=0.7510762214660645, Reg Loss=0.3059474229812622
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=1.018813169002533
Loss made of: CE 0.7071212530136108, LKD 0.308219850063324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6917857527732849, Reg Loss=0.30363738536834717
Clinet index 0, End of Epoch 5/6, Average Loss=0.9954231381416321, Class Loss=0.6917857527732849, Reg Loss=0.30363738536834717
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.9405180618166924
Loss made of: CE 0.593159556388855, LKD 0.24593496322631836, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.6457527875900269, Reg Loss=0.30227112770080566
Clinet index 0, End of Epoch 6/6, Average Loss=0.9480239152908325, Class Loss=0.6457527875900269, Reg Loss=0.30227112770080566
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=2.1015753984451293
Loss made of: CE 1.10239839553833, LKD 0.45634913444519043, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.3061076402664185, Reg Loss=0.5122987031936646
Clinet index 15, End of Epoch 1/6, Average Loss=1.818406343460083, Class Loss=1.3061076402664185, Reg Loss=0.5122987031936646
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=1.3584941506385804
Loss made of: CE 0.6693581938743591, LKD 0.33561253547668457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.9059206247329712, Reg Loss=0.37612274289131165
Clinet index 15, End of Epoch 2/6, Average Loss=1.2820433378219604, Class Loss=0.9059206247329712, Reg Loss=0.37612274289131165
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=1.180728268623352
Loss made of: CE 0.9194387197494507, LKD 0.29251259565353394, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8227611184120178, Reg Loss=0.30739670991897583
Clinet index 15, End of Epoch 3/6, Average Loss=1.1301578283309937, Class Loss=0.8227611184120178, Reg Loss=0.30739670991897583
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=1.0622424453496933
Loss made of: CE 0.7605384588241577, LKD 0.3022863566875458, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.7583567500114441, Reg Loss=0.29619497060775757
Clinet index 15, End of Epoch 4/6, Average Loss=1.0545517206192017, Class Loss=0.7583567500114441, Reg Loss=0.29619497060775757
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=1.0357407361268998
Loss made of: CE 0.6174184083938599, LKD 0.3136563301086426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.7045611143112183, Reg Loss=0.30463576316833496
Clinet index 15, End of Epoch 5/6, Average Loss=1.0091968774795532, Class Loss=0.7045611143112183, Reg Loss=0.30463576316833496
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.9408448278903961
Loss made of: CE 0.6232936382293701, LKD 0.2912742495536804, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.646632730960846, Reg Loss=0.30165520310401917
Clinet index 15, End of Epoch 6/6, Average Loss=0.9482879638671875, Class Loss=0.646632730960846, Reg Loss=0.30165520310401917
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/35, Loss=2.4208623111248015
Loss made of: CE 1.410912275314331, LKD 0.7162929773330688, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=1.740010106563568
Loss made of: CE 0.825675368309021, LKD 0.5399499535560608, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=1.4536562621593476
Loss made of: CE 0.8272442817687988, LKD 0.7069610953330994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.1652292013168335, Reg Loss=0.6283833980560303
Clinet index 1, End of Epoch 1/6, Average Loss=1.7936125993728638, Class Loss=1.1652292013168335, Reg Loss=0.6283833980560303
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/35, Loss=1.2615150183439254
Loss made of: CE 0.6086322069168091, LKD 0.5250155925750732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=1.2196148127317428
Loss made of: CE 0.7665146589279175, LKD 0.46240267157554626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=1.1453422635793686
Loss made of: CE 0.5087602138519287, LKD 0.5686773657798767, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6231011152267456, Reg Loss=0.5763845443725586
Clinet index 1, End of Epoch 2/6, Average Loss=1.1994856595993042, Class Loss=0.6231011152267456, Reg Loss=0.5763845443725586
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/35, Loss=1.0855114549398421
Loss made of: CE 0.5262799263000488, LKD 0.6291831731796265, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=1.0824400812387467
Loss made of: CE 0.4533827304840088, LKD 0.5912803411483765, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=1.051507756114006
Loss made of: CE 0.48804986476898193, LKD 0.586131751537323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.49743926525115967, Reg Loss=0.5533124804496765
Clinet index 1, End of Epoch 3/6, Average Loss=1.0507516860961914, Class Loss=0.49743926525115967, Reg Loss=0.5533124804496765
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/35, Loss=1.0475921422243117
Loss made of: CE 0.41197097301483154, LKD 0.5530597567558289, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.9906765103340149
Loss made of: CE 0.40787753462791443, LKD 0.44344252347946167, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=1.0062148600816727
Loss made of: CE 0.4591204822063446, LKD 0.47628068923950195, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.46028339862823486, Reg Loss=0.5533644556999207
Clinet index 1, End of Epoch 4/6, Average Loss=1.0136477947235107, Class Loss=0.46028339862823486, Reg Loss=0.5533644556999207
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/35, Loss=0.9589705228805542
Loss made of: CE 0.38331174850463867, LKD 0.5322331786155701, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=1.0511619925498963
Loss made of: CE 0.4505375325679779, LKD 0.5902633666992188, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.8890969097614289
Loss made of: CE 0.3452867865562439, LKD 0.4564841389656067, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4295145273208618, Reg Loss=0.5467281937599182
Clinet index 1, End of Epoch 5/6, Average Loss=0.97624272108078, Class Loss=0.4295145273208618, Reg Loss=0.5467281937599182
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/35, Loss=0.9328615844249726
Loss made of: CE 0.3087208867073059, LKD 0.4864434599876404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.9518062353134156
Loss made of: CE 0.39888235926628113, LKD 0.510434091091156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.9976830780506134
Loss made of: CE 0.4651818871498108, LKD 0.5004754066467285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4063315689563751, Reg Loss=0.5543330311775208
Clinet index 1, End of Epoch 6/6, Average Loss=0.9606646299362183, Class Loss=0.4063315689563751, Reg Loss=0.5543330311775208
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=2.0659979194402696
Loss made of: CE 1.3150386810302734, LKD 0.46850818395614624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.283398985862732, Reg Loss=0.5059805512428284
Clinet index 4, End of Epoch 1/6, Average Loss=1.789379596710205, Class Loss=1.283398985862732, Reg Loss=0.5059805512428284
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=1.3176699310541153
Loss made of: CE 0.8190412521362305, LKD 0.4236287474632263, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8756486177444458, Reg Loss=0.38029569387435913
Clinet index 4, End of Epoch 2/6, Average Loss=1.2559442520141602, Class Loss=0.8756486177444458, Reg Loss=0.38029569387435913
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=1.1440434157848358
Loss made of: CE 0.7037472128868103, LKD 0.31852641701698303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.8210020065307617, Reg Loss=0.3112925887107849
Clinet index 4, End of Epoch 3/6, Average Loss=1.1322946548461914, Class Loss=0.8210020065307617, Reg Loss=0.3112925887107849
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=1.0540922373533248
Loss made of: CE 0.7478272914886475, LKD 0.28498172760009766, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.747281014919281, Reg Loss=0.3050757348537445
Clinet index 4, End of Epoch 4/6, Average Loss=1.0523567199707031, Class Loss=0.747281014919281, Reg Loss=0.3050757348537445
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=1.036896187067032
Loss made of: CE 0.7201529741287231, LKD 0.3160603940486908, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6959344744682312, Reg Loss=0.3028157353401184
Clinet index 4, End of Epoch 5/6, Average Loss=0.9987502098083496, Class Loss=0.6959344744682312, Reg Loss=0.3028157353401184
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.9198912888765335
Loss made of: CE 0.590278148651123, LKD 0.25803646445274353, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.640650749206543, Reg Loss=0.30725860595703125
Clinet index 4, End of Epoch 6/6, Average Loss=0.9479093551635742, Class Loss=0.640650749206543, Reg Loss=0.30725860595703125
federated aggregation...
Validation, Class Loss=0.5098707675933838, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.856185
Mean Acc: 0.433605
FreqW Acc: 0.746919
Mean IoU: 0.367475
Class IoU:
	class 0: 0.87418675
	class 1: 0.6684245
	class 2: 0.09181933
	class 3: 0.5783845
	class 4: 0.57063586
	class 5: 0.11171889
	class 6: 0.7738743
	class 7: 0.58755684
	class 8: 0.47779518
	class 9: 0.0
	class 10: 0.042783763
	class 11: 0.0
	class 12: 0.0
Class Acc:
	class 0: 0.98999995
	class 1: 0.6795815
	class 2: 0.10536576
	class 3: 0.7264099
	class 4: 0.6621731
	class 5: 0.11201865
	class 6: 0.8006475
	class 7: 0.63549143
	class 8: 0.8823495
	class 9: 0.0
	class 10: 0.042828836
	class 11: 0.0
	class 12: 0.0

federated global round: 11, step: 2
select part of clients to conduct local training
[1, 13, 11, 12]
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/35, Loss=1.6462024480104447
Loss made of: CE 0.9373173713684082, LKD 0.7350777983665466, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=1.4548377841711044
Loss made of: CE 0.7341610193252563, LKD 0.471230685710907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=1.2426286101341248
Loss made of: CE 0.7355064749717712, LKD 0.6692304611206055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.8458847403526306, Reg Loss=0.5578152537345886
Clinet index 1, End of Epoch 1/6, Average Loss=1.4036999940872192, Class Loss=0.8458847403526306, Reg Loss=0.5578152537345886
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/35, Loss=1.1362225443124772
Loss made of: CE 0.49075543880462646, LKD 0.5007250308990479, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=1.0769538134336472
Loss made of: CE 0.6085984706878662, LKD 0.4691983461380005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=1.068943664431572
Loss made of: CE 0.4464072585105896, LKD 0.5555411577224731, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5154585838317871, Reg Loss=0.5750994682312012
Clinet index 1, End of Epoch 2/6, Average Loss=1.0905580520629883, Class Loss=0.5154585838317871, Reg Loss=0.5750994682312012
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/35, Loss=1.045491749048233
Loss made of: CE 0.44900578260421753, LKD 0.6595547199249268, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=1.0444724708795547
Loss made of: CE 0.4269770085811615, LKD 0.5623997449874878, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.9920876383781433
Loss made of: CE 0.4581245183944702, LKD 0.5860602855682373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.44878655672073364, Reg Loss=0.5567329525947571
Clinet index 1, End of Epoch 3/6, Average Loss=1.0055195093154907, Class Loss=0.44878655672073364, Reg Loss=0.5567329525947571
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/35, Loss=1.000949764251709
Loss made of: CE 0.4091219902038574, LKD 0.5568525791168213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.9237061887979507
Loss made of: CE 0.34885358810424805, LKD 0.41318249702453613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.9647247225046158
Loss made of: CE 0.38328003883361816, LKD 0.45305928587913513, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.410139262676239, Reg Loss=0.5510225892066956
Clinet index 1, End of Epoch 4/6, Average Loss=0.9611618518829346, Class Loss=0.410139262676239, Reg Loss=0.5510225892066956
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/35, Loss=0.9245719373226166
Loss made of: CE 0.36680278182029724, LKD 0.5290920734405518, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=1.0128389924764634
Loss made of: CE 0.4220421314239502, LKD 0.6469199657440186, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.8643868267536163
Loss made of: CE 0.3274990916252136, LKD 0.46743831038475037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39068102836608887, Reg Loss=0.5552402138710022
Clinet index 1, End of Epoch 5/6, Average Loss=0.9459212422370911, Class Loss=0.39068102836608887, Reg Loss=0.5552402138710022
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/35, Loss=0.9028097510337829
Loss made of: CE 0.30026206374168396, LKD 0.46287891268730164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.9237781643867493
Loss made of: CE 0.36253246665000916, LKD 0.5503652095794678, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.972510626912117
Loss made of: CE 0.40434297919273376, LKD 0.5066943168640137, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.37252745032310486, Reg Loss=0.5629298090934753
Clinet index 1, End of Epoch 6/6, Average Loss=0.9354572296142578, Class Loss=0.37252745032310486, Reg Loss=0.5629298090934753
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=1.0264761418104171
Loss made of: CE 0.6530265808105469, LKD 0.2691496014595032, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6830795407295227, Reg Loss=0.30422574281692505
Clinet index 13, End of Epoch 1/6, Average Loss=0.9873052835464478, Class Loss=0.6830795407295227, Reg Loss=0.30422574281692505
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/19, Loss=0.9701377764344216
Loss made of: CE 0.6661664843559265, LKD 0.3139222264289856, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.609804630279541, Reg Loss=0.30363208055496216
Clinet index 13, End of Epoch 2/6, Average Loss=0.9134367108345032, Class Loss=0.609804630279541, Reg Loss=0.30363208055496216
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/19, Loss=0.8810381948947906
Loss made of: CE 0.4896916151046753, LKD 0.2743474245071411, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5578982830047607, Reg Loss=0.31102827191352844
Clinet index 13, End of Epoch 3/6, Average Loss=0.8689265251159668, Class Loss=0.5578982830047607, Reg Loss=0.31102827191352844
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/19, Loss=0.8032133176922798
Loss made of: CE 0.5883290767669678, LKD 0.29254841804504395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5076066255569458, Reg Loss=0.29978060722351074
Clinet index 13, End of Epoch 4/6, Average Loss=0.8073872327804565, Class Loss=0.5076066255569458, Reg Loss=0.29978060722351074
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/19, Loss=0.7922171071171761
Loss made of: CE 0.4180086553096771, LKD 0.3310315012931824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.476791650056839, Reg Loss=0.3077484667301178
Clinet index 13, End of Epoch 5/6, Average Loss=0.7845401167869568, Class Loss=0.476791650056839, Reg Loss=0.3077484667301178
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/19, Loss=0.7421217799186707
Loss made of: CE 0.4483082890510559, LKD 0.31235599517822266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.449217289686203, Reg Loss=0.3011806011199951
Clinet index 13, End of Epoch 6/6, Average Loss=0.7503979206085205, Class Loss=0.449217289686203, Reg Loss=0.3011806011199951
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=0.9894890323281288
Loss made of: CE 0.6771056652069092, LKD 0.22685065865516663, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=0.9686785221099854
Loss made of: CE 0.6711668372154236, LKD 0.37492620944976807, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.956053963303566
Loss made of: CE 0.5469121932983398, LKD 0.3032841384410858, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6602194905281067, Reg Loss=0.299588680267334
Clinet index 11, End of Epoch 1/6, Average Loss=0.9598081707954407, Class Loss=0.6602194905281067, Reg Loss=0.299588680267334
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/33, Loss=0.8786743223667145
Loss made of: CE 0.6772362589836121, LKD 0.24215571582317352, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.859652790427208
Loss made of: CE 0.6287163496017456, LKD 0.311137318611145, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.8883193820714951
Loss made of: CE 0.5122912526130676, LKD 0.30059385299682617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5747355818748474, Reg Loss=0.2909969091415405
Clinet index 11, End of Epoch 2/6, Average Loss=0.8657324910163879, Class Loss=0.5747355818748474, Reg Loss=0.2909969091415405
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/33, Loss=0.822504936158657
Loss made of: CE 0.49894803762435913, LKD 0.3092019557952881, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.8238778442144394
Loss made of: CE 0.536787748336792, LKD 0.21511487662792206, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.8105931341648102
Loss made of: CE 0.5847358107566833, LKD 0.26688313484191895, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5271937847137451, Reg Loss=0.28618013858795166
Clinet index 11, End of Epoch 3/6, Average Loss=0.8133739233016968, Class Loss=0.5271937847137451, Reg Loss=0.28618013858795166
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/33, Loss=0.8231236666440964
Loss made of: CE 0.4686283767223358, LKD 0.289570152759552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.7911862835288048
Loss made of: CE 0.47179412841796875, LKD 0.2821504473686218, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.7937651693820953
Loss made of: CE 0.5653846859931946, LKD 0.35942596197128296, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4966793656349182, Reg Loss=0.29465872049331665
Clinet index 11, End of Epoch 4/6, Average Loss=0.7913380861282349, Class Loss=0.4966793656349182, Reg Loss=0.29465872049331665
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/33, Loss=0.7941324323415756
Loss made of: CE 0.43417251110076904, LKD 0.2936554551124573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.7410622641444207
Loss made of: CE 0.40179502964019775, LKD 0.2397514283657074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.7762895911931992
Loss made of: CE 0.5067819952964783, LKD 0.2719457745552063, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.478357195854187, Reg Loss=0.2903280556201935
Clinet index 11, End of Epoch 5/6, Average Loss=0.7686852216720581, Class Loss=0.478357195854187, Reg Loss=0.2903280556201935
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/33, Loss=0.7336978435516357
Loss made of: CE 0.4107620120048523, LKD 0.27565401792526245, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.7336549073457718
Loss made of: CE 0.4110042452812195, LKD 0.2986728549003601, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.7181025668978691
Loss made of: CE 0.38646364212036133, LKD 0.2508261799812317, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.445100873708725, Reg Loss=0.28389644622802734
Clinet index 11, End of Epoch 6/6, Average Loss=0.7289973497390747, Class Loss=0.445100873708725, Reg Loss=0.28389644622802734
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/33, Loss=0.923823145031929
Loss made of: CE 0.6542220115661621, LKD 0.27107056975364685, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/33, Loss=1.0101788222789765
Loss made of: CE 0.7627167701721191, LKD 0.34936344623565674, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/33, Loss=0.935581062734127
Loss made of: CE 0.5149171948432922, LKD 0.25821805000305176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6550024747848511, Reg Loss=0.296157568693161
Clinet index 12, End of Epoch 1/6, Average Loss=0.9511600732803345, Class Loss=0.6550024747848511, Reg Loss=0.296157568693161
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/33, Loss=0.873532173037529
Loss made of: CE 0.46518072485923767, LKD 0.27426135540008545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/33, Loss=0.8611740365624427
Loss made of: CE 0.7031618356704712, LKD 0.3721366822719574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/33, Loss=0.8554627388715744
Loss made of: CE 0.5369042754173279, LKD 0.3172522187232971, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5734819769859314, Reg Loss=0.2933397889137268
Clinet index 12, End of Epoch 2/6, Average Loss=0.8668217658996582, Class Loss=0.5734819769859314, Reg Loss=0.2933397889137268
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/33, Loss=0.8128038018941879
Loss made of: CE 0.5689180493354797, LKD 0.2706757187843323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/33, Loss=0.8239974528551102
Loss made of: CE 0.4974415898323059, LKD 0.3064989745616913, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/33, Loss=0.8105416908860207
Loss made of: CE 0.6016401052474976, LKD 0.29299286007881165, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5272434949874878, Reg Loss=0.2955959737300873
Clinet index 12, End of Epoch 3/6, Average Loss=0.8228394985198975, Class Loss=0.5272434949874878, Reg Loss=0.2955959737300873
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/33, Loss=0.8281232625246048
Loss made of: CE 0.4557993412017822, LKD 0.21416166424751282, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/33, Loss=0.7654403746128082
Loss made of: CE 0.45227617025375366, LKD 0.3517739474773407, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/33, Loss=0.7619553357362747
Loss made of: CE 0.4555168151855469, LKD 0.24416106939315796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4894084930419922, Reg Loss=0.2930563986301422
Clinet index 12, End of Epoch 4/6, Average Loss=0.782464861869812, Class Loss=0.4894084930419922, Reg Loss=0.2930563986301422
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/33, Loss=0.7656622558832169
Loss made of: CE 0.4224415719509125, LKD 0.3242356777191162, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/33, Loss=0.7555200070142746
Loss made of: CE 0.5970735549926758, LKD 0.3588702082633972, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/33, Loss=0.7633655786514282
Loss made of: CE 0.5501302480697632, LKD 0.3639655113220215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.46657952666282654, Reg Loss=0.2992907762527466
Clinet index 12, End of Epoch 5/6, Average Loss=0.7658703327178955, Class Loss=0.46657952666282654, Reg Loss=0.2992907762527466
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/33, Loss=0.7810006856918335
Loss made of: CE 0.5667657852172852, LKD 0.38586729764938354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/33, Loss=0.7590221524238586
Loss made of: CE 0.45765846967697144, LKD 0.40246784687042236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/33, Loss=0.7463329702615737
Loss made of: CE 0.4707416296005249, LKD 0.32747799158096313, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.45551833510398865, Reg Loss=0.2978856861591339
Clinet index 12, End of Epoch 6/6, Average Loss=0.7534040212631226, Class Loss=0.45551833510398865, Reg Loss=0.2978856861591339
federated aggregation...
Validation, Class Loss=0.4233461618423462, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.872342
Mean Acc: 0.527093
FreqW Acc: 0.779446
Mean IoU: 0.438362
Class IoU:
	class 0: 0.8961514
	class 1: 0.7317957
	class 2: 0.22342934
	class 3: 0.58494735
	class 4: 0.5684425
	class 5: 0.20398083
	class 6: 0.74842674
	class 7: 0.70155966
	class 8: 0.48143095
	class 9: 2.345925e-05
	class 10: 0.55842733
	class 11: 8.9757916e-05
	class 12: 0.0
Class Acc:
	class 0: 0.98319227
	class 1: 0.7448709
	class 2: 0.34593672
	class 3: 0.72035575
	class 4: 0.6918063
	class 5: 0.20517
	class 6: 0.7681943
	class 7: 0.765337
	class 8: 0.9223397
	class 9: 2.346603e-05
	class 10: 0.7048934
	class 11: 8.9763e-05
	class 12: 0.0

federated global round: 12, step: 2
select part of clients to conduct local training
[0, 16, 7, 4]
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/19, Loss=0.8568305775523186
Loss made of: CE 0.5866409540176392, LKD 0.2502380609512329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.543093204498291, Reg Loss=0.2994312047958374
Clinet index 0, End of Epoch 1/6, Average Loss=0.8425244092941284, Class Loss=0.543093204498291, Reg Loss=0.2994312047958374
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/19, Loss=0.7708763048052788
Loss made of: CE 0.5149143934249878, LKD 0.2789100408554077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.46680590510368347, Reg Loss=0.3096312880516052
Clinet index 0, End of Epoch 2/6, Average Loss=0.7764371633529663, Class Loss=0.46680590510368347, Reg Loss=0.3096312880516052
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/19, Loss=0.7931665733456612
Loss made of: CE 0.5058199167251587, LKD 0.3838692605495453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4381634593009949, Reg Loss=0.31501245498657227
Clinet index 0, End of Epoch 3/6, Average Loss=0.7531759142875671, Class Loss=0.4381634593009949, Reg Loss=0.31501245498657227
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/19, Loss=0.7148746833205223
Loss made of: CE 0.465170681476593, LKD 0.2794498801231384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41797521710395813, Reg Loss=0.3168247640132904
Clinet index 0, End of Epoch 4/6, Average Loss=0.7347999811172485, Class Loss=0.41797521710395813, Reg Loss=0.3168247640132904
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/19, Loss=0.7227335423231125
Loss made of: CE 0.43227824568748474, LKD 0.3177720010280609, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.40107181668281555, Reg Loss=0.3041938543319702
Clinet index 0, End of Epoch 5/6, Average Loss=0.7052656412124634, Class Loss=0.40107181668281555, Reg Loss=0.3041938543319702
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/19, Loss=0.6869915813207627
Loss made of: CE 0.387606143951416, LKD 0.27640020847320557, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3918790817260742, Reg Loss=0.3096117377281189
Clinet index 0, End of Epoch 6/6, Average Loss=0.7014908194541931, Class Loss=0.3918790817260742, Reg Loss=0.3096117377281189
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/42, Loss=1.3068002969026566
Loss made of: CE 0.7754541635513306, LKD 0.5506210327148438, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/42, Loss=1.1657430827617645
Loss made of: CE 0.5038478374481201, LKD 0.45641350746154785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/42, Loss=1.028843852877617
Loss made of: CE 0.5787200331687927, LKD 0.5872868299484253, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/42, Loss=0.8694794803857804
Loss made of: CE 0.393394410610199, LKD 0.42662519216537476, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.628526508808136, Reg Loss=0.4530979096889496
Clinet index 16, End of Epoch 1/6, Average Loss=1.0816243886947632, Class Loss=0.628526508808136, Reg Loss=0.4530979096889496
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/42, Loss=0.9719189375638961
Loss made of: CE 0.40572088956832886, LKD 0.46780675649642944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/42, Loss=0.9127840310335159
Loss made of: CE 0.4057580828666687, LKD 0.524010181427002, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/42, Loss=0.8418092101812362
Loss made of: CE 0.3653009533882141, LKD 0.4437428414821625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/42, Loss=0.8218967974185943
Loss made of: CE 0.40462979674339294, LKD 0.3268246054649353, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.42530232667922974, Reg Loss=0.4629771411418915
Clinet index 16, End of Epoch 2/6, Average Loss=0.8882794380187988, Class Loss=0.42530232667922974, Reg Loss=0.4629771411418915
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/42, Loss=0.8192109435796737
Loss made of: CE 0.39371490478515625, LKD 0.4325222969055176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/42, Loss=0.8180516719818115
Loss made of: CE 0.34863871335983276, LKD 0.6260671615600586, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/42, Loss=0.8237089455127716
Loss made of: CE 0.3489864468574524, LKD 0.5627787113189697, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/42, Loss=0.9484173893928528
Loss made of: CE 0.33741700649261475, LKD 0.5597803592681885, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.38688400387763977, Reg Loss=0.46223896741867065
Clinet index 16, End of Epoch 3/6, Average Loss=0.8491230010986328, Class Loss=0.38688400387763977, Reg Loss=0.46223896741867065
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/42, Loss=0.8394274264574051
Loss made of: CE 0.350167453289032, LKD 0.43007147312164307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/42, Loss=0.8461793392896653
Loss made of: CE 0.4205724596977234, LKD 0.4907020032405853, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/42, Loss=0.8198072522878647
Loss made of: CE 0.3309917151927948, LKD 0.4130835235118866, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/42, Loss=0.8136135339736938
Loss made of: CE 0.33053314685821533, LKD 0.38519996404647827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3748309314250946, Reg Loss=0.45867711305618286
Clinet index 16, End of Epoch 4/6, Average Loss=0.8335080146789551, Class Loss=0.3748309314250946, Reg Loss=0.45867711305618286
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/42, Loss=0.817570972442627
Loss made of: CE 0.361696720123291, LKD 0.42420172691345215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/42, Loss=0.8234603464603424
Loss made of: CE 0.32748502492904663, LKD 0.3876330852508545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/42, Loss=0.798311996459961
Loss made of: CE 0.41271114349365234, LKD 0.37521037459373474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/42, Loss=0.820088067650795
Loss made of: CE 0.34502360224723816, LKD 0.5942553281784058, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.35239043831825256, Reg Loss=0.4577748477458954
Clinet index 16, End of Epoch 5/6, Average Loss=0.810165286064148, Class Loss=0.35239043831825256, Reg Loss=0.4577748477458954
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/42, Loss=0.8100492089986802
Loss made of: CE 0.2773985266685486, LKD 0.4469960927963257, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/42, Loss=0.7717766642570496
Loss made of: CE 0.36982887983322144, LKD 0.3795633316040039, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/42, Loss=0.8238609135150909
Loss made of: CE 0.35114797949790955, LKD 0.41556745767593384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/42, Loss=0.8732950001955032
Loss made of: CE 0.38215598464012146, LKD 0.43896061182022095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34711647033691406, Reg Loss=0.46533435583114624
Clinet index 16, End of Epoch 6/6, Average Loss=0.8124508261680603, Class Loss=0.34711647033691406, Reg Loss=0.46533435583114624
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/31, Loss=0.843757975101471
Loss made of: CE 0.6029804944992065, LKD 0.2260158509016037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/31, Loss=0.8896239474415779
Loss made of: CE 0.625305712223053, LKD 0.27293509244918823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/31, Loss=0.8093287944793701
Loss made of: CE 0.5203672051429749, LKD 0.22591659426689148, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5867831110954285, Reg Loss=0.26665082573890686
Clinet index 7, End of Epoch 1/6, Average Loss=0.8534339666366577, Class Loss=0.5867831110954285, Reg Loss=0.26665082573890686
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/31, Loss=0.803971828520298
Loss made of: CE 0.4978942573070526, LKD 0.20718815922737122, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/31, Loss=0.7261585384607315
Loss made of: CE 0.5418975353240967, LKD 0.2667567729949951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/31, Loss=0.7466629788279533
Loss made of: CE 0.4734257161617279, LKD 0.27503693103790283, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.510527491569519, Reg Loss=0.2493949830532074
Clinet index 7, End of Epoch 2/6, Average Loss=0.7599225044250488, Class Loss=0.510527491569519, Reg Loss=0.2493949830532074
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/31, Loss=0.7346110686659812
Loss made of: CE 0.574638843536377, LKD 0.3303532600402832, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/31, Loss=0.7293631255626678
Loss made of: CE 0.47641420364379883, LKD 0.27973589301109314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/31, Loss=0.6804986476898194
Loss made of: CE 0.34421586990356445, LKD 0.27802151441574097, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.460784375667572, Reg Loss=0.25020983815193176
Clinet index 7, End of Epoch 3/6, Average Loss=0.7109942436218262, Class Loss=0.460784375667572, Reg Loss=0.25020983815193176
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/31, Loss=0.7380312785506249
Loss made of: CE 0.526308000087738, LKD 0.2604077458381653, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/31, Loss=0.6829360678792
Loss made of: CE 0.4993550777435303, LKD 0.264687716960907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/31, Loss=0.6821678012609482
Loss made of: CE 0.556495189666748, LKD 0.24537794291973114, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4473768472671509, Reg Loss=0.2520808279514313
Clinet index 7, End of Epoch 4/6, Average Loss=0.6994576454162598, Class Loss=0.4473768472671509, Reg Loss=0.2520808279514313
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/31, Loss=0.6921992108225823
Loss made of: CE 0.40034669637680054, LKD 0.23467347025871277, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/31, Loss=0.6246204122900962
Loss made of: CE 0.4164852499961853, LKD 0.2577628195285797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/31, Loss=0.6831588357686996
Loss made of: CE 0.38650211691856384, LKD 0.26797541975975037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.41871631145477295, Reg Loss=0.24816206097602844
Clinet index 7, End of Epoch 5/6, Average Loss=0.666878342628479, Class Loss=0.41871631145477295, Reg Loss=0.24816206097602844
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/31, Loss=0.6297024577856064
Loss made of: CE 0.45747923851013184, LKD 0.2518220543861389, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/31, Loss=0.6757324427366257
Loss made of: CE 0.42006397247314453, LKD 0.23765794932842255, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/31, Loss=0.6496504038572312
Loss made of: CE 0.5004117488861084, LKD 0.30010056495666504, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3993263244628906, Reg Loss=0.252047061920166
Clinet index 7, End of Epoch 6/6, Average Loss=0.6513733863830566, Class Loss=0.3993263244628906, Reg Loss=0.252047061920166
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/19, Loss=0.8745649784803391
Loss made of: CE 0.5232071876525879, LKD 0.31251776218414307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5552800297737122, Reg Loss=0.2932814657688141
Clinet index 4, End of Epoch 1/6, Average Loss=0.8485615253448486, Class Loss=0.5552800297737122, Reg Loss=0.2932814657688141
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/19, Loss=0.8317933768033982
Loss made of: CE 0.4664454162120819, LKD 0.34228676557540894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.47631776332855225, Reg Loss=0.3102056384086609
Clinet index 4, End of Epoch 2/6, Average Loss=0.7865234017372131, Class Loss=0.47631776332855225, Reg Loss=0.3102056384086609
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/19, Loss=0.7468275398015976
Loss made of: CE 0.37351465225219727, LKD 0.29097992181777954, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.43236857652664185, Reg Loss=0.3029058873653412
Clinet index 4, End of Epoch 3/6, Average Loss=0.7352744340896606, Class Loss=0.43236857652664185, Reg Loss=0.3029058873653412
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/19, Loss=0.729538057744503
Loss made of: CE 0.4204885959625244, LKD 0.31279560923576355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4196092188358307, Reg Loss=0.30229341983795166
Clinet index 4, End of Epoch 4/6, Average Loss=0.72190260887146, Class Loss=0.4196092188358307, Reg Loss=0.30229341983795166
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/19, Loss=0.7349775820970536
Loss made of: CE 0.40687644481658936, LKD 0.3405493199825287, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.396793395280838, Reg Loss=0.30892401933670044
Clinet index 4, End of Epoch 5/6, Average Loss=0.7057174444198608, Class Loss=0.396793395280838, Reg Loss=0.30892401933670044
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/19, Loss=0.6583317950367927
Loss made of: CE 0.340984582901001, LKD 0.2645066976547241, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3865078389644623, Reg Loss=0.30440959334373474
Clinet index 4, End of Epoch 6/6, Average Loss=0.690917432308197, Class Loss=0.3865078389644623, Reg Loss=0.30440959334373474
federated aggregation...
Validation, Class Loss=0.39805757999420166, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.868481
Mean Acc: 0.560924
FreqW Acc: 0.787817
Mean IoU: 0.453688
Class IoU:
	class 0: 0.9058789
	class 1: 0.7411652
	class 2: 0.23378552
	class 3: 0.58469456
	class 4: 0.5898913
	class 5: 0.23739928
	class 6: 0.75299114
	class 7: 0.72495437
	class 8: 0.4174804
	class 9: 0.009876131
	class 10: 0.3708835
	class 11: 0.32700428
	class 12: 0.0019417433
Class Acc:
	class 0: 0.9691288
	class 1: 0.7562105
	class 2: 0.36738828
	class 3: 0.692666
	class 4: 0.7257555
	class 5: 0.2396654
	class 6: 0.774424
	class 7: 0.808939
	class 8: 0.9345177
	class 9: 0.010106786
	class 10: 0.3751206
	class 11: 0.63614285
	class 12: 0.001941779

federated global round: 13, step: 2
select part of clients to conduct local training
[14, 13, 0, 1]
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.772886860370636
Loss made of: CE 0.42442601919174194, LKD 0.37637990713119507, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4380492568016052, Reg Loss=0.30453261733055115
Clinet index 14, End of Epoch 1/6, Average Loss=0.742581844329834, Class Loss=0.4380492568016052, Reg Loss=0.30453261733055115
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/19, Loss=0.7009904384613037
Loss made of: CE 0.4803360402584076, LKD 0.44401025772094727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3743658661842346, Reg Loss=0.3100551962852478
Clinet index 14, End of Epoch 2/6, Average Loss=0.6844210624694824, Class Loss=0.3743658661842346, Reg Loss=0.3100551962852478
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/19, Loss=0.6736320108175278
Loss made of: CE 0.29984092712402344, LKD 0.21140888333320618, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3614582419395447, Reg Loss=0.30952900648117065
Clinet index 14, End of Epoch 3/6, Average Loss=0.6709872484207153, Class Loss=0.3614582419395447, Reg Loss=0.30952900648117065
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/19, Loss=0.649601049721241
Loss made of: CE 0.3536210060119629, LKD 0.32099100947380066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3484083116054535, Reg Loss=0.31831806898117065
Clinet index 14, End of Epoch 4/6, Average Loss=0.6667263507843018, Class Loss=0.3484083116054535, Reg Loss=0.31831806898117065
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/19, Loss=0.6713806360960006
Loss made of: CE 0.3134637475013733, LKD 0.30136334896087646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.34233468770980835, Reg Loss=0.3118249177932739
Clinet index 14, End of Epoch 5/6, Average Loss=0.6541596055030823, Class Loss=0.34233468770980835, Reg Loss=0.3118249177932739
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/19, Loss=0.6970904529094696
Loss made of: CE 0.27466273307800293, LKD 0.31735026836395264, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3371118903160095, Reg Loss=0.3266936242580414
Clinet index 14, End of Epoch 6/6, Average Loss=0.6638054847717285, Class Loss=0.3371118903160095, Reg Loss=0.3266936242580414
Current Client Index:  13
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/19, Loss=0.772090895473957
Loss made of: CE 0.39006251096725464, LKD 0.26068732142448425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.43778300285339355, Reg Loss=0.29191312193870544
Clinet index 13, End of Epoch 1/6, Average Loss=0.7296961545944214, Class Loss=0.43778300285339355, Reg Loss=0.29191312193870544
Pseudo labeling is: None
Epoch 2, lr = 0.000714
Epoch 2, Batch 10/19, Loss=0.7417434841394425
Loss made of: CE 0.40959569811820984, LKD 0.3071816563606262, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3812466561794281, Reg Loss=0.3121201694011688
Clinet index 13, End of Epoch 2/6, Average Loss=0.6933668255805969, Class Loss=0.3812466561794281, Reg Loss=0.3121201694011688
Pseudo labeling is: None
Epoch 3, lr = 0.000655
Epoch 3, Batch 10/19, Loss=0.6992667466402054
Loss made of: CE 0.3245612382888794, LKD 0.3361848294734955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37094634771347046, Reg Loss=0.3205516040325165
Clinet index 13, End of Epoch 3/6, Average Loss=0.6914979219436646, Class Loss=0.37094634771347046, Reg Loss=0.3205516040325165
Pseudo labeling is: None
Epoch 4, lr = 0.000596
Epoch 4, Batch 10/19, Loss=0.6353525206446647
Loss made of: CE 0.40330132842063904, LKD 0.24731187522411346, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3508570194244385, Reg Loss=0.3076179027557373
Clinet index 13, End of Epoch 4/6, Average Loss=0.6584749221801758, Class Loss=0.3508570194244385, Reg Loss=0.3076179027557373
Pseudo labeling is: None
Epoch 5, lr = 0.000536
Epoch 5, Batch 10/19, Loss=0.6653304994106293
Loss made of: CE 0.3268057107925415, LKD 0.32048672437667847, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.35082653164863586, Reg Loss=0.31155166029930115
Clinet index 13, End of Epoch 5/6, Average Loss=0.662378191947937, Class Loss=0.35082653164863586, Reg Loss=0.31155166029930115
Pseudo labeling is: None
Epoch 6, lr = 0.000475
Epoch 6, Batch 10/19, Loss=0.6173536315560341
Loss made of: CE 0.3450888991355896, LKD 0.32203829288482666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3376399278640747, Reg Loss=0.30383092164993286
Clinet index 13, End of Epoch 6/6, Average Loss=0.6414708495140076, Class Loss=0.3376399278640747, Reg Loss=0.30383092164993286
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/19, Loss=0.7586050495505333
Loss made of: CE 0.3799898624420166, LKD 0.27643874287605286, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.4373026490211487, Reg Loss=0.3005431890487671
Clinet index 0, End of Epoch 1/6, Average Loss=0.7378458380699158, Class Loss=0.4373026490211487, Reg Loss=0.3005431890487671
Pseudo labeling is: None
Epoch 2, lr = 0.000525
Epoch 2, Batch 10/19, Loss=0.6786299526691437
Loss made of: CE 0.4529840350151062, LKD 0.30070292949676514, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.39488181471824646, Reg Loss=0.30820420384407043
Clinet index 0, End of Epoch 2/6, Average Loss=0.7030860185623169, Class Loss=0.39488181471824646, Reg Loss=0.30820420384407043
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/19, Loss=0.7412900105118752
Loss made of: CE 0.459629625082016, LKD 0.3938186764717102, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.37484094500541687, Reg Loss=0.3164072334766388
Clinet index 0, End of Epoch 3/6, Average Loss=0.6912481784820557, Class Loss=0.37484094500541687, Reg Loss=0.3164072334766388
Pseudo labeling is: None
Epoch 4, lr = 0.000438
Epoch 4, Batch 10/19, Loss=0.6564162895083427
Loss made of: CE 0.44412732124328613, LKD 0.24795083701610565, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3677709996700287, Reg Loss=0.3185371458530426
Clinet index 0, End of Epoch 4/6, Average Loss=0.6863081455230713, Class Loss=0.3677709996700287, Reg Loss=0.3185371458530426
Pseudo labeling is: None
Epoch 5, lr = 0.000394
Epoch 5, Batch 10/19, Loss=0.6797273933887482
Loss made of: CE 0.3579774498939514, LKD 0.31670570373535156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.35866889357566833, Reg Loss=0.31050631403923035
Clinet index 0, End of Epoch 5/6, Average Loss=0.6691752076148987, Class Loss=0.35866889357566833, Reg Loss=0.31050631403923035
Pseudo labeling is: None
Epoch 6, lr = 0.000350
Epoch 6, Batch 10/19, Loss=0.6439231634140015
Loss made of: CE 0.33889004588127136, LKD 0.28092217445373535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3559431731700897, Reg Loss=0.3040649890899658
Clinet index 0, End of Epoch 6/6, Average Loss=0.6600081920623779, Class Loss=0.3559431731700897, Reg Loss=0.3040649890899658
Current Client Index:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/35, Loss=1.4310864627361297
Loss made of: CE 0.7774726748466492, LKD 0.8319588899612427, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=1.279074102640152
Loss made of: CE 0.5915528535842896, LKD 0.5206539630889893, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=1.1231072425842286
Loss made of: CE 0.5948194265365601, LKD 0.7656322717666626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6690897941589355, Reg Loss=0.5697408318519592
Clinet index 1, End of Epoch 1/6, Average Loss=1.23883056640625, Class Loss=0.6690897941589355, Reg Loss=0.5697408318519592
Pseudo labeling is: None
Epoch 2, lr = 0.000584
Epoch 2, Batch 10/35, Loss=1.081910914182663
Loss made of: CE 0.3975306451320648, LKD 0.5732621550559998, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=1.0233177483081817
Loss made of: CE 0.5195738077163696, LKD 0.517887532711029, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=1.0021949648857116
Loss made of: CE 0.3828882575035095, LKD 0.6070648431777954, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4349880516529083, Reg Loss=0.6045647263526917
Clinet index 1, End of Epoch 2/6, Average Loss=1.0395528078079224, Class Loss=0.4349880516529083, Reg Loss=0.6045647263526917
Pseudo labeling is: None
Epoch 3, lr = 0.000536
Epoch 3, Batch 10/35, Loss=0.9804891407489776
Loss made of: CE 0.40917879343032837, LKD 0.7157670855522156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=1.0012168884277344
Loss made of: CE 0.44645971059799194, LKD 0.6784156560897827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.9421035170555114
Loss made of: CE 0.4382895827293396, LKD 0.6488596200942993, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3937363624572754, Reg Loss=0.5642696619033813
Clinet index 1, End of Epoch 3/6, Average Loss=0.9580060243606567, Class Loss=0.3937363624572754, Reg Loss=0.5642696619033813
Pseudo labeling is: None
Epoch 4, lr = 0.000487
Epoch 4, Batch 10/35, Loss=0.9424686402082443
Loss made of: CE 0.3529651165008545, LKD 0.5255106687545776, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.9085250794887543
Loss made of: CE 0.3103082776069641, LKD 0.4258820414543152, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.9179770857095718
Loss made of: CE 0.32719308137893677, LKD 0.4852411150932312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36409565806388855, Reg Loss=0.5604416131973267
Clinet index 1, End of Epoch 4/6, Average Loss=0.9245373010635376, Class Loss=0.36409565806388855, Reg Loss=0.5604416131973267
Pseudo labeling is: None
Epoch 5, lr = 0.000438
Epoch 5, Batch 10/35, Loss=0.9032353579998016
Loss made of: CE 0.3785187900066376, LKD 0.5670788884162903, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=0.9702293187379837
Loss made of: CE 0.37761664390563965, LKD 0.6119703650474548, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.8582387268543243
Loss made of: CE 0.32289883494377136, LKD 0.527656078338623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3571843206882477, Reg Loss=0.5666122436523438
Clinet index 1, End of Epoch 5/6, Average Loss=0.923796534538269, Class Loss=0.3571843206882477, Reg Loss=0.5666122436523438
Pseudo labeling is: None
Epoch 6, lr = 0.000389
Epoch 6, Batch 10/35, Loss=0.8831975549459458
Loss made of: CE 0.27308085560798645, LKD 0.4874224066734314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.923233163356781
Loss made of: CE 0.33892518281936646, LKD 0.5486950278282166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.9502539753913879
Loss made of: CE 0.3534941077232361, LKD 0.48960041999816895, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3485780656337738, Reg Loss=0.5716539621353149
Clinet index 1, End of Epoch 6/6, Average Loss=0.9202320575714111, Class Loss=0.3485780656337738, Reg Loss=0.5716539621353149
federated aggregation...
Validation, Class Loss=0.3736109733581543, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.879196
Mean Acc: 0.603226
FreqW Acc: 0.800876
Mean IoU: 0.484625
Class IoU:
	class 0: 0.91030544
	class 1: 0.7307716
	class 2: 0.22925344
	class 3: 0.60810894
	class 4: 0.5800174
	class 5: 0.27098703
	class 6: 0.763792
	class 7: 0.72181726
	class 8: 0.4854182
	class 9: 0.018838393
	class 10: 0.6047755
	class 11: 0.35134017
	class 12: 0.024700927
Class Acc:
	class 0: 0.96781856
	class 1: 0.7444521
	class 2: 0.36271596
	class 3: 0.7077885
	class 4: 0.7299908
	class 5: 0.27426717
	class 6: 0.7893499
	class 7: 0.81487066
	class 8: 0.9423027
	class 9: 0.019599598
	class 10: 0.8091926
	class 11: 0.65483093
	class 12: 0.024761414

federated global round: 14, step: 2
select part of clients to conduct local training
[16, 9, 4, 0]
Current Client Index:  16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/42, Loss=1.0855319797992706
Loss made of: CE 0.6391899585723877, LKD 0.5441728234291077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/42, Loss=1.0194729834794998
Loss made of: CE 0.4383794963359833, LKD 0.40849992632865906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/42, Loss=0.9290822684764862
Loss made of: CE 0.4471855163574219, LKD 0.5127991437911987, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/42, Loss=0.8130754232406616
Loss made of: CE 0.3032425045967102, LKD 0.4268934726715088, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5012991428375244, Reg Loss=0.45114418864250183
Clinet index 16, End of Epoch 1/6, Average Loss=0.9524433612823486, Class Loss=0.5012991428375244, Reg Loss=0.45114418864250183
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/42, Loss=0.8760862439870835
Loss made of: CE 0.3658962845802307, LKD 0.4788246154785156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/42, Loss=0.8639869421720505
Loss made of: CE 0.3523043990135193, LKD 0.5581774115562439, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/42, Loss=0.7895082920789719
Loss made of: CE 0.3287028670310974, LKD 0.447793185710907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/42, Loss=0.7943685233592988
Loss made of: CE 0.33936986327171326, LKD 0.35665494203567505, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36196354031562805, Reg Loss=0.47026675939559937
Clinet index 16, End of Epoch 2/6, Average Loss=0.8322303295135498, Class Loss=0.36196354031562805, Reg Loss=0.47026675939559937
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/42, Loss=0.7823959290981293
Loss made of: CE 0.38050395250320435, LKD 0.4058017134666443, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/42, Loss=0.7936549186706543
Loss made of: CE 0.3521464765071869, LKD 0.6126000285148621, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/42, Loss=0.7936640948057174
Loss made of: CE 0.34686440229415894, LKD 0.5454533100128174, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/42, Loss=0.9181456655263901
Loss made of: CE 0.3207445740699768, LKD 0.5783616304397583, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.35225003957748413, Reg Loss=0.4659116566181183
Clinet index 16, End of Epoch 3/6, Average Loss=0.8181617259979248, Class Loss=0.35225003957748413, Reg Loss=0.4659116566181183
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/42, Loss=0.8254408687353134
Loss made of: CE 0.3072352111339569, LKD 0.43888720870018005, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/42, Loss=0.7972373306751251
Loss made of: CE 0.3512044847011566, LKD 0.4930739402770996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/42, Loss=0.7866764456033707
Loss made of: CE 0.2945917844772339, LKD 0.4058648943901062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/42, Loss=0.7743570476770401
Loss made of: CE 0.31585976481437683, LKD 0.39800724387168884, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3455686569213867, Reg Loss=0.4583199918270111
Clinet index 16, End of Epoch 4/6, Average Loss=0.8038886785507202, Class Loss=0.3455686569213867, Reg Loss=0.4583199918270111
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/42, Loss=0.7952426314353943
Loss made of: CE 0.32967275381088257, LKD 0.4331398010253906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/42, Loss=0.8323782056570053
Loss made of: CE 0.3009646534919739, LKD 0.36259758472442627, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/42, Loss=0.7934110790491105
Loss made of: CE 0.37876519560813904, LKD 0.3687402009963989, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/42, Loss=0.8098169147968293
Loss made of: CE 0.3562370240688324, LKD 0.6045994758605957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33669036626815796, Reg Loss=0.4657268524169922
Clinet index 16, End of Epoch 5/6, Average Loss=0.8024172186851501, Class Loss=0.33669036626815796, Reg Loss=0.4657268524169922
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/42, Loss=0.7915016353130341
Loss made of: CE 0.2623633146286011, LKD 0.4267005920410156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/42, Loss=0.7606052428483963
Loss made of: CE 0.3372191786766052, LKD 0.36960524320602417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/42, Loss=0.8177447259426117
Loss made of: CE 0.3544158637523651, LKD 0.4160395562648773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/42, Loss=0.8558978468179703
Loss made of: CE 0.3789920210838318, LKD 0.426546573638916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3384469449520111, Reg Loss=0.4615474045276642
Clinet index 16, End of Epoch 6/6, Average Loss=0.7999943494796753, Class Loss=0.3384469449520111, Reg Loss=0.4615474045276642
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/35, Loss=1.3226383537054063
Loss made of: CE 0.7302216291427612, LKD 0.6442222595214844, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/35, Loss=1.1772447645664215
Loss made of: CE 0.4053735136985779, LKD 0.6217579245567322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/35, Loss=0.9783285170793533
Loss made of: CE 0.39913520216941833, LKD 0.6791183352470398, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5448113679885864, Reg Loss=0.5841749906539917
Clinet index 9, End of Epoch 1/6, Average Loss=1.1289863586425781, Class Loss=0.5448113679885864, Reg Loss=0.5841749906539917
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/35, Loss=0.9345905780792236
Loss made of: CE 0.45305508375167847, LKD 0.4635985791683197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/35, Loss=0.9870849072933197
Loss made of: CE 0.3036307692527771, LKD 0.56593918800354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/35, Loss=0.9219657331705093
Loss made of: CE 0.3321499824523926, LKD 0.5249576568603516, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3806449770927429, Reg Loss=0.5679241418838501
Clinet index 9, End of Epoch 2/6, Average Loss=0.948569118976593, Class Loss=0.3806449770927429, Reg Loss=0.5679241418838501
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/35, Loss=0.9102716743946075
Loss made of: CE 0.3770328462123871, LKD 0.5963252782821655, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/35, Loss=0.9937213569879532
Loss made of: CE 0.328365683555603, LKD 0.4705660343170166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/35, Loss=0.8669994533061981
Loss made of: CE 0.27819329500198364, LKD 0.48083028197288513, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3526451885700226, Reg Loss=0.5654743909835815
Clinet index 9, End of Epoch 3/6, Average Loss=0.9181195497512817, Class Loss=0.3526451885700226, Reg Loss=0.5654743909835815
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/35, Loss=0.9445552438497543
Loss made of: CE 0.27420198917388916, LKD 0.4696391522884369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/35, Loss=0.8531875878572464
Loss made of: CE 0.2911718487739563, LKD 0.5138876438140869, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/35, Loss=0.8935336142778396
Loss made of: CE 0.36910480260849, LKD 0.4819870889186859, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.336244136095047, Reg Loss=0.5591782331466675
Clinet index 9, End of Epoch 4/6, Average Loss=0.8954223394393921, Class Loss=0.336244136095047, Reg Loss=0.5591782331466675
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/35, Loss=0.8530375167727471
Loss made of: CE 0.23849283158779144, LKD 0.4429728388786316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/35, Loss=0.8998638987541199
Loss made of: CE 0.25985413789749146, LKD 0.507428765296936, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/35, Loss=0.9346460938453675
Loss made of: CE 0.38729405403137207, LKD 0.7647327780723572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3319489061832428, Reg Loss=0.5562896132469177
Clinet index 9, End of Epoch 5/6, Average Loss=0.8882385492324829, Class Loss=0.3319489061832428, Reg Loss=0.5562896132469177
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/35, Loss=0.898939049243927
Loss made of: CE 0.3476346731185913, LKD 0.6470004320144653, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/35, Loss=0.8687674969434738
Loss made of: CE 0.3296304941177368, LKD 0.5081363916397095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/35, Loss=0.854420617222786
Loss made of: CE 0.3099467158317566, LKD 0.5512294769287109, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3227730393409729, Reg Loss=0.5587342381477356
Clinet index 9, End of Epoch 6/6, Average Loss=0.8815072774887085, Class Loss=0.3227730393409729, Reg Loss=0.5587342381477356
Current Client Index:  4
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000568
Epoch 1, Batch 10/19, Loss=0.6849306344985961
Loss made of: CE 0.3300081491470337, LKD 0.3035827875137329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.37635892629623413, Reg Loss=0.30105507373809814
Clinet index 4, End of Epoch 1/6, Average Loss=0.6774140000343323, Class Loss=0.37635892629623413, Reg Loss=0.30105507373809814
Pseudo labeling is: None
Epoch 2, lr = 0.000482
Epoch 2, Batch 10/19, Loss=0.7041319876909256
Loss made of: CE 0.3844425082206726, LKD 0.33698686957359314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3637267053127289, Reg Loss=0.3090294897556305
Clinet index 4, End of Epoch 2/6, Average Loss=0.6727561950683594, Class Loss=0.3637267053127289, Reg Loss=0.3090294897556305
Pseudo labeling is: None
Epoch 3, lr = 0.000394
Epoch 3, Batch 10/19, Loss=0.6483257383108139
Loss made of: CE 0.2978817820549011, LKD 0.30721554160118103, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.34148144721984863, Reg Loss=0.301541268825531
Clinet index 4, End of Epoch 3/6, Average Loss=0.6430227160453796, Class Loss=0.34148144721984863, Reg Loss=0.301541268825531
Pseudo labeling is: None
Epoch 4, lr = 0.000304
Epoch 4, Batch 10/19, Loss=0.6551675856113434
Loss made of: CE 0.33726033568382263, LKD 0.3292161822319031, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3473244309425354, Reg Loss=0.3084712326526642
Clinet index 4, End of Epoch 4/6, Average Loss=0.655795693397522, Class Loss=0.3473244309425354, Reg Loss=0.3084712326526642
Pseudo labeling is: None
Epoch 5, lr = 0.000211
Epoch 5, Batch 10/19, Loss=0.6580956548452377
Loss made of: CE 0.3849142789840698, LKD 0.3571913242340088, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33299949765205383, Reg Loss=0.303284615278244
Clinet index 4, End of Epoch 5/6, Average Loss=0.6362841129302979, Class Loss=0.33299949765205383, Reg Loss=0.303284615278244
Pseudo labeling is: None
Epoch 6, lr = 0.000113
Epoch 6, Batch 10/19, Loss=0.6173839434981346
Loss made of: CE 0.2857567369937897, LKD 0.23965315520763397, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.33728018403053284, Reg Loss=0.30885037779808044
Clinet index 4, End of Epoch 6/6, Average Loss=0.6461305618286133, Class Loss=0.33728018403053284, Reg Loss=0.30885037779808044
Current Client Index:  0
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000304
Epoch 1, Batch 10/19, Loss=0.6873865976929665
Loss made of: CE 0.3530292212963104, LKD 0.27053672075271606, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3754107654094696, Reg Loss=0.30177682638168335
Clinet index 0, End of Epoch 1/6, Average Loss=0.6771875619888306, Class Loss=0.3754107654094696, Reg Loss=0.30177682638168335
Pseudo labeling is: None
Epoch 2, lr = 0.000258
Epoch 2, Batch 10/19, Loss=0.6650508493185043
Loss made of: CE 0.4282485842704773, LKD 0.28456324338912964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.36153706908226013, Reg Loss=0.301872581243515
Clinet index 0, End of Epoch 2/6, Average Loss=0.6634096503257751, Class Loss=0.36153706908226013, Reg Loss=0.301872581243515
Pseudo labeling is: None
Epoch 3, lr = 0.000211
Epoch 3, Batch 10/19, Loss=0.7279363542795181
Loss made of: CE 0.43668049573898315, LKD 0.388056218624115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3557834029197693, Reg Loss=0.3163451552391052
Clinet index 0, End of Epoch 3/6, Average Loss=0.6721285581588745, Class Loss=0.3557834029197693, Reg Loss=0.3163451552391052
Pseudo labeling is: None
Epoch 4, lr = 0.000163
Epoch 4, Batch 10/19, Loss=0.6471779972314835
Loss made of: CE 0.4210204780101776, LKD 0.28954559564590454, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3516242504119873, Reg Loss=0.31245946884155273
Clinet index 0, End of Epoch 4/6, Average Loss=0.66408371925354, Class Loss=0.3516242504119873, Reg Loss=0.31245946884155273
Pseudo labeling is: None
Epoch 5, lr = 0.000113
Epoch 5, Batch 10/19, Loss=0.6709799379110336
Loss made of: CE 0.3663647174835205, LKD 0.2943943738937378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3504631519317627, Reg Loss=0.31200626492500305
Clinet index 0, End of Epoch 5/6, Average Loss=0.6624693870544434, Class Loss=0.3504631519317627, Reg Loss=0.31200626492500305
Pseudo labeling is: None
Epoch 6, lr = 0.000061
Epoch 6, Batch 10/19, Loss=0.6376501098275185
Loss made of: CE 0.3346869945526123, LKD 0.2701469659805298, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.34951484203338623, Reg Loss=0.3208462595939636
Clinet index 0, End of Epoch 6/6, Average Loss=0.6703611016273499, Class Loss=0.34951484203338623, Reg Loss=0.3208462595939636
federated aggregation...
Validation, Class Loss=0.3432556390762329, Reg Loss=0.0 (without scaling)

Total samples: 1005.000000
Overall Acc: 0.894286
Mean Acc: 0.629809
FreqW Acc: 0.823377
Mean IoU: 0.528194
Class IoU:
	class 0: 0.9153853
	class 1: 0.72712594
	class 2: 0.2338603
	class 3: 0.59289753
	class 4: 0.5702864
	class 5: 0.30691952
	class 6: 0.7992016
	class 7: 0.72968554
	class 8: 0.523498
	class 9: 0.025305081
	class 10: 0.6310038
	class 11: 0.40524122
	class 12: 0.40611225
Class Acc:
	class 0: 0.96886545
	class 1: 0.7405208
	class 2: 0.38252982
	class 3: 0.68004924
	class 4: 0.7362679
	class 5: 0.31116146
	class 6: 0.8290065
	class 7: 0.8364956
	class 8: 0.9216112
	class 9: 0.0266243
	class 10: 0.6538412
	class 11: 0.6225292
	class 12: 0.47801048

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 15, step: 3
select part of clients to conduct local training
[11, 6, 10, 7]
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=1.9228073060512543
Loss made of: CE 1.1404502391815186, LKD 0.46021267771720886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=1.5269341826438905
Loss made of: CE 0.8087319135665894, LKD 0.480350136756897, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=1.3249324440956116
Loss made of: CE 0.8682726621627808, LKD 0.548098087310791, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=1.2245691269636154
Loss made of: CE 0.5779306888580322, LKD 0.4357447028160095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=1.1572552293539047
Loss made of: CE 0.5561522841453552, LKD 0.3975461423397064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=1.1251534968614578
Loss made of: CE 0.6853625178337097, LKD 0.3903743624687195, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=1.0852115124464035
Loss made of: CE 0.5884671807289124, LKD 0.4444011449813843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=1.0384782403707504
Loss made of: CE 0.6158308982849121, LKD 0.43410491943359375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=1.0117331624031067
Loss made of: CE 0.5454044342041016, LKD 0.5092417597770691, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=1.0279737710952759
Loss made of: CE 0.636035144329071, LKD 0.5616101622581482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7713211178779602, Reg Loss=0.47050631046295166
Clinet index 11, End of Epoch 1/6, Average Loss=1.2418274879455566, Class Loss=0.7713211178779602, Reg Loss=0.47050631046295166
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/102, Loss=0.9608359962701798
Loss made of: CE 0.48886629939079285, LKD 0.3980311155319214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.9277392029762268
Loss made of: CE 0.39142662286758423, LKD 0.35263681411743164, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.9349986642599106
Loss made of: CE 0.5801288485527039, LKD 0.5011745691299438, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.9129397422075272
Loss made of: CE 0.559400200843811, LKD 0.4774986207485199, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.872879683971405
Loss made of: CE 0.44262874126434326, LKD 0.5021320581436157, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.8991003900766372
Loss made of: CE 0.3789331316947937, LKD 0.4920364022254944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.8131418645381927
Loss made of: CE 0.38882964849472046, LKD 0.5330373644828796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.9138075143098832
Loss made of: CE 0.2770777940750122, LKD 0.6143962740898132, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.7996448904275895
Loss made of: CE 0.5953008532524109, LKD 0.5397599935531616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.8087242901325226
Loss made of: CE 0.3088870942592621, LKD 0.4221668243408203, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4383355379104614, Reg Loss=0.44706568121910095
Clinet index 11, End of Epoch 2/6, Average Loss=0.8854012489318848, Class Loss=0.4383355379104614, Reg Loss=0.44706568121910095
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/102, Loss=0.8172627508640289
Loss made of: CE 0.4380192756652832, LKD 0.46461161971092224, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.8251808255910873
Loss made of: CE 0.45465466380119324, LKD 0.4969509243965149, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.7761378914117814
Loss made of: CE 0.29688602685928345, LKD 0.4385067820549011, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.7534924954175949
Loss made of: CE 0.31240314245224, LKD 0.5100404620170593, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.7814831912517548
Loss made of: CE 0.35845836997032166, LKD 0.47890743613243103, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.739279343187809
Loss made of: CE 0.28809815645217896, LKD 0.4065556526184082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.7878225654363632
Loss made of: CE 0.24249398708343506, LKD 0.4451621472835541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.7819996327161789
Loss made of: CE 0.26372218132019043, LKD 0.45680782198905945, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.7391509935259819
Loss made of: CE 0.33930832147598267, LKD 0.4753198027610779, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.8156005680561066
Loss made of: CE 0.2606982886791229, LKD 0.43364962935447693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3304018974304199, Reg Loss=0.45027899742126465
Clinet index 11, End of Epoch 3/6, Average Loss=0.7806808948516846, Class Loss=0.3304018974304199, Reg Loss=0.45027899742126465
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/102, Loss=0.779926672577858
Loss made of: CE 0.3365879952907562, LKD 0.39674681425094604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.7175294280052185
Loss made of: CE 0.23114757239818573, LKD 0.36077141761779785, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.7587440490722657
Loss made of: CE 0.45434293150901794, LKD 0.4752744138240814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.7754406601190567
Loss made of: CE 0.2607494592666626, LKD 0.4224316477775574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.7592450708150864
Loss made of: CE 0.3838140368461609, LKD 0.4980839490890503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.740014337003231
Loss made of: CE 0.29678136110305786, LKD 0.3789340853691101, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.7064754039049148
Loss made of: CE 0.3667871356010437, LKD 0.5313010811805725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.7693713650107383
Loss made of: CE 0.3650381565093994, LKD 0.44548094272613525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.7426657348871231
Loss made of: CE 0.23683404922485352, LKD 0.4228682219982147, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.7638318330049515
Loss made of: CE 0.35510778427124023, LKD 0.44300970435142517, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2951769530773163, Reg Loss=0.4566134512424469
Clinet index 11, End of Epoch 4/6, Average Loss=0.7517904043197632, Class Loss=0.2951769530773163, Reg Loss=0.4566134512424469
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/102, Loss=0.7645847171545028
Loss made of: CE 0.26233309507369995, LKD 0.5395700335502625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.7670811891555787
Loss made of: CE 0.2110472321510315, LKD 0.4420594871044159, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.7253826811909676
Loss made of: CE 0.22275768220424652, LKD 0.41144514083862305, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.726714451611042
Loss made of: CE 0.349051833152771, LKD 0.49587923288345337, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.7390081509947777
Loss made of: CE 0.23153233528137207, LKD 0.4237508177757263, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.7440738171339035
Loss made of: CE 0.29517650604248047, LKD 0.6312264204025269, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6570742890238762
Loss made of: CE 0.31579846143722534, LKD 0.46211910247802734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6416495904326439
Loss made of: CE 0.20043396949768066, LKD 0.4162289798259735, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.7024993732571602
Loss made of: CE 0.23030376434326172, LKD 0.45144495368003845, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6940599873661994
Loss made of: CE 0.21475599706172943, LKD 0.4404994249343872, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26736339926719666, Reg Loss=0.45054909586906433
Clinet index 11, End of Epoch 5/6, Average Loss=0.717912495136261, Class Loss=0.26736339926719666, Reg Loss=0.45054909586906433
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/102, Loss=0.7001646280288696
Loss made of: CE 0.2252514362335205, LKD 0.37828323245048523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.7217707470059395
Loss made of: CE 0.30659806728363037, LKD 0.5683908462524414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.712558051943779
Loss made of: CE 0.20408904552459717, LKD 0.34270769357681274, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.7349148258566857
Loss made of: CE 0.36039870977401733, LKD 0.4369027614593506, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.7154600843787193
Loss made of: CE 0.25097906589508057, LKD 0.47293537855148315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.720696160197258
Loss made of: CE 0.2763831317424774, LKD 0.5752508640289307, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.7369714185595513
Loss made of: CE 0.25388872623443604, LKD 0.35200080275535583, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.7009652048349381
Loss made of: CE 0.24649140238761902, LKD 0.61253821849823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.7020015805959702
Loss made of: CE 0.26117008924484253, LKD 0.42025870084762573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6728895410895348
Loss made of: CE 0.26001423597335815, LKD 0.5134803056716919, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.25661763548851013, Reg Loss=0.45678919553756714
Clinet index 11, End of Epoch 6/6, Average Loss=0.7134068012237549, Class Loss=0.25661763548851013, Reg Loss=0.45678919553756714
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=2.2812548875808716
Loss made of: CE 1.3360364437103271, LKD 0.6210731863975525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.7752194941043853
Loss made of: CE 0.953100860118866, LKD 0.6229642629623413, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.2941703796386719, Reg Loss=0.675476610660553
Clinet index 6, End of Epoch 1/6, Average Loss=1.96964693069458, Class Loss=1.2941703796386719, Reg Loss=0.675476610660553
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/23, Loss=1.5803390085697173
Loss made of: CE 1.0363787412643433, LKD 0.6782798171043396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=1.5270826637744903
Loss made of: CE 0.6732394099235535, LKD 0.5596559047698975, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8853822946548462, Reg Loss=0.6588701009750366
Clinet index 6, End of Epoch 2/6, Average Loss=1.5442523956298828, Class Loss=0.8853822946548462, Reg Loss=0.6588701009750366
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/23, Loss=1.413796630501747
Loss made of: CE 0.7835490703582764, LKD 0.6195446848869324, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=1.404775655269623
Loss made of: CE 0.8084620237350464, LKD 0.581998348236084, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7678709626197815, Reg Loss=0.6195562481880188
Clinet index 6, End of Epoch 3/6, Average Loss=1.3874272108078003, Class Loss=0.7678709626197815, Reg Loss=0.6195562481880188
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/23, Loss=1.3604583442211151
Loss made of: CE 0.7603589296340942, LKD 0.7621623277664185, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=1.2932367742061615
Loss made of: CE 0.5279616713523865, LKD 0.5809301137924194, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6789605617523193, Reg Loss=0.6376802325248718
Clinet index 6, End of Epoch 4/6, Average Loss=1.316640853881836, Class Loss=0.6789605617523193, Reg Loss=0.6376802325248718
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/23, Loss=1.2448823213577271
Loss made of: CE 0.6265420913696289, LKD 0.5191010236740112, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=1.2601062148809432
Loss made of: CE 0.5194705724716187, LKD 0.6068801879882812, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6257156133651733, Reg Loss=0.6446481943130493
Clinet index 6, End of Epoch 5/6, Average Loss=1.2703638076782227, Class Loss=0.6257156133651733, Reg Loss=0.6446481943130493
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/23, Loss=1.2389175772666932
Loss made of: CE 0.621082067489624, LKD 0.7022708654403687, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=1.1820563673973083
Loss made of: CE 0.5277635455131531, LKD 0.5788707137107849, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5842718482017517, Reg Loss=0.6335597038269043
Clinet index 6, End of Epoch 6/6, Average Loss=1.2178316116333008, Class Loss=0.5842718482017517, Reg Loss=0.6335597038269043
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=2.2557190477848055
Loss made of: CE 1.3396427631378174, LKD 0.6673307418823242, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.80174760222435
Loss made of: CE 0.9705926775932312, LKD 0.641152560710907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.3028336763381958, Reg Loss=0.6746581792831421
Clinet index 10, End of Epoch 1/6, Average Loss=1.977491855621338, Class Loss=1.3028336763381958, Reg Loss=0.6746581792831421
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/23, Loss=1.674002319574356
Loss made of: CE 1.0124611854553223, LKD 0.8180201053619385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=1.4474950551986694
Loss made of: CE 0.7291678190231323, LKD 0.7301236987113953, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.8795638680458069, Reg Loss=0.6599225997924805
Clinet index 10, End of Epoch 2/6, Average Loss=1.5394864082336426, Class Loss=0.8795638680458069, Reg Loss=0.6599225997924805
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/23, Loss=1.388030344247818
Loss made of: CE 0.7543809413909912, LKD 0.6461740136146545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=1.397799414396286
Loss made of: CE 0.6905595064163208, LKD 0.6094193458557129, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.7775844931602478, Reg Loss=0.6208051443099976
Clinet index 10, End of Epoch 3/6, Average Loss=1.3983895778656006, Class Loss=0.7775844931602478, Reg Loss=0.6208051443099976
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/23, Loss=1.3141585379838943
Loss made of: CE 0.5911053419113159, LKD 0.6024608016014099, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=1.3286747246980668
Loss made of: CE 0.6524503231048584, LKD 0.6180317997932434, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.6821876168251038, Reg Loss=0.6328237652778625
Clinet index 10, End of Epoch 4/6, Average Loss=1.3150113821029663, Class Loss=0.6821876168251038, Reg Loss=0.6328237652778625
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/23, Loss=1.291168862581253
Loss made of: CE 0.545872688293457, LKD 0.6978703737258911, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=1.276459962129593
Loss made of: CE 0.7675119638442993, LKD 0.8631159663200378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.6266099810600281, Reg Loss=0.6456086039543152
Clinet index 10, End of Epoch 5/6, Average Loss=1.2722185850143433, Class Loss=0.6266099810600281, Reg Loss=0.6456086039543152
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/23, Loss=1.2127659738063812
Loss made of: CE 0.456265926361084, LKD 0.47887033224105835, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=1.2375389695167542
Loss made of: CE 0.555335521697998, LKD 0.6030744910240173, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.5897555947303772, Reg Loss=0.6318941712379456
Clinet index 10, End of Epoch 6/6, Average Loss=1.2216497659683228, Class Loss=0.5897555947303772, Reg Loss=0.6318941712379456
Current Client Index:  7
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=2.0635600864887236
Loss made of: CE 1.2345541715621948, LKD 0.5563342571258545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=1.3903719156980514
Loss made of: CE 0.8445355296134949, LKD 0.4714331328868866, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=1.2481766134500503
Loss made of: CE 0.7462310791015625, LKD 0.4538683295249939, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=1.2762137293815612
Loss made of: CE 0.5796995162963867, LKD 0.48480457067489624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=1.1717946112155915
Loss made of: CE 0.68684983253479, LKD 0.50629723072052, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=1.0849463313817977
Loss made of: CE 0.6769658923149109, LKD 0.41144928336143494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=1.0533944964408875
Loss made of: CE 0.7092520594596863, LKD 0.37840336561203003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=1.1055370926856996
Loss made of: CE 0.7121251821517944, LKD 0.5234377980232239, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=1.0103973895311356
Loss made of: CE 0.5005226135253906, LKD 0.42967939376831055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=1.0640092939138412
Loss made of: CE 0.5491135120391846, LKD 0.42343875765800476, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.771099865436554, Reg Loss=0.4708760678768158
Clinet index 7, End of Epoch 1/6, Average Loss=1.2419759035110474, Class Loss=0.771099865436554, Reg Loss=0.4708760678768158
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/102, Loss=0.9610965818166732
Loss made of: CE 0.5522155165672302, LKD 0.4411796033382416, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.8762147426605225
Loss made of: CE 0.4694826006889343, LKD 0.44505438208580017, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.9458056092262268
Loss made of: CE 0.4834631383419037, LKD 0.48397859930992126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.93189235329628
Loss made of: CE 0.39866265654563904, LKD 0.4189964234828949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.9071959376335144
Loss made of: CE 0.30938720703125, LKD 0.3750271797180176, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.9181640118360519
Loss made of: CE 0.40378689765930176, LKD 0.40042394399642944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.8486683577299118
Loss made of: CE 0.3960663080215454, LKD 0.37882959842681885, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.8178632587194443
Loss made of: CE 0.3221980631351471, LKD 0.4070609211921692, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.8478860437870026
Loss made of: CE 0.29977139830589294, LKD 0.4179316759109497, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.7673012107610703
Loss made of: CE 0.28348517417907715, LKD 0.4039120078086853, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.42948806285858154, Reg Loss=0.4495851397514343
Clinet index 7, End of Epoch 2/6, Average Loss=0.8790732026100159, Class Loss=0.42948806285858154, Reg Loss=0.4495851397514343
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/102, Loss=0.8138393759727478
Loss made of: CE 0.37446898221969604, LKD 0.47665345668792725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.7759665369987487
Loss made of: CE 0.35023877024650574, LKD 0.4929315447807312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.7687635630369186
Loss made of: CE 0.30375295877456665, LKD 0.4226101338863373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.8037734180688858
Loss made of: CE 0.2516464591026306, LKD 0.34187254309654236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.793379220366478
Loss made of: CE 0.328604519367218, LKD 0.48492658138275146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.7936009854078293
Loss made of: CE 0.2495279312133789, LKD 0.36197829246520996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.787639145553112
Loss made of: CE 0.25799864530563354, LKD 0.5184003114700317, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.761928716301918
Loss made of: CE 0.2541919946670532, LKD 0.5827081203460693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.8054795354604721
Loss made of: CE 0.3142913579940796, LKD 0.4651404321193695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.7420373812317849
Loss made of: CE 0.23435735702514648, LKD 0.3420165181159973, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3279499411582947, Reg Loss=0.45512819290161133
Clinet index 7, End of Epoch 3/6, Average Loss=0.783078134059906, Class Loss=0.3279499411582947, Reg Loss=0.45512819290161133
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/102, Loss=0.7075744718313217
Loss made of: CE 0.28498655557632446, LKD 0.40862518548965454, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.7904399141669274
Loss made of: CE 0.32991620898246765, LKD 0.5092756152153015, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.7870640560984612
Loss made of: CE 0.24993185698986053, LKD 0.41792964935302734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.731186418235302
Loss made of: CE 0.28501707315444946, LKD 0.43705686926841736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.7464432179927826
Loss made of: CE 0.3359888792037964, LKD 0.48190873861312866, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.7647936120629311
Loss made of: CE 0.38950204849243164, LKD 0.43412360548973083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.7280251145362854
Loss made of: CE 0.2773381471633911, LKD 0.4650533199310303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.7646546304225922
Loss made of: CE 0.28668808937072754, LKD 0.47670993208885193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.7389708638191224
Loss made of: CE 0.27248167991638184, LKD 0.3168261647224426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.7590133935213089
Loss made of: CE 0.22777792811393738, LKD 0.3957659900188446, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.29239410161972046, Reg Loss=0.4587852656841278
Clinet index 7, End of Epoch 4/6, Average Loss=0.7511793375015259, Class Loss=0.29239410161972046, Reg Loss=0.4587852656841278
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/102, Loss=0.7655366763472558
Loss made of: CE 0.25313037633895874, LKD 0.4546125531196594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.7259413316845894
Loss made of: CE 0.2705151438713074, LKD 0.45095881819725037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.689701022207737
Loss made of: CE 0.3500261902809143, LKD 0.46925419569015503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.7146613210439682
Loss made of: CE 0.2327212691307068, LKD 0.4327940344810486, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.7223371252417564
Loss made of: CE 0.34984835982322693, LKD 0.4616014361381531, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6982882201671601
Loss made of: CE 0.2451140582561493, LKD 0.5015439987182617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.7212657317519188
Loss made of: CE 0.22935757040977478, LKD 0.39334261417388916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.7303739294409752
Loss made of: CE 0.22513966262340546, LKD 0.387561559677124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.7773245513439179
Loss made of: CE 0.4022282063961029, LKD 0.566107451915741, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.698541721701622
Loss made of: CE 0.24835452437400818, LKD 0.447690486907959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.26985764503479004, Reg Loss=0.45509183406829834
Clinet index 7, End of Epoch 5/6, Average Loss=0.7249494791030884, Class Loss=0.26985764503479004, Reg Loss=0.45509183406829834
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/102, Loss=0.7599342450499534
Loss made of: CE 0.30275312066078186, LKD 0.49688681960105896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.756408816576004
Loss made of: CE 0.243133544921875, LKD 0.538881778717041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.70270836353302
Loss made of: CE 0.26022273302078247, LKD 0.49508556723594666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.7423649981617928
Loss made of: CE 0.2477303445339203, LKD 0.41937196254730225, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.7031932920217514
Loss made of: CE 0.36834073066711426, LKD 0.43517574667930603, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6574080064892769
Loss made of: CE 0.22602014243602753, LKD 0.3617461323738098, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6759640336036682
Loss made of: CE 0.22356224060058594, LKD 0.47229617834091187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6995823055505752
Loss made of: CE 0.19264110922813416, LKD 0.49875324964523315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6934344351291657
Loss made of: CE 0.21539348363876343, LKD 0.451569139957428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6918639793992043
Loss made of: CE 0.35535407066345215, LKD 0.4900135397911072, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2537330389022827, Reg Loss=0.4585818648338318
Clinet index 7, End of Epoch 6/6, Average Loss=0.7123149037361145, Class Loss=0.2537330389022827, Reg Loss=0.4585818648338318
federated aggregation...
Validation, Class Loss=0.5356979966163635, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.840277
Mean Acc: 0.553264
FreqW Acc: 0.736490
Mean IoU: 0.421390
Class IoU:
	class 0: 0.8624447
	class 1: 0.6954716
	class 2: 0.22330686
	class 3: 0.4731121
	class 4: 0.4923152
	class 5: 0.25785035
	class 6: 0.74641013
	class 7: 0.7351753
	class 8: 0.5210452
	class 9: 0.03201176
	class 10: 0.47218063
	class 11: 0.31750646
	class 12: 0.3494853
	class 13: 0.0
	class 14: 0.55889475
	class 15: 0.42642564
	class 16: 0.0
Class Acc:
	class 0: 0.9555819
	class 1: 0.70963275
	class 2: 0.36604443
	class 3: 0.54627633
	class 4: 0.70456934
	class 5: 0.2605203
	class 6: 0.8196861
	class 7: 0.8476424
	class 8: 0.9171389
	class 9: 0.033887837
	class 10: 0.85209703
	class 11: 0.7131445
	class 12: 0.4282106
	class 13: 0.0
	class 14: 0.8091229
	class 15: 0.44193786
	class 16: 0.0

federated global round: 16, step: 3
select part of clients to conduct local training
[7, 11, 16, 18]
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/102, Loss=0.9357794851064682
Loss made of: CE 0.47783321142196655, LKD 0.5027844905853271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.7734868288040161
Loss made of: CE 0.3848413825035095, LKD 0.44139981269836426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.7709036320447922
Loss made of: CE 0.3181789815425873, LKD 0.3973776698112488, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.8724623173475266
Loss made of: CE 0.2811230421066284, LKD 0.4817623496055603, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.7890744000673294
Loss made of: CE 0.3703307509422302, LKD 0.4587574899196625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.7527461618185043
Loss made of: CE 0.30533021688461304, LKD 0.42381685972213745, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.7452456042170524
Loss made of: CE 0.37488889694213867, LKD 0.3860543668270111, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.7874051943421364
Loss made of: CE 0.41608065366744995, LKD 0.5814025402069092, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.7487593933939933
Loss made of: CE 0.3034251928329468, LKD 0.4351470470428467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.810543006658554
Loss made of: CE 0.3082682490348816, LKD 0.43370962142944336, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3444522023200989, Reg Loss=0.4535995423793793
Clinet index 7, End of Epoch 1/6, Average Loss=0.7980517148971558, Class Loss=0.3444522023200989, Reg Loss=0.4535995423793793
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/102, Loss=0.7397159710526466
Loss made of: CE 0.2979528605937958, LKD 0.4416750371456146, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.712053507566452
Loss made of: CE 0.27142196893692017, LKD 0.4846561551094055, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.7692814737558364
Loss made of: CE 0.24936875700950623, LKD 0.4561351239681244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.7487313121557235
Loss made of: CE 0.26153063774108887, LKD 0.4170846939086914, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.7508772611618042
Loss made of: CE 0.2202279269695282, LKD 0.37996384501457214, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.7558909818530083
Loss made of: CE 0.2768164277076721, LKD 0.41734665632247925, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.737668652832508
Loss made of: CE 0.2901250123977661, LKD 0.4116702079772949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.7027915224432946
Loss made of: CE 0.25395554304122925, LKD 0.40356701612472534, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.7476526156067849
Loss made of: CE 0.20452027022838593, LKD 0.3976968228816986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6813249289989471
Loss made of: CE 0.20966997742652893, LKD 0.36173638701438904, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2800469994544983, Reg Loss=0.4525417685508728
Clinet index 7, End of Epoch 2/6, Average Loss=0.7325887680053711, Class Loss=0.2800469994544983, Reg Loss=0.4525417685508728
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/102, Loss=0.7157103657722473
Loss made of: CE 0.2870136499404907, LKD 0.46585139632225037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6952572673559189
Loss made of: CE 0.2534506618976593, LKD 0.48659205436706543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.7075742036104202
Loss made of: CE 0.2641434073448181, LKD 0.4591841697692871, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.7172427028417587
Loss made of: CE 0.23139946162700653, LKD 0.3257642090320587, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.7311480790376663
Loss made of: CE 0.2644120454788208, LKD 0.4991421699523926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.717848590016365
Loss made of: CE 0.21029119193553925, LKD 0.399921715259552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.7174794718623161
Loss made of: CE 0.23221135139465332, LKD 0.5196742415428162, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.7068287506699562
Loss made of: CE 0.21201948821544647, LKD 0.5659725666046143, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.7517470881342888
Loss made of: CE 0.27387934923171997, LKD 0.49236902594566345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.6860527604818344
Loss made of: CE 0.2031230628490448, LKD 0.3542499542236328, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25956079363822937, Reg Loss=0.45408347249031067
Clinet index 7, End of Epoch 3/6, Average Loss=0.71364426612854, Class Loss=0.25956079363822937, Reg Loss=0.45408347249031067
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/102, Loss=0.6675253659486771
Loss made of: CE 0.2402084469795227, LKD 0.4183596968650818, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.7200536727905273
Loss made of: CE 0.2924526631832123, LKD 0.5087396502494812, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.7570503696799278
Loss made of: CE 0.21983228623867035, LKD 0.41714876890182495, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6892793491482735
Loss made of: CE 0.2438262701034546, LKD 0.45336729288101196, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.6852618291974067
Loss made of: CE 0.24910913407802582, LKD 0.4896087646484375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.7229776829481125
Loss made of: CE 0.3931810259819031, LKD 0.46500539779663086, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6946187004446983
Loss made of: CE 0.23713283240795135, LKD 0.4593942165374756, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.717975564301014
Loss made of: CE 0.2521621584892273, LKD 0.458445280790329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6939894810318947
Loss made of: CE 0.2303953468799591, LKD 0.32589346170425415, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.699096468091011
Loss made of: CE 0.20439931750297546, LKD 0.4249255359172821, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.24924881756305695, Reg Loss=0.4547717571258545
Clinet index 7, End of Epoch 4/6, Average Loss=0.7040205597877502, Class Loss=0.24924881756305695, Reg Loss=0.4547717571258545
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/102, Loss=0.7272849664092064
Loss made of: CE 0.23443500697612762, LKD 0.4631604850292206, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6929531335830689
Loss made of: CE 0.21477234363555908, LKD 0.42005738615989685, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6605414941906929
Loss made of: CE 0.2844151258468628, LKD 0.49464136362075806, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6821680098772049
Loss made of: CE 0.19872891902923584, LKD 0.4308549165725708, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.6765383303165435
Loss made of: CE 0.29110756516456604, LKD 0.43516311049461365, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6848011866211892
Loss made of: CE 0.21779309213161469, LKD 0.5173313617706299, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6966014713048935
Loss made of: CE 0.22492095828056335, LKD 0.36472266912460327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6926650792360306
Loss made of: CE 0.18736927211284637, LKD 0.3620666265487671, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.7499250039458275
Loss made of: CE 0.3592587411403656, LKD 0.6105102896690369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6557749971747399
Loss made of: CE 0.2101563662290573, LKD 0.43391868472099304, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23714429140090942, Reg Loss=0.45617255568504333
Clinet index 7, End of Epoch 5/6, Average Loss=0.6933168172836304, Class Loss=0.23714429140090942, Reg Loss=0.45617255568504333
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/102, Loss=0.7120573595166206
Loss made of: CE 0.26832854747772217, LKD 0.49771255254745483, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.7184546604752541
Loss made of: CE 0.22461456060409546, LKD 0.5288618803024292, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.6926245093345642
Loss made of: CE 0.22185032069683075, LKD 0.4891135096549988, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.7023249939084053
Loss made of: CE 0.20253358781337738, LKD 0.4112151861190796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6789100483059883
Loss made of: CE 0.35033780336380005, LKD 0.42905139923095703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6282816261053086
Loss made of: CE 0.17702794075012207, LKD 0.3518971800804138, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6411259204149247
Loss made of: CE 0.1985655128955841, LKD 0.47443389892578125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6957209154963493
Loss made of: CE 0.17147694528102875, LKD 0.520082950592041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.672430045902729
Loss made of: CE 0.1898689717054367, LKD 0.47781381011009216, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6643268972635269
Loss made of: CE 0.3424221873283386, LKD 0.4618193805217743, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22890320420265198, Reg Loss=0.4558767080307007
Clinet index 7, End of Epoch 6/6, Average Loss=0.6847798824310303, Class Loss=0.22890320420265198, Reg Loss=0.4558767080307007
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/102, Loss=0.8311584174633027
Loss made of: CE 0.45287880301475525, LKD 0.40811190009117126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.9094260632991791
Loss made of: CE 0.38994714617729187, LKD 0.44026798009872437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.8332509994506836
Loss made of: CE 0.35719236731529236, LKD 0.5323302745819092, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.8068710923194885
Loss made of: CE 0.2707862854003906, LKD 0.40611502528190613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.7870906084775925
Loss made of: CE 0.2684384286403656, LKD 0.3479590117931366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.7961147040128708
Loss made of: CE 0.3306781053543091, LKD 0.38948482275009155, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.7729503184556961
Loss made of: CE 0.30936962366104126, LKD 0.410674512386322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.7457208946347237
Loss made of: CE 0.30076032876968384, LKD 0.43857234716415405, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.7175656840205192
Loss made of: CE 0.28476566076278687, LKD 0.460541307926178, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.7506655290722847
Loss made of: CE 0.31523197889328003, LKD 0.577314019203186, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3467833399772644, Reg Loss=0.4494307041168213
Clinet index 11, End of Epoch 1/6, Average Loss=0.7962140440940857, Class Loss=0.3467833399772644, Reg Loss=0.4494307041168213
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/102, Loss=0.7462857007980347
Loss made of: CE 0.25018367171287537, LKD 0.38999706506729126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.7149067625403405
Loss made of: CE 0.2751076817512512, LKD 0.3664042353630066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.7411706954240799
Loss made of: CE 0.35189780592918396, LKD 0.5202052593231201, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.7506448209285737
Loss made of: CE 0.3450797498226166, LKD 0.5058628916740417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.7277624174952507
Loss made of: CE 0.25883519649505615, LKD 0.5224062204360962, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.7610931918025017
Loss made of: CE 0.2547051012516022, LKD 0.4606820344924927, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6816945627331734
Loss made of: CE 0.26584237813949585, LKD 0.5968554615974426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.7808715090155601
Loss made of: CE 0.2042427510023117, LKD 0.6646758913993835, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6807931214570999
Loss made of: CE 0.37323540449142456, LKD 0.500806450843811, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6972729951143265
Loss made of: CE 0.24932372570037842, LKD 0.43846362829208374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.28086817264556885, Reg Loss=0.4492083787918091
Clinet index 11, End of Epoch 2/6, Average Loss=0.7300765514373779, Class Loss=0.28086817264556885, Reg Loss=0.4492083787918091
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/102, Loss=0.7252897173166275
Loss made of: CE 0.29682061076164246, LKD 0.5112903118133545, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.7395216196775436
Loss made of: CE 0.3253987729549408, LKD 0.4799564480781555, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.6999911323189736
Loss made of: CE 0.22218549251556396, LKD 0.4281090199947357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6955597296357154
Loss made of: CE 0.21259503066539764, LKD 0.5081737041473389, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.7067404195666314
Loss made of: CE 0.28686410188674927, LKD 0.4813804626464844, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6763927191495895
Loss made of: CE 0.21165913343429565, LKD 0.37643975019454956, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.7220081657171249
Loss made of: CE 0.20763945579528809, LKD 0.40651735663414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.7138182744383812
Loss made of: CE 0.2229580134153366, LKD 0.4165143370628357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.6919250696897506
Loss made of: CE 0.26080548763275146, LKD 0.44898897409439087, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.7680014252662659
Loss made of: CE 0.21430806815624237, LKD 0.43139633536338806, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2592451572418213, Reg Loss=0.4545467495918274
Clinet index 11, End of Epoch 3/6, Average Loss=0.7137919068336487, Class Loss=0.2592451572418213, Reg Loss=0.4545467495918274
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/102, Loss=0.732481399178505
Loss made of: CE 0.2772245407104492, LKD 0.3886513113975525, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6678878888487816
Loss made of: CE 0.19773650169372559, LKD 0.336051344871521, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.7089207336306572
Loss made of: CE 0.40464019775390625, LKD 0.525209903717041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6960342034697533
Loss made of: CE 0.22131840884685516, LKD 0.4095040261745453, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.7186908438801766
Loss made of: CE 0.38262277841567993, LKD 0.5025702118873596, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.6897676199674606
Loss made of: CE 0.22393035888671875, LKD 0.3442955017089844, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6768971085548401
Loss made of: CE 0.34409499168395996, LKD 0.5266503095626831, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.7295260220766068
Loss made of: CE 0.3040526807308197, LKD 0.46608075499534607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.7070951163768768
Loss made of: CE 0.19779133796691895, LKD 0.4465981423854828, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.7105136528611183
Loss made of: CE 0.31665536761283875, LKD 0.4134386479854584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2510322630405426, Reg Loss=0.4532014727592468
Clinet index 11, End of Epoch 4/6, Average Loss=0.7042337656021118, Class Loss=0.2510322630405426, Reg Loss=0.4532014727592468
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/102, Loss=0.7180754601955414
Loss made of: CE 0.22494564950466156, LKD 0.5552486777305603, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.7381292551755905
Loss made of: CE 0.1785857081413269, LKD 0.4790080189704895, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.7009336024522781
Loss made of: CE 0.21248917281627655, LKD 0.42137807607650757, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6961579248309135
Loss made of: CE 0.2785104215145111, LKD 0.5029749274253845, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.7065790325403214
Loss made of: CE 0.22243425250053406, LKD 0.44632503390312195, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.712021017074585
Loss made of: CE 0.23591098189353943, LKD 0.6300724744796753, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6275347769260406
Loss made of: CE 0.24683670699596405, LKD 0.44357022643089294, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6166763439774513
Loss made of: CE 0.1817178726196289, LKD 0.41177329421043396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.6771747455000877
Loss made of: CE 0.21711349487304688, LKD 0.516817569732666, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6639694809913635
Loss made of: CE 0.212480828166008, LKD 0.4202975928783417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2332700490951538, Reg Loss=0.4534633755683899
Clinet index 11, End of Epoch 5/6, Average Loss=0.6867334246635437, Class Loss=0.2332700490951538, Reg Loss=0.4534633755683899
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/102, Loss=0.6773606032133103
Loss made of: CE 0.1884744018316269, LKD 0.39302730560302734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6844228088855744
Loss made of: CE 0.2621336877346039, LKD 0.5246794819831848, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.6802530318498612
Loss made of: CE 0.19380927085876465, LKD 0.3782370686531067, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6912180945277214
Loss made of: CE 0.30015259981155396, LKD 0.4809042811393738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6761724293231964
Loss made of: CE 0.23314893245697021, LKD 0.44381052255630493, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6765250250697136
Loss made of: CE 0.23430857062339783, LKD 0.5323876738548279, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6961439028382301
Loss made of: CE 0.2213520109653473, LKD 0.36859259009361267, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6851304620504379
Loss made of: CE 0.23913440108299255, LKD 0.5794464349746704, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6529704019427299
Loss made of: CE 0.2265404909849167, LKD 0.4166257381439209, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6361849963665008
Loss made of: CE 0.25439655780792236, LKD 0.5494995713233948, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22698837518692017, Reg Loss=0.4513854682445526
Clinet index 11, End of Epoch 6/6, Average Loss=0.6783738136291504, Class Loss=0.22698837518692017, Reg Loss=0.4513854682445526
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/105, Loss=0.922620752453804
Loss made of: CE 0.6692962050437927, LKD 0.42705079913139343, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/105, Loss=0.8551804214715958
Loss made of: CE 0.43239325284957886, LKD 0.4283638596534729, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/105, Loss=0.7919481605291366
Loss made of: CE 0.3711690902709961, LKD 0.43938618898391724, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/105, Loss=0.8033816978335381
Loss made of: CE 0.24350957572460175, LKD 0.4221442639827728, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/105, Loss=0.7587748348712922
Loss made of: CE 0.3202146887779236, LKD 0.34082168340682983, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/105, Loss=0.7119256108999252
Loss made of: CE 0.39930590987205505, LKD 0.5763338804244995, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/105, Loss=0.7964321911334992
Loss made of: CE 0.2948255240917206, LKD 0.385930597782135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/105, Loss=0.757222655415535
Loss made of: CE 0.3355497717857361, LKD 0.42682239413261414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/105, Loss=0.7828175112605095
Loss made of: CE 0.31546327471733093, LKD 0.3989216685295105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/105, Loss=0.7385446071624756
Loss made of: CE 0.3033474087715149, LKD 0.4177839159965515, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.364894837141037, Reg Loss=0.4276871681213379
Clinet index 16, End of Epoch 1/6, Average Loss=0.7925820350646973, Class Loss=0.364894837141037, Reg Loss=0.4276871681213379
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/105, Loss=0.7293727397918701
Loss made of: CE 0.3023187220096588, LKD 0.3374343514442444, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/105, Loss=0.7625513464212418
Loss made of: CE 0.3611540198326111, LKD 0.4370921552181244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/105, Loss=0.6960201889276505
Loss made of: CE 0.30248913168907166, LKD 0.435119092464447, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/105, Loss=0.7618576154112816
Loss made of: CE 0.21943867206573486, LKD 0.4315025806427002, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/105, Loss=0.6967690661549568
Loss made of: CE 0.28407448530197144, LKD 0.4870832860469818, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/105, Loss=0.7022623762488365
Loss made of: CE 0.1892765760421753, LKD 0.3618191182613373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/105, Loss=0.7090967178344727
Loss made of: CE 0.2996178865432739, LKD 0.4641464352607727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/105, Loss=0.7322722911834717
Loss made of: CE 0.3042280077934265, LKD 0.36665043234825134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/105, Loss=0.7264115169644356
Loss made of: CE 0.25464221835136414, LKD 0.4861468970775604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/105, Loss=0.7317958399653435
Loss made of: CE 0.28706642985343933, LKD 0.4110472798347473, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.29825207591056824, Reg Loss=0.4265039563179016
Clinet index 16, End of Epoch 2/6, Average Loss=0.7247560024261475, Class Loss=0.29825207591056824, Reg Loss=0.4265039563179016
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/105, Loss=0.7195745259523392
Loss made of: CE 0.236066073179245, LKD 0.5226259827613831, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/105, Loss=0.6913540825247765
Loss made of: CE 0.26028209924697876, LKD 0.408435583114624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/105, Loss=0.6931665137410163
Loss made of: CE 0.2034401148557663, LKD 0.39994633197784424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/105, Loss=0.7140835106372834
Loss made of: CE 0.3137088716030121, LKD 0.4395131468772888, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/105, Loss=0.6780566275119781
Loss made of: CE 0.23966357111930847, LKD 0.48528188467025757, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/105, Loss=0.7072980865836144
Loss made of: CE 0.34480583667755127, LKD 0.5406901240348816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/105, Loss=0.6715525582432746
Loss made of: CE 0.24554309248924255, LKD 0.3640090227127075, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/105, Loss=0.6716953501105308
Loss made of: CE 0.3292033076286316, LKD 0.37103521823883057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/105, Loss=0.7207184880971909
Loss made of: CE 0.2645157277584076, LKD 0.4526035785675049, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/105, Loss=0.7427063390612603
Loss made of: CE 0.26544439792633057, LKD 0.41771435737609863, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.27370044589042664, Reg Loss=0.42767179012298584
Clinet index 16, End of Epoch 3/6, Average Loss=0.7013722658157349, Class Loss=0.27370044589042664, Reg Loss=0.42767179012298584
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/105, Loss=0.7007200852036476
Loss made of: CE 0.23591545224189758, LKD 0.36513397097587585, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/105, Loss=0.7012250036001205
Loss made of: CE 0.21184204518795013, LKD 0.4806897044181824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/105, Loss=0.6746616989374161
Loss made of: CE 0.2242918461561203, LKD 0.40532857179641724, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/105, Loss=0.6606798991560936
Loss made of: CE 0.18796126544475555, LKD 0.3867228031158447, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/105, Loss=0.7053741008043289
Loss made of: CE 0.27798569202423096, LKD 0.5288398861885071, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/105, Loss=0.7084723189473152
Loss made of: CE 0.3008647561073303, LKD 0.5149062275886536, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/105, Loss=0.6848175793886184
Loss made of: CE 0.2621244490146637, LKD 0.39729493856430054, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/105, Loss=0.6958768025040627
Loss made of: CE 0.283264696598053, LKD 0.3559685945510864, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/105, Loss=0.650640495121479
Loss made of: CE 0.247575581073761, LKD 0.3406873643398285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/105, Loss=0.6757924392819404
Loss made of: CE 0.20564782619476318, LKD 0.4668906629085541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.253213495016098, Reg Loss=0.4299275577068329
Clinet index 16, End of Epoch 4/6, Average Loss=0.6831410527229309, Class Loss=0.253213495016098, Reg Loss=0.4299275577068329
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/105, Loss=0.6718954026699067
Loss made of: CE 0.3049440085887909, LKD 0.4514698386192322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/105, Loss=0.7095023021101952
Loss made of: CE 0.24061505496501923, LKD 0.42268866300582886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/105, Loss=0.6479252636432647
Loss made of: CE 0.20459222793579102, LKD 0.4216899573802948, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/105, Loss=0.6928751409053803
Loss made of: CE 0.2521144151687622, LKD 0.4247923791408539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/105, Loss=0.6594900891184807
Loss made of: CE 0.39634212851524353, LKD 0.4681282937526703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/105, Loss=0.65794258415699
Loss made of: CE 0.24534699320793152, LKD 0.4275047183036804, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/105, Loss=0.650465440750122
Loss made of: CE 0.17524492740631104, LKD 0.45208343863487244, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/105, Loss=0.6801129505038261
Loss made of: CE 0.24608521163463593, LKD 0.4701150357723236, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/105, Loss=0.7189330205321312
Loss made of: CE 0.23634952306747437, LKD 0.48749908804893494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/105, Loss=0.6654243052005768
Loss made of: CE 0.22811436653137207, LKD 0.37560948729515076, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.24024757742881775, Reg Loss=0.43281885981559753
Clinet index 16, End of Epoch 5/6, Average Loss=0.6730664372444153, Class Loss=0.24024757742881775, Reg Loss=0.43281885981559753
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/105, Loss=0.7041633516550064
Loss made of: CE 0.2200772762298584, LKD 0.46317362785339355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/105, Loss=0.6987382620573044
Loss made of: CE 0.45525050163269043, LKD 0.6011449098587036, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/105, Loss=0.6726650223135948
Loss made of: CE 0.25635436177253723, LKD 0.4563251733779907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/105, Loss=0.6393782213330269
Loss made of: CE 0.2292037457227707, LKD 0.43025708198547363, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/105, Loss=0.6403458416461945
Loss made of: CE 0.20032846927642822, LKD 0.4115191102027893, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/105, Loss=0.6368834331631661
Loss made of: CE 0.17261922359466553, LKD 0.46017083525657654, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/105, Loss=0.6457877054810524
Loss made of: CE 0.19898945093154907, LKD 0.5096791982650757, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/105, Loss=0.6337231591343879
Loss made of: CE 0.19959402084350586, LKD 0.313787043094635, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/105, Loss=0.6145372942090035
Loss made of: CE 0.19369685649871826, LKD 0.42351168394088745, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/105, Loss=0.638344107568264
Loss made of: CE 0.2008211314678192, LKD 0.4986151456832886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.227086141705513, Reg Loss=0.4271353781223297
Clinet index 16, End of Epoch 6/6, Average Loss=0.6542215347290039, Class Loss=0.227086141705513, Reg Loss=0.4271353781223297
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.9233026444911957
Loss made of: CE 0.5094055533409119, LKD 0.47714561223983765, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.864519664645195
Loss made of: CE 0.346549928188324, LKD 0.5320515632629395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.7918608009815216
Loss made of: CE 0.37978944182395935, LKD 0.5636408925056458, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.8008539289236069
Loss made of: CE 0.2831977307796478, LKD 0.474392831325531, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.7964748919010163
Loss made of: CE 0.2850876450538635, LKD 0.39763718843460083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.7647371873259544
Loss made of: CE 0.3918306231498718, LKD 0.4605425000190735, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.7136803328990936
Loss made of: CE 0.32644301652908325, LKD 0.4041981101036072, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.7532567799091339
Loss made of: CE 0.3068055808544159, LKD 0.43433448672294617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.766339835524559
Loss made of: CE 0.32922786474227905, LKD 0.529514491558075, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.7357733651995659
Loss made of: CE 0.2939017415046692, LKD 0.5167499780654907, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3391437232494354, Reg Loss=0.45257842540740967
Clinet index 18, End of Epoch 1/6, Average Loss=0.7917221784591675, Class Loss=0.3391437232494354, Reg Loss=0.45257842540740967
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/102, Loss=0.7549376100301742
Loss made of: CE 0.2463219165802002, LKD 0.4608272910118103, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.7594305202364922
Loss made of: CE 0.3907952308654785, LKD 0.5985223650932312, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.74741430580616
Loss made of: CE 0.32587331533432007, LKD 0.4254302978515625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.7189996689558029
Loss made of: CE 0.2429560124874115, LKD 0.38025838136672974, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.7356369435787201
Loss made of: CE 0.31588155031204224, LKD 0.5083848237991333, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.7427437379956245
Loss made of: CE 0.2654752731323242, LKD 0.6508673429489136, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6948453068733216
Loss made of: CE 0.20697054266929626, LKD 0.3747047781944275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.7302184388041496
Loss made of: CE 0.3154425621032715, LKD 0.5264930725097656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6617223992943764
Loss made of: CE 0.2607223391532898, LKD 0.3850143849849701, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.7470477253198624
Loss made of: CE 0.22792601585388184, LKD 0.431818425655365, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.27555564045906067, Reg Loss=0.4532426595687866
Clinet index 18, End of Epoch 2/6, Average Loss=0.7287982702255249, Class Loss=0.27555564045906067, Reg Loss=0.4532426595687866
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/102, Loss=0.7206151455640792
Loss made of: CE 0.22643020749092102, LKD 0.5302440524101257, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.689063049852848
Loss made of: CE 0.27592775225639343, LKD 0.384951651096344, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.7589242830872536
Loss made of: CE 0.21356964111328125, LKD 0.32682034373283386, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.7604136139154434
Loss made of: CE 0.2321660965681076, LKD 0.4862719476222992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.6896694019436836
Loss made of: CE 0.27034831047058105, LKD 0.42414161562919617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6739305302500724
Loss made of: CE 0.25736838579177856, LKD 0.4461142420768738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.6795052230358124
Loss made of: CE 0.20716699957847595, LKD 0.5035771131515503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.6769506528973579
Loss made of: CE 0.2546330690383911, LKD 0.3468804359436035, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.7283696293830871
Loss made of: CE 0.16439375281333923, LKD 0.4033586382865906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.7156110659241677
Loss made of: CE 0.18647480010986328, LKD 0.3759048879146576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.25537896156311035, Reg Loss=0.4554583430290222
Clinet index 18, End of Epoch 3/6, Average Loss=0.7108373045921326, Class Loss=0.25537896156311035, Reg Loss=0.4554583430290222
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/102, Loss=0.7179990440607071
Loss made of: CE 0.2306232452392578, LKD 0.4098603129386902, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.69914660602808
Loss made of: CE 0.21709144115447998, LKD 0.48250603675842285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.7106659814715386
Loss made of: CE 0.28853222727775574, LKD 0.513924777507782, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.7142949193716049
Loss made of: CE 0.2866513133049011, LKD 0.6316499710083008, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.6873579755425453
Loss made of: CE 0.2298908680677414, LKD 0.41585588455200195, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.7109879568219185
Loss made of: CE 0.24522100389003754, LKD 0.4453291893005371, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6563411951065063
Loss made of: CE 0.15787763893604279, LKD 0.3391171395778656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.6813874661922454
Loss made of: CE 0.22528314590454102, LKD 0.494769811630249, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6832817465066909
Loss made of: CE 0.2771039307117462, LKD 0.41650956869125366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.7211039394140244
Loss made of: CE 0.21574239432811737, LKD 0.4679608941078186, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.23933380842208862, Reg Loss=0.4560369849205017
Clinet index 18, End of Epoch 4/6, Average Loss=0.6953707933425903, Class Loss=0.23933380842208862, Reg Loss=0.4560369849205017
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/102, Loss=0.6908795475959778
Loss made of: CE 0.2493085116147995, LKD 0.4384182393550873, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6921132639050483
Loss made of: CE 0.21078310906887054, LKD 0.4467380940914154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6870446458458901
Loss made of: CE 0.18683645129203796, LKD 0.43939074873924255, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6769771993160247
Loss made of: CE 0.2109602689743042, LKD 0.45604270696640015, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.7129867479205132
Loss made of: CE 0.2384466826915741, LKD 0.40127119421958923, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.7126583367586136
Loss made of: CE 0.23882818222045898, LKD 0.4556719660758972, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6828594490885734
Loss made of: CE 0.30056363344192505, LKD 0.5413357615470886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6978812590241432
Loss made of: CE 0.20639142394065857, LKD 0.44636091589927673, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.6500861167907714
Loss made of: CE 0.23822598159313202, LKD 0.42038917541503906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6705948352813721
Loss made of: CE 0.14924874901771545, LKD 0.4429411292076111, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.23308466374874115, Reg Loss=0.4538308084011078
Clinet index 18, End of Epoch 5/6, Average Loss=0.6869154572486877, Class Loss=0.23308466374874115, Reg Loss=0.4538308084011078
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/102, Loss=0.6487049326300621
Loss made of: CE 0.23036625981330872, LKD 0.48554229736328125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6643579065799713
Loss made of: CE 0.17544619739055634, LKD 0.39453551173210144, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.7041017025709152
Loss made of: CE 0.2399309128522873, LKD 0.5502541065216064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6722988858819008
Loss made of: CE 0.25991833209991455, LKD 0.5225991010665894, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6708414807915688
Loss made of: CE 0.16738352179527283, LKD 0.4034374952316284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6687086790800094
Loss made of: CE 0.22523558139801025, LKD 0.4854748249053955, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6680489182472229
Loss made of: CE 0.2233896553516388, LKD 0.41121453046798706, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.7310656040906907
Loss made of: CE 0.1700867861509323, LKD 0.4486446976661682, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.681311097741127
Loss made of: CE 0.18592636287212372, LKD 0.5378659963607788, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6996269837021828
Loss made of: CE 0.27321600914001465, LKD 0.5220041871070862, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.22457891702651978, Reg Loss=0.4565091133117676
Clinet index 18, End of Epoch 6/6, Average Loss=0.6810880303382874, Class Loss=0.22457891702651978, Reg Loss=0.4565091133117676
federated aggregation...
Validation, Class Loss=0.43956315517425537, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.864528
Mean Acc: 0.598079
FreqW Acc: 0.783361
Mean IoU: 0.462307
Class IoU:
	class 0: 0.8946207
	class 1: 0.74898505
	class 2: 0.26478612
	class 3: 0.5039569
	class 4: 0.50336504
	class 5: 0.22848578
	class 6: 0.757352
	class 7: 0.7365555
	class 8: 0.49592528
	class 9: 0.033709634
	class 10: 0.39382976
	class 11: 0.3114171
	class 12: 0.2826644
	class 13: 0.307082
	class 14: 0.6731149
	class 15: 0.72336715
	class 16: 0.0
Class Acc:
	class 0: 0.94030297
	class 1: 0.77175653
	class 2: 0.45203352
	class 3: 0.5891063
	class 4: 0.7438964
	class 5: 0.23029174
	class 6: 0.85338867
	class 7: 0.85492927
	class 8: 0.92582154
	class 9: 0.036503177
	class 10: 0.5556533
	class 11: 0.67441785
	class 12: 0.33866417
	class 13: 0.40988934
	class 14: 0.8794898
	class 15: 0.91119385
	class 16: 0.0

federated global round: 17, step: 3
select part of clients to conduct local training
[5, 3, 17, 11]
Current Client Index:  5
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.6700327217578887
Loss made of: CE 0.23838478326797485, LKD 0.3599526882171631, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.6628517791628837
Loss made of: CE 0.1950853317975998, LKD 0.44134971499443054, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.6702022269368172
Loss made of: CE 0.1920512616634369, LKD 0.37096258997917175, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6998235642910003
Loss made of: CE 0.2311004102230072, LKD 0.4574253261089325, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.660243371129036
Loss made of: CE 0.2519623041152954, LKD 0.4573625326156616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.6846671089529991
Loss made of: CE 0.42624956369400024, LKD 0.49418050050735474, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.6542454659938812
Loss made of: CE 0.26668787002563477, LKD 0.4457794427871704, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.7165924131870269
Loss made of: CE 0.23595580458641052, LKD 0.3333686292171478, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.6689755618572235
Loss made of: CE 0.17607927322387695, LKD 0.4174221456050873, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.6611473664641381
Loss made of: CE 0.17983245849609375, LKD 0.5145387649536133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2245854139328003, Reg Loss=0.44998642802238464
Clinet index 5, End of Epoch 1/6, Average Loss=0.6745718717575073, Class Loss=0.2245854139328003, Reg Loss=0.44998642802238464
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/102, Loss=0.6736326679587364
Loss made of: CE 0.18909268081188202, LKD 0.44523775577545166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.6898295894265175
Loss made of: CE 0.19522610306739807, LKD 0.4259985387325287, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.6608106479048729
Loss made of: CE 0.20394006371498108, LKD 0.5167460441589355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.661886702477932
Loss made of: CE 0.22742992639541626, LKD 0.46214041113853455, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.6929721266031266
Loss made of: CE 0.16989879310131073, LKD 0.41842055320739746, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.6755244210362434
Loss made of: CE 0.18846487998962402, LKD 0.409839004278183, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6369997665286065
Loss made of: CE 0.22003015875816345, LKD 0.40213435888290405, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.6879971161484718
Loss made of: CE 0.2817097008228302, LKD 0.5565381050109863, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6420306369662285
Loss made of: CE 0.2015388011932373, LKD 0.43714308738708496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6517709463834762
Loss made of: CE 0.1825670450925827, LKD 0.47029823064804077, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2188168615102768, Reg Loss=0.4478563666343689
Clinet index 5, End of Epoch 2/6, Average Loss=0.6666732430458069, Class Loss=0.2188168615102768, Reg Loss=0.4478563666343689
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/102, Loss=0.6633735030889512
Loss made of: CE 0.1809307336807251, LKD 0.44905993342399597, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6561933770775795
Loss made of: CE 0.16179654002189636, LKD 0.3607669770717621, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.6368449330329895
Loss made of: CE 0.2768428921699524, LKD 0.516608715057373, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6935964152216911
Loss made of: CE 0.2163110226392746, LKD 0.4293934106826782, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.7228432759642601
Loss made of: CE 0.2953791618347168, LKD 0.5844352841377258, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6533262178301811
Loss made of: CE 0.2665311098098755, LKD 0.576471209526062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.649563516676426
Loss made of: CE 0.2643386125564575, LKD 0.5931269526481628, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.6609401717782021
Loss made of: CE 0.1653437316417694, LKD 0.3812433183193207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.6340321362018585
Loss made of: CE 0.19526052474975586, LKD 0.3968990743160248, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.6510076254606247
Loss made of: CE 0.16720980405807495, LKD 0.37665075063705444, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21368040144443512, Reg Loss=0.4464462995529175
Clinet index 5, End of Epoch 3/6, Average Loss=0.6601266860961914, Class Loss=0.21368040144443512, Reg Loss=0.4464462995529175
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/102, Loss=0.7045242264866829
Loss made of: CE 0.22897522151470184, LKD 0.464744508266449, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6468049108982086
Loss made of: CE 0.18333014845848083, LKD 0.4291408658027649, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.6896895721554757
Loss made of: CE 0.22967486083507538, LKD 0.3651891350746155, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6979981645941734
Loss made of: CE 0.1921204775571823, LKD 0.43472588062286377, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.5938621789216996
Loss made of: CE 0.21457979083061218, LKD 0.5267274379730225, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.6601304858922958
Loss made of: CE 0.3074093163013458, LKD 0.4829206168651581, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6494362533092499
Loss made of: CE 0.16995131969451904, LKD 0.3559245765209198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.6718125320971012
Loss made of: CE 0.20420494675636292, LKD 0.33380958437919617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6566652551293373
Loss made of: CE 0.21397066116333008, LKD 0.43770188093185425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.6283458426594735
Loss made of: CE 0.19178259372711182, LKD 0.5252741575241089, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.20704859495162964, Reg Loss=0.4515722095966339
Clinet index 5, End of Epoch 4/6, Average Loss=0.6586208343505859, Class Loss=0.20704859495162964, Reg Loss=0.4515722095966339
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/102, Loss=0.6423407852649688
Loss made of: CE 0.2108861207962036, LKD 0.4614604413509369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.7112636476755142
Loss made of: CE 0.2026292085647583, LKD 0.44058024883270264, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6888085275888443
Loss made of: CE 0.1943635195493698, LKD 0.4142197370529175, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6911769762635231
Loss made of: CE 0.22415205836296082, LKD 0.47018206119537354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.6228206411004067
Loss made of: CE 0.1806468963623047, LKD 0.39955639839172363, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6597140088677407
Loss made of: CE 0.20627975463867188, LKD 0.4611155390739441, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6188486486673355
Loss made of: CE 0.1628699153661728, LKD 0.40584224462509155, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.5932782158255577
Loss made of: CE 0.25604912638664246, LKD 0.42611515522003174, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.6483257830142974
Loss made of: CE 0.18306732177734375, LKD 0.4909745156764984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6349664762616157
Loss made of: CE 0.15366491675376892, LKD 0.4105475842952728, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20086373388767242, Reg Loss=0.447406530380249
Clinet index 5, End of Epoch 5/6, Average Loss=0.6482702493667603, Class Loss=0.20086373388767242, Reg Loss=0.447406530380249
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/102, Loss=0.6336051106452942
Loss made of: CE 0.1606251448392868, LKD 0.43917545676231384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6100832715630531
Loss made of: CE 0.15420925617218018, LKD 0.3981395661830902, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.7028915390372277
Loss made of: CE 0.233613058924675, LKD 0.47009000182151794, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6241781577467919
Loss made of: CE 0.2134055495262146, LKD 0.46376317739486694, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.616896590590477
Loss made of: CE 0.2840586304664612, LKD 0.37961527705192566, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6081387355923653
Loss made of: CE 0.14191770553588867, LKD 0.363744854927063, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.682997478544712
Loss made of: CE 0.24602024257183075, LKD 0.429220050573349, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6333867028355599
Loss made of: CE 0.18581649661064148, LKD 0.3817868232727051, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6521876513957977
Loss made of: CE 0.15384727716445923, LKD 0.4989240765571594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6681489914655685
Loss made of: CE 0.19460636377334595, LKD 0.4011784493923187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1964384913444519, Reg Loss=0.4460291266441345
Clinet index 5, End of Epoch 6/6, Average Loss=0.6424676179885864, Class Loss=0.1964384913444519, Reg Loss=0.4460291266441345
Current Client Index:  3
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.6742251858115196
Loss made of: CE 0.22925607860088348, LKD 0.4777557849884033, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.6812763482332229
Loss made of: CE 0.18984344601631165, LKD 0.4828205108642578, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.6906480550765991
Loss made of: CE 0.24327342212200165, LKD 0.5421527028083801, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6442708492279052
Loss made of: CE 0.3124886453151703, LKD 0.41748160123825073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.6500572711229324
Loss made of: CE 0.23503409326076508, LKD 0.48895496129989624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.6946959882974625
Loss made of: CE 0.2320100963115692, LKD 0.536331832408905, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.6616712868213653
Loss made of: CE 0.22463318705558777, LKD 0.3916429877281189, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.6311156004667282
Loss made of: CE 0.2126859426498413, LKD 0.4113016128540039, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.7048826739192009
Loss made of: CE 0.2348787784576416, LKD 0.5076072812080383, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.6783872663974762
Loss made of: CE 0.2624591886997223, LKD 0.39443668723106384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2252335548400879, Reg Loss=0.44744908809661865
Clinet index 3, End of Epoch 1/6, Average Loss=0.6726826429367065, Class Loss=0.2252335548400879, Reg Loss=0.44744908809661865
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/102, Loss=0.6554296717047692
Loss made of: CE 0.3035350441932678, LKD 0.46681079268455505, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.7451692044734954
Loss made of: CE 0.30744922161102295, LKD 0.48099178075790405, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.6497218534350395
Loss made of: CE 0.25772330164909363, LKD 0.49304792284965515, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.677897660434246
Loss made of: CE 0.17046207189559937, LKD 0.4341575503349304, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.7089620709419251
Loss made of: CE 0.19685280323028564, LKD 0.4380602240562439, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.6138738095760345
Loss made of: CE 0.18354356288909912, LKD 0.4237670302391052, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6514157384634018
Loss made of: CE 0.16242766380310059, LKD 0.4020172953605652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.6312315568327904
Loss made of: CE 0.17977747321128845, LKD 0.49216771125793457, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.648240813612938
Loss made of: CE 0.18716353178024292, LKD 0.5095056295394897, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.673650124669075
Loss made of: CE 0.20476746559143066, LKD 0.39692848920822144, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.21607190370559692, Reg Loss=0.4481699764728546
Clinet index 3, End of Epoch 2/6, Average Loss=0.6642419099807739, Class Loss=0.21607190370559692, Reg Loss=0.4481699764728546
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/102, Loss=0.6793277785181999
Loss made of: CE 0.15097203850746155, LKD 0.41718435287475586, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6943528205156326
Loss made of: CE 0.1815624237060547, LKD 0.4071680009365082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.5903244540095329
Loss made of: CE 0.1821691244840622, LKD 0.3834598958492279, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6723629295825958
Loss made of: CE 0.22798757255077362, LKD 0.4365926682949066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.6908401787281037
Loss made of: CE 0.18693169951438904, LKD 0.3577241897583008, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6735204875469207
Loss made of: CE 0.2553861439228058, LKD 0.501370370388031, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.6378240153193474
Loss made of: CE 0.13552367687225342, LKD 0.37787124514579773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.6103938832879067
Loss made of: CE 0.18786349892616272, LKD 0.3948410451412201, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.651609654724598
Loss made of: CE 0.1943390816450119, LKD 0.5820290446281433, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.6389707326889038
Loss made of: CE 0.2596379220485687, LKD 0.433273047208786, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.20704810321331024, Reg Loss=0.4474414885044098
Clinet index 3, End of Epoch 3/6, Average Loss=0.6544895768165588, Class Loss=0.20704810321331024, Reg Loss=0.4474414885044098
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/102, Loss=0.6968881353735924
Loss made of: CE 0.2207879275083542, LKD 0.5729867815971375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6715036362409592
Loss made of: CE 0.22147850692272186, LKD 0.39272618293762207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.6629751905798912
Loss made of: CE 0.1827799379825592, LKD 0.570218026638031, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6399658232927322
Loss made of: CE 0.22525012493133545, LKD 0.5397671461105347, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.6749733254313469
Loss made of: CE 0.2207893580198288, LKD 0.4708481431007385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.6643520787358284
Loss made of: CE 0.1996413916349411, LKD 0.5218064785003662, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6339032009243966
Loss made of: CE 0.3276040852069855, LKD 0.5370450019836426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.621091665327549
Loss made of: CE 0.1409555822610855, LKD 0.424102783203125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6161619380116463
Loss made of: CE 0.20077309012413025, LKD 0.4492132067680359, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.6360953480005265
Loss made of: CE 0.2337912917137146, LKD 0.5219148397445679, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2042607218027115, Reg Loss=0.44749903678894043
Clinet index 3, End of Epoch 4/6, Average Loss=0.6517597436904907, Class Loss=0.2042607218027115, Reg Loss=0.44749903678894043
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/102, Loss=0.631044565141201
Loss made of: CE 0.2008509486913681, LKD 0.435749351978302, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6639026299118995
Loss made of: CE 0.23391541838645935, LKD 0.5933218002319336, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6409218177199364
Loss made of: CE 0.16908550262451172, LKD 0.34865301847457886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6605239525437355
Loss made of: CE 0.18622855842113495, LKD 0.46734553575515747, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.655264613032341
Loss made of: CE 0.18075034022331238, LKD 0.6215001344680786, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6605220243334771
Loss made of: CE 0.13261497020721436, LKD 0.36956900358200073, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6353842273354531
Loss made of: CE 0.1390722393989563, LKD 0.37681302428245544, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6155404150485992
Loss made of: CE 0.16234728693962097, LKD 0.34216684103012085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.6552844420075417
Loss made of: CE 0.17151062190532684, LKD 0.48236531019210815, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6634183809161186
Loss made of: CE 0.20599365234375, LKD 0.35781538486480713, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.20094390213489532, Reg Loss=0.4478895962238312
Clinet index 3, End of Epoch 5/6, Average Loss=0.6488335132598877, Class Loss=0.20094390213489532, Reg Loss=0.4478895962238312
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/102, Loss=0.643151231110096
Loss made of: CE 0.22436818480491638, LKD 0.5288483500480652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6415161564946175
Loss made of: CE 0.15867450833320618, LKD 0.4852291941642761, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.6241496130824089
Loss made of: CE 0.1776600331068039, LKD 0.4136240482330322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6051174879074097
Loss made of: CE 0.15167276561260223, LKD 0.3874594569206238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.598939673602581
Loss made of: CE 0.1449785679578781, LKD 0.4392946660518646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.7102415770292282
Loss made of: CE 0.2236657589673996, LKD 0.5205416083335876, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6401937812566757
Loss made of: CE 0.17022979259490967, LKD 0.4641358256340027, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6277730643749238
Loss made of: CE 0.18511860072612762, LKD 0.3931741714477539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6284899428486824
Loss made of: CE 0.21945717930793762, LKD 0.5487134456634521, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6640051886439323
Loss made of: CE 0.15262198448181152, LKD 0.34510356187820435, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1947275549173355, Reg Loss=0.44365137815475464
Clinet index 3, End of Epoch 6/6, Average Loss=0.638378918170929, Class Loss=0.1947275549173355, Reg Loss=0.44365137815475464
Current Client Index:  17
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=1.4859862983226777
Loss made of: CE 0.6553378105163574, LKD 0.556891143321991, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.2521011650562286
Loss made of: CE 0.6593444347381592, LKD 0.6038769483566284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7549123764038086, Reg Loss=0.597608745098114
Clinet index 17, End of Epoch 1/6, Average Loss=1.3525211811065674, Class Loss=0.7549123764038086, Reg Loss=0.597608745098114
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/23, Loss=1.102879711985588
Loss made of: CE 0.5083780288696289, LKD 0.5806231498718262, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=1.0585504680871964
Loss made of: CE 0.3578014373779297, LKD 0.593580961227417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5087717175483704, Reg Loss=0.5742505788803101
Clinet index 17, End of Epoch 2/6, Average Loss=1.0830223560333252, Class Loss=0.5087717175483704, Reg Loss=0.5742505788803101
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/23, Loss=1.007304960489273
Loss made of: CE 0.3254931569099426, LKD 0.575075626373291, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.9963825732469559
Loss made of: CE 0.47887319326400757, LKD 0.6654795408248901, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4083118140697479, Reg Loss=0.58085036277771
Clinet index 17, End of Epoch 3/6, Average Loss=0.9891622066497803, Class Loss=0.4083118140697479, Reg Loss=0.58085036277771
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/23, Loss=0.980775997042656
Loss made of: CE 0.48303645849227905, LKD 0.7363058924674988, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.9198415100574493
Loss made of: CE 0.3290688991546631, LKD 0.6540884971618652, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.36932501196861267, Reg Loss=0.5752504467964172
Clinet index 17, End of Epoch 4/6, Average Loss=0.9445754289627075, Class Loss=0.36932501196861267, Reg Loss=0.5752504467964172
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/23, Loss=0.9115806460380554
Loss made of: CE 0.3560190200805664, LKD 0.44499653577804565, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.921389177441597
Loss made of: CE 0.2732200026512146, LKD 0.5476727485656738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.35082918405532837, Reg Loss=0.5699716210365295
Clinet index 17, End of Epoch 5/6, Average Loss=0.9208008050918579, Class Loss=0.35082918405532837, Reg Loss=0.5699716210365295
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/23, Loss=0.9341559648513794
Loss made of: CE 0.32445842027664185, LKD 0.4718668460845947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.8946265816688538
Loss made of: CE 0.3926107585430145, LKD 0.5438079237937927, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3406171202659607, Reg Loss=0.5737742781639099
Clinet index 17, End of Epoch 6/6, Average Loss=0.9143913984298706, Class Loss=0.3406171202659607, Reg Loss=0.5737742781639099
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/102, Loss=0.6029593110084533
Loss made of: CE 0.22609297931194305, LKD 0.34899482131004333, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.715265330672264
Loss made of: CE 0.20760434865951538, LKD 0.41880202293395996, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.6863877445459365
Loss made of: CE 0.26257118582725525, LKD 0.5269879102706909, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6966000452637673
Loss made of: CE 0.15476320683956146, LKD 0.40674781799316406, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.6708942458033562
Loss made of: CE 0.1597595512866974, LKD 0.3687278926372528, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.6783121913671494
Loss made of: CE 0.19527000188827515, LKD 0.40603893995285034, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.6845922350883484
Loss made of: CE 0.2182648479938507, LKD 0.4181622266769409, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.663820430636406
Loss made of: CE 0.2357228845357895, LKD 0.4272575080394745, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.6455939814448357
Loss made of: CE 0.18670549988746643, LKD 0.5050677061080933, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.6743653655052185
Loss made of: CE 0.23088592290878296, LKD 0.5382043123245239, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.22473491728305817, Reg Loss=0.4491187632083893
Clinet index 11, End of Epoch 1/6, Average Loss=0.6738536953926086, Class Loss=0.22473491728305817, Reg Loss=0.4491187632083893
Pseudo labeling is: None
Epoch 2, lr = 0.000600
Epoch 2, Batch 10/102, Loss=0.6756820276379585
Loss made of: CE 0.1736135482788086, LKD 0.4003590941429138, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.6469908997416496
Loss made of: CE 0.21111701428890228, LKD 0.3660268187522888, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.6854352906346322
Loss made of: CE 0.252287358045578, LKD 0.507347047328949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.6612087324261665
Loss made of: CE 0.23091495037078857, LKD 0.48573678731918335, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.6704206049442292
Loss made of: CE 0.20819728076457977, LKD 0.516991138458252, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.7087701588869095
Loss made of: CE 0.2274785041809082, LKD 0.55278480052948, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6161891996860505
Loss made of: CE 0.19169095158576965, LKD 0.5186352729797363, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.7255787119269371
Loss made of: CE 0.17716841399669647, LKD 0.621126651763916, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6367540508508682
Loss made of: CE 0.33821719884872437, LKD 0.5084210634231567, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6344182536005973
Loss made of: CE 0.20112381875514984, LKD 0.4142560362815857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2176411896944046, Reg Loss=0.4504193365573883
Clinet index 11, End of Epoch 2/6, Average Loss=0.6680605411529541, Class Loss=0.2176411896944046, Reg Loss=0.4504193365573883
Pseudo labeling is: None
Epoch 3, lr = 0.000568
Epoch 3, Batch 10/102, Loss=0.6709890305995941
Loss made of: CE 0.2336798757314682, LKD 0.4845190942287445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6781716644763947
Loss made of: CE 0.24940697848796844, LKD 0.4988914132118225, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.6452926248311996
Loss made of: CE 0.21114520728588104, LKD 0.45732778310775757, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6510162964463234
Loss made of: CE 0.1912040114402771, LKD 0.48909565806388855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.6698551639914513
Loss made of: CE 0.21930146217346191, LKD 0.4936707019805908, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6183577179908752
Loss made of: CE 0.16509908437728882, LKD 0.39975088834762573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.6610908180475235
Loss made of: CE 0.1662764698266983, LKD 0.431007444858551, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.6722227513790131
Loss made of: CE 0.19456779956817627, LKD 0.4553905427455902, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.6539432585239411
Loss made of: CE 0.2532789707183838, LKD 0.443767786026001, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.7090957626700402
Loss made of: CE 0.14642274379730225, LKD 0.4341373145580292, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.21162357926368713, Reg Loss=0.4507748484611511
Clinet index 11, End of Epoch 3/6, Average Loss=0.6623984575271606, Class Loss=0.21162357926368713, Reg Loss=0.4507748484611511
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/102, Loss=0.6761552944779397
Loss made of: CE 0.22678451240062714, LKD 0.41907283663749695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6151383444666862
Loss made of: CE 0.1615810990333557, LKD 0.3114854097366333, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.6529494643211364
Loss made of: CE 0.33836740255355835, LKD 0.45149582624435425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6695598214864731
Loss made of: CE 0.1755155324935913, LKD 0.42434531450271606, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.6782965421676636
Loss made of: CE 0.2797817885875702, LKD 0.49786967039108276, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.6460120245814324
Loss made of: CE 0.17860381305217743, LKD 0.3334066867828369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6237567573785782
Loss made of: CE 0.26257196068763733, LKD 0.5474202036857605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.6806362599134446
Loss made of: CE 0.2405397891998291, LKD 0.4245772957801819, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6625977054238319
Loss made of: CE 0.1765531599521637, LKD 0.44229358434677124, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.6856361657381058
Loss made of: CE 0.28766995668411255, LKD 0.4432411193847656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2105206400156021, Reg Loss=0.4491790235042572
Clinet index 11, End of Epoch 4/6, Average Loss=0.6596996784210205, Class Loss=0.2105206400156021, Reg Loss=0.4491790235042572
Pseudo labeling is: None
Epoch 5, lr = 0.000504
Epoch 5, Batch 10/102, Loss=0.6806243628263473
Loss made of: CE 0.18681834638118744, LKD 0.5334041118621826, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6930480301380157
Loss made of: CE 0.16993963718414307, LKD 0.4385296702384949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6503296002745629
Loss made of: CE 0.17179875075817108, LKD 0.40852636098861694, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6679991081357002
Loss made of: CE 0.229475736618042, LKD 0.48521265387535095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.6700579777359963
Loss made of: CE 0.21135662496089935, LKD 0.44008302688598633, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6936255499720574
Loss made of: CE 0.22707371413707733, LKD 0.642467737197876, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.5908422827720642
Loss made of: CE 0.21974048018455505, LKD 0.44171351194381714, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.5807605355978012
Loss made of: CE 0.1500987857580185, LKD 0.4284672141075134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.651878148317337
Loss made of: CE 0.19084107875823975, LKD 0.5031296014785767, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.655066505074501
Loss made of: CE 0.200617253780365, LKD 0.44071197509765625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2036573886871338, Reg Loss=0.4512162506580353
Clinet index 11, End of Epoch 5/6, Average Loss=0.6548736095428467, Class Loss=0.2036573886871338, Reg Loss=0.4512162506580353
Pseudo labeling is: None
Epoch 6, lr = 0.000471
Epoch 6, Batch 10/102, Loss=0.6354461640119553
Loss made of: CE 0.17058563232421875, LKD 0.37501901388168335, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6533461958169937
Loss made of: CE 0.23544913530349731, LKD 0.5216255187988281, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.6563445314764976
Loss made of: CE 0.1701374351978302, LKD 0.3493135869503021, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6644466176629067
Loss made of: CE 0.28526806831359863, LKD 0.4822879731655121, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6322461470961571
Loss made of: CE 0.19929485023021698, LKD 0.4702669382095337, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6609068915247918
Loss made of: CE 0.23097185790538788, LKD 0.5571956038475037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.66483044475317
Loss made of: CE 0.21734631061553955, LKD 0.3651729226112366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6678562492132187
Loss made of: CE 0.1824679970741272, LKD 0.5894059538841248, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6497450590133667
Loss made of: CE 0.18526670336723328, LKD 0.430786669254303, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6102234661579132
Loss made of: CE 0.21572284400463104, LKD 0.47279852628707886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.20164889097213745, Reg Loss=0.4501313865184784
Clinet index 11, End of Epoch 6/6, Average Loss=0.6517802476882935, Class Loss=0.20164889097213745, Reg Loss=0.4501313865184784
federated aggregation...
Validation, Class Loss=0.4285958409309387, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.864987
Mean Acc: 0.593005
FreqW Acc: 0.784997
Mean IoU: 0.458738
Class IoU:
	class 0: 0.89560044
	class 1: 0.73409665
	class 2: 0.24924953
	class 3: 0.4899379
	class 4: 0.49167454
	class 5: 0.23673254
	class 6: 0.737136
	class 7: 0.7322541
	class 8: 0.49040002
	class 9: 0.042317197
	class 10: 0.23432584
	class 11: 0.31157088
	class 12: 0.31438294
	class 13: 0.39728358
	class 14: 0.6884349
	class 15: 0.7531568
	class 16: 0.0
Class Acc:
	class 0: 0.9413595
	class 1: 0.75260854
	class 2: 0.3987228
	class 3: 0.550623
	class 4: 0.7226797
	class 5: 0.2386688
	class 6: 0.81844974
	class 7: 0.84837127
	class 8: 0.9237364
	class 9: 0.047150645
	class 10: 0.26147133
	class 11: 0.6785834
	class 12: 0.40407377
	class 13: 0.67998016
	class 14: 0.90391606
	class 15: 0.9106883
	class 16: 0.0

federated global round: 18, step: 3
select part of clients to conduct local training
[9, 11, 13, 10]
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/102, Loss=0.6928792044520378
Loss made of: CE 0.2607617974281311, LKD 0.48488402366638184, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.6086454339325428
Loss made of: CE 0.2010217159986496, LKD 0.5172802209854126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.7064563691616058
Loss made of: CE 0.2672933340072632, LKD 0.39316922426223755, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6196154862642288
Loss made of: CE 0.21565786004066467, LKD 0.4679677486419678, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.6951353430747986
Loss made of: CE 0.24858582019805908, LKD 0.4335553050041199, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.6507369473576545
Loss made of: CE 0.2652111351490021, LKD 0.4598967432975769, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.6405477881431579
Loss made of: CE 0.20972812175750732, LKD 0.42536407709121704, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.6372625321149826
Loss made of: CE 0.22988133132457733, LKD 0.5310913920402527, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.7033192619681359
Loss made of: CE 0.21555016934871674, LKD 0.4975295066833496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.6278665214776993
Loss made of: CE 0.22600480914115906, LKD 0.4703964591026306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2084885686635971, Reg Loss=0.44976553320884705
Clinet index 9, End of Epoch 1/6, Average Loss=0.658254086971283, Class Loss=0.2084885686635971, Reg Loss=0.44976553320884705
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/102, Loss=0.6449140921235085
Loss made of: CE 0.19119152426719666, LKD 0.430009126663208, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.6413851544260979
Loss made of: CE 0.22698578238487244, LKD 0.49683016538619995, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.7237222477793693
Loss made of: CE 0.3569774627685547, LKD 0.5903964042663574, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.6020652145147324
Loss made of: CE 0.16916906833648682, LKD 0.3758888840675354, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.6725766360759735
Loss made of: CE 0.16807562112808228, LKD 0.4493786096572876, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.6437540024518966
Loss made of: CE 0.16895286738872528, LKD 0.4399902820587158, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6628420904278756
Loss made of: CE 0.1633421629667282, LKD 0.4180872440338135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.591389125585556
Loss made of: CE 0.17262238264083862, LKD 0.37526750564575195, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6496626034379005
Loss made of: CE 0.2170536369085312, LKD 0.49810928106307983, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6406345024704934
Loss made of: CE 0.1873796582221985, LKD 0.39739763736724854, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.2030670940876007, Reg Loss=0.44526171684265137
Clinet index 9, End of Epoch 2/6, Average Loss=0.6483287811279297, Class Loss=0.2030670940876007, Reg Loss=0.44526171684265137
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/102, Loss=0.6165271013975143
Loss made of: CE 0.18226151168346405, LKD 0.4200882911682129, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6767903864383698
Loss made of: CE 0.2538972496986389, LKD 0.40491431951522827, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.6474636599421502
Loss made of: CE 0.1518753170967102, LKD 0.5350989699363708, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6242559179663658
Loss made of: CE 0.1987510621547699, LKD 0.44239211082458496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.6326021939516068
Loss made of: CE 0.23018178343772888, LKD 0.47752904891967773, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.691101747751236
Loss made of: CE 0.21515004336833954, LKD 0.46272343397140503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.6601909503340722
Loss made of: CE 0.25547799468040466, LKD 0.40779727697372437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.6126266300678254
Loss made of: CE 0.21825364232063293, LKD 0.42926692962646484, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.6352470234036446
Loss made of: CE 0.15295350551605225, LKD 0.3939751088619232, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.6549947202205658
Loss made of: CE 0.17207036912441254, LKD 0.44295257329940796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19764478504657745, Reg Loss=0.4467751979827881
Clinet index 9, End of Epoch 3/6, Average Loss=0.6444199681282043, Class Loss=0.19764478504657745, Reg Loss=0.4467751979827881
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/102, Loss=0.6715434327721596
Loss made of: CE 0.2122010588645935, LKD 0.4269478917121887, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6275885984301567
Loss made of: CE 0.24088071286678314, LKD 0.5168731808662415, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.5852295853197574
Loss made of: CE 0.1592528373003006, LKD 0.34860700368881226, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6786533981561661
Loss made of: CE 0.20025554299354553, LKD 0.4177548587322235, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.630431966483593
Loss made of: CE 0.16981247067451477, LKD 0.46225985884666443, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.6603332370519638
Loss made of: CE 0.13690736889839172, LKD 0.4235801100730896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.5939355581998825
Loss made of: CE 0.13831724226474762, LKD 0.44807398319244385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.6943742632865906
Loss made of: CE 0.2840602397918701, LKD 0.5460910797119141, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6692277312278747
Loss made of: CE 0.1750251054763794, LKD 0.502335250377655, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.608858485519886
Loss made of: CE 0.16839680075645447, LKD 0.49436670541763306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.192530557513237, Reg Loss=0.4503265619277954
Clinet index 9, End of Epoch 4/6, Average Loss=0.6428571343421936, Class Loss=0.192530557513237, Reg Loss=0.4503265619277954
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/102, Loss=0.6125880181789398
Loss made of: CE 0.14217260479927063, LKD 0.368921160697937, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6615825161337853
Loss made of: CE 0.19317840039730072, LKD 0.42640790343284607, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6355519726872444
Loss made of: CE 0.1498408019542694, LKD 0.38230404257774353, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6259832173585892
Loss made of: CE 0.20512700080871582, LKD 0.4417871832847595, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.63523168861866
Loss made of: CE 0.14590995013713837, LKD 0.4361599087715149, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6099999770522118
Loss made of: CE 0.2640741765499115, LKD 0.44667717814445496, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6175209641456604
Loss made of: CE 0.17259681224822998, LKD 0.37569689750671387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6205150276422501
Loss made of: CE 0.14880073070526123, LKD 0.35776084661483765, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.6344218388199806
Loss made of: CE 0.15551868081092834, LKD 0.5011614561080933, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.694716089963913
Loss made of: CE 0.14025115966796875, LKD 0.4690472483634949, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18804733455181122, Reg Loss=0.44777047634124756
Clinet index 9, End of Epoch 5/6, Average Loss=0.63581782579422, Class Loss=0.18804733455181122, Reg Loss=0.44777047634124756
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/102, Loss=0.6240429356694221
Loss made of: CE 0.1694781482219696, LKD 0.43270254135131836, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6199145883321762
Loss made of: CE 0.174272820353508, LKD 0.4541139602661133, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.6752458706498146
Loss made of: CE 0.2568511962890625, LKD 0.4417809844017029, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.5846377864480019
Loss made of: CE 0.152723491191864, LKD 0.5438176393508911, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6683113470673561
Loss made of: CE 0.1608469933271408, LKD 0.4710165858268738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6325941264629364
Loss made of: CE 0.16199874877929688, LKD 0.45033955574035645, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6247433498501778
Loss made of: CE 0.17791470885276794, LKD 0.5275578498840332, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6316478177905083
Loss made of: CE 0.21991297602653503, LKD 0.4246792793273926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6266731351613999
Loss made of: CE 0.1905585527420044, LKD 0.3698233962059021, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6254356443881989
Loss made of: CE 0.17383375763893127, LKD 0.4531514346599579, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18642506003379822, Reg Loss=0.44558990001678467
Clinet index 9, End of Epoch 6/6, Average Loss=0.6320149898529053, Class Loss=0.18642506003379822, Reg Loss=0.44558990001678467
Current Client Index:  11
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000438
Epoch 1, Batch 10/102, Loss=0.61126888692379
Loss made of: CE 0.1878412365913391, LKD 0.3706771731376648, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.7157126694917679
Loss made of: CE 0.18775436282157898, LKD 0.413769006729126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.6733619794249535
Loss made of: CE 0.2561377286911011, LKD 0.5153332948684692, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.6791957065463066
Loss made of: CE 0.1651274412870407, LKD 0.37131422758102417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.6554936617612839
Loss made of: CE 0.149164617061615, LKD 0.3440189063549042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.6737446308135986
Loss made of: CE 0.1947304606437683, LKD 0.40114009380340576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.6667157262563705
Loss made of: CE 0.20012882351875305, LKD 0.44127726554870605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.6499056190252304
Loss made of: CE 0.23643982410430908, LKD 0.4354528784751892, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.6251055836677551
Loss made of: CE 0.17377865314483643, LKD 0.4772464632987976, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.6706925973296165
Loss made of: CE 0.23693911731243134, LKD 0.5816933512687683, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.21422424912452698, Reg Loss=0.4497348964214325
Clinet index 11, End of Epoch 1/6, Average Loss=0.6639591455459595, Class Loss=0.21422424912452698, Reg Loss=0.4497348964214325
Pseudo labeling is: None
Epoch 2, lr = 0.000405
Epoch 2, Batch 10/102, Loss=0.6514819651842118
Loss made of: CE 0.1751309484243393, LKD 0.43311557173728943, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.6404990628361702
Loss made of: CE 0.20840466022491455, LKD 0.3659137487411499, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.666258591413498
Loss made of: CE 0.23628553748130798, LKD 0.5397554636001587, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.6579737231135369
Loss made of: CE 0.21393924951553345, LKD 0.49245938658714294, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.6400585442781448
Loss made of: CE 0.16249816119670868, LKD 0.5234286785125732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.6888060837984085
Loss made of: CE 0.18104366958141327, LKD 0.48650646209716797, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.6050130024552345
Loss made of: CE 0.1904076337814331, LKD 0.5650231838226318, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.716311252117157
Loss made of: CE 0.17330901324748993, LKD 0.6336590051651001, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6328328117728234
Loss made of: CE 0.3343657851219177, LKD 0.5575177073478699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6187022656202317
Loss made of: CE 0.1859918087720871, LKD 0.41484373807907104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20233146846294403, Reg Loss=0.45150718092918396
Clinet index 11, End of Epoch 2/6, Average Loss=0.6538386344909668, Class Loss=0.20233146846294403, Reg Loss=0.45150718092918396
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/102, Loss=0.668495038151741
Loss made of: CE 0.2266598343849182, LKD 0.5176112651824951, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6501143127679825
Loss made of: CE 0.22770735621452332, LKD 0.4535558819770813, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.6375860124826431
Loss made of: CE 0.19248971343040466, LKD 0.44538992643356323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6274398908019065
Loss made of: CE 0.169404536485672, LKD 0.5027682781219482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.6473885402083397
Loss made of: CE 0.21138779819011688, LKD 0.47037214040756226, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6198201909661293
Loss made of: CE 0.15278035402297974, LKD 0.4060891270637512, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.6496904209256172
Loss made of: CE 0.16569173336029053, LKD 0.41728246212005615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.656057420372963
Loss made of: CE 0.1780911087989807, LKD 0.4424915015697479, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.6533153235912323
Loss made of: CE 0.20101138949394226, LKD 0.45346125960350037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.6901136308908462
Loss made of: CE 0.17099009454250336, LKD 0.4531998038291931, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.1977744698524475, Reg Loss=0.4526025950908661
Clinet index 11, End of Epoch 3/6, Average Loss=0.6503770351409912, Class Loss=0.1977744698524475, Reg Loss=0.4526025950908661
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/102, Loss=0.6475521713495255
Loss made of: CE 0.20519131422042847, LKD 0.37659192085266113, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6300496146082878
Loss made of: CE 0.16161423921585083, LKD 0.3709791898727417, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.6473034173250198
Loss made of: CE 0.30244994163513184, LKD 0.4616966247558594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.6692472755908966
Loss made of: CE 0.19114165008068085, LKD 0.4367954730987549, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.6755166694521904
Loss made of: CE 0.300021767616272, LKD 0.5218405723571777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.6407934635877609
Loss made of: CE 0.17291359603405, LKD 0.3395315110683441, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6225625425577164
Loss made of: CE 0.24427267909049988, LKD 0.5864619016647339, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.6628712341189384
Loss made of: CE 0.22285370528697968, LKD 0.4393853545188904, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6531991779804229
Loss made of: CE 0.16748277842998505, LKD 0.44198155403137207, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.671864652633667
Loss made of: CE 0.2769968509674072, LKD 0.4439675807952881, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2028738111257553, Reg Loss=0.4497261345386505
Clinet index 11, End of Epoch 4/6, Average Loss=0.6525999307632446, Class Loss=0.2028738111257553, Reg Loss=0.4497261345386505
Pseudo labeling is: None
Epoch 5, lr = 0.000304
Epoch 5, Batch 10/102, Loss=0.6743314310908317
Loss made of: CE 0.1866302192211151, LKD 0.5662564039230347, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6907469645142555
Loss made of: CE 0.15467336773872375, LKD 0.44716882705688477, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.651608507335186
Loss made of: CE 0.16811446845531464, LKD 0.41246137022972107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.643024492263794
Loss made of: CE 0.22173857688903809, LKD 0.5211364030838013, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.6624043554067611
Loss made of: CE 0.2163233458995819, LKD 0.44083476066589355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6799997925758362
Loss made of: CE 0.2223818004131317, LKD 0.617507815361023, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.5789859503507614
Loss made of: CE 0.17260798811912537, LKD 0.40314042568206787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.5918370515108109
Loss made of: CE 0.13856491446495056, LKD 0.4467330873012543, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.624576349556446
Loss made of: CE 0.18050450086593628, LKD 0.46568140387535095, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6248803779482841
Loss made of: CE 0.19741110503673553, LKD 0.44370028376579285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19366233050823212, Reg Loss=0.44965630769729614
Clinet index 11, End of Epoch 5/6, Average Loss=0.6433186531066895, Class Loss=0.19366233050823212, Reg Loss=0.44965630769729614
Pseudo labeling is: None
Epoch 6, lr = 0.000270
Epoch 6, Batch 10/102, Loss=0.6234983012080193
Loss made of: CE 0.15229740738868713, LKD 0.35413503646850586, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6463247075676918
Loss made of: CE 0.22742056846618652, LKD 0.4975442886352539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.633414876461029
Loss made of: CE 0.1721043586730957, LKD 0.33987998962402344, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6604144796729088
Loss made of: CE 0.3020986020565033, LKD 0.46857738494873047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6271712139248848
Loss made of: CE 0.1925063580274582, LKD 0.4580647647380829, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6586325585842132
Loss made of: CE 0.2254006266593933, LKD 0.5679437518119812, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6474473178386688
Loss made of: CE 0.21382653713226318, LKD 0.3573174476623535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6424135997891426
Loss made of: CE 0.19577965140342712, LKD 0.5583752393722534, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.6376426517963409
Loss made of: CE 0.20712411403656006, LKD 0.42699378728866577, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.5971810847520829
Loss made of: CE 0.19270102679729462, LKD 0.49053606390953064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1935095340013504, Reg Loss=0.44581520557403564
Clinet index 11, End of Epoch 6/6, Average Loss=0.6393247246742249, Class Loss=0.1935095340013504, Reg Loss=0.44581520557403564
Current Client Index:  13
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/23, Loss=1.3824586391448974
Loss made of: CE 0.5844757556915283, LKD 0.5425333976745605, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.1688583016395568
Loss made of: CE 0.5956300497055054, LKD 0.6658047437667847, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6379545331001282, Reg Loss=0.5991818904876709
Clinet index 13, End of Epoch 1/6, Average Loss=1.2371363639831543, Class Loss=0.6379545331001282, Reg Loss=0.5991818904876709
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/23, Loss=1.1310104340314866
Loss made of: CE 0.4632265567779541, LKD 0.6827234029769897, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=1.009915229678154
Loss made of: CE 0.435621976852417, LKD 0.6380902528762817, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.443865567445755, Reg Loss=0.6010280847549438
Clinet index 13, End of Epoch 2/6, Average Loss=1.0448936223983765, Class Loss=0.443865567445755, Reg Loss=0.6010280847549438
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/23, Loss=1.0072246193885803
Loss made of: CE 0.4217756390571594, LKD 0.7211861610412598, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.9784669518470764
Loss made of: CE 0.39677831530570984, LKD 0.6674480438232422, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3677988052368164, Reg Loss=0.6062059998512268
Clinet index 13, End of Epoch 3/6, Average Loss=0.9740048050880432, Class Loss=0.3677988052368164, Reg Loss=0.6062059998512268
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/23, Loss=0.9842704057693481
Loss made of: CE 0.3709963262081146, LKD 0.6590783596038818, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.9219111412763595
Loss made of: CE 0.3095053434371948, LKD 0.5841091871261597, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3455902934074402, Reg Loss=0.5986493825912476
Clinet index 13, End of Epoch 4/6, Average Loss=0.9442396759986877, Class Loss=0.3455902934074402, Reg Loss=0.5986493825912476
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/23, Loss=0.8910817682743073
Loss made of: CE 0.29715606570243835, LKD 0.5410220623016357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.9429566442966462
Loss made of: CE 0.3046514689922333, LKD 0.6124471426010132, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33405935764312744, Reg Loss=0.5992691516876221
Clinet index 13, End of Epoch 5/6, Average Loss=0.9333285093307495, Class Loss=0.33405935764312744, Reg Loss=0.5992691516876221
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/23, Loss=0.9550804048776627
Loss made of: CE 0.4873064160346985, LKD 0.7328152060508728, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.9209953933954239
Loss made of: CE 0.2858465909957886, LKD 0.7099458575248718, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3298700451850891, Reg Loss=0.6032173037528992
Clinet index 13, End of Epoch 6/6, Average Loss=0.9330873489379883, Class Loss=0.3298700451850891, Reg Loss=0.6032173037528992
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/23, Loss=1.3728371679782867
Loss made of: CE 0.6569068431854248, LKD 0.6354100108146667, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.1570007294416427
Loss made of: CE 0.5315545797348022, LKD 0.5864819884300232, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6125703454017639, Reg Loss=0.6386744379997253
Clinet index 10, End of Epoch 1/6, Average Loss=1.2512447834014893, Class Loss=0.6125703454017639, Reg Loss=0.6386744379997253
Pseudo labeling is: None
Epoch 2, lr = 0.000756
Epoch 2, Batch 10/23, Loss=1.1721637755632401
Loss made of: CE 0.5185322165489197, LKD 0.801301121711731, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=1.016453179717064
Loss made of: CE 0.3347168564796448, LKD 0.768835186958313, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4279022812843323, Reg Loss=0.6457997560501099
Clinet index 10, End of Epoch 2/6, Average Loss=1.073702096939087, Class Loss=0.4279022812843323, Reg Loss=0.6457997560501099
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/23, Loss=0.9900517195463181
Loss made of: CE 0.3370562791824341, LKD 0.6540224552154541, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=1.0158079028129579
Loss made of: CE 0.30836015939712524, LKD 0.6085635423660278, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3727969229221344, Reg Loss=0.6373250484466553
Clinet index 10, End of Epoch 3/6, Average Loss=1.0101219415664673, Class Loss=0.3727969229221344, Reg Loss=0.6373250484466553
Pseudo labeling is: None
Epoch 4, lr = 0.000631
Epoch 4, Batch 10/23, Loss=0.9596216782927514
Loss made of: CE 0.33013439178466797, LKD 0.6041344404220581, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=1.0068777978420258
Loss made of: CE 0.3409980237483978, LKD 0.6111711263656616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3466566205024719, Reg Loss=0.637160062789917
Clinet index 10, End of Epoch 4/6, Average Loss=0.9838166832923889, Class Loss=0.3466566205024719, Reg Loss=0.637160062789917
Pseudo labeling is: None
Epoch 5, lr = 0.000568
Epoch 5, Batch 10/23, Loss=1.0010184347629547
Loss made of: CE 0.32498061656951904, LKD 0.7699860334396362, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.9648837894201279
Loss made of: CE 0.4371780753135681, LKD 0.8242419958114624, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.33077144622802734, Reg Loss=0.6468321681022644
Clinet index 10, End of Epoch 5/6, Average Loss=0.9776036143302917, Class Loss=0.33077144622802734, Reg Loss=0.6468321681022644
Pseudo labeling is: None
Epoch 6, lr = 0.000504
Epoch 6, Batch 10/23, Loss=0.9466030165553093
Loss made of: CE 0.23774215579032898, LKD 0.5221933126449585, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.9769958853721619
Loss made of: CE 0.33398962020874023, LKD 0.6041630506515503, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3219563364982605, Reg Loss=0.637753427028656
Clinet index 10, End of Epoch 6/6, Average Loss=0.9597097635269165, Class Loss=0.3219563364982605, Reg Loss=0.637753427028656
federated aggregation...
Validation, Class Loss=0.4282810688018799, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.863933
Mean Acc: 0.594897
FreqW Acc: 0.784318
Mean IoU: 0.460159
Class IoU:
	class 0: 0.89489245
	class 1: 0.72835803
	class 2: 0.22846511
	class 3: 0.49929708
	class 4: 0.4848191
	class 5: 0.26946127
	class 6: 0.7253897
	class 7: 0.73501813
	class 8: 0.48405552
	class 9: 0.042490706
	class 10: 0.1884301
	class 11: 0.30897227
	class 12: 0.29702938
	class 13: 0.41623804
	class 14: 0.6936669
	class 15: 0.75971335
	class 16: 0.066409625
Class Acc:
	class 0: 0.93940157
	class 1: 0.74284065
	class 2: 0.35229477
	class 3: 0.5603289
	class 4: 0.7172654
	class 5: 0.272648
	class 6: 0.80566233
	class 7: 0.84237146
	class 8: 0.9234212
	class 9: 0.047114
	class 10: 0.20170659
	class 11: 0.6807689
	class 12: 0.39099452
	class 13: 0.75568634
	class 14: 0.8961219
	class 15: 0.9172014
	class 16: 0.067421295

federated global round: 19, step: 3
select part of clients to conduct local training
[4, 7, 17, 15]
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/105, Loss=0.7085124924778938
Loss made of: CE 0.4040495753288269, LKD 0.3776441514492035, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/105, Loss=0.7096388041973114
Loss made of: CE 0.3332575857639313, LKD 0.36190319061279297, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/105, Loss=0.6333320066332817
Loss made of: CE 0.2619318962097168, LKD 0.4089218080043793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/105, Loss=0.6406058996915818
Loss made of: CE 0.193460151553154, LKD 0.42653974890708923, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/105, Loss=0.6343865275382996
Loss made of: CE 0.15879736840724945, LKD 0.37958988547325134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/105, Loss=0.6348407596349717
Loss made of: CE 0.23483829200267792, LKD 0.3413132131099701, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/105, Loss=0.6725078240036965
Loss made of: CE 0.18214643001556396, LKD 0.448847234249115, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/105, Loss=0.6339785635471344
Loss made of: CE 0.14554950594902039, LKD 0.38565120100975037, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/105, Loss=0.6531786769628525
Loss made of: CE 0.13737085461616516, LKD 0.35770440101623535, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/105, Loss=0.5944847241044044
Loss made of: CE 0.2116338014602661, LKD 0.4013241231441498, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.2235856056213379, Reg Loss=0.4281991422176361
Clinet index 4, End of Epoch 1/6, Average Loss=0.6517847776412964, Class Loss=0.2235856056213379, Reg Loss=0.4281991422176361
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/105, Loss=0.6290228173136712
Loss made of: CE 0.20512327551841736, LKD 0.43443259596824646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/105, Loss=0.6217602863907814
Loss made of: CE 0.21047380566596985, LKD 0.4731549620628357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/105, Loss=0.6229566141963006
Loss made of: CE 0.18247179687023163, LKD 0.4064440131187439, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/105, Loss=0.6712684407830238
Loss made of: CE 0.24482658505439758, LKD 0.49818772077560425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/105, Loss=0.6214703649282456
Loss made of: CE 0.24215881526470184, LKD 0.4139281213283539, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/105, Loss=0.6240621685981751
Loss made of: CE 0.18076758086681366, LKD 0.4600205421447754, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/105, Loss=0.6466723889112472
Loss made of: CE 0.17700128257274628, LKD 0.42706209421157837, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/105, Loss=0.65520890802145
Loss made of: CE 0.1935875415802002, LKD 0.49900245666503906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/105, Loss=0.58875512778759
Loss made of: CE 0.15148943662643433, LKD 0.3465496003627777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/105, Loss=0.6117795094847679
Loss made of: CE 0.2079237699508667, LKD 0.37035831809043884, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.20091502368450165, Reg Loss=0.4254491925239563
Clinet index 4, End of Epoch 2/6, Average Loss=0.6263642311096191, Class Loss=0.20091502368450165, Reg Loss=0.4254491925239563
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/105, Loss=0.6425355672836304
Loss made of: CE 0.23055104911327362, LKD 0.38751357793807983, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/105, Loss=0.6375403746962547
Loss made of: CE 0.22037121653556824, LKD 0.4801337718963623, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/105, Loss=0.6196802631020546
Loss made of: CE 0.1890932321548462, LKD 0.3981646001338959, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/105, Loss=0.6560050562024117
Loss made of: CE 0.17706671357154846, LKD 0.3764975070953369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/105, Loss=0.6340561643242836
Loss made of: CE 0.2805511951446533, LKD 0.5121966600418091, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/105, Loss=0.6143973603844642
Loss made of: CE 0.1885616034269333, LKD 0.4278866946697235, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/105, Loss=0.6279143035411835
Loss made of: CE 0.19505354762077332, LKD 0.5259649753570557, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/105, Loss=0.5731463715434074
Loss made of: CE 0.17711922526359558, LKD 0.5100765824317932, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/105, Loss=0.6229511618614196
Loss made of: CE 0.25338083505630493, LKD 0.4465026259422302, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/105, Loss=0.6262996524572373
Loss made of: CE 0.182151198387146, LKD 0.4608568549156189, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19659997522830963, Reg Loss=0.4279067814350128
Clinet index 4, End of Epoch 3/6, Average Loss=0.6245067715644836, Class Loss=0.19659997522830963, Reg Loss=0.4279067814350128
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/105, Loss=0.5632777601480484
Loss made of: CE 0.21025273203849792, LKD 0.336972177028656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/105, Loss=0.600028358399868
Loss made of: CE 0.18129760026931763, LKD 0.322562575340271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/105, Loss=0.6663536682724953
Loss made of: CE 0.195485919713974, LKD 0.5147802233695984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/105, Loss=0.595926420390606
Loss made of: CE 0.193325936794281, LKD 0.4739226698875427, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/105, Loss=0.5833844304084778
Loss made of: CE 0.18915235996246338, LKD 0.43153080344200134, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/105, Loss=0.6050496071577072
Loss made of: CE 0.2830224335193634, LKD 0.3626077175140381, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/105, Loss=0.6239519760012626
Loss made of: CE 0.1990920603275299, LKD 0.4799298942089081, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/105, Loss=0.6319256857037544
Loss made of: CE 0.17236322164535522, LKD 0.4954466223716736, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/105, Loss=0.650416861474514
Loss made of: CE 0.1907649040222168, LKD 0.47697287797927856, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/105, Loss=0.6436012104153633
Loss made of: CE 0.18359524011611938, LKD 0.4118295907974243, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18868286907672882, Reg Loss=0.42647498846054077
Clinet index 4, End of Epoch 4/6, Average Loss=0.6151578426361084, Class Loss=0.18868286907672882, Reg Loss=0.42647498846054077
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/105, Loss=0.6064384743571282
Loss made of: CE 0.17030827701091766, LKD 0.4117082953453064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/105, Loss=0.6553054556250573
Loss made of: CE 0.2366228997707367, LKD 0.4477367401123047, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/105, Loss=0.6229675203561783
Loss made of: CE 0.16347073018550873, LKD 0.48455771803855896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/105, Loss=0.6551735505461693
Loss made of: CE 0.1458836793899536, LKD 0.3511967658996582, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/105, Loss=0.5864805087447167
Loss made of: CE 0.1657353788614273, LKD 0.38527414202690125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/105, Loss=0.5975977852940559
Loss made of: CE 0.14885322749614716, LKD 0.34233713150024414, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/105, Loss=0.6089542657136917
Loss made of: CE 0.1788949966430664, LKD 0.37471771240234375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/105, Loss=0.6189816683530808
Loss made of: CE 0.16453269124031067, LKD 0.35838139057159424, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/105, Loss=0.6124453470110893
Loss made of: CE 0.18863117694854736, LKD 0.4434918761253357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/105, Loss=0.587002520263195
Loss made of: CE 0.18319138884544373, LKD 0.4718265235424042, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.18950188159942627, Reg Loss=0.42485472559928894
Clinet index 4, End of Epoch 5/6, Average Loss=0.6143566370010376, Class Loss=0.18950188159942627, Reg Loss=0.42485472559928894
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/105, Loss=0.5893593385815621
Loss made of: CE 0.17860393226146698, LKD 0.3307490348815918, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/105, Loss=0.663020883500576
Loss made of: CE 0.18729792535305023, LKD 0.4717745780944824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/105, Loss=0.5813884809613228
Loss made of: CE 0.14064453542232513, LKD 0.3597683608531952, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/105, Loss=0.6377447083592415
Loss made of: CE 0.16630443930625916, LKD 0.413085401058197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/105, Loss=0.5915031731128693
Loss made of: CE 0.17896735668182373, LKD 0.3671361207962036, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/105, Loss=0.6117513731122017
Loss made of: CE 0.20111215114593506, LKD 0.4456404149532318, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/105, Loss=0.6114328950643539
Loss made of: CE 0.16444045305252075, LKD 0.35348471999168396, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/105, Loss=0.6051002070307732
Loss made of: CE 0.14169727265834808, LKD 0.35142451524734497, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/105, Loss=0.610609321296215
Loss made of: CE 0.18001942336559296, LKD 0.4003590941429138, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/105, Loss=0.5912745982408524
Loss made of: CE 0.133331298828125, LKD 0.35795721411705017, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18532882630825043, Reg Loss=0.4237847328186035
Clinet index 4, End of Epoch 6/6, Average Loss=0.6091135740280151, Class Loss=0.18532882630825043, Reg Loss=0.4237847328186035
Current Client Index:  7
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000631
Epoch 1, Batch 10/102, Loss=0.708479568362236
Loss made of: CE 0.2590004503726959, LKD 0.5360000133514404, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/102, Loss=0.6197461396455765
Loss made of: CE 0.2615881562232971, LKD 0.44019246101379395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/102, Loss=0.648574811220169
Loss made of: CE 0.20082315802574158, LKD 0.42844924330711365, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/102, Loss=0.7154618293046952
Loss made of: CE 0.1746560037136078, LKD 0.4545370936393738, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/102, Loss=0.6672037467360497
Loss made of: CE 0.19564226269721985, LKD 0.47482025623321533, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/102, Loss=0.6268568724393845
Loss made of: CE 0.15919864177703857, LKD 0.44344961643218994, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/102, Loss=0.6387882381677628
Loss made of: CE 0.22274944186210632, LKD 0.39183756709098816, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/102, Loss=0.6555457502603531
Loss made of: CE 0.23242902755737305, LKD 0.534496545791626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/102, Loss=0.6638228565454483
Loss made of: CE 0.19752934575080872, LKD 0.44079217314720154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/102, Loss=0.7008460372686386
Loss made of: CE 0.22987806797027588, LKD 0.4394998550415039, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.21205002069473267, Reg Loss=0.45193004608154297
Clinet index 7, End of Epoch 1/6, Average Loss=0.6639800667762756, Class Loss=0.21205002069473267, Reg Loss=0.45193004608154297
Pseudo labeling is: None
Epoch 2, lr = 0.000536
Epoch 2, Batch 10/102, Loss=0.6364082470536232
Loss made of: CE 0.20225076377391815, LKD 0.45557457208633423, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/102, Loss=0.6152726635336876
Loss made of: CE 0.21030865609645844, LKD 0.45441240072250366, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/102, Loss=0.6792701110243797
Loss made of: CE 0.19235853850841522, LKD 0.49833011627197266, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/102, Loss=0.6598208025097847
Loss made of: CE 0.17953109741210938, LKD 0.41624101996421814, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/102, Loss=0.6546756654977799
Loss made of: CE 0.14403384923934937, LKD 0.35197359323501587, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/102, Loss=0.6762599214911461
Loss made of: CE 0.19933371245861053, LKD 0.40651965141296387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/102, Loss=0.659242007136345
Loss made of: CE 0.19164781272411346, LKD 0.38136589527130127, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/102, Loss=0.6302054136991501
Loss made of: CE 0.19420385360717773, LKD 0.43072614073753357, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/102, Loss=0.6601474404335022
Loss made of: CE 0.17115172743797302, LKD 0.38916802406311035, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/102, Loss=0.6056734979152679
Loss made of: CE 0.15174677968025208, LKD 0.38610804080963135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.1963123381137848, Reg Loss=0.45036348700523376
Clinet index 7, End of Epoch 2/6, Average Loss=0.6466758251190186, Class Loss=0.1963123381137848, Reg Loss=0.45036348700523376
Pseudo labeling is: None
Epoch 3, lr = 0.000438
Epoch 3, Batch 10/102, Loss=0.6654442951083184
Loss made of: CE 0.1939287781715393, LKD 0.452123761177063, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/102, Loss=0.6268787428736686
Loss made of: CE 0.19468806684017181, LKD 0.4858975410461426, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/102, Loss=0.6301795080304146
Loss made of: CE 0.1889631450176239, LKD 0.4086209237575531, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/102, Loss=0.6538872331380844
Loss made of: CE 0.15994803607463837, LKD 0.3407794237136841, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/102, Loss=0.6582012102007866
Loss made of: CE 0.196694478392601, LKD 0.49442046880722046, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/102, Loss=0.6586156204342842
Loss made of: CE 0.1508709043264389, LKD 0.40993112325668335, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/102, Loss=0.6523809030652046
Loss made of: CE 0.16312825679779053, LKD 0.5389974117279053, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/102, Loss=0.6454596534371376
Loss made of: CE 0.1573367714881897, LKD 0.5275680422782898, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/102, Loss=0.6834423780441284
Loss made of: CE 0.2184724062681198, LKD 0.44872018694877625, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/102, Loss=0.6139120385050774
Loss made of: CE 0.154654860496521, LKD 0.35080036520957947, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.19460441172122955, Reg Loss=0.45394596457481384
Clinet index 7, End of Epoch 3/6, Average Loss=0.6485503911972046, Class Loss=0.19460441172122955, Reg Loss=0.45394596457481384
Pseudo labeling is: None
Epoch 4, lr = 0.000338
Epoch 4, Batch 10/102, Loss=0.5988928630948067
Loss made of: CE 0.18489758670330048, LKD 0.41117626428604126, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/102, Loss=0.6784258514642716
Loss made of: CE 0.2673428952693939, LKD 0.5338444709777832, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/102, Loss=0.6859172374010086
Loss made of: CE 0.1670721024274826, LKD 0.46208733320236206, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/102, Loss=0.631939834356308
Loss made of: CE 0.18644283711910248, LKD 0.43018317222595215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/102, Loss=0.64393200725317
Loss made of: CE 0.19689610600471497, LKD 0.5107960104942322, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/102, Loss=0.659536199271679
Loss made of: CE 0.2597041726112366, LKD 0.4140951633453369, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/102, Loss=0.6455064371228219
Loss made of: CE 0.199425607919693, LKD 0.4699457287788391, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/102, Loss=0.6659611538052559
Loss made of: CE 0.1818901002407074, LKD 0.4546986222267151, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/102, Loss=0.6325675696134567
Loss made of: CE 0.191279336810112, LKD 0.3422390818595886, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/102, Loss=0.6561430752277374
Loss made of: CE 0.17091575264930725, LKD 0.41490575671195984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.1958375722169876, Reg Loss=0.453622430562973
Clinet index 7, End of Epoch 4/6, Average Loss=0.6494600176811218, Class Loss=0.1958375722169876, Reg Loss=0.453622430562973
Pseudo labeling is: None
Epoch 5, lr = 0.000235
Epoch 5, Batch 10/102, Loss=0.6774595588445663
Loss made of: CE 0.22933757305145264, LKD 0.4579443335533142, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/102, Loss=0.6419367313385009
Loss made of: CE 0.1931578814983368, LKD 0.43929481506347656, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/102, Loss=0.6217661917209625
Loss made of: CE 0.22621333599090576, LKD 0.4947950839996338, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/102, Loss=0.6404288247227669
Loss made of: CE 0.1515168398618698, LKD 0.43208593130111694, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/102, Loss=0.6312966525554657
Loss made of: CE 0.281657338142395, LKD 0.48594731092453003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/102, Loss=0.6240653812885284
Loss made of: CE 0.1515851467847824, LKD 0.4524429738521576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/102, Loss=0.6546270489692688
Loss made of: CE 0.1759362667798996, LKD 0.39455974102020264, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/102, Loss=0.6492320001125336
Loss made of: CE 0.16621717810630798, LKD 0.4029141366481781, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/102, Loss=0.6843517869710922
Loss made of: CE 0.28555259108543396, LKD 0.5513775944709778, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/102, Loss=0.6071821808815002
Loss made of: CE 0.14742758870124817, LKD 0.4071006178855896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.19165019690990448, Reg Loss=0.4534706473350525
Clinet index 7, End of Epoch 5/6, Average Loss=0.6451208591461182, Class Loss=0.19165019690990448, Reg Loss=0.4534706473350525
Pseudo labeling is: None
Epoch 6, lr = 0.000126
Epoch 6, Batch 10/102, Loss=0.6766574546694756
Loss made of: CE 0.2063695192337036, LKD 0.4550228714942932, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/102, Loss=0.6619970262050628
Loss made of: CE 0.17510148882865906, LKD 0.5156418085098267, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/102, Loss=0.6393593922257423
Loss made of: CE 0.18768510222434998, LKD 0.48280903697013855, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/102, Loss=0.6847746416926384
Loss made of: CE 0.18261830508708954, LKD 0.4095916748046875, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/102, Loss=0.6203460916876793
Loss made of: CE 0.2573827803134918, LKD 0.4384421110153198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/102, Loss=0.6024734169244766
Loss made of: CE 0.16447755694389343, LKD 0.35974010825157166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/102, Loss=0.6133353590965271
Loss made of: CE 0.1637691706418991, LKD 0.4811818599700928, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/102, Loss=0.6486583948135376
Loss made of: CE 0.15406613051891327, LKD 0.5276492834091187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/102, Loss=0.633175690472126
Loss made of: CE 0.1863432377576828, LKD 0.4463939368724823, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/102, Loss=0.6173186779022217
Loss made of: CE 0.24689525365829468, LKD 0.44290614128112793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.18948785960674286, Reg Loss=0.45336851477622986
Clinet index 7, End of Epoch 6/6, Average Loss=0.6428563594818115, Class Loss=0.18948785960674286, Reg Loss=0.45336851477622986
Current Client Index:  17
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000694
Epoch 1, Batch 10/23, Loss=1.1135011970996858
Loss made of: CE 0.46755367517471313, LKD 0.5428531765937805, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/23, Loss=1.0447531193494797
Loss made of: CE 0.4826509952545166, LKD 0.6317023038864136, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.51203453540802, Reg Loss=0.5666347146034241
Clinet index 17, End of Epoch 1/6, Average Loss=1.0786693096160889, Class Loss=0.51203453540802, Reg Loss=0.5666347146034241
Pseudo labeling is: None
Epoch 2, lr = 0.000589
Epoch 2, Batch 10/23, Loss=0.9787606924772263
Loss made of: CE 0.3896794021129608, LKD 0.5588587522506714, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/23, Loss=0.9594561040401459
Loss made of: CE 0.3069027066230774, LKD 0.623741626739502, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3962961733341217, Reg Loss=0.5741122961044312
Clinet index 17, End of Epoch 2/6, Average Loss=0.9704084396362305, Class Loss=0.3962961733341217, Reg Loss=0.5741122961044312
Pseudo labeling is: None
Epoch 3, lr = 0.000482
Epoch 3, Batch 10/23, Loss=0.9498841345310212
Loss made of: CE 0.28509053587913513, LKD 0.5916657447814941, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/23, Loss=0.9362497597932815
Loss made of: CE 0.40873557329177856, LKD 0.674846351146698, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.35468727350234985, Reg Loss=0.5771941542625427
Clinet index 17, End of Epoch 3/6, Average Loss=0.9318814277648926, Class Loss=0.35468727350234985, Reg Loss=0.5771941542625427
Pseudo labeling is: None
Epoch 4, lr = 0.000372
Epoch 4, Batch 10/23, Loss=0.9507765740156173
Loss made of: CE 0.47114312648773193, LKD 0.7032389640808105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/23, Loss=0.9041399955749512
Loss made of: CE 0.3144652843475342, LKD 0.5865716934204102, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3374970257282257, Reg Loss=0.5833215117454529
Clinet index 17, End of Epoch 4/6, Average Loss=0.920818567276001, Class Loss=0.3374970257282257, Reg Loss=0.5833215117454529
Pseudo labeling is: None
Epoch 5, lr = 0.000258
Epoch 5, Batch 10/23, Loss=0.8934413999319076
Loss made of: CE 0.33342355489730835, LKD 0.4413185119628906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/23, Loss=0.9104433834552765
Loss made of: CE 0.26872941851615906, LKD 0.5464974045753479, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3307875692844391, Reg Loss=0.5758489370346069
Clinet index 17, End of Epoch 5/6, Average Loss=0.9066364765167236, Class Loss=0.3307875692844391, Reg Loss=0.5758489370346069
Pseudo labeling is: None
Epoch 6, lr = 0.000138
Epoch 6, Batch 10/23, Loss=0.9377091288566589
Loss made of: CE 0.30400481820106506, LKD 0.4539458751678467, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/23, Loss=0.910594367980957
Loss made of: CE 0.40092453360557556, LKD 0.5723781585693359, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3366392254829407, Reg Loss=0.5839166641235352
Clinet index 17, End of Epoch 6/6, Average Loss=0.9205558896064758, Class Loss=0.3366392254829407, Reg Loss=0.5839166641235352
Current Client Index:  15
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/103, Loss=0.6972878783941269
Loss made of: CE 0.2079697549343109, LKD 0.4677925705909729, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/103, Loss=0.6641781851649284
Loss made of: CE 0.22105592489242554, LKD 0.4650658071041107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 30/103, Loss=0.6374323055148124
Loss made of: CE 0.22000877559185028, LKD 0.4084526002407074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 40/103, Loss=0.6590484261512757
Loss made of: CE 0.18295881152153015, LKD 0.4280967116355896, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 50/103, Loss=0.6039460599422455
Loss made of: CE 0.22228386998176575, LKD 0.46244892477989197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 60/103, Loss=0.6441391617059707
Loss made of: CE 0.19016492366790771, LKD 0.42795246839523315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 70/103, Loss=0.6595819234848023
Loss made of: CE 0.20551149547100067, LKD 0.43523821234703064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 80/103, Loss=0.6493260532617569
Loss made of: CE 0.19028669595718384, LKD 0.31651681661605835, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 90/103, Loss=0.6049608558416366
Loss made of: CE 0.15700329840183258, LKD 0.45683521032333374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 100/103, Loss=0.6147188246250153
Loss made of: CE 0.1972711980342865, LKD 0.45361578464508057, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.21153457462787628, Reg Loss=0.4349748492240906
Clinet index 15, End of Epoch 1/6, Average Loss=0.6465094089508057, Class Loss=0.21153457462787628, Reg Loss=0.4349748492240906
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/103, Loss=0.6913998514413834
Loss made of: CE 0.22975006699562073, LKD 0.4889363646507263, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/103, Loss=0.6261341392993927
Loss made of: CE 0.17013001441955566, LKD 0.43067067861557007, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 30/103, Loss=0.6303361341357231
Loss made of: CE 0.21946120262145996, LKD 0.3748524785041809, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 40/103, Loss=0.605880792438984
Loss made of: CE 0.2423003911972046, LKD 0.41369253396987915, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 50/103, Loss=0.6249375194311142
Loss made of: CE 0.17828808724880219, LKD 0.413666307926178, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 60/103, Loss=0.6574221834540367
Loss made of: CE 0.16235387325286865, LKD 0.4207574725151062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 70/103, Loss=0.6286134421825409
Loss made of: CE 0.18891486525535583, LKD 0.4779900908470154, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 80/103, Loss=0.584136001765728
Loss made of: CE 0.19695726037025452, LKD 0.37910196185112, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 90/103, Loss=0.5838370516896247
Loss made of: CE 0.12935583293437958, LKD 0.32736849784851074, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 100/103, Loss=0.6764589101076126
Loss made of: CE 0.19903215765953064, LKD 0.41982266306877136, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.19550864398479462, Reg Loss=0.4355233907699585
Clinet index 15, End of Epoch 2/6, Average Loss=0.6310320496559143, Class Loss=0.19550864398479462, Reg Loss=0.4355233907699585
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/103, Loss=0.6605496436357499
Loss made of: CE 0.14832380414009094, LKD 0.4063427448272705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/103, Loss=0.6149355918169022
Loss made of: CE 0.23652729392051697, LKD 0.4146804213523865, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 30/103, Loss=0.6197528451681137
Loss made of: CE 0.23637568950653076, LKD 0.584391713142395, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 40/103, Loss=0.6396572336554527
Loss made of: CE 0.1473124623298645, LKD 0.39999112486839294, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 50/103, Loss=0.6262074083089828
Loss made of: CE 0.21963445842266083, LKD 0.44331973791122437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 60/103, Loss=0.6071195155382156
Loss made of: CE 0.15530237555503845, LKD 0.44233518838882446, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 70/103, Loss=0.5935226529836655
Loss made of: CE 0.1574002206325531, LKD 0.43036991357803345, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 80/103, Loss=0.6352310016751289
Loss made of: CE 0.1765684336423874, LKD 0.4613893926143646, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 90/103, Loss=0.6161418035626411
Loss made of: CE 0.17463737726211548, LKD 0.47405970096588135, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 100/103, Loss=0.6178191974759102
Loss made of: CE 0.23513679206371307, LKD 0.5127741694450378, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.18888409435749054, Reg Loss=0.43397003412246704
Clinet index 15, End of Epoch 3/6, Average Loss=0.6228541135787964, Class Loss=0.18888409435749054, Reg Loss=0.43397003412246704
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/103, Loss=0.6634392872452736
Loss made of: CE 0.21792104840278625, LKD 0.5119562149047852, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/103, Loss=0.6235305592417717
Loss made of: CE 0.27493172883987427, LKD 0.5168027877807617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 30/103, Loss=0.6446863293647767
Loss made of: CE 0.1882123053073883, LKD 0.44945019483566284, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 40/103, Loss=0.5834266632795334
Loss made of: CE 0.2007371038198471, LKD 0.4177092909812927, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 50/103, Loss=0.6040914997458458
Loss made of: CE 0.13996078073978424, LKD 0.4112515449523926, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 60/103, Loss=0.6341320089995861
Loss made of: CE 0.16375641524791718, LKD 0.4530874192714691, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 70/103, Loss=0.6264992102980613
Loss made of: CE 0.1919984519481659, LKD 0.416840136051178, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 80/103, Loss=0.592101302742958
Loss made of: CE 0.15771470963954926, LKD 0.3741515576839447, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 90/103, Loss=0.6219114989042283
Loss made of: CE 0.16399618983268738, LKD 0.38224563002586365, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 100/103, Loss=0.5894441545009613
Loss made of: CE 0.1739821434020996, LKD 0.33021873235702515, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.18422125279903412, Reg Loss=0.4353066384792328
Clinet index 15, End of Epoch 4/6, Average Loss=0.6195278763771057, Class Loss=0.18422125279903412, Reg Loss=0.4353066384792328
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/103, Loss=0.6175446376204491
Loss made of: CE 0.1259559988975525, LKD 0.35267922282218933, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/103, Loss=0.6562091559171677
Loss made of: CE 0.2557077705860138, LKD 0.44906336069107056, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 30/103, Loss=0.625688011944294
Loss made of: CE 0.15414687991142273, LKD 0.4455915689468384, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 40/103, Loss=0.5942799627780915
Loss made of: CE 0.14495892822742462, LKD 0.3612622618675232, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 50/103, Loss=0.5919603824615478
Loss made of: CE 0.1340382695198059, LKD 0.38419854640960693, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 60/103, Loss=0.6172293290495873
Loss made of: CE 0.20971202850341797, LKD 0.44169092178344727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 70/103, Loss=0.6194256007671356
Loss made of: CE 0.18157760798931122, LKD 0.4330141544342041, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 80/103, Loss=0.6481451362371444
Loss made of: CE 0.18021753430366516, LKD 0.39288362860679626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 90/103, Loss=0.6539306491613388
Loss made of: CE 0.18807470798492432, LKD 0.45406585931777954, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 100/103, Loss=0.6434294953942299
Loss made of: CE 0.17761389911174774, LKD 0.43103715777397156, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.188202366232872, Reg Loss=0.4369182586669922
Clinet index 15, End of Epoch 5/6, Average Loss=0.6251206398010254, Class Loss=0.188202366232872, Reg Loss=0.4369182586669922
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/103, Loss=0.607131315767765
Loss made of: CE 0.13622252643108368, LKD 0.439903199672699, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/103, Loss=0.6313669756054878
Loss made of: CE 0.1621781438589096, LKD 0.4273710250854492, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 30/103, Loss=0.6079711809754371
Loss made of: CE 0.20103809237480164, LKD 0.3654923439025879, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 40/103, Loss=0.5970620512962341
Loss made of: CE 0.17724943161010742, LKD 0.40503811836242676, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 50/103, Loss=0.6021556422114372
Loss made of: CE 0.13060785830020905, LKD 0.38609468936920166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 60/103, Loss=0.5873854115605355
Loss made of: CE 0.13302063941955566, LKD 0.3967195451259613, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 70/103, Loss=0.6309735722839832
Loss made of: CE 0.19054636359214783, LKD 0.4472433030605316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 80/103, Loss=0.6220691978931427
Loss made of: CE 0.24658751487731934, LKD 0.4143408238887787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 90/103, Loss=0.6007173046469688
Loss made of: CE 0.20466697216033936, LKD 0.4826420545578003, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 100/103, Loss=0.681064210832119
Loss made of: CE 0.18407146632671356, LKD 0.3779067397117615, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.1824823021888733, Reg Loss=0.4345466196537018
Clinet index 15, End of Epoch 6/6, Average Loss=0.6170289516448975, Class Loss=0.1824823021888733, Reg Loss=0.4345466196537018
federated aggregation...
Validation, Class Loss=0.42145076394081116, Reg Loss=0.0 (without scaling)

Total samples: 1277.000000
Overall Acc: 0.865940
Mean Acc: 0.610821
FreqW Acc: 0.786861
Mean IoU: 0.471730
Class IoU:
	class 0: 0.89641154
	class 1: 0.73855966
	class 2: 0.25222635
	class 3: 0.49220106
	class 4: 0.4966553
	class 5: 0.25577435
	class 6: 0.7486678
	class 7: 0.7262621
	class 8: 0.48898926
	class 9: 0.045879573
	class 10: 0.1045956
	class 11: 0.31579602
	class 12: 0.32028076
	class 13: 0.42372954
	class 14: 0.7113643
	class 15: 0.7571559
	class 16: 0.24485564
Class Acc:
	class 0: 0.93862796
	class 1: 0.7587407
	class 2: 0.4012865
	class 3: 0.55908465
	class 4: 0.7297457
	class 5: 0.258429
	class 6: 0.8376862
	class 7: 0.8484857
	class 8: 0.9169318
	class 9: 0.051624298
	class 10: 0.10734989
	class 11: 0.6824432
	class 12: 0.41601047
	class 13: 0.7817749
	class 14: 0.9045774
	class 15: 0.92250246
	class 16: 0.2686519

Filtering images...
	0/1449 ...
	1000/1449 ...
federated global round: 20, step: 4
select part of clients to conduct local training
[19, 23, 1, 8]
Current Client Index:  19
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=2.060145190358162
Loss made of: CE 1.5099780559539795, LKD 0.5037873983383179, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=1.6014870584011078
Loss made of: CE 0.9427728652954102, LKD 0.4326103627681732, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.2853443622589111, Reg Loss=0.4702635407447815
Clinet index 19, End of Epoch 1/6, Average Loss=1.7556078433990479, Class Loss=1.2853443622589111, Reg Loss=0.4702635407447815
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/24, Loss=1.2463250130414962
Loss made of: CE 0.7176797389984131, LKD 0.4705668091773987, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=1.2266460448503493
Loss made of: CE 0.7291535139083862, LKD 0.40169525146484375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7688042521476746, Reg Loss=0.4547671675682068
Clinet index 19, End of Epoch 2/6, Average Loss=1.2235714197158813, Class Loss=0.7688042521476746, Reg Loss=0.4547671675682068
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/24, Loss=1.068820270895958
Loss made of: CE 0.5507455468177795, LKD 0.3886396884918213, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.9908224046230316
Loss made of: CE 0.5164225101470947, LKD 0.4237633943557739, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.6057112216949463, Reg Loss=0.4179830551147461
Clinet index 19, End of Epoch 3/6, Average Loss=1.0236942768096924, Class Loss=0.6057112216949463, Reg Loss=0.4179830551147461
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/24, Loss=0.9407132387161254
Loss made of: CE 0.4968472421169281, LKD 0.42920660972595215, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.8990733683109283
Loss made of: CE 0.46505147218704224, LKD 0.4276188313961029, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5121597051620483, Reg Loss=0.426141619682312
Clinet index 19, End of Epoch 4/6, Average Loss=0.9383013248443604, Class Loss=0.5121597051620483, Reg Loss=0.426141619682312
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/24, Loss=0.8716690897941589
Loss made of: CE 0.43050968647003174, LKD 0.40436574816703796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.8447038233280182
Loss made of: CE 0.3957459330558777, LKD 0.480299174785614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.4534730911254883, Reg Loss=0.4240356683731079
Clinet index 19, End of Epoch 5/6, Average Loss=0.8775087594985962, Class Loss=0.4534730911254883, Reg Loss=0.4240356683731079
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/24, Loss=0.8310836464166641
Loss made of: CE 0.396552175283432, LKD 0.33317869901657104, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.8408151984214782
Loss made of: CE 0.44499701261520386, LKD 0.3728099763393402, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4143187403678894, Reg Loss=0.4190623164176941
Clinet index 19, End of Epoch 6/6, Average Loss=0.8333810567855835, Class Loss=0.4143187403678894, Reg Loss=0.4190623164176941
Current Client Index:  23
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/21, Loss=2.005645662546158
Loss made of: CE 1.0703858137130737, LKD 0.4995776116847992, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=1.5038132578134538
Loss made of: CE 0.8631409406661987, LKD 0.3965899646282196, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.2570374011993408, Reg Loss=0.47750401496887207
Clinet index 23, End of Epoch 1/6, Average Loss=1.734541416168213, Class Loss=1.2570374011993408, Reg Loss=0.47750401496887207
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/21, Loss=1.2736134111881257
Loss made of: CE 0.659569501876831, LKD 0.47423887252807617, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=1.0832793951034545
Loss made of: CE 0.5166050791740417, LKD 0.36530888080596924, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.6999799609184265, Reg Loss=0.4810275137424469
Clinet index 23, End of Epoch 2/6, Average Loss=1.1810075044631958, Class Loss=0.6999799609184265, Reg Loss=0.4810275137424469
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/21, Loss=1.155295068025589
Loss made of: CE 0.5352926254272461, LKD 0.5059846043586731, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.9587996214628219
Loss made of: CE 0.5948975682258606, LKD 0.49098581075668335, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5828311443328857, Reg Loss=0.46591079235076904
Clinet index 23, End of Epoch 3/6, Average Loss=1.0487419366836548, Class Loss=0.5828311443328857, Reg Loss=0.46591079235076904
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/21, Loss=0.9989573180675506
Loss made of: CE 0.5655549764633179, LKD 0.4650658369064331, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.9237310111522674
Loss made of: CE 0.4025443196296692, LKD 0.401886522769928, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5024998784065247, Reg Loss=0.4608154296875
Clinet index 23, End of Epoch 4/6, Average Loss=0.9633153080940247, Class Loss=0.5024998784065247, Reg Loss=0.4608154296875
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/21, Loss=0.9635986357927322
Loss made of: CE 0.49837321043014526, LKD 0.5114068984985352, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.861784702539444
Loss made of: CE 0.5040854811668396, LKD 0.3282259404659271, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.44963541626930237, Reg Loss=0.46055757999420166
Clinet index 23, End of Epoch 5/6, Average Loss=0.9101929664611816, Class Loss=0.44963541626930237, Reg Loss=0.46055757999420166
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/21, Loss=0.9042092144489289
Loss made of: CE 0.3985971212387085, LKD 0.4018203020095825, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.8505093216896057
Loss made of: CE 0.3465232253074646, LKD 0.4669909179210663, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4142284393310547, Reg Loss=0.45923909544944763
Clinet index 23, End of Epoch 6/6, Average Loss=0.8734675645828247, Class Loss=0.4142284393310547, Reg Loss=0.45923909544944763
Current Client Index:  1
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=2.2881448447704313
Loss made of: CE 1.6322901248931885, LKD 0.6683268547058105, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.4942436218261719, Reg Loss=0.5801507234573364
Clinet index 1, End of Epoch 1/6, Average Loss=2.0743942260742188, Class Loss=1.4942436218261719, Reg Loss=0.5801507234573364
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/19, Loss=1.4670998394489287
Loss made of: CE 0.6352725625038147, LKD 0.5022119283676147, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7621228694915771, Reg Loss=0.60222327709198
Clinet index 1, End of Epoch 2/6, Average Loss=1.3643461465835571, Class Loss=0.7621228694915771, Reg Loss=0.60222327709198
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/19, Loss=1.152633649110794
Loss made of: CE 0.6402225494384766, LKD 0.6005920767784119, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.5624908804893494, Reg Loss=0.5347644090652466
Clinet index 1, End of Epoch 3/6, Average Loss=1.0972552299499512, Class Loss=0.5624908804893494, Reg Loss=0.5347644090652466
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/19, Loss=1.0044837862253189
Loss made of: CE 0.4156001806259155, LKD 0.4745543599128723, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4531044363975525, Reg Loss=0.5235066413879395
Clinet index 1, End of Epoch 4/6, Average Loss=0.9766110777854919, Class Loss=0.4531044363975525, Reg Loss=0.5235066413879395
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/19, Loss=0.9048840582370759
Loss made of: CE 0.3632834553718567, LKD 0.5229572057723999, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3786787688732147, Reg Loss=0.5156052112579346
Clinet index 1, End of Epoch 5/6, Average Loss=0.8942840099334717, Class Loss=0.3786787688732147, Reg Loss=0.5156052112579346
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/19, Loss=0.8357117384672165
Loss made of: CE 0.2822284996509552, LKD 0.38642120361328125, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3303726017475128, Reg Loss=0.5085987448692322
Clinet index 1, End of Epoch 6/6, Average Loss=0.8389713764190674, Class Loss=0.3303726017475128, Reg Loss=0.5085987448692322
Current Client Index:  8
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=1.6907148718833924
Loss made of: CE 1.0501930713653564, LKD 0.48495543003082275, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=1.3493894279003142
Loss made of: CE 0.7359693050384521, LKD 0.5124855041503906, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=1.0307108163833618, Reg Loss=0.4352305829524994
Clinet index 8, End of Epoch 1/6, Average Loss=1.4659414291381836, Class Loss=1.0307108163833618, Reg Loss=0.4352305829524994
Pseudo labeling is: None
Epoch 2, lr = 0.000970
Epoch 2, Batch 10/24, Loss=1.1544937014579773
Loss made of: CE 0.7767118215560913, LKD 0.516423225402832, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=1.1331710785627365
Loss made of: CE 0.6210753917694092, LKD 0.41703876852989197, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.7218941450119019, Reg Loss=0.4069445729255676
Clinet index 8, End of Epoch 2/6, Average Loss=1.1288387775421143, Class Loss=0.7218941450119019, Reg Loss=0.4069445729255676
Pseudo labeling is: None
Epoch 3, lr = 0.000940
Epoch 3, Batch 10/24, Loss=1.0670046031475067
Loss made of: CE 0.6606805324554443, LKD 0.403491735458374, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.9956201285123825
Loss made of: CE 0.5977449417114258, LKD 0.3986210227012634, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.640297532081604, Reg Loss=0.3903549611568451
Clinet index 8, End of Epoch 3/6, Average Loss=1.0306525230407715, Class Loss=0.640297532081604, Reg Loss=0.3903549611568451
Pseudo labeling is: None
Epoch 4, lr = 0.000910
Epoch 4, Batch 10/24, Loss=0.9275147706270218
Loss made of: CE 0.5973663330078125, LKD 0.33380672335624695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.971140906214714
Loss made of: CE 0.5066038966178894, LKD 0.3892144560813904, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.5766074061393738, Reg Loss=0.38975656032562256
Clinet index 8, End of Epoch 4/6, Average Loss=0.9663639664649963, Class Loss=0.5766074061393738, Reg Loss=0.38975656032562256
Pseudo labeling is: None
Epoch 5, lr = 0.000879
Epoch 5, Batch 10/24, Loss=0.9087132722139358
Loss made of: CE 0.5698972940444946, LKD 0.40848487615585327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.9091611802577972
Loss made of: CE 0.5038174390792847, LKD 0.369675874710083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.5208444595336914, Reg Loss=0.3880133330821991
Clinet index 8, End of Epoch 5/6, Average Loss=0.9088578224182129, Class Loss=0.5208444595336914, Reg Loss=0.3880133330821991
Pseudo labeling is: None
Epoch 6, lr = 0.000849
Epoch 6, Batch 10/24, Loss=0.8959957182407379
Loss made of: CE 0.5003724694252014, LKD 0.46332499384880066, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.8312213331460953
Loss made of: CE 0.38129374384880066, LKD 0.37078115344047546, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.4796714782714844, Reg Loss=0.39835625886917114
Clinet index 8, End of Epoch 6/6, Average Loss=0.8780277371406555, Class Loss=0.4796714782714844, Reg Loss=0.39835625886917114
federated aggregation...
Validation, Class Loss=0.5987541675567627, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.826680
Mean Acc: 0.432762
FreqW Acc: 0.716162
Mean IoU: 0.316992
Class IoU:
	class 0: 0.86367285
	class 1: 0.6046635
	class 2: 0.16417325
	class 3: 0.17101206
	class 4: 0.35334936
	class 5: 0.1840156
	class 6: 0.62363225
	class 7: 0.68360025
	class 8: 0.45373666
	class 9: 0.030576302
	class 10: 0.017292066
	class 11: 0.2769494
	class 12: 0.3750587
	class 13: 0.3752071
	class 14: 0.6717037
	class 15: 0.73680013
	class 16: 0.07113652
	class 17: 0.0
	class 18: 0.0
	class 19: 0.000254489
	class 20: 0.0
Class Acc:
	class 0: 0.95732105
	class 1: 0.63719386
	class 2: 0.19644862
	class 3: 0.1790222
	class 4: 0.6038937
	class 5: 0.18489216
	class 6: 0.77952373
	class 7: 0.78640276
	class 8: 0.9103135
	class 9: 0.03336355
	class 10: 0.017839983
	class 11: 0.5575288
	class 12: 0.46270618
	class 13: 0.8704492
	class 14: 0.92781425
	class 15: 0.91136676
	class 16: 0.07166302
	class 17: 0.0
	class 18: 0.0
	class 19: 0.00025454574
	class 20: 0.0

federated global round: 21, step: 4
select part of clients to conduct local training
[23, 14, 4, 11]
Current Client Index:  23
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/21, Loss=1.1364510208368301
Loss made of: CE 0.5503376722335815, LKD 0.44077348709106445, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=1.091911792755127
Loss made of: CE 0.5441441535949707, LKD 0.3594234585762024, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6672885417938232, Reg Loss=0.440138041973114
Clinet index 23, End of Epoch 1/6, Average Loss=1.107426643371582, Class Loss=0.6672885417938232, Reg Loss=0.440138041973114
Pseudo labeling is: None
Epoch 2, lr = 0.000787
Epoch 2, Batch 10/21, Loss=1.0098384737968444
Loss made of: CE 0.5172416567802429, LKD 0.41914480924606323, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.8690329909324646
Loss made of: CE 0.33893173933029175, LKD 0.35846394300460815, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4902925491333008, Reg Loss=0.4482337534427643
Clinet index 23, End of Epoch 2/6, Average Loss=0.9385262727737427, Class Loss=0.4902925491333008, Reg Loss=0.4482337534427643
Pseudo labeling is: None
Epoch 3, lr = 0.000756
Epoch 3, Batch 10/21, Loss=0.9808313459157944
Loss made of: CE 0.37712806463241577, LKD 0.5483680963516235, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.8171028554439544
Loss made of: CE 0.4308006167411804, LKD 0.507246732711792, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.42296209931373596, Reg Loss=0.4724119305610657
Clinet index 23, End of Epoch 3/6, Average Loss=0.895374059677124, Class Loss=0.42296209931373596, Reg Loss=0.4724119305610657
Pseudo labeling is: None
Epoch 4, lr = 0.000725
Epoch 4, Batch 10/21, Loss=0.8753334701061248
Loss made of: CE 0.47007736563682556, LKD 0.4618455171585083, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.8275945693254471
Loss made of: CE 0.3160114288330078, LKD 0.4043172299861908, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3970731198787689, Reg Loss=0.4590934216976166
Clinet index 23, End of Epoch 4/6, Average Loss=0.8561665415763855, Class Loss=0.3970731198787689, Reg Loss=0.4590934216976166
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/21, Loss=0.8687853723764419
Loss made of: CE 0.3829813599586487, LKD 0.5285590887069702, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.8134670257568359
Loss made of: CE 0.40501007437705994, LKD 0.3184352219104767, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3696560561656952, Reg Loss=0.4683586359024048
Clinet index 23, End of Epoch 5/6, Average Loss=0.8380147218704224, Class Loss=0.3696560561656952, Reg Loss=0.4683586359024048
Pseudo labeling is: None
Epoch 6, lr = 0.000663
Epoch 6, Batch 10/21, Loss=0.8467593610286712
Loss made of: CE 0.3157588839530945, LKD 0.44265007972717285, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.784290274977684
Loss made of: CE 0.28385186195373535, LKD 0.5044706463813782, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3496417701244354, Reg Loss=0.4623914062976837
Clinet index 23, End of Epoch 6/6, Average Loss=0.8120331764221191, Class Loss=0.3496417701244354, Reg Loss=0.4623914062976837
Current Client Index:  14
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/26, Loss=1.1758653849363327
Loss made of: CE 0.642684817314148, LKD 0.44554877281188965, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=1.0687050610780715
Loss made of: CE 0.5403314828872681, LKD 0.3793815076351166, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6706898808479309, Reg Loss=0.41982725262641907
Clinet index 14, End of Epoch 1/6, Average Loss=1.0905171632766724, Class Loss=0.6706898808479309, Reg Loss=0.41982725262641907
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/26, Loss=0.9850173115730285
Loss made of: CE 0.5161891579627991, LKD 0.5028578042984009, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.9132642328739167
Loss made of: CE 0.5212283134460449, LKD 0.43924063444137573, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5092134475708008, Reg Loss=0.4342591464519501
Clinet index 14, End of Epoch 2/6, Average Loss=0.9434726238250732, Class Loss=0.5092134475708008, Reg Loss=0.4342591464519501
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/26, Loss=0.9122027665376663
Loss made of: CE 0.6111718416213989, LKD 0.374026358127594, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.8952875852584838
Loss made of: CE 0.40754565596580505, LKD 0.4511967897415161, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.46248382329940796, Reg Loss=0.4265015721321106
Clinet index 14, End of Epoch 3/6, Average Loss=0.8889853954315186, Class Loss=0.46248382329940796, Reg Loss=0.4265015721321106
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/26, Loss=0.8031247675418853
Loss made of: CE 0.4110979437828064, LKD 0.43373411893844604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.8893101990222931
Loss made of: CE 0.5077928304672241, LKD 0.45998644828796387, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.4088561236858368, Reg Loss=0.42851054668426514
Clinet index 14, End of Epoch 4/6, Average Loss=0.8373667001724243, Class Loss=0.4088561236858368, Reg Loss=0.42851054668426514
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/26, Loss=0.7839808255434036
Loss made of: CE 0.5131503343582153, LKD 0.43220698833465576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.8376459151506424
Loss made of: CE 0.4595005512237549, LKD 0.3755408227443695, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3814886808395386, Reg Loss=0.4235388934612274
Clinet index 14, End of Epoch 5/6, Average Loss=0.8050276041030884, Class Loss=0.3814886808395386, Reg Loss=0.4235388934612274
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/26, Loss=0.7747618854045868
Loss made of: CE 0.33892056345939636, LKD 0.36107540130615234, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.7820592910051346
Loss made of: CE 0.28998810052871704, LKD 0.40814146399497986, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3552374243736267, Reg Loss=0.4340135157108307
Clinet index 14, End of Epoch 6/6, Average Loss=0.7892509698867798, Class Loss=0.3552374243736267, Reg Loss=0.4340135157108307
Current Client Index:  4
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/26, Loss=1.144224974513054
Loss made of: CE 0.8779940605163574, LKD 0.5301018953323364, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=1.0832297533750535
Loss made of: CE 0.5372391939163208, LKD 0.40939855575561523, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6661763787269592, Reg Loss=0.41912418603897095
Clinet index 4, End of Epoch 1/6, Average Loss=1.0853005647659302, Class Loss=0.6661763787269592, Reg Loss=0.41912418603897095
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/26, Loss=0.9500657975673675
Loss made of: CE 0.6523127555847168, LKD 0.6594911813735962, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.9305447727441788
Loss made of: CE 0.5196607112884521, LKD 0.42662709951400757, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5119450092315674, Reg Loss=0.4304088354110718
Clinet index 4, End of Epoch 2/6, Average Loss=0.9423538446426392, Class Loss=0.5119450092315674, Reg Loss=0.4304088354110718
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/26, Loss=0.8520048499107361
Loss made of: CE 0.4072888493537903, LKD 0.4106329381465912, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.8948293596506118
Loss made of: CE 0.4432046115398407, LKD 0.4282490611076355, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.45361942052841187, Reg Loss=0.41407719254493713
Clinet index 4, End of Epoch 3/6, Average Loss=0.8676966428756714, Class Loss=0.45361942052841187, Reg Loss=0.41407719254493713
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/26, Loss=0.8597225993871689
Loss made of: CE 0.3310715854167938, LKD 0.46473145484924316, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.8030811727046967
Loss made of: CE 0.3209516108036041, LKD 0.3914739787578583, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.412619024515152, Reg Loss=0.42207610607147217
Clinet index 4, End of Epoch 4/6, Average Loss=0.8346951007843018, Class Loss=0.412619024515152, Reg Loss=0.42207610607147217
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/26, Loss=0.8329677790403366
Loss made of: CE 0.32393547892570496, LKD 0.3551707863807678, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.8085557162761688
Loss made of: CE 0.4163583219051361, LKD 0.43392419815063477, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3876422643661499, Reg Loss=0.424634724855423
Clinet index 4, End of Epoch 5/6, Average Loss=0.8122769594192505, Class Loss=0.3876422643661499, Reg Loss=0.424634724855423
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/26, Loss=0.7672295987606048
Loss made of: CE 0.34044891595840454, LKD 0.4369373023509979, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.7965817987918854
Loss made of: CE 0.3605550527572632, LKD 0.4761028289794922, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.35700473189353943, Reg Loss=0.4196029305458069
Clinet index 4, End of Epoch 6/6, Average Loss=0.7766076326370239, Class Loss=0.35700473189353943, Reg Loss=0.4196029305458069
Current Client Index:  11
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=1.1100830256938934
Loss made of: CE 0.6832919120788574, LKD 0.3647875487804413, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=1.0923936069011688
Loss made of: CE 0.7008435130119324, LKD 0.4462912976741791, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6746560335159302, Reg Loss=0.40737468004226685
Clinet index 11, End of Epoch 1/6, Average Loss=1.0820307731628418, Class Loss=0.6746560335159302, Reg Loss=0.40737468004226685
Pseudo labeling is: None
Epoch 2, lr = 0.000962
Epoch 2, Batch 10/24, Loss=0.9101737439632416
Loss made of: CE 0.617483377456665, LKD 0.39927661418914795, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.9418381839990616
Loss made of: CE 0.5245727300643921, LKD 0.4024052619934082, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.5221767425537109, Reg Loss=0.4017583131790161
Clinet index 11, End of Epoch 2/6, Average Loss=0.923935055732727, Class Loss=0.5221767425537109, Reg Loss=0.4017583131790161
Pseudo labeling is: None
Epoch 3, lr = 0.000925
Epoch 3, Batch 10/24, Loss=0.8629058390855789
Loss made of: CE 0.4868190288543701, LKD 0.4425061345100403, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.8372415691614151
Loss made of: CE 0.3896232843399048, LKD 0.3662843108177185, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.46964818239212036, Reg Loss=0.4037734270095825
Clinet index 11, End of Epoch 3/6, Average Loss=0.8734216094017029, Class Loss=0.46964818239212036, Reg Loss=0.4037734270095825
Pseudo labeling is: None
Epoch 4, lr = 0.000887
Epoch 4, Batch 10/24, Loss=0.7922503679990769
Loss made of: CE 0.39253735542297363, LKD 0.4138122797012329, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.8275726139545441
Loss made of: CE 0.4326491057872772, LKD 0.3975207209587097, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.41981542110443115, Reg Loss=0.39606595039367676
Clinet index 11, End of Epoch 4/6, Average Loss=0.8158813714981079, Class Loss=0.41981542110443115, Reg Loss=0.39606595039367676
Pseudo labeling is: None
Epoch 5, lr = 0.000849
Epoch 5, Batch 10/24, Loss=0.8103194862604142
Loss made of: CE 0.36509260535240173, LKD 0.3893447816371918, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.7895544946193696
Loss made of: CE 0.32565197348594666, LKD 0.389819473028183, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.39556318521499634, Reg Loss=0.4014074504375458
Clinet index 11, End of Epoch 5/6, Average Loss=0.7969706058502197, Class Loss=0.39556318521499634, Reg Loss=0.4014074504375458
Pseudo labeling is: None
Epoch 6, lr = 0.000810
Epoch 6, Batch 10/24, Loss=0.7456496298313141
Loss made of: CE 0.42045411467552185, LKD 0.5330856442451477, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.7778044253587723
Loss made of: CE 0.42792487144470215, LKD 0.45234858989715576, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3599805235862732, Reg Loss=0.39871928095817566
Clinet index 11, End of Epoch 6/6, Average Loss=0.7586997747421265, Class Loss=0.3599805235862732, Reg Loss=0.39871928095817566
federated aggregation...
Validation, Class Loss=0.5923311114311218, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.818257
Mean Acc: 0.459199
FreqW Acc: 0.722452
Mean IoU: 0.322086
Class IoU:
	class 0: 0.87520576
	class 1: 0.64078414
	class 2: 0.18654808
	class 3: 0.17134728
	class 4: 0.3156456
	class 5: 0.19820093
	class 6: 0.46837768
	class 7: 0.69541985
	class 8: 0.4021179
	class 9: 0.037509594
	class 10: 0.011555776
	class 11: 0.272976
	class 12: 0.23104914
	class 13: 0.3637847
	class 14: 0.7081403
	class 15: 0.7460781
	class 16: 0.04568225
	class 17: 0.0
	class 18: 0.0
	class 19: 0.21071121
	class 20: 0.18267423
Class Acc:
	class 0: 0.9428476
	class 1: 0.6823207
	class 2: 0.23733063
	class 3: 0.1814873
	class 4: 0.60518944
	class 5: 0.19977893
	class 6: 0.52378386
	class 7: 0.8056303
	class 8: 0.93396866
	class 9: 0.042775355
	class 10: 0.011866098
	class 11: 0.582888
	class 12: 0.2880628
	class 13: 0.8780056
	class 14: 0.91905177
	class 15: 0.915867
	class 16: 0.046014663
	class 17: 0.0
	class 18: 0.0
	class 19: 0.21255329
	class 20: 0.6337589

federated global round: 22, step: 4
select part of clients to conduct local training
[0, 8, 16, 14]
Current Client Index:  0
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.9192615568637847
Loss made of: CE 0.5800894498825073, LKD 0.4453968405723572, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.9254667341709137
Loss made of: CE 0.5385496616363525, LKD 0.3671071529388428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5192391276359558, Reg Loss=0.392701119184494
Clinet index 0, End of Epoch 1/6, Average Loss=0.9119402170181274, Class Loss=0.5192391276359558, Reg Loss=0.392701119184494
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/24, Loss=0.7929280072450637
Loss made of: CE 0.40119168162345886, LKD 0.33960312604904175, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.8117100805044174
Loss made of: CE 0.3692142367362976, LKD 0.35714206099510193, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4064446687698364, Reg Loss=0.3972838521003723
Clinet index 0, End of Epoch 2/6, Average Loss=0.8037285208702087, Class Loss=0.4064446687698364, Reg Loss=0.3972838521003723
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/24, Loss=0.767506268620491
Loss made of: CE 0.40197286009788513, LKD 0.47134777903556824, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.7395664334297181
Loss made of: CE 0.34621676802635193, LKD 0.4085674285888672, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.36324983835220337, Reg Loss=0.3907414376735687
Clinet index 0, End of Epoch 3/6, Average Loss=0.7539912462234497, Class Loss=0.36324983835220337, Reg Loss=0.3907414376735687
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/24, Loss=0.7366108387708664
Loss made of: CE 0.35188016295433044, LKD 0.3668912351131439, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.7311511009931564
Loss made of: CE 0.29506802558898926, LKD 0.3800179362297058, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3428550362586975, Reg Loss=0.39190489053726196
Clinet index 0, End of Epoch 4/6, Average Loss=0.7347599267959595, Class Loss=0.3428550362586975, Reg Loss=0.39190489053726196
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/24, Loss=0.7105117499828338
Loss made of: CE 0.3712625503540039, LKD 0.4103870987892151, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.733611261844635
Loss made of: CE 0.30848196148872375, LKD 0.40516242384910583, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.32247352600097656, Reg Loss=0.39510512351989746
Clinet index 0, End of Epoch 5/6, Average Loss=0.717578649520874, Class Loss=0.32247352600097656, Reg Loss=0.39510512351989746
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/24, Loss=0.6859904289245605
Loss made of: CE 0.34828776121139526, LKD 0.3861948847770691, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.7137309834361076
Loss made of: CE 0.24250172078609467, LKD 0.3807238042354584, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3071241080760956, Reg Loss=0.3906605839729309
Clinet index 0, End of Epoch 6/6, Average Loss=0.6977846622467041, Class Loss=0.3071241080760956, Reg Loss=0.3906605839729309
Current Client Index:  8
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000818
Epoch 1, Batch 10/24, Loss=1.0380595117807387
Loss made of: CE 0.5855777263641357, LKD 0.5420849323272705, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.8904579669237137
Loss made of: CE 0.392793744802475, LKD 0.45555609464645386, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5460076928138733, Reg Loss=0.40901821851730347
Clinet index 8, End of Epoch 1/6, Average Loss=0.9550259113311768, Class Loss=0.5460076928138733, Reg Loss=0.40901821851730347
Pseudo labeling is: None
Epoch 2, lr = 0.000777
Epoch 2, Batch 10/24, Loss=0.8441235095262527
Loss made of: CE 0.4440478980541229, LKD 0.48872095346450806, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.8677579790353775
Loss made of: CE 0.4012509286403656, LKD 0.40044841170310974, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4452120065689087, Reg Loss=0.39573967456817627
Clinet index 8, End of Epoch 2/6, Average Loss=0.840951681137085, Class Loss=0.4452120065689087, Reg Loss=0.39573967456817627
Pseudo labeling is: None
Epoch 3, lr = 0.000736
Epoch 3, Batch 10/24, Loss=0.8131347715854644
Loss made of: CE 0.36785122752189636, LKD 0.43296587467193604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.7452034145593643
Loss made of: CE 0.380176305770874, LKD 0.4282577633857727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.3861556649208069, Reg Loss=0.3942258358001709
Clinet index 8, End of Epoch 3/6, Average Loss=0.7803815007209778, Class Loss=0.3861556649208069, Reg Loss=0.3942258358001709
Pseudo labeling is: None
Epoch 4, lr = 0.000694
Epoch 4, Batch 10/24, Loss=0.7218378633260727
Loss made of: CE 0.4245396554470062, LKD 0.3444450795650482, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.7741558164358139
Loss made of: CE 0.3668433129787445, LKD 0.4639549255371094, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3623323142528534, Reg Loss=0.40293702483177185
Clinet index 8, End of Epoch 4/6, Average Loss=0.7652693390846252, Class Loss=0.3623323142528534, Reg Loss=0.40293702483177185
Pseudo labeling is: None
Epoch 5, lr = 0.000652
Epoch 5, Batch 10/24, Loss=0.744805496931076
Loss made of: CE 0.38293981552124023, LKD 0.38216203451156616, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.7437897980213165
Loss made of: CE 0.34393590688705444, LKD 0.4073021411895752, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3474511504173279, Reg Loss=0.39981067180633545
Clinet index 8, End of Epoch 5/6, Average Loss=0.7472618222236633, Class Loss=0.3474511504173279, Reg Loss=0.39981067180633545
Pseudo labeling is: None
Epoch 6, lr = 0.000610
Epoch 6, Batch 10/24, Loss=0.740127119421959
Loss made of: CE 0.3059927523136139, LKD 0.41488218307495117, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.7178964436054229
Loss made of: CE 0.26926061511039734, LKD 0.3845922350883484, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3375815749168396, Reg Loss=0.4047795236110687
Clinet index 8, End of Epoch 6/6, Average Loss=0.7423610687255859, Class Loss=0.3375815749168396, Reg Loss=0.4047795236110687
Current Client Index:  16
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=1.2988072484731674
Loss made of: CE 0.6938008069992065, LKD 0.47749921679496765, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.6989487409591675, Reg Loss=0.495111882686615
Clinet index 16, End of Epoch 1/6, Average Loss=1.1940605640411377, Class Loss=0.6989487409591675, Reg Loss=0.495111882686615
Pseudo labeling is: None
Epoch 2, lr = 0.000950
Epoch 2, Batch 10/19, Loss=0.9457672983407974
Loss made of: CE 0.3630062937736511, LKD 0.4609763026237488, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4164939224720001, Reg Loss=0.547902524471283
Clinet index 16, End of Epoch 2/6, Average Loss=0.9643964767456055, Class Loss=0.4164939224720001, Reg Loss=0.547902524471283
Pseudo labeling is: None
Epoch 3, lr = 0.000899
Epoch 3, Batch 10/19, Loss=0.8607300251722336
Loss made of: CE 0.3331884741783142, LKD 0.5408254265785217, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.319557785987854, Reg Loss=0.5240211486816406
Clinet index 16, End of Epoch 3/6, Average Loss=0.8435789346694946, Class Loss=0.319557785987854, Reg Loss=0.5240211486816406
Pseudo labeling is: None
Epoch 4, lr = 0.000849
Epoch 4, Batch 10/19, Loss=0.7888064175844193
Loss made of: CE 0.413185179233551, LKD 0.5486831665039062, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3023020625114441, Reg Loss=0.5047505497932434
Clinet index 16, End of Epoch 4/6, Average Loss=0.8070526123046875, Class Loss=0.3023020625114441, Reg Loss=0.5047505497932434
Pseudo labeling is: None
Epoch 5, lr = 0.000798
Epoch 5, Batch 10/19, Loss=0.7849102318286896
Loss made of: CE 0.24557358026504517, LKD 0.4396383762359619, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2936772406101227, Reg Loss=0.5210121870040894
Clinet index 16, End of Epoch 5/6, Average Loss=0.8146893978118896, Class Loss=0.2936772406101227, Reg Loss=0.5210121870040894
Pseudo labeling is: None
Epoch 6, lr = 0.000746
Epoch 6, Batch 10/19, Loss=0.7864336833357811
Loss made of: CE 0.23061053454875946, LKD 0.4367692470550537, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2728221118450165, Reg Loss=0.5121196508407593
Clinet index 16, End of Epoch 6/6, Average Loss=0.7849417924880981, Class Loss=0.2728221118450165, Reg Loss=0.5121196508407593
Current Client Index:  14
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000772
Epoch 1, Batch 10/26, Loss=0.9685460239648819
Loss made of: CE 0.4833453595638275, LKD 0.42842453718185425, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=0.8784911006689071
Loss made of: CE 0.45597681403160095, LKD 0.38394150137901306, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.48514464497566223, Reg Loss=0.418910413980484
Clinet index 14, End of Epoch 1/6, Average Loss=0.9040550589561462, Class Loss=0.48514464497566223, Reg Loss=0.418910413980484
Pseudo labeling is: None
Epoch 2, lr = 0.000733
Epoch 2, Batch 10/26, Loss=0.8383759468793869
Loss made of: CE 0.4556043744087219, LKD 0.4778604209423065, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.7880062520503998
Loss made of: CE 0.3668181896209717, LKD 0.4484274387359619, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.37988603115081787, Reg Loss=0.43512940406799316
Clinet index 14, End of Epoch 2/6, Average Loss=0.815015435218811, Class Loss=0.37988603115081787, Reg Loss=0.43512940406799316
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/26, Loss=0.7991022139787674
Loss made of: CE 0.4349011182785034, LKD 0.3705991208553314, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.7790980756282806
Loss made of: CE 0.2788384258747101, LKD 0.5076438188552856, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.34618350863456726, Reg Loss=0.4289969801902771
Clinet index 14, End of Epoch 3/6, Average Loss=0.775180459022522, Class Loss=0.34618350863456726, Reg Loss=0.4289969801902771
Pseudo labeling is: None
Epoch 4, lr = 0.000655
Epoch 4, Batch 10/26, Loss=0.7291575968265533
Loss made of: CE 0.3062676191329956, LKD 0.4157583713531494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.7854811996221542
Loss made of: CE 0.3747488856315613, LKD 0.45996469259262085, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3220159709453583, Reg Loss=0.4300573468208313
Clinet index 14, End of Epoch 4/6, Average Loss=0.7520732879638672, Class Loss=0.3220159709453583, Reg Loss=0.4300573468208313
Pseudo labeling is: None
Epoch 5, lr = 0.000616
Epoch 5, Batch 10/26, Loss=0.7187601268291474
Loss made of: CE 0.4212888181209564, LKD 0.4151451587677002, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.7806388214230537
Loss made of: CE 0.3559706211090088, LKD 0.3933391273021698, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3123561441898346, Reg Loss=0.43256598711013794
Clinet index 14, End of Epoch 5/6, Average Loss=0.7449221611022949, Class Loss=0.3123561441898346, Reg Loss=0.43256598711013794
Pseudo labeling is: None
Epoch 6, lr = 0.000576
Epoch 6, Batch 10/26, Loss=0.7069033950567245
Loss made of: CE 0.3044136166572571, LKD 0.3499242067337036, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.7225042134523392
Loss made of: CE 0.23800432682037354, LKD 0.38349002599716187, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3010866641998291, Reg Loss=0.4323946237564087
Clinet index 14, End of Epoch 6/6, Average Loss=0.7334812879562378, Class Loss=0.3010866641998291, Reg Loss=0.4323946237564087
federated aggregation...
Validation, Class Loss=0.5692888498306274, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.828019
Mean Acc: 0.487789
FreqW Acc: 0.734183
Mean IoU: 0.354359
Class IoU:
	class 0: 0.87795925
	class 1: 0.64139783
	class 2: 0.20768073
	class 3: 0.20176508
	class 4: 0.33290315
	class 5: 0.17537253
	class 6: 0.61571234
	class 7: 0.71095365
	class 8: 0.39792266
	class 9: 0.040556613
	class 10: 0.0140855
	class 11: 0.2672557
	class 12: 0.24560535
	class 13: 0.38416895
	class 14: 0.7166052
	class 15: 0.7309944
	class 16: 0.02197281
	class 17: 0.017988287
	class 18: 0.13686025
	class 19: 0.37049025
	class 20: 0.3332975
Class Acc:
	class 0: 0.93981785
	class 1: 0.6737354
	class 2: 0.27284652
	class 3: 0.21478437
	class 4: 0.61474526
	class 5: 0.17628227
	class 6: 0.67890644
	class 7: 0.8007784
	class 8: 0.93711835
	class 9: 0.045923017
	class 10: 0.014242184
	class 11: 0.57140094
	class 12: 0.29716745
	class 13: 0.8430598
	class 14: 0.9102159
	class 15: 0.92726
	class 16: 0.022078704
	class 17: 0.01841462
	class 18: 0.17005569
	class 19: 0.49833614
	class 20: 0.6164112

federated global round: 23, step: 4
select part of clients to conduct local training
[12, 10, 9, 6]
Current Client Index:  12
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/26, Loss=0.8920818626880646
Loss made of: CE 0.3447524309158325, LKD 0.3312164545059204, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/26, Loss=0.8859876096248627
Loss made of: CE 0.2814730107784271, LKD 0.4228358268737793, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.43558844923973083, Reg Loss=0.43789157271385193
Clinet index 12, End of Epoch 1/6, Average Loss=0.8734800219535828, Class Loss=0.43558844923973083, Reg Loss=0.43789157271385193
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/26, Loss=0.7927688032388687
Loss made of: CE 0.4285892844200134, LKD 0.4391920268535614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/26, Loss=0.7699547111988068
Loss made of: CE 0.2582714557647705, LKD 0.4017121195793152, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.34009066224098206, Reg Loss=0.444519579410553
Clinet index 12, End of Epoch 2/6, Average Loss=0.7846102714538574, Class Loss=0.34009066224098206, Reg Loss=0.444519579410553
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/26, Loss=0.7810943514108658
Loss made of: CE 0.25779446959495544, LKD 0.4926900863647461, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/26, Loss=0.7471655964851379
Loss made of: CE 0.2785814702510834, LKD 0.4256839156150818, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.31929683685302734, Reg Loss=0.4471137225627899
Clinet index 12, End of Epoch 3/6, Average Loss=0.7664105892181396, Class Loss=0.31929683685302734, Reg Loss=0.4471137225627899
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/26, Loss=0.7440278843045235
Loss made of: CE 0.3737594485282898, LKD 0.4905437231063843, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/26, Loss=0.7281864434480667
Loss made of: CE 0.26678699254989624, LKD 0.467115581035614, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2916266918182373, Reg Loss=0.44310006499290466
Clinet index 12, End of Epoch 4/6, Average Loss=0.7347267866134644, Class Loss=0.2916266918182373, Reg Loss=0.44310006499290466
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/26, Loss=0.7364370569586753
Loss made of: CE 0.25858432054519653, LKD 0.46210166811943054, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/26, Loss=0.7115326389670372
Loss made of: CE 0.3079429566860199, LKD 0.4039636552333832, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.28005450963974, Reg Loss=0.4499056339263916
Clinet index 12, End of Epoch 5/6, Average Loss=0.7299601435661316, Class Loss=0.28005450963974, Reg Loss=0.4499056339263916
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/26, Loss=0.7022218227386474
Loss made of: CE 0.24372564256191254, LKD 0.3835490643978119, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/26, Loss=0.7404808104038239
Loss made of: CE 0.24536290764808655, LKD 0.4727630615234375, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2693318724632263, Reg Loss=0.4479660391807556
Clinet index 12, End of Epoch 6/6, Average Loss=0.7172979116439819, Class Loss=0.2693318724632263, Reg Loss=0.4479660391807556
Current Client Index:  10
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=1.2675569236278534
Loss made of: CE 0.6891851425170898, LKD 0.48053011298179626, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.7226834893226624, Reg Loss=0.45782390236854553
Clinet index 10, End of Epoch 1/6, Average Loss=1.1805074214935303, Class Loss=0.7226834893226624, Reg Loss=0.45782390236854553
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/19, Loss=0.962614220380783
Loss made of: CE 0.37454748153686523, LKD 0.33792781829833984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4917411804199219, Reg Loss=0.4750310480594635
Clinet index 10, End of Epoch 2/6, Average Loss=0.966772198677063, Class Loss=0.4917411804199219, Reg Loss=0.4750310480594635
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/19, Loss=0.8462222784757614
Loss made of: CE 0.37921008467674255, LKD 0.4990505576133728, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.41007640957832336, Reg Loss=0.47374358773231506
Clinet index 10, End of Epoch 3/6, Average Loss=0.8838199973106384, Class Loss=0.41007640957832336, Reg Loss=0.47374358773231506
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/19, Loss=0.8391455233097076
Loss made of: CE 0.40094733238220215, LKD 0.5455188751220703, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3565831482410431, Reg Loss=0.4688724875450134
Clinet index 10, End of Epoch 4/6, Average Loss=0.8254556655883789, Class Loss=0.3565831482410431, Reg Loss=0.4688724875450134
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/19, Loss=0.8174398273229599
Loss made of: CE 0.33348536491394043, LKD 0.42583340406417847, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.355461448431015, Reg Loss=0.4601728022098541
Clinet index 10, End of Epoch 5/6, Average Loss=0.8156342506408691, Class Loss=0.355461448431015, Reg Loss=0.4601728022098541
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/19, Loss=0.7902265399694443
Loss made of: CE 0.37048953771591187, LKD 0.448373407125473, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3385492265224457, Reg Loss=0.46672946214675903
Clinet index 10, End of Epoch 6/6, Average Loss=0.8052786588668823, Class Loss=0.3385492265224457, Reg Loss=0.46672946214675903
Current Client Index:  9
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/21, Loss=0.9577466189861298
Loss made of: CE 0.5292783379554749, LKD 0.549965500831604, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=0.8582717508077622
Loss made of: CE 0.34875354170799255, LKD 0.4398888051509857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.45454326272010803, Reg Loss=0.45531079173088074
Clinet index 9, End of Epoch 1/6, Average Loss=0.9098540544509888, Class Loss=0.45454326272010803, Reg Loss=0.45531079173088074
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/21, Loss=0.8332773894071579
Loss made of: CE 0.31277140974998474, LKD 0.48945221304893494, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.7868934541940689
Loss made of: CE 0.2828059494495392, LKD 0.508664608001709, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.32623231410980225, Reg Loss=0.4810069501399994
Clinet index 9, End of Epoch 2/6, Average Loss=0.807239294052124, Class Loss=0.32623231410980225, Reg Loss=0.4810069501399994
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/21, Loss=0.8139500260353089
Loss made of: CE 0.33333081007003784, LKD 0.41513508558273315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.7684112131595612
Loss made of: CE 0.3068210482597351, LKD 0.495429128408432, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.30856817960739136, Reg Loss=0.47668445110321045
Clinet index 9, End of Epoch 3/6, Average Loss=0.7852526307106018, Class Loss=0.30856817960739136, Reg Loss=0.47668445110321045
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/21, Loss=0.7385740041732788
Loss made of: CE 0.30410224199295044, LKD 0.5245605707168579, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.7560249328613281
Loss made of: CE 0.25747257471084595, LKD 0.5110751390457153, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.28310710191726685, Reg Loss=0.4732656478881836
Clinet index 9, End of Epoch 4/6, Average Loss=0.7563727498054504, Class Loss=0.28310710191726685, Reg Loss=0.4732656478881836
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/21, Loss=0.7503047123551368
Loss made of: CE 0.19301210343837738, LKD 0.4302946925163269, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.7415013328194618
Loss made of: CE 0.22294466197490692, LKD 0.4610917568206787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.27009961009025574, Reg Loss=0.4703425168991089
Clinet index 9, End of Epoch 5/6, Average Loss=0.740442156791687, Class Loss=0.27009961009025574, Reg Loss=0.4703425168991089
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/21, Loss=0.7164857223629951
Loss made of: CE 0.23449718952178955, LKD 0.4257880449295044, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.7724918648600578
Loss made of: CE 0.22985081374645233, LKD 0.37852582335472107, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2608563005924225, Reg Loss=0.4779967963695526
Clinet index 9, End of Epoch 6/6, Average Loss=0.7388530969619751, Class Loss=0.2608563005924225, Reg Loss=0.4779967963695526
Current Client Index:  6
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.8804524064064025
Loss made of: CE 0.4275026023387909, LKD 0.38515448570251465, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.7965107023715973
Loss made of: CE 0.41170817613601685, LKD 0.3232651352882385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.43500375747680664, Reg Loss=0.3907533586025238
Clinet index 6, End of Epoch 1/6, Average Loss=0.8257571458816528, Class Loss=0.43500375747680664, Reg Loss=0.3907533586025238
Pseudo labeling is: None
Epoch 2, lr = 0.000925
Epoch 2, Batch 10/24, Loss=0.7600582331418991
Loss made of: CE 0.3503434360027313, LKD 0.41260838508605957, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.7073599457740783
Loss made of: CE 0.34237122535705566, LKD 0.3822646737098694, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.35176461935043335, Reg Loss=0.39636123180389404
Clinet index 6, End of Epoch 2/6, Average Loss=0.7481258511543274, Class Loss=0.35176461935043335, Reg Loss=0.39636123180389404
Pseudo labeling is: None
Epoch 3, lr = 0.000849
Epoch 3, Batch 10/24, Loss=0.696507814526558
Loss made of: CE 0.27157220244407654, LKD 0.3680689334869385, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.7466362714767456
Loss made of: CE 0.3173602521419525, LKD 0.5010738372802734, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.32627880573272705, Reg Loss=0.39917975664138794
Clinet index 6, End of Epoch 3/6, Average Loss=0.725458562374115, Class Loss=0.32627880573272705, Reg Loss=0.39917975664138794
Pseudo labeling is: None
Epoch 4, lr = 0.000772
Epoch 4, Batch 10/24, Loss=0.6950679421424866
Loss made of: CE 0.30086901783943176, LKD 0.42228174209594727, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.7130868405103683
Loss made of: CE 0.3640012741088867, LKD 0.39322715997695923, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3147152066230774, Reg Loss=0.39287471771240234
Clinet index 6, End of Epoch 4/6, Average Loss=0.7075899243354797, Class Loss=0.3147152066230774, Reg Loss=0.39287471771240234
Pseudo labeling is: None
Epoch 5, lr = 0.000694
Epoch 5, Batch 10/24, Loss=0.7113444834947587
Loss made of: CE 0.40901893377304077, LKD 0.3584860563278198, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.6610740587115288
Loss made of: CE 0.24670329689979553, LKD 0.3840633034706116, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.29907482862472534, Reg Loss=0.3901982307434082
Clinet index 6, End of Epoch 5/6, Average Loss=0.6892730593681335, Class Loss=0.29907482862472534, Reg Loss=0.3901982307434082
Pseudo labeling is: None
Epoch 6, lr = 0.000616
Epoch 6, Batch 10/24, Loss=0.7116905212402344
Loss made of: CE 0.30905455350875854, LKD 0.3963852822780609, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.6513664960861206
Loss made of: CE 0.26489055156707764, LKD 0.37933093309402466, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2846091389656067, Reg Loss=0.39457187056541443
Clinet index 6, End of Epoch 6/6, Average Loss=0.6791809797286987, Class Loss=0.2846091389656067, Reg Loss=0.39457187056541443
federated aggregation...
Validation, Class Loss=0.5772245526313782, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.823171
Mean Acc: 0.518652
FreqW Acc: 0.736388
Mean IoU: 0.364888
Class IoU:
	class 0: 0.8767961
	class 1: 0.61027765
	class 2: 0.22945838
	class 3: 0.19269733
	class 4: 0.2922513
	class 5: 0.13712417
	class 6: 0.55749166
	class 7: 0.70601535
	class 8: 0.40621382
	class 9: 0.048936676
	class 10: 0.011282424
	class 11: 0.28207198
	class 12: 0.2531901
	class 13: 0.43941414
	class 14: 0.70907736
	class 15: 0.7328452
	class 16: 0.03751426
	class 17: 0.17278048
	class 18: 0.32392436
	class 19: 0.3767753
	class 20: 0.26650658
Class Acc:
	class 0: 0.9237864
	class 1: 0.6334761
	class 2: 0.32619306
	class 3: 0.20346683
	class 4: 0.62116504
	class 5: 0.13752507
	class 6: 0.6230131
	class 7: 0.7859752
	class 8: 0.9370103
	class 9: 0.055172812
	class 10: 0.011315415
	class 11: 0.63777834
	class 12: 0.30542663
	class 13: 0.6563008
	class 14: 0.9094652
	class 15: 0.9298625
	class 16: 0.037767775
	class 17: 0.38160044
	class 18: 0.56678885
	class 19: 0.45078635
	class 20: 0.7578132

federated global round: 24, step: 4
select part of clients to conduct local training
[18, 24, 25, 10]
Current Client Index:  18
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/19, Loss=0.9899203598499298
Loss made of: CE 0.49317309260368347, LKD 0.42831525206565857, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.523736834526062, Reg Loss=0.4319060146808624
Clinet index 18, End of Epoch 1/6, Average Loss=0.955642819404602, Class Loss=0.523736834526062, Reg Loss=0.4319060146808624
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/19, Loss=0.8837662667036057
Loss made of: CE 0.4251633584499359, LKD 0.46044573187828064, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3925798237323761, Reg Loss=0.45393672585487366
Clinet index 18, End of Epoch 2/6, Average Loss=0.8465165495872498, Class Loss=0.3925798237323761, Reg Loss=0.45393672585487366
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/19, Loss=0.8438253790140152
Loss made of: CE 0.42415285110473633, LKD 0.6163093447685242, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.34523245692253113, Reg Loss=0.4510417878627777
Clinet index 18, End of Epoch 3/6, Average Loss=0.7962742447853088, Class Loss=0.34523245692253113, Reg Loss=0.4510417878627777
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/19, Loss=0.797175920009613
Loss made of: CE 0.29837557673454285, LKD 0.4260253310203552, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3320813477039337, Reg Loss=0.4497743844985962
Clinet index 18, End of Epoch 4/6, Average Loss=0.7818557024002075, Class Loss=0.3320813477039337, Reg Loss=0.4497743844985962
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/19, Loss=0.8210490882396698
Loss made of: CE 0.2759271562099457, LKD 0.3460569977760315, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.32529205083847046, Reg Loss=0.45046114921569824
Clinet index 18, End of Epoch 5/6, Average Loss=0.7757532000541687, Class Loss=0.32529205083847046, Reg Loss=0.45046114921569824
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/19, Loss=0.7931544661521912
Loss made of: CE 0.3612113893032074, LKD 0.4773859679698944, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3142336905002594, Reg Loss=0.4543445408344269
Clinet index 18, End of Epoch 6/6, Average Loss=0.7685782313346863, Class Loss=0.3142336905002594, Reg Loss=0.4543445408344269
Current Client Index:  24
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/21, Loss=0.8458867311477661
Loss made of: CE 0.27967917919158936, LKD 0.36972343921661377, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/21, Loss=0.8433786332607269
Loss made of: CE 0.3888343274593353, LKD 0.523597776889801, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3714084327220917, Reg Loss=0.46364715695381165
Clinet index 24, End of Epoch 1/6, Average Loss=0.8350555896759033, Class Loss=0.3714084327220917, Reg Loss=0.46364715695381165
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/21, Loss=0.7574260517954826
Loss made of: CE 0.26146596670150757, LKD 0.5336183309555054, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/21, Loss=0.8076000988483429
Loss made of: CE 0.46433448791503906, LKD 0.5728856921195984, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3016989827156067, Reg Loss=0.4797523617744446
Clinet index 24, End of Epoch 2/6, Average Loss=0.7814513444900513, Class Loss=0.3016989827156067, Reg Loss=0.4797523617744446
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/21, Loss=0.7178382262587547
Loss made of: CE 0.3481537699699402, LKD 0.5130992531776428, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/21, Loss=0.7935467690229416
Loss made of: CE 0.2500298023223877, LKD 0.43732011318206787, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.2787927985191345, Reg Loss=0.48014143109321594
Clinet index 24, End of Epoch 3/6, Average Loss=0.7589342594146729, Class Loss=0.2787927985191345, Reg Loss=0.48014143109321594
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/21, Loss=0.7739698871970176
Loss made of: CE 0.32092973589897156, LKD 0.5816206932067871, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/21, Loss=0.6904598399996758
Loss made of: CE 0.2770198583602905, LKD 0.5167787075042725, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.2624182105064392, Reg Loss=0.4851655662059784
Clinet index 24, End of Epoch 4/6, Average Loss=0.7475837469100952, Class Loss=0.2624182105064392, Reg Loss=0.4851655662059784
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/21, Loss=0.7369172513484955
Loss made of: CE 0.20456986129283905, LKD 0.3571816384792328, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/21, Loss=0.7554781407117843
Loss made of: CE 0.2581666111946106, LKD 0.6838433146476746, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2651107609272003, Reg Loss=0.4842178225517273
Clinet index 24, End of Epoch 5/6, Average Loss=0.74932861328125, Class Loss=0.2651107609272003, Reg Loss=0.4842178225517273
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/21, Loss=0.7817724347114563
Loss made of: CE 0.32294362783432007, LKD 0.628591775894165, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/21, Loss=0.7073063150048255
Loss made of: CE 0.2549791634082794, LKD 0.44941920042037964, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.2609391510486603, Reg Loss=0.4786628484725952
Clinet index 24, End of Epoch 6/6, Average Loss=0.7396019697189331, Class Loss=0.2609391510486603, Reg Loss=0.4786628484725952
Current Client Index:  25
Filtering images...
	0/10582 ...
	1000/10582 ...
	2000/10582 ...
	3000/10582 ...
	4000/10582 ...
	5000/10582 ...
	6000/10582 ...
	7000/10582 ...
	8000/10582 ...
	9000/10582 ...
	10000/10582 ...
load old model
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.001000
Epoch 1, Batch 10/24, Loss=0.7909347504377365
Loss made of: CE 0.41791248321533203, LKD 0.4931666851043701, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Batch 20/24, Loss=0.7622243940830231
Loss made of: CE 0.37845224142074585, LKD 0.3969744145870209, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.3708121180534363, Reg Loss=0.4080837368965149
Clinet index 25, End of Epoch 1/6, Average Loss=0.7788958549499512, Class Loss=0.3708121180534363, Reg Loss=0.4080837368965149
Pseudo labeling is: None
Epoch 2, lr = 0.000849
Epoch 2, Batch 10/24, Loss=0.7609203815460205
Loss made of: CE 0.3937591016292572, LKD 0.5108685493469238, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Batch 20/24, Loss=0.7115852415561676
Loss made of: CE 0.3050457239151001, LKD 0.4486587643623352, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.3288746178150177, Reg Loss=0.40845024585723877
Clinet index 25, End of Epoch 2/6, Average Loss=0.7373248338699341, Class Loss=0.3288746178150177, Reg Loss=0.40845024585723877
Pseudo labeling is: None
Epoch 3, lr = 0.000694
Epoch 3, Batch 10/24, Loss=0.7033380031585693
Loss made of: CE 0.30980199575424194, LKD 0.3462013006210327, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Batch 20/24, Loss=0.7414847403764725
Loss made of: CE 0.23028337955474854, LKD 0.3798747956752777, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.30327168107032776, Reg Loss=0.41408559679985046
Clinet index 25, End of Epoch 3/6, Average Loss=0.7173572778701782, Class Loss=0.30327168107032776, Reg Loss=0.41408559679985046
Pseudo labeling is: None
Epoch 4, lr = 0.000536
Epoch 4, Batch 10/24, Loss=0.7203740656375885
Loss made of: CE 0.34290632605552673, LKD 0.45048660039901733, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Batch 20/24, Loss=0.6912140041589737
Loss made of: CE 0.32771316170692444, LKD 0.4832955002784729, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3014768362045288, Reg Loss=0.4137035012245178
Clinet index 25, End of Epoch 4/6, Average Loss=0.7151803374290466, Class Loss=0.3014768362045288, Reg Loss=0.4137035012245178
Pseudo labeling is: None
Epoch 5, lr = 0.000372
Epoch 5, Batch 10/24, Loss=0.6951566278934479
Loss made of: CE 0.3007257282733917, LKD 0.45515960454940796, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Batch 20/24, Loss=0.7135411396622657
Loss made of: CE 0.3446464240550995, LKD 0.5051271319389343, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.2909783720970154, Reg Loss=0.40814968943595886
Clinet index 25, End of Epoch 5/6, Average Loss=0.6991280317306519, Class Loss=0.2909783720970154, Reg Loss=0.40814968943595886
Pseudo labeling is: None
Epoch 6, lr = 0.000199
Epoch 6, Batch 10/24, Loss=0.6942550227046013
Loss made of: CE 0.31434595584869385, LKD 0.5051065683364868, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Batch 20/24, Loss=0.6901779919862747
Loss made of: CE 0.29340919852256775, LKD 0.4246809184551239, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.28950291872024536, Reg Loss=0.40745314955711365
Clinet index 25, End of Epoch 6/6, Average Loss=0.6969560384750366, Class Loss=0.28950291872024536, Reg Loss=0.40745314955711365
Current Client Index:  10
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Pseudo labeling is: None
Epoch 1, lr = 0.000536
Epoch 1, Batch 10/19, Loss=1.082588681578636
Loss made of: CE 0.5556833148002625, LKD 0.4777413606643677, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 1, Class Loss=0.5796532034873962, Reg Loss=0.44859322905540466
Clinet index 10, End of Epoch 1/6, Average Loss=1.0282464027404785, Class Loss=0.5796532034873962, Reg Loss=0.44859322905540466
Pseudo labeling is: None
Epoch 2, lr = 0.000455
Epoch 2, Batch 10/19, Loss=0.933033236861229
Loss made of: CE 0.34008288383483887, LKD 0.33481884002685547, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 2, Class Loss=0.4712333679199219, Reg Loss=0.46341681480407715
Clinet index 10, End of Epoch 2/6, Average Loss=0.934650182723999, Class Loss=0.4712333679199219, Reg Loss=0.46341681480407715
Pseudo labeling is: None
Epoch 3, lr = 0.000372
Epoch 3, Batch 10/19, Loss=0.8322713077068329
Loss made of: CE 0.40841609239578247, LKD 0.4925573468208313, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 3, Class Loss=0.4217969477176666, Reg Loss=0.4785028398036957
Clinet index 10, End of Epoch 3/6, Average Loss=0.9002997875213623, Class Loss=0.4217969477176666, Reg Loss=0.4785028398036957
Pseudo labeling is: None
Epoch 4, lr = 0.000287
Epoch 4, Batch 10/19, Loss=0.8546475261449814
Loss made of: CE 0.4446909427642822, LKD 0.5511981248855591, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 4, Class Loss=0.3788995146751404, Reg Loss=0.46761903166770935
Clinet index 10, End of Epoch 4/6, Average Loss=0.8465185165405273, Class Loss=0.3788995146751404, Reg Loss=0.46761903166770935
Pseudo labeling is: None
Epoch 5, lr = 0.000199
Epoch 5, Batch 10/19, Loss=0.8447854697704316
Loss made of: CE 0.385532021522522, LKD 0.42225122451782227, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 5, Class Loss=0.3817916810512543, Reg Loss=0.4726913869380951
Clinet index 10, End of Epoch 5/6, Average Loss=0.8544830679893494, Class Loss=0.3817916810512543, Reg Loss=0.4726913869380951
Pseudo labeling is: None
Epoch 6, lr = 0.000107
Epoch 6, Batch 10/19, Loss=0.8283956497907639
Loss made of: CE 0.36757588386535645, LKD 0.4386865496635437, LDE 0.0, LReg 0.0, POD 0.0 EntMin 0.0
Epoch 6, Class Loss=0.3688303828239441, Reg Loss=0.464587926864624
Clinet index 10, End of Epoch 6/6, Average Loss=0.8334183096885681, Class Loss=0.3688303828239441, Reg Loss=0.464587926864624
federated aggregation...
/data/zhangdz/CVPR2023/FISS/metrics/stream_metrics.py:132: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
Validation, Class Loss=0.6151161193847656, Reg Loss=0.0 (without scaling)

Total samples: 1449.000000
Overall Acc: 0.806411
Mean Acc: 0.496132
FreqW Acc: 0.720845
Mean IoU: 0.330492
Class IoU:
	class 0: 0.8672586
	class 1: 0.5088478
	class 2: 0.23009928
	class 3: 0.17705569
	class 4: 0.24973246
	class 5: 0.08884427
	class 6: 0.41251227
	class 7: 0.67095035
	class 8: 0.47936562
	class 9: 0.04468815
	class 10: 0.0006713349
	class 11: 0.29120055
	class 12: 0.26930776
	class 13: 0.21708784
	class 14: 0.69794
	class 15: 0.7319831
	class 16: 0.030650353
	class 17: 0.17915215
	class 18: 0.30261952
	class 19: 0.2921875
	class 20: 0.19818415
Class Acc:
	class 0: 0.9140895
	class 1: 0.52305406
	class 2: 0.33516073
	class 3: 0.18712525
	class 4: 0.60672945
	class 5: 0.08891851
	class 6: 0.4646784
	class 7: 0.7191854
	class 8: 0.91945803
	class 9: 0.049015712
	class 10: 0.0006716178
	class 11: 0.664696
	class 12: 0.30608457
	class 13: 0.22920808
	class 14: 0.9018916
	class 15: 0.9251407
	class 16: 0.030983085
	class 17: 0.77660644
	class 18: 0.6724406
	class 19: 0.31165433
	class 20: 0.7919783

voc_4-4_MiB On GPUs 0
Run in 46577s
